{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import digits\n",
    "import acquire\n",
    "import prepare\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rc('figure', figsize=(8, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63, 2), (21, 2), (21, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = acquire.get_urls()\n",
    "df = acquire.get_readme_articles(urls=urls, cached=True)\n",
    "df = prepare.clean_data(df)\n",
    "train, validate, test = prepare.train_validate_test(df)\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>text_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>javascript</td>\n",
       "      <td>weight agnostic neural network repo contains s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>javascript</td>\n",
       "      <td>github button showcase github repos success st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>javascript</td>\n",
       "      <td>webpack cs example example repo showing automa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>javascript</td>\n",
       "      <td>ionicsite repo ionicframeworkcom site preview ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>python</td>\n",
       "      <td>ironpython development ha moved httpsgithubcom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>javascript</td>\n",
       "      <td>analytics reporter lightweight system publishi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>python</td>\n",
       "      <td>dash user contributed docsets report bug reque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>javascript</td>\n",
       "      <td>simple demonstration get basic understanding k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>python</td>\n",
       "      <td>note repo going updated anymore tensorflow ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>python</td>\n",
       "      <td>topstarreddevsandrepostofollow topstarred pyth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        language                                      text_filtered\n",
       "102  javascript   weight agnostic neural network repo contains s...\n",
       "14   javascript   github button showcase github repos success st...\n",
       "97   javascript   webpack cs example example repo showing automa...\n",
       "87   javascript   ionicsite repo ionicframeworkcom site preview ...\n",
       "35       python   ironpython development ha moved httpsgithubcom...\n",
       "..           ...                                                ...\n",
       "84   javascript   analytics reporter lightweight system publishi...\n",
       "27       python   dash user contributed docsets report bug reque...\n",
       "23   javascript   simple demonstration get basic understanding k...\n",
       "58       python   note repo going updated anymore tensorflow ver...\n",
       "62       python   topstarreddevsandrepostofollow topstarred pyth...\n",
       "\n",
       "[63 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_json('project_readme.json')\n",
    "df\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the most common words in READMEs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "javascript     58\n",
       "python         47\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of all the white spaces\n",
    "df.language=df.language.apply(lambda x:x.strip())\n",
    "train.language=df.language.apply(lambda x:x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "javascript_words = ' '.join(train[train.language=='javascript'].text_filtered)\n",
    "python_words = ' '.join(train[train.language=='python'].text_filtered)\n",
    "\n",
    "all_words = ' '.join(train.text_filtered)\n",
    "\n",
    "javascript_words = re.sub(r'\\s.\\s', '', javascript_words)\n",
    "python_words = re.sub(r'\\s.\\s', '', python_words)\n",
    "\n",
    "all_words = re.sub(r'\\s.\\s', '', all_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "git      127\n",
       "use      123\n",
       "model    108\n",
       "file      96\n",
       "code      87\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming to a panda series\n",
    "javascript_freq = pd.Series(javascript_words.split()).value_counts()\n",
    "python_freq = pd.Series(python_words.split()).value_counts()\n",
    "all_freq = pd.Series(all_words.split()).value_counts()\n",
    "\n",
    "python_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>javascript</th>\n",
       "      <th>python</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&amp;#9;</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000aux</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        javascript  python  all\n",
       "&#9;             0       1    1\n",
       "00               2       0    2\n",
       "000              2       0    2\n",
       "0001             0       1    1\n",
       "000aux           1       0    1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = (pd.concat([javascript_freq, python_freq, all_freq], axis=1, sort=True)\n",
    "               .set_axis(['javascript', 'python', 'all'], axis=1, inplace=False)\n",
    "               .fillna(0)\n",
    "               .apply(lambda s: s.astype(int))\n",
    "              )\n",
    "\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "git       127\n",
       "use       123\n",
       "model     108\n",
       "file       96\n",
       "code       87\n",
       "layer      86\n",
       "using      84\n",
       "python     82\n",
       "run        74\n",
       "also       69\n",
       "Name: python, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.sort_values(by='all', ascending=False).head(10)\n",
    "\n",
    "word_counts.python.sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pod           434\n",
       "label         136\n",
       "container     132\n",
       "file          130\n",
       "node          125\n",
       "run           117\n",
       "kubectl       110\n",
       "kubernetes    107\n",
       "running       106\n",
       "name          106\n",
       "Name: javascript, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.javascript.sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>javascript</th>\n",
       "      <th>python</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pod</th>\n",
       "      <td>434</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>130</td>\n",
       "      <td>96</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>99</td>\n",
       "      <td>123</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <td>117</td>\n",
       "      <td>74</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>using</th>\n",
       "      <td>96</td>\n",
       "      <td>84</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>106</td>\n",
       "      <td>50</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>98</td>\n",
       "      <td>47</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>136</td>\n",
       "      <td>6</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>git</th>\n",
       "      <td>12</td>\n",
       "      <td>127</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>command</th>\n",
       "      <td>73</td>\n",
       "      <td>65</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         javascript  python  all\n",
       "pod             434       0  434\n",
       "file            130      96  226\n",
       "use              99     123  222\n",
       "run             117      74  191\n",
       "using            96      84  180\n",
       "name            106      50  156\n",
       "see              98      47  145\n",
       "label           136       6  142\n",
       "git              12     127  139\n",
       "command          73      65  138"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.sort_values(by='all', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does the distribution of IDFs look like for the most common words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "      <th>augmented_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pod</th>\n",
       "      <td>434</td>\n",
       "      <td>0.023733</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>136</td>\n",
       "      <td>0.007437</td>\n",
       "      <td>0.313364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>container</th>\n",
       "      <td>132</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>0.304147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>130</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>0.299539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <td>125</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>0.288018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipfsobjectpatchaddlinkmultihash</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rpm</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rcused</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poolsize</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4205 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 raw_count  frequency  augmented_frequency\n",
       "pod                                    434   0.023733             1.000000\n",
       "label                                  136   0.007437             0.313364\n",
       "container                              132   0.007218             0.304147\n",
       "file                                   130   0.007109             0.299539\n",
       "node                                   125   0.006835             0.288018\n",
       "...                                    ...        ...                  ...\n",
       "direct                                   1   0.000055             0.002304\n",
       "ipfsobjectpatchaddlinkmultihash          1   0.000055             0.002304\n",
       "rpm                                      1   0.000055             0.002304\n",
       "rcused                                   1   0.000055             0.002304\n",
       "poolsize                                 1   0.000055             0.002304\n",
       "\n",
       "[4205 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = javascript_words#'Mary had a little lamb, a little lamb, a little lamb.'\n",
    "\n",
    "# clean up the text\n",
    "document = document.lower().replace(',', '').replace('.', '')\n",
    "# transform into a series\n",
    "words = pd.Series(document.split())\n",
    "\n",
    "# From the Series we can extract the value_counts, which is our raw count\n",
    "# for term frequency. Once we have the raw counts, we can calculate the\n",
    "# other measures.\n",
    "(pd.DataFrame({'raw_count': words.value_counts()})\n",
    " .assign(frequency=lambda df: df.raw_count / df.raw_count.sum())\n",
    " .assign(augmented_frequency=lambda df: df.frequency / df.frequency.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "      <th>augmented_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>git</th>\n",
       "      <td>127</td>\n",
       "      <td>0.008270</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>123</td>\n",
       "      <td>0.008009</td>\n",
       "      <td>0.968504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>108</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>0.850394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>96</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.755906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <td>87</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>0.685039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itaisod</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tensorflowpytorch</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfisstopword</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>git2240</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19th</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4516 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   raw_count  frequency  augmented_frequency\n",
       "git                      127   0.008270             1.000000\n",
       "use                      123   0.008009             0.968504\n",
       "model                    108   0.007033             0.850394\n",
       "file                      96   0.006251             0.755906\n",
       "code                      87   0.005665             0.685039\n",
       "...                      ...        ...                  ...\n",
       "itaisod                    1   0.000065             0.007874\n",
       "tensorflowpytorch          1   0.000065             0.007874\n",
       "dfisstopword               1   0.000065             0.007874\n",
       "git2240                    1   0.000065             0.007874\n",
       "19th                       1   0.000065             0.007874\n",
       "\n",
       "[4516 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = python_words#'Mary had a little lamb, a little lamb, a little lamb.'\n",
    "\n",
    "# clean up the text\n",
    "document = document.lower().replace(',', '').replace('.', '')\n",
    "# transform into a series\n",
    "words = pd.Series(document.split())\n",
    "\n",
    "# From the Series we can extract the value_counts, which is our raw count\n",
    "# for term frequency. Once we have the raw counts, we can calculate the\n",
    "# other measures.\n",
    "(pd.DataFrame({'raw_count': words.value_counts()})\n",
    " .assign(frequency=lambda df: df.raw_count / df.raw_count.sum())\n",
    " .assign(augmented_frequency=lambda df: df.frequency / df.frequency.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "      <th>augmented_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pod</th>\n",
       "      <td>434</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>226</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>0.520737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>222</td>\n",
       "      <td>0.006599</td>\n",
       "      <td>0.511521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <td>191</td>\n",
       "      <td>0.005677</td>\n",
       "      <td>0.440092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>using</th>\n",
       "      <td>180</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>0.414747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dnaeon</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kubernetesdashboard</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>composition</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorprone</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cprofileprofile</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7351 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     raw_count  frequency  augmented_frequency\n",
       "pod                        434   0.012900             1.000000\n",
       "file                       226   0.006717             0.520737\n",
       "use                        222   0.006599             0.511521\n",
       "run                        191   0.005677             0.440092\n",
       "using                      180   0.005350             0.414747\n",
       "...                        ...        ...                  ...\n",
       "dnaeon                       1   0.000030             0.002304\n",
       "kubernetesdashboard          1   0.000030             0.002304\n",
       "composition                  1   0.000030             0.002304\n",
       "errorprone                   1   0.000030             0.002304\n",
       "cprofileprofile              1   0.000030             0.002304\n",
       "\n",
       "[7351 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = all_words#'Mary had a little lamb, a little lamb, a little lamb.'\n",
    "\n",
    "# clean up the text\n",
    "document = document.lower().replace(',', '').replace('.', '')\n",
    "# transform into a series\n",
    "words = pd.Series(document.split())\n",
    "\n",
    "# From the Series we can extract the value_counts, which is our raw count\n",
    "# for term frequency. Once we have the raw counts, we can calculate the\n",
    "# other measures.\n",
    "(pd.DataFrame({'raw_count': words.value_counts()})\n",
    " .assign(frequency=lambda df: df.raw_count / df.raw_count.sum())\n",
    " .assign(augmented_frequency=lambda df: df.frequency / df.frequency.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idf - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdocs = dict(train[train.language=='javascript'].text_filtered)\n",
    "pydocs = dict(train[train.language=='python'].text_filtered)\n",
    "\n",
    "#def Merge(jdocs, pydocs): \n",
    "#    res = jdocs | pydocs\n",
    "#    return res\n",
    "\n",
    "langs = {**jdocs,**pydocs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lego</th>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kubiadmdck</th>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>altogether</th>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appkubia2</th>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spun</th>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             idf\n",
       "word            \n",
       "lego        63.0\n",
       "kubiadmdck  63.0\n",
       "altogether  63.0\n",
       "appkubia2   63.0\n",
       "spun        63.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = langs\n",
    "#jdocs = dict(train[train.language=='javascript'].text_filtered)\n",
    "\n",
    "def idf(word):\n",
    "    n_occurences = sum([1 for doc in documents.values() if word in doc])\n",
    "    return len(documents) / n_occurences\n",
    "\n",
    "# Get a list of the unique words\n",
    "unique_words = pd.Series(' '.join(documents.values()).split()).unique()\n",
    "\n",
    "# put the unique words into a data frame\n",
    "(pd.DataFrame(dict(word=unique_words))\n",
    " # calculate the idf for each word\n",
    " .assign(idf=lambda train: train.word.apply(idf))\n",
    " # sort the data for presentation purposes\n",
    " .set_index('word')\n",
    " .sort_values(by='idf', ascending=False)\n",
    " .head(5))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#documents = df[df.language=='javascript'].text_lemmatized\n",
    "pydocs = dict(train[train.language=='python'].text_filtered)\n",
    "\n",
    "def idf(word):\n",
    "    n_occurences = sum([1 for doc in pydocs.values() if word in doc])\n",
    "    return len(pydocs) / n_occurences\n",
    "\n",
    "# Get a list of the unique words\n",
    "unique_words = pd.Series(' '.join(pydocs.values()).split()).unique()\n",
    "\n",
    "# put the unique words into a data frame\n",
    "(pd.DataFrame(dict(word=unique_words))\n",
    " # calculate the idf for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # sort the data for presentation purposes\n",
    " .set_index('word')\n",
    " .sort_values(by='idf', ascending=False)\n",
    " .head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does the length of the README vary by programming language?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>text_filtered</th>\n",
       "      <th>doc_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>javascript</td>\n",
       "      <td>weight agnostic neural network repo contains s...</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>javascript</td>\n",
       "      <td>github button showcase github repos success st...</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>javascript</td>\n",
       "      <td>webpack cs example example repo showing automa...</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>javascript</td>\n",
       "      <td>ionicsite repo ionicframeworkcom site preview ...</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>python</td>\n",
       "      <td>ironpython development ha moved httpsgithubcom...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>javascript</td>\n",
       "      <td>analytics reporter lightweight system publishi...</td>\n",
       "      <td>6557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>python</td>\n",
       "      <td>dash user contributed docsets report bug reque...</td>\n",
       "      <td>1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>javascript</td>\n",
       "      <td>simple demonstration get basic understanding k...</td>\n",
       "      <td>61828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>python</td>\n",
       "      <td>note repo going updated anymore tensorflow ver...</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>python</td>\n",
       "      <td>topstarreddevsandrepostofollow topstarred pyth...</td>\n",
       "      <td>7283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       language                                      text_filtered  doc_length\n",
       "102  javascript  weight agnostic neural network repo contains s...         758\n",
       "14   javascript  github button showcase github repos success st...         906\n",
       "97   javascript  webpack cs example example repo showing automa...         437\n",
       "87   javascript  ionicsite repo ionicframeworkcom site preview ...         812\n",
       "35       python  ironpython development ha moved httpsgithubcom...          70\n",
       "..          ...                                                ...         ...\n",
       "84   javascript  analytics reporter lightweight system publishi...        6557\n",
       "27       python  dash user contributed docsets report bug reque...        1269\n",
       "23   javascript  simple demonstration get basic understanding k...       61828\n",
       "58       python  note repo going updated anymore tensorflow ver...         266\n",
       "62       python  topstarreddevsandrepostofollow topstarred pyth...        7283\n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['doc_length'] = [len(wordlist) for wordlist in train.text_filtered]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avergage word count in python coded READMEs is: 4211.827586206897 words\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4211.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4526.964996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1269.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2332.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5452.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18714.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         doc_length\n",
       "count     29.000000\n",
       "mean    4211.827586\n",
       "std     4526.964996\n",
       "min       70.000000\n",
       "25%     1269.000000\n",
       "50%     2332.000000\n",
       "75%     5452.000000\n",
       "max    18714.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The avergage word count in python coded READMEs is:', train[train.language=='python'].doc_length.mean(), 'words')\n",
    "train[train.language=='python'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avergage word count in javascript coded READMEs is: 4319.941176470588 words\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4319.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10715.050429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>470.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1160.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3223.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61828.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         doc_length\n",
       "count     34.000000\n",
       "mean    4319.941176\n",
       "std    10715.050429\n",
       "min       37.000000\n",
       "25%      470.750000\n",
       "50%     1160.500000\n",
       "75%     3223.750000\n",
       "max    61828.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The avergage word count in javascript coded READMEs is:', train[train.language=='javascript'].doc_length.mean(), 'words')\n",
    "train[train.language=='javascript'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do different programming languages use a different number of unique words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd5e10d6d10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 936x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the percentage of the term in ham vs. spam\n",
    "plt.figure(figsize = (13,7))\n",
    "(word_counts.assign(p_javascript = word_counts.javascript/word_counts['all'], \n",
    "                   p_python = word_counts.python/word_counts['all'])\n",
    "                   \n",
    " .sort_values(by='all')[['p_javascript', 'p_python']]\n",
    " .tail(20)\n",
    " .sort_values('p_javascript')\n",
    " .plot.barh(stacked=True)\n",
    ")\n",
    "\n",
    "plt.title(\"Proportion of readme words\")\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>javascript</th>\n",
       "      <th>python</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pod</th>\n",
       "      <td>434</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>136</td>\n",
       "      <td>6</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>container</th>\n",
       "      <td>132</td>\n",
       "      <td>5</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>130</td>\n",
       "      <td>96</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <td>125</td>\n",
       "      <td>5</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <td>117</td>\n",
       "      <td>74</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kubectl</th>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kubernetes</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running</th>\n",
       "      <td>106</td>\n",
       "      <td>19</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>106</td>\n",
       "      <td>50</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            javascript  python  all\n",
       "pod                434       0  434\n",
       "label              136       6  142\n",
       "container          132       5  137\n",
       "file               130      96  226\n",
       "node               125       5  130\n",
       "run                117      74  191\n",
       "kubectl            110       0  110\n",
       "kubernetes         107       1  108\n",
       "running            106      19  125\n",
       "name               106      50  156"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.sort_values(by='javascript', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>javascript</th>\n",
       "      <th>python</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>git</th>\n",
       "      <td>12</td>\n",
       "      <td>127</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>99</td>\n",
       "      <td>123</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>130</td>\n",
       "      <td>96</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <td>47</td>\n",
       "      <td>87</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer</th>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>using</th>\n",
       "      <td>96</td>\n",
       "      <td>84</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>14</td>\n",
       "      <td>82</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <td>117</td>\n",
       "      <td>74</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also</th>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        javascript  python  all\n",
       "git             12     127  139\n",
       "use             99     123  222\n",
       "model            0     108  108\n",
       "file           130      96  226\n",
       "code            47      87  134\n",
       "layer            1      86   87\n",
       "using           96      84  180\n",
       "python          14      82   96\n",
       "run            117      74  191\n",
       "also            65      69  134"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.sort_values(by='python', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['add',\n",
       " 'build',\n",
       " 'change',\n",
       " 'check',\n",
       " 'code',\n",
       " 'create',\n",
       " 'data',\n",
       " 'dont',\n",
       " 'example',\n",
       " 'feature',\n",
       " 'file',\n",
       " 'following',\n",
       " 'ha',\n",
       " 'install',\n",
       " 'issue',\n",
       " 'library',\n",
       " 'license',\n",
       " 'like',\n",
       " 'make',\n",
       " 'need',\n",
       " 'new',\n",
       " 'note',\n",
       " 'open',\n",
       " 'project',\n",
       " 'repo',\n",
       " 'repository',\n",
       " 'request',\n",
       " 'run',\n",
       " 'set',\n",
       " 'source',\n",
       " 'support',\n",
       " 'time',\n",
       " 'use',\n",
       " 'used',\n",
       " 'user',\n",
       " 'using',\n",
       " 'version',\n",
       " 'want',\n",
       " 'way',\n",
       " 'work']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create CountVectorizer, which create bag-of-words model.\n",
    "# stop_words : Specify language to remove stopwords. \n",
    "# min_df: ignore terms that have a document frequency strictly \n",
    "# lower than the given threshold. This value is also called cut-off in the literature. \n",
    "# If float, the parameter represents a proportion of documents, integer absolute counts. \n",
    "# ngram_range: the lower and upper boundary of the range of n-values for \n",
    "# different word n-grams or char n-grams to be extracted. \n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', \n",
    "                             min_df=20, \n",
    "                             ngram_range=(1,2), \n",
    "                             binary=True)\n",
    "\n",
    "# Learn vocabulary in sentences. \n",
    "vectorizer.fit(train.text_filtered)\n",
    "\n",
    "# Get dictionary. \n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform each sentences in vector space.\n",
    "bow = vectorizer.transform(train.text_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is just to see the array of 0's and 1's\n",
    "bow_array = bow.toarray()\n",
    "bow_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight agnostic neural network repo contains source article want view page locally run python httpserver serve base directory view indexhtml local browser article draftmd main text article markdown draftappendixmd appendix markdown draftbibhtml citation draftheaderhtml start document indexhtml generated dont edit file instruction build test git clone httpsgithubcomweightagnosticweightagnosticgithubiogit cd weightagnosticgithubio npm install modify text editing draftmd content exists appendix content go draftappendixmd add bib entry draftbibhtml run binmake build document indexhtml identical run python httpserver serve base directory view indexhtml local browser debugging watch markdown file change compile run following brew install fswatch binwatch\n",
      "[1 1 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0]\n",
      "github button showcase github repos success static button featuring link github repo profile page uptodate watch fork sponsor follower count get started checkout httpsghbtnscom bug tracker bug please create issue github httpsgithubcommdogithubbuttonsissues development clone project install dependency getting started github button require nodejs ruby bundler local development npm bundle github button source code split across three file srcthe html cs j use inlinesourcecli htmlminifer include compiled docsgithubbtnhtml file build file npm run build httpsghbtnscom site built jekyll installing dependency run local server bundle exec jekyll serve open http1270014000 browse locally see also ntkmegithubbuttons twitter account keep date announcement following mark twitter mdo author mark otto httpstwittercommdo httpsgithubcommdo copyright license copyright 20142020 mark otto released apache 20 license\n",
      "[0 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0]\n",
      "webpack cs example example repo showing automatically generate cs bundle explicitly required sas source webpack read blog post running yarn install npm install yarn run build npm run build take look generated cs build contributing please adhere existing code style javascript doesnt comply standard cause build fail issue pull request code contribution must comply contributor code conduct license webpack cs example released mit license\n",
      "[0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "ionicsite repo ionicframeworkcom site preview local ionic change follow instruction ionic repo doc ionic doc separate repo site primarily used general communication promotion ionic framework related product service local build run npm install run npm start first run step needed third party library 3rd part library concatenated site bundle adding via packagejson specifying file include assets3rdpartylibsjson file deploy change master automatically deployed stagingionicframeworkcom periodically ionic tean inspect staging promote ionicframeworkcom community follow ionicframework twitter subscribe ionic newsletter question thats feature request bug report discus ionic forum read blog feature request find bug submit issue see problem documentation submit issue see typo browser bug nondocs page submit issue\n",
      "[0 1 1 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0]\n",
      "ironpython development ha moved httpsgithubcomironlanguagesironpython2\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "python code data science code nlp deep learning reinforcement learning artificial intelligence welcome github repo data scientist code r python wolfram mathematica find machine learning deep learning natural language processing artificial intelligence model developed output model seen portfolio httpsdrivegooglecomfiled0b0rlknml54khdjrqwvbketvxshmviewuspsharing kera version used model keras110 autoencoder audio model compressed audio file used autoencoder reconstruct audio file use phoneme classification collaborative filtering recommender system algorithm predicts movie review based genre movie similarity among people watched movie convolutional nn lasagne convolutional neural network model lasagne solve mnist task ensembled machine learning py file 7 machine learning algorithm used classification task 3 class possible hyperparameters algorithm adjusted iris dataset scikitlearn gan generative adversarial model generative adversarial neural network hyperparameter tuning rl model hyperparameters neural network adjusted via reinforcement learning according reward hyperparameter tuning environment changed policy mechanization knowledge using boston dataset hyperparameters tuned learning rate epoch decay momentum number hidden layer node initial weight kera regularization l2 neural network model regression made kera l2 regularization wa applied prevent overfitting lasagne neural net regression neural network model based theano lasagne make linear regression continuous target variable reach 994 accuracy us dadosteselogitcsv sample file lasagne neural net weight neural network model based theano lasagne possible visualize weight x1 x2 hidden layer also adapted visualize weight hidden layer output us dadosteselogitcsv sample file multinomial regression regression model target variable ha 3 class neural network regression show multiple solution regression problem solved sklearn kera theano lasagne us boston dataset sample file sklearn reach 98 accuracy nlp naive bayes classifier model movie review labeled positive negative algorithm classifies totally new set review using logistic regression decision tree naive bayes reaching accuracy 92 nlp anger analysis doc2vec model associated word2vec model analyze level anger using synonym consumer complaint u retailer facebook post nlp consumer complaint model facebook post u computer retailer scraped tokenized lemmatized applied word2vec tsne latent dirichlet allocation developed order classify argument weight keyword used consumer complaint code also analyzes frequency word 100 post nlp convolutional neural network convolutional neural network text order classify movie review nlp doc2vec natural language procesing file cosine similarity among phrase measured doc2vec nlp document classification code document classification according latent dirichlet allocation nlp facebook analysis analyzes facebook post regarding word frequency topic modelling using lda nlp facebook scrap python code scraping data facebook nlp latent dirichlet allocation natural language processing model wikipedia page statistical inference classified regarding topic using latent dirichlet allocation gensim nltk tsne kmeans nlp probabilistic ann natural language processing model sentence vectorized gensim probabilistic neural network model deveoped using gensim sentiment analysis nlp semantic doc2vec neural network model positive negative movie review extracted semantically classified nltk beautifulsoup labeled positive negative text wa used input neural network model training training new sentence entered kera neural network model classified us zip file nlp sentiment positive model identifies website content positive neutral negative using beautifulsoup nltk library plotting result nlp twitter analysis id model extract post twitter based id user hashtag nlp twitter scrap model scrap twitter data show cleaned text output nlp twitter streaming model analysis realtime data twitter development nlp twitter streaming mood model evolution mood twitter post measured period time nlp wikipedia summarization python code summarizes given page sentence nlp word frequency model calculates frequency noun verb word facebook post probabilistic neural network probabilistic neural network time series prediction realtime twitter analysis model twitter streaming extracted word sentence tokenized word embeddings created topic modeling wa made classified using kmeans nltk sentimentanalyzer wa used classify sentence streaming positive neutral negative accumulated sum wa used generate plot code loop 1 second collecting new tweet resnet2 deep residual neural network roc curve multiclass py file naive bayes wa used solve iris dataset task roc curve different class plotted squeezenet simplified version alexnet stacked machine learning py notebook tsne principal component analysis factor analysis applied reduce dimensionality data classification performance measured applying kmeans support vector regression svm model non linear regression artificial dataset texttospeech py file python speaks given text save audio wav file time series arima arima model forecast time series error margin 02 time series prediction neural network kera neural network model forecast time series using kera adaptive learning rate depending upon derivative loss variational autoencoder vae made kera web crawler code scrap data different url hotel website tsne dimensionality reduction tsne model dimensionality reduction compared principal component analysis regarding discriminatory power tsne pca neural network model compare performance neural network made tsne pca kmeans tsne pca lda embeddings model tsne principal component analysis linear discriminant analysis random forest embeddings compared task classify cluster similar digit\n",
      "[0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1 1 1\n",
      " 0 0 0]\n",
      "gitbanner generates git repo show cool banner github profile gitbanner work creating new git repository filling dummy commits date set correspond pixel github contribution graph see example iamtrasks profile httpsgithubcomiamtrask installing first might need install dependency nodecanvas cairo nodegit set npm install g gitbanner usage 1 generate repo gitbanner github email text notice gitbanner need email associated github account otherwise github wont think made commits see preview banner doesnt look great try using different font gitbanner f 7pt arial email text 2 create repo github 3 push repo github cd banner git push f gitgithubcomusernamereponamegit master note ever feel like removing banner profile simply delete repository github instantly update contribution graph want specify longer banner width gitbanner w x width longer 52 cut github banner slowly revealed week go\n",
      "[0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0\n",
      " 1 0 1]\n",
      "heroku repo plugin plugin add command heroku gem interact apps repo installation install heroku pluginsinstall herokurepo command clone heroku repoclone appname clone application repo local filesystem collaboration necessary download heroku repodownload appname download application repo tarball gc heroku repogc appname run git gc aggressive application repo done inside run process application purgecache heroku repopurgecache appname delete content build cache stored repository done inside run process application reset heroku reporeset appname empty remote repository\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "deeplift deep learning important feature version deeplift ha tested kera 224 tensorflow 1140 see faq question information implementation deeplift may work different version tensorflowpytorch well wider range architecture see tag older version repository implement method learning important feature propagating activation difference shrikumar greenside kundaje well commonlyused method gradient gradienttimesinput equivalent version layerwise relevance propagation relu network guided backprop integrated gradient link slide video 15minute talk given icml link longer series video tutorial please see faq file github issue question note running deeplift certain computer vision task may get better result compute contribution score higher convolutional layer rather input pixel use argument findscoreslayeridx specify layer compute score please aware figuring optimal reference still open problem suggestion good heuristic different application welcome meantime feel free look github issue general idea httpsgithubcomkundajelabdeepliftissues104 please feel free follow repository stay abreast update table content installation quickstart example faq provide brief intuition deeplift work model architecture supported deeplift implementation similarity difference deepliftlike implementation deepexplain ancona et al iclr 2018 deepshapdeepexplainer shap repository doe deeplift compare integrated gradient doe implementation repository compare deeplift implementation poerner et al acl 2018 support nonkeras model negative score mean provide reference argument use reference get sense much input contributes across example multiple input mode get contribution score multiple input layer whats license heard deeplift pattern discovery right contact hood layer forward pas backward pas installation deeplift pypi installed using pip pip install deeplift want able make edits code recommended clone repository install using editable flag git clone httpsgithubcomkundajelabdeepliftgit clone deeplift repository pip install editable deeplift install deeplift cloned repository editable flag mean change code picked automatically deeplift doe require model trained particular library provided autoconversion function convert model trained using kera deeplift format used different library train model still use deeplift recreate model using deeplift layer implementation deeplift wa tested tensorflow 17 autoconversion wa tested using kera 20 quickstart example show autoconvert kera model obtain importance score nonkeras model converted deeplift saved kera 20 format convert kera sequential model import deeplift deepliftconversion import kerasapiconversion kc nonlinearmxtsmode defines method computing importance score nonlinearmxtsmodedeepliftgenomicsdefault us revealcancel rule dense layer rescale rule conv layer see paper rationale supported value nonlinearmxtsmoderevealcancel deepliftrevealcancel layer used mnist example nonlinearmxtsmoderescale deepliftrescale layer nonlinearmxtsmodegradient multiplier gradient nonlinearmxtsmodeguidedbackprop multiplier get guided backprop use deepliftutilgetintegratedgradientsfunction compute integrated gradient feel free email avanti dot shrikumargmailcom anything unclear deepliftmodel kcconvertmodelfromsavedfiles savedhdf5filepath nonlinearmxtsmodedeepliftlayersnonlinearmxtsmodedeepliftgenomicsdefault specify index layer compute importance score example find score input layer idx 0 deepliftmodelgetlayers findscoreslayeridx 0 compile function computes contribution score sigmoid softmax output targetlayeridx 2 default computes explanation wrt logits see 36 choice target layer httpsarxivorgabs170402685 justification regression task linear output targetlayeridx 1 simply refers last layer note case softmax output may good idea normalize softmax logits sum zero across task ensures feature contributing equally softmax logits effectly seen contributing none task adding constant logits softmax doe change output discussed httpsgithubcomkundajelabdeepliftissues116 one way efficiently acheive normalization meannormalize weight going softmax layer discussed eqn 21 section 25 httpsarxivorgpdf160501713pdf note softmax activation want deeplift multiplier instead contribution score use gettargetmultipliersfunc deepliftcontribsfunc deepliftmodelgettargetcontribsfunc findscoreslayeridxfindscoreslayeridx targetlayeridx1 also provide array index findscoreslayeridx get score multiple layer compute score input inputdatalist list containing data different input layer eg mnist one input layer dimension 1 x 28 x 28 example let x array dimension n x 1 x 28 x 28 n number example taskidx represents index node output layer wish compute score eg output 10way softmax taskidx 0 compute score first softmax class score nparraydeepliftcontribsfunctaskidx0 inputdatalistx batchsize10 progressupdate1000 work sequential model involving dense andor conv1dconv2d layer linearrelusigmoidsoftmax prelu activation please create github issue email avanti dot shrikumargmailcom readme interested support layer type syntax using functional model similar use deepliftmodelgetnametolayerkeys get list layer name figuring specify findscoreslayername preactivationtargetlayername deepliftmodel kcconvertmodelfromsavedfiles savedhdf5filepath nonlinearmxtsmodedeepliftlayersnonlinearmxtsmodedeepliftgenomicsdefault syntax obtaining score similar converted graph model see deepliftmodelgetnametolayerkeys see layer name provide array name findscoreslayername get score multiple layer deepliftcontribsfunc deepliftmodelgettargetcontribsfunc findscoreslayernamenameofinputlayer preactivationtargetlayernamenamegoeshere example notebook replicating result paper mnist examplesmnistmnistreplicatefiguresipynb notebook demonstrating use genomics model 1d convolution examplesgenomicsgenomicssimulationipynb faq provide brief intuition deeplift work 15minute talk icml give intuition method link slide video video truncates slide slide linked separately please file github issue question model architecture supported deeplift implementation first suggestion would look deepshapdeepexplainer lundberg lee deepexplain ancona et al captum using pytorch see satisfy need implemented overriding gradient operator thus support wider variety architecture however none implementation support revealcancel rule deal failure mode min function pro con deepshap v deepexplain discussed detail would really like revealcancel rule go ahead post github issue although energy currently focused project may able get time similarity difference deepliftlike implementation deepexplain ancona et al iclr 2018 deepshapdeepexplainer shap repository deepexplain ancona et al deepshapdeepexplainer work overriding gradient operator thus support wider variety architecture covered deeplift repo fact deepshapdeepexplainer implementation wa inspired ancona et al work build connection deeplift shap described shap paper set architecture described deeplift paper ie linear matrix multiplication convolution singleinput nonlinearities like relus implementation identical deeplift rescale rule however neither implementation support deeplift revealcancel rule rule wa developed deal failure case min function unfortunately easily implemented overriding gradient operator key difference follows 1 deepexplain us standard gradient backpropagation elementwise operation present lstmsgrusattention likely violate summationtodelta property ie property sum attribution input equal differencefromreference output elementwise operation recommend use deepshapdeepexplainer employ summationtodeltapreserving backprop rule technically true maxpooling operation nonuniform reference used though ha salient problem u practice deepshapdeepexplainer implementation guarantee summationtodelta satisfied maxpooling assigning creditblame either neuron max actual input neuron wa max reference different max attribution rule proposed shap paper attribution rule doe scale well 2 deepexplain ancona et al doe support dynamic reference demonstrated deeplift repo ie case different reference generated according property input example dinucleotide shuffled reference used genomics ive implemented dynamic reference feature deepshapdeepexplainer associated example notebook warning process generating dinucleotide shuffled sequence many application bottleneck running interpretation getting poor gpu usage may get around may good idea cache pregenerated shuffled sequence particular gc content retrieve example cache according gc content input sequence 3 deepshapdeepexplainer implemented multiple reference used single example final attribution averaged reference however way implemented gpu batch calculates attribution single example reference mean deepshapdeepexplainer implementation might slow case large number sample one reference contrast deepexplain ancona et al structured user provides single reference reference used example thus deepexplain ancona et al allows gpu batching across example doe allow gpu batching across different reference summary recommendation use deepshap elementwise operation eg gruslstmsattention need dynamic reference large number reference compared sample use deepexplain large number sample compared reference doe implementation repository compare deeplift implementation poerner et al acl 2018 poerner et al conducted series benchmark comparing deeplift explanation method nlp task implementation differs canonical deeplift implementation two main way first considered rescale rule deeplift according implementation second handle operation involve multiplication gating unit deeplift wa designed treat gating neuron weight similar approach arras et al assign importance nongating neuron note differs implementation deepshapdeepexplainer handle elementwise multiplication using backprop rule base shap would assign importance gating neuron studied appropriateness arras et al approach author find limsse lrp bach et al 2015 deeplift shrikumar et al 2017 effective explanation method 4 lrp deeplift consistent method limsse win hybrid document experiment compare deepshapdeepexplainer implementation doe deeplift compare integrated gradient illustrated deeplift paper revealcancel rule deeplift allow deeplift properly handle case integrated gradient may give misleading result independent researcher found deeplift rescale rule performs comparably integrated gradient write integrated gradient deeplift high correlation suggesting latter good faster approximation former practice finding wa consistent personal experience speed improvement deeplift relative integrated gradient becomes particularly useful using collection reference since collection reference per example increase runtime support nonkeras model moment however able convert model saved file format used kera 2 api use branch load deeplift format inspiration achieve look examplesconvertmodelskeras12to2 notebook demonstrating convert model saved keras12 format kera 2 deeplift conversion work directly kera saved file without ever actually loading model kera pytorch model may also interested captum implementation negative score mean negative contribution score input mean input contributed moving output reference value reference value output value ha provided reference input negative contribution doe mean input unimportant want find input deeplift considers unimportant ie deeplift think dont influence output model much would input contribution score near 0 provide reference argument supply inputdatalist argument scoring function also supply inputreferenceslist would dimension inputdatalist would contain reference image input use reference choice reference depends question wish ask data generally speaking reference retain property dont care scramble property care supplement deeplift paper appendix l look result cifar10 model two different choice reference youll notice blurred version input used reference outline object stand black reference used result confusing possibly net also highlighting color particular reference mind good idea check output model reference consistent expect another idea consider using multiple different reference interpret single image averaging result different reference use approach genomics generate collection reference per input sequence shuffling sequence demonstrated genomics example notebook get sense much input contributes across example fine average deeplift contribution score across example aware might considerable heterogeneity data ie input may important subset example others input may contribute positively example negatively others clustering may prove insightful averaging purpose feature selection reasonable heuristic would rank input descending order average magnitude deeplift contribution score multiple input mode yes rather providing single numpy array inputdatalist provide list numpy array containing input mode also provide dictionary inputdatalist key mode name value numpy array numpy array first axis sample axis get contribution score multiple input layer also yes provide list findscoreslayername rather single argument whats license mit license originally filed patent interpretability work since disbanded patent appears project ha enough interest community best distributed opensource format heard deeplift pattern discovery right likely thinking tfmodisco link code contact please email avanti dot shrikumar gmailcom question idea feature request etc dont respond keep emailing feel guilty respond also feel free email adviser anshul kundaje dot net guilt responding promise actually want respond im busy thing incentive structure academia doesnt reward maintenance project hood section explains finer aspect deeplift implementation layer layer deepliftlayerscorelayer basic unit deepliftlayerscoredense deepliftlayersconvolutionconv2d example layer layer implement following key method getactivationvars return symbolic variable representing activation layer understanding symbolic variable refer documentation symbolic computation package like theano tensorflow getposmxts getnegmxts return symbolic variable representing positivenegative multiplier layer selected output see paper detail gettargetcontribvars return symbolic variable representing importance score convenience function return selfgetposmxtsselfposcontribs selfgetnegmxtsselfnegcontribs see paper detail forward pas step necessary implement forward pas executed correctly result identical within numerical precision forward pas original model definitely worth sanity check note autoconversion described quickstart option skip step 1 2 create layer object every layer network tell layer input via setinputs function argument setinputs depends layer expects layer ha single layer input eg dense layer argument simply layer input layer take multiple layer input argument depends specific implementation example case concat layer argument list layer every layer linked input may compile forward propagation function deepliftbackendfunctioninputlayergetactivationvars outputlayergetactivationvars working model produced autoconversion access individual layer via modelgetlayers sequential model function would return list layer modelgetnametolayer graph model function would return dictionary mapping layer name layer first argument list symbolic tensor representing input net net ha one input layer list containing one tensor second argument output function example single tensor also list tensor want output one layer function compiled use deepliftutilrunfunctioninbatchesfunc inputdatalist run function batch would advisable want call function large number input wont fit memory func simply compiled function returned deepliftbackendfunction inputdatalist list numpy array containing data different input layer network case network one input list containing one numpy array optional argument runfunctioninbatches batchsize progressupdate backward pas step necessary implement backward pas importance score calculated ideally create model autoconversion described quickstart use modelgettargetcontribsfunc modelgettargetmultipliersfunc howver option read please also consider sending u message let u know enough demand feature consider adding note instruction assume done step 1 2 forward pas section layer wish compute importance score call resetmxtsupdated reset symbolic variable computing multiplier first time compiling backward pas step strictly necessary output layer containing neuron importance score calculated respect call setscoringmodedeepliftlayersscoringmodeoneandzeros briefly scoring mode used want find score respect single target neuron kind scoring mode may added later eg difference neuron point clarification eventually compile function function computes score single output neuron single layer every time called specific neuron layer toggled later runtime right step call setscoringmode target layer might conceivably want find score respect save recompile function allow different target layer later sigmoidsoftmax output layer output layer use linear layer usually dense layer come final nonlinear activation see 36 choice target layer paper justification final nonlinearity eg case many regression task output layer last linear layer softmax output may want subtract average contribution softmax class described adjustment softmax layer paper section 36 number softmax class large dont want calculate contribution class separately example contact avanti dot shrikumargmailcom implement efficient way calculation way havent coded yet layer wish compute importance score call updatemxts create symbolic variable compute multiplier respect layer specified step 2 compile importance score computation function deepliftbackendfunctioninputlayergetactivationvars inputlayergetreferencevars layertofindscoresforgettargetcontribvars first argument represents input function list one symbolic tensor activation input layer forward pas followed list one symbolic tensor reference input layer second argument represents output function example single tensor containing importance score single layer also list tensor wish compute score multiple layer instead gettargetcontribvars return importance score case nonlinearmxtsmodedeeplift called contribution score use getposmxts getnegmxts get multiplier ready call function find importance score select specific output layer compute importance score respect calling setactive layer select specific target neuron within layer calling updatetaskindextaskidx layer taskidx index neuron within layer call function compiled step 4 find importance score target neuron refer step 4 forward pas section tip using deepliftutilrunfunctioninbatches deselect output layer calling setinactive layer dont forget yes bundle single function point\n",
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1]\n",
      "headset attention headset longer us shared youtube api key please create key following quick guide make sure running latest version headset simple music player mac window linux integrated youtube search home screen popularity list genre era best radio powered reddit headset take song shared 80 music subreddits categorizes play automatically great pretty unique way find new music chosen human like algorithm question join slack workspace httpstinyurlcomy7m8y5x4 want start contributing check contributing doc installation macos homebrew update homebrew install headset using hombrew cask brew update brew cask install headset window chocolatey install run following command command line powershell c choco install headset upgrade run following command command line powershell c choco upgrade headset detail chocolatey page httpschocolateyorgpackagesheadset linux alternative deb rpm package website also install directly commandline debian wget q httpheadsetappcoheadsetelectrondebianheadsetasc sudo aptkey add echo deb archamd64 httpheadsetappcoheadsetelectrondebian stable nonfree sudo tee etcaptsourceslistdheadsetlist sudo aptget update sudo aptget install headset redhat sudo dnf configmanager addrepo httpheadsetappcoheadsetelectronredhatheadsetrepo sudo dnf install headset sudo yumconfigmanager addrepo httpheadsetappcoheadsetelectronredhatheadsetrepo sudo yum install headset build source would like create build different environment eg manjaro aur etc please follow step install nodejs 8 later clone repo git clone httpsgithubcomheadsetappheadsetelectrongit install dependency cd headsetelectron npm ci create build electronpackager executablename headset ignore binsigghpagesplayertestprocfilemd prune true build overwrite asar platformlinux archx64 optional ubuntu build using electroninstallerdebian fedora build using electroninstallerredhat might installer specific version google contributor app design helene giraud wwwgirographecom\n",
      "[1 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 1\n",
      " 1 1 0]\n",
      "sqlalchemy python sql toolkit object relational mapper introduction sqlalchemy python sql toolkit object relational mapper give application developer full power flexibility sql sqlalchemy provides full suite well known enterpriselevel persistence pattern designed efficient highperforming database access adapted simple pythonic domain language major sqlalchemy feature include industrial strength orm built core identity map unit work data mapper pattern pattern allow transparent persistence object using declarative configuration system domain model constructed manipulated naturally change synchronized current transaction automatically relationallyoriented query system exposing full range sqls capability explicitly including join subqueries correlation everything else term object model writing query orm us technique relational composition use writing sql drop literal sql time virtually never needed comprehensive flexible system eager loading related collection object collection cached within session loaded individual access using join query per collection across full result set core sql construction system dbapi interaction layer sqlalchemy core separate orm full database abstraction layer right includes extensible pythonbased sql expression language schema metadata connection pooling type coercion custom type primary foreign key constraint assumed composite natural surrogate integer primary key course still norm sqlalchemy never assumes hardcodes model database introspection generation database schema reflected one step python structure representing database metadata structure generate create statement right back within core independent orm sqlalchemys philosophy sql database behave le le like object collection size performance start matter object collection behave le le like table row abstraction start matter sqlalchemy aim accommodate principle orm doesnt need hide r relational database provides rich setbased functionality fully exposed sqlalchemys orm provides openended set pattern allow developer construct custom mediation layer domain model relational schema turning socalled object relational impedance issue distant memory developer case make decision regarding design structure naming convention object model well relational schema sqlalchemy provides mean automate execution decision sqlalchemy thing orm generated bad query retain full control structure query including join organized subqueries correlation used column requested everything sqlalchemy doe ultimately result developer initiated decision dont use orm problem doesnt need one sqlalchemy consists core separate orm component core offer full sql expression language allows pythonic construction sql construct render directly sql string target database returning result set essentially enhanced dbapi cursor transaction norm sqlalchemys orm nothing go permanent storage commit called sqlalchemy encourages application create consistent mean delineating start end series operation never render literal value sql statement bound parameter used greatest degree possible allowing query optimizers cache query plan effectively making sql injection attack nonissue documentation latest documentation httpwwwsqlalchemyorgdocs installation requirement full documentation installation installation getting help development bug reporting please refer sqlalchemy community guide code conduct sqlalchemy place great emphasis polite thoughtful constructive communication user developer please see current code conduct code conduct license sqlalchemy distributed mit license\n",
      "[0 0 1 0 1 1 1 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 0\n",
      " 0 0 1]\n",
      "inconsolata opensource monospace font code listing originally raphlinus ligature inconsolata includes ligature javascript operator available two family inconsolata expose ligature dlig disabled default probably wont show editor enable cs rule fontvariantligatures discretionaryligatures ligconsolata expose ligature liga enabled default family use text editor note ligconsolata variant ha yet upgraded version 3000 prioritizing nonligature variant building family family built using glyph fontmake gftools post processing script tool python based install python tool virtualenv following python3 venv venv source venvbinactivate pip install r requirementstxt build font must load sourcesinconsolatavfglyphs glyph following run decomposetransformedcomponentspy script run geninstancespy script run incofixpy script save file back source directory filename prodglyphs run build script terminal cd source script need run source dir sh buildsh font take approximately 25 minute build changelog v3000 upgrade 2axis variable font family width 50 200 weight 200 900 changelog v2013 removed ligature fi fl operator ligature moved dlig new variant ligconsolata introduced expose operator ligature liga changelog v2011 march 2018 glyph set expansion wa completed appsforartists included glyph set expanded include ligature changelog v2001 august 2016 glyph set expansion wa completed alexei vanyashin cyreal included glyph set expanded gf latin pro additional glyph minor design improvement trademark corner spur reading inconsolata expansion project thread google font discussion supported glyph set gf latin pro license font software licensed sil open font license version 11 license copied also available faq httpscriptssilorgofl inconsolata build instruction inconsolata font built using either export glyph using fontmake font file committed repo done using fontmake source file inconsolata source file available glyph format located source directory adding ligature follow creating ligature section glyph ligature tutorial name new glyph suffix dlig instance bargreaterdlig open font info panel switch feature tab click dlig sidebar click update button bottom panel switch instance tab update rename glyph value ligconsolata regular include new line new glyph instance bargreaterdligbargreaterliga update rename glyph value ligconsolata bold export font explained exporting variable font using fontmake possible export project single variable font bit tricky font us component varying 2x2 component triggering bug present fontmake glyph export thus incofixpy script source directory detects case decomposes component run script exporting script also decomposes corner component make resulting glyph file suitable fontmake export well fontmake currently ha support corner component copy script script folder glyph make available script menu copy macro panel running script following fontmake invocation generate variable font fontmake g sourcesinconsolatavfglyphs variable version font directory slightly smaller version generated glyph check result incofix script version control want preserve editability entirely possible future version fontmake glyph able handle source file without running script exporting instance using fontmake source file contains 15 instance including weight normal 100 width also master reasonable complement working font run geninstancespy script generate total 72 instance combination weight 200 900 width 50 70 80 90 110 120 150 200 two instance ligconsolata fontmake attempt generate rename glyph custom parameter doesnt seem respected fontmake wont ligature enabled use glyph export instead detailed run command generate otf fontmake g sourcesinconsolatavfglyphs otf command generate autohinted ttf fontmake g sourcesinconsolatavfglyphs ttf version font directory font export option glyph preferred way generate ligconsolata instance ttf otf file exported fontsttf fontsotf folder ttfs generated glyph app autohint option checked moment custom build script required produce font file since default ttfautohinting option suffice otfs generated option remove overlap autohint save ttf export destination repopathfontsotf future work addition want export subset including vietnamese script coverage avoid overlarge line spacing older application terminal text editor dont understand use typo metric flag see httpsgithubcomgooglefontsinconsolataissues35 copyright copyright 2006 inconsolata project author link inconsolata google font inconsolata leviencom official upstream git\n",
      "[0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1\n",
      " 1 1 1]\n",
      "akihabara important note read moving new repository community friendly tidy httpsgithubcomakihabara start playing whats akihabara akihabara set library tool presets create pixelated indiestyle 816bit era game javascript run browser without flash plugin making use small small small subset html5 feature actually available many modern browser note developer maximum compatibility make sure youre using name setting object property reserved name like goto data discovered patching wii also use comma last element array property object still work many browser broken opera wii probably ie supported making sure subscript loaded try add alert end opera wii silently fail syntax error like one explained opera wii want canvas blitted least used fails browser crash builtin gboxcreatecanvas wa already fixed good thing use method spawning canvas akibaka thought flexible simple akihabara resource editor akibaka ha committed partially uncompleted due lack time functional enough hope ill start working better someone pick code give spin experimental feature feature available current stable version use section changelog next one syncrhonous keyboard listener use function called frame instead usual keyupdown listener changing keyboard status order support specific hardware like wiiu wiiu official support synchronous keyboard listener standard button mapping unusable since impossibile cancel default action todo way updating jsdoc automatically darren darius wrapped tutorial doc btw script generating doc form source needed better embeddability keeping playability mobile solve randomly blinking sprite wii akibaka add addimage addtiles used improvement audio compatibility work progress nice networking\n",
      "[1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1]\n",
      "ipython productive interactive computing overview welcome ipython full documentation available ipythonreadthedocsio contains information install use contribute project ipython interactive python command shell interactive computing multiple programming language originally developed python programming language offer introspection rich medium shell syntax tab completion history ipython version python support starting ipython 710 ipython follows nep 29 ipython 717 requires python version 37 ipython 710 requires python version 36 ipython 70 requires python version 35 ipython 6x requires python version 33 ipython 5x lts compatible release python 27 require python 2 support must use ipython 5x lts please update project configuration requirement necessary notebook qt console number piece part jupyter see jupyter installation doc want use main feature ipython comprehensive object introspection input history persistent across session caching output result session automatically generated reference extensible tab completion support default completion python variable keywords filename function keywords extensible system magic command controlling environment performing many task related ipython operating system rich configuration system easy switching different setup simpler changing pythonstartup environment variable every time session logging reloading extensible syntax processing special purpose situation access system shell userextensible alias system easily embeddable python program gui integrated access pdb debugger python profiler development instant running find latest version development documentation readthedocs run ipython directory without even installing systemwide typing terminal python ipython see development installation doc latest revision read doc documentation installation instruction older version ipython found ipython website ipython requires python version 3 starting version 60 ipython doe support python 27 30 31 32 version compatible python 27 please install 5x lts long term support version encountering error message likely trying install use ipython source need checkout remote 5x branch using git following work git fetch origin git checkout 5x encounter error message regular install ipython likely need update package manager example using pip check version pip pip version need update pip version 901 greater using pip please inquiry maintainer package package manager information see one blog post httpsblogjupyterorgreleaseofipython508ce60b8d2e8e well following pullrequest discussion httpsgithubcomipythonipythonpull9900 error doe also occur invoking setuppy directly using easyinstall case use pip install instead setuppy install pip install e instead setuppy develop depending ipython dependency may also want conditional dependency ipython depending python version installreq ipython sysversioninfo0 3 bdistwheel sysargv installreqremoveipython installreqappendipython6 setup installrequiresinstallreq alternative ipython ipython may taste thats case might similar project might want use classic python repl bpython mypython ptpython ptipython httpspypiorgprojectptpython xonsh httpsxonsh ignoring commits git blameignorerevsfile git 223 possible make formatting change without breaking git blame see git documentation detail use feature must install git 223 configure local git repo running posix toolsconfiguregitblameignorerevssh window toolsconfiguregitblameignorerevsbat\n",
      "[0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1\n",
      " 1 0 1]\n",
      "5 super senior swift developer question link offtop ua pull request datajson url laravel framework laravel framework gitter httpsgitterimphpualaravel atlassian user group saintpetersburg atlassian user group atlassian telegram httpstmeaugspb interesting question performance plugin hacking please ask aimlds dev ua data science gitter httpsgitterimdevuaaimlds allthatjs javascript slack httpsallthatjsherokuappcom angular ru angularjs javascript gitter httpsgitterimangularjsruschat angularjs ua dev ua angularjs javascript gitter httpangularim angularjs angularjs angularjs telegram httpstelegrammeangularjs android russpeaking developer chat android gitter httpsgitterimrusspeakingandroid android russpeaking slack team android slack httpsgooglformsymwbvtvseslyhwwh3 android developer android telegram httpstelegrammeandroidru android united android skype httpbitlyandroidchat android developer ua android skype httpsjoinskypecomvg41lckg7ptg android job ua adroid android telegram httpstmejoinchathmerxjoq6lkltufhepkg pet android android declarative android declarative android ui jetpack compose anko anvil litho android ui jetpack compose anko anvil litho telegram httpstmeandroiddeclarative ansible ru ansible slack httpsgooglvqfjzp slack register form httpgooglsbmi3f android dev android dev apptractorruandroiddev telegram httpstmeandroiddevpodcast android architecture telegram httpstmeandroidarchitecture ruembedded embedded softwarehardware ircircforestnetorg6667ruembedded webdev webdevelopment theory practice irc httpwebdevaecname net c azure net aspnet c azure xamarin skype httpbitlydotnetchat atlassian user group moscow atlassian user group atlassian telegram httpstmeaugmoscow php telegram php telegram telegram httpstelegrammeprophp7 clojure ua dev ua clojure clojurescript fp gitter httpsgitterimdevuaclojure cicerone chat ru httpsgithubcomterrakokcicerone telegram httpstmeciceronerus c russia telegram httpstelegrammejoinchatcmhkjwai8vac99lmyofq clojure ru clojure clojurescript telegram httpstmeclojureru clojure pro clojure clojurescript telegram httpstmeclojurepro postgreschat postgres gitter httpsgitterimpostgresmenpostgresqlrussia devops devops telegram httpstmedevopsru dagger 2 dagger 2 telegram httpstmedagger2 dart group dev ua dart gitter httpsgitterimdevuadartskype httpbitlydartchat cocoa chat cocoa skype httpbitlycocoachat read guideline banned cocoa developer club iosos x slack httpcocoadevelopersclubchat delphi developer ua delphi skype httpsjoinskypecombklfxscj6kwy diy glory sad robot hardware microcontrollers robotics skype httpbitlyrobotschat devops devs vagrant docker dokku oh skype httpbitlydevopsfordevs continuous integrationdelivery ru continuous integrationdelivery telegram httpstelegrammecicdru propython prodot python telegram httpstelegrammejoinchata7kpxzxo8hpyxsxtsku7g itcrowd kz developer community kazakhstan slack httpitcrowdkzslackcom gentoo gentoo linux telegram httpstmerussiangentooother httptelegraphinfo0611 go lang dev ua go gitter httpsgitterimdevuagoskype httpisgd0hu7ar programming work metarhia computer science software engeneering programming telegram httpstmeprogrammingip9x graphql graphql telegram httpstelegrammegraphqlru hangopsru russian devops hangout slack httpjoinhangopsruskype skype outdated httptinyurlcomhangopsru frontend kz html5 css3 javascript slack httpfrontendkzgithubio haskell ua dev ua haskell chat gitter httpsgitterimdevuahaskell haskell haskell chat gitter httpsgitterimruhaskellforall haxe haxe telegram httpstmehaxeru hexlet c java ruby php j slack httpslackruhexletio game made gamedev slack httphgaminviteherokuappcom docker docker docker swarm telegram httpstmedockerru itchat web scraping python skype httptinyurlcomitchatnew ember chat dev ua emberjs gitter httpsgitterimdevuaember flask flask telegram httpstmeruflask erlang elixir erlang elixir slack httpotprussianherokuappcomtelegram httpstelegrammeproelixir nice perm perm telegram httpstmeitperm 1 feather j feathersjs telegram httpstmefeatherjs flow type checker community flow j telegram httpstelegrammeflowtyperu fronthub j cs html fun flood slack httpsfronthubslackcom gamedev gamedev skype httpsbitlyrugamedevskypechat django django telegram httpstmepydjango rubywhatever ruby skype httptinyurlcomrubyconf good person openvidu kurento openvidu kurento openvidukurento telegram httpstmeopenvidu nodeua metarhia nodejs software engineering telegram httpstmenodeua javachat java jvm skype httpbitlyjavachatru moxy mvp android httpsgithubcomarellomobilemoxy moxy moxy moxy telegram httpstmemoxyru java talk java jvm software design skype httpbitlyjavatalksby kotlin community kotlin telegram httpstmekotlinlang krasnodar dev day telegram httpstelegrammekrddevdays krasnodar frontend c frontend telegram httpstelegrammekrdfrontend kubernetes kubernetes telegram httpstmekubernetesru slack httpanjlabcomruvladimir8bit nodejs ua dev ua nodejs devops nosql gitter httpsgitterimdevuanode nodejs ru nodejs gitter httpsgitterimnodejsruschat moscowjs html5 css3 javascript gitter httpsgitterimmoscowjschat mobile web ua hybrid apps phonegap crosswalk skype httpbitlymobilewebua lovely clojure clojure clojurescript fp skype httptinyurlcomcljcljs odeskconf undefined slack httpsodeskconfherokuappcom laravel laravel php gitter httpsgitterimlaravelruschat javascriptru javascript nodejs angularjs slack httpslackjavascriptru javascript noobs j telegram httpstelegrammejsnoobsru slackdevby belarussian dev community lot channel different topic slack httpslackdevby true c true c skype httpgoogltajsf2 reactivex telegram httpstmereactivex python community chelyabinsk python telegram httpstmepychel rollup rollupjs telegram httpstmerollupru true big data true big datadata science skype httpgoogln2djvo true net true net skype httpgoogl3lkldj russianspeaking rubyjs dev community ruby j slack httpsrusdevsherokuappcom phalcon ru phalcon php gitter httpsgitterimphalconruschat phalcon framework phalcon framework gitter httpsgitterimphpuaphalcon php ua dev ua php gitter httpsgitterimdevuaphpskype httpbitlyphpua chat migrated gitter php community php community gitter httpsgitterimphpuaphp true android development true android skype httpgooglv8cica pyha pyharu slack httpspyhaslackcom piter united slack httpbitlypiterunited symfony symfony component symfony framework telegram httpstmesymfonyphp symfony framework ru symfony framework gitter httpsgitterimsymfonysibsymfony symfony framework ua symfony framework gitter httpsgitterimphpuasymfony spb frontend j cs html gitter httpsgitterimspbfrontendtalksslack httpslackspbfrontendru scala user group telegram scala telegram httpstmescalaru true asm true assembler skype httpgooglcvxdnr scalachat dev ua scala jvm software design gitter httpsgitterimdevuascalaslack httpsscalaruherokuappcomskype httpbitlyscalachat swiftchat swift io osx skype httpbitlyswiftskypechat python python telegram httpstelegrammerupython python ua python skype httpbitlypythonua qac automation testing qa automation skype httpbitlytestautomationchat qac performance load testing qa skype httpsjoinskypecomivtvbl4t6r9k qt qt qml qtcreator telegram httpstmeqtchat reportportalio community reportportalio community open sourced tool test automation slack httpsreportportalslackautoherokuappcom reactjs dev ua reactjs flux redux gitter httpsgitterimdevuareactjsskype httpbitlyreactjschat scala ua dev ua scala jvm gitter httpsgitterimdevuascalaskype httpbitlyscalaua skype readonly archive rubyror dev ua ruby rail gitter httpsgitterimdevuarubyuaskype httpbitlyrubyuatelegram httpstelegrammerubylang startup startup entrepreneurship skype httpbitlystartupsuachat rustua dev ua rust gitter httpsgitterimdevuarust salesforcedevelopersru skype salesforcedevelopersru skype httpsjoinskypecomh9hvp9pnxioc salesforceru russianspeaking salesforce developer gitter httpsgitterimsalesforcerusalesforceru softwaretesters urkqa slack httpssoftwaretestersherokuappcom xamarin net xamarin android io window 10 telegram httpstmexamarinrussia true cs true cs skype httpgooglnsmtb3 chatbots ai community chatbots ai community chatbots telegram httpstelegrammejoinchatabi4pz6rz2ivzwuzavqpma chatbots ai community true window development true development window phonertwpf skype httpgooglqzot3t true database true database skype httpgoogljhuouj true unix true nix skype httpgooglrqcepd true system administration true russian speaking sysadmins skype httpgooglznsgaf true devops true devops skype httpgoogli3mwjc true htmlcssjs true htmlcssjs skype httpgooglnvj9fk true infosec true info security skype httpgooglnoc6rq true true skype httpgooglfolxzp true startup true russian speaking startup community skype httpgooglunpceb true rust true rust skype httpgooglkwhhov true javascript true javascript skype httpgoogl1atiyi true lamp true linuxapachemysqlphp python perl skype httpgooglfbeagb true ruby true ruby skype httpgooglg5bvgd true python true python skype httpgooglc8ky7e vim vim skype httptinyurlcomruvimchat prolua prodot telegram httpstelegrammeprolua projs prodot javascript nodejs telegram httpstelegrammejoinchatbe4rst5rsgq30dhutjxxga golangruslackcom go slack http4gophersruslack io developer io telegram httpstelegrammeiosru phpgeeks 22 php telegram telegram httpstmephpgeeks typescript typescript russian speaking community telegram httpstelegrammetypescriptru projvm prodot jvm android java scala kotlin groovy clojure telegram httpstelegrammejvmchat procxx telegram httpstmeprocxx ntwrk network engineer community telegram httpstelegrammentwrk zend framework zend framework gitter httpsgitterimphpuazf yii framework yii framework gitter httpsgitterimphpuayii codingteam codingteam gitter httpsgitterimcodingteamtelegram httpstmecodingteam vuejs vuejs javascript gitter httpsgitterimvuejsrudiscussion visual studio code telegram httpstmevscoderu proasm assembler telegram httpstmeproasm unity dev ua unity engine gitter httpsgitterimdevuaunity true java true java jvm software design skype httptinyurlcomtruejava yiijobs yii telegram httpstmeyiijobs pgsql postgresql telegram postgresql telegram httpstmepgsql true io true development io skype httpgooglkjnfsn jquery ru jquery javascript gitter httpsgitterimjqueryruschat supaprocxx telegram httpstmesupapro html cs svg j slack httpslackwebstandardsru russian speaking community berlin germany slack httpsslackfilescomt09s9jdu1f0hheg8pkc9396c730askype httpbitlyberlinruitchattelegram httpstelegrammeberlinru russian speaking community munich germany skype httptinyurlcomskypetraktoristivmunchene rust gitter httpsgitterimrurustgeneral offence flame spam net dotnetru net c f telegram httpstmedotnetruchat f fsharplangru f gitter httpsgitterimfsharplangrulobbytelegram httpstmefsharpchat ua plan work work abroad skype httpbitlyitemigrantua beware troll\n",
      "[0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1]\n",
      "main repository discussion coordination code live elsewhere follow repository update project check homepage stay date reading post medium join u spectrum\n",
      "[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "reduxcode companion repo course udemy\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "healthclinicbiz connect 2015 showcased many technology available developer across azure office window visual studio visual studio team service weve also heard love realworld application directly experience whats possible using technology year built full health technology scenario connect 2015 demo delighted share source code healthclinicbiz fictitious regular doctor practice specialized offering healthcare preventive care clinic using different microsoft multichannel apps built visual studio 2015 grow business modernize customer experience also innovate offer multiple apps servicesincluding website mobile apps wearable appsto empower patient wellbeing easy access manage healthcare data stay healthy license project us thirdparty asset license requires attribution roboto font christian robertson roboto google font raleway font matt mcinerney pablo impallari rodrigo fuenzalida igino marini raleway google font extra information license see dependency repository prerequisite window 10 visual studio 2015 update 2 make sure install uwp development tool cross platform mobile development office developer tool xamarin visual studio microsoft azure sdk visual studio 2015 microsoft office 2016 bing map key getting bing map key microsoft azure subscription sign microsoft azure need azure account work demo code open azure account freeazure subscription get credit used try paid azure service even credit used keep account use free azure service feature web apps feature azure app service activate visual studio subscriber benefit visual studio subscription give credit every month use paid azure service visual studio subscriber get 25 monthly azure credit joining visual studio dev essential please see wiki detailed azure deployment instruction demo scenario blog post link blog post related project connectdemos 2015 healthclinicbiz erika ehrli aspnet 5 net core rc1 context plus connect 2015 news scott hanselman license sample template licensed mit license see licensetxt file root code conduct project ha adopted microsoft open source code conduct information see code conduct faq contact opencodemicrosoftcom additional question comment\n",
      "[0 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0\n",
      " 0 0 1]\n",
      "reactnativereduxcasts companion repo complete react native redux course repo organized branch branch line one video course use branch seletor left side select section want see alternatively look completed code available master branch\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0]\n",
      "hey welcome hacktoberfest 2020 disclaimer pull request wont count toward hacktoberfest repo welcome beginner github opensource community helping learn make first pr contribution open source said highquality contribution pull request add value open source project part core value hacktoberfest repository like one others allow user quickly gain pr toward completing challenge excluded hacktoberfest pull request wont count toward hacktoberfest try contributing meaningful way hacktoberfest issue still want generate music certificate add hacktoberfest2020vercelapp go ahead raise pr open first pull request hacktoberfest 2020 challenge generate personalized music certificate make first pull request step1 star repo step2 show love step3 fork clone repository step4 create new branch git checkout b newuser step5 create new file contributor folder name file yourgithubusernamejson forget include json file extension step6 add detail yourgithubusernamejson file format githubusername yourgithubusername favouriteemoji yourfavouriteemoji favouritemusic yourfavouritemusicurl favouritecolor yourfavouritecolor note githubusername one youre making pull request favouriteemoji emoji supported modern browser pick one httpsemojipediaorg favouritemusic song httpssoundcloudcom favouritecolor color hex format example fff44f pick colour httpswwwgooglecomsearchqcolorpicker step7 add file git add step8 commit change git commit added step9 push fork git push origin newuser submit pull request step10 pat self back wait pull request reviewed merged designer react developer project built using nextjs react based framework open contribution frontend devs designer want make bigger better hacktoberfest monthlong celebration october 1st 31st sponsored digital ocean github get people involved open source create first pull request public repository github contribute open source developer community httpshacktoberfestdigitaloceancom checkout hacktoberfest video faq profile showing website raise pull request wait approved merged master branch upon successful merge detail show automatically within 612 hr website httpshacktoberfest2020vercelapp make pull request welcomed raise pr anytime increasing count hacktoberfest star repo raise pr oct 1st 31st pull request counted towards hacktoberfest 2020 repo welcome beginner github opensource community helping learn make first pr contribution open source said highquality contribution pull request add value open source project part core value hacktoberfest repository like one others allow user quickly gain pr toward completing challenge might excluded hacktoberfest highly recommend contribute meaningful way hacktoberfest issue rely repository alone awesome contributor generated using contributorsimg\n",
      "[1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 1 0\n",
      " 1 1 0]\n",
      "weight bias use wb organize analyze machine learning experiment frameworkagnostic lighter tensorboard time run script instrumented wandb save hyperparameters output metric visualize model course training compare version model easily also automatically track state code system metric configuration parameter sign free account feature store hyperparameters used training run search compare visualize training run analyze system usage metric alongside run collaborate team member replicate historic result run parameter sweep keep record experiment available forever documentation question please dont hesitate ask slack community simple integration framework install wandb library login pip install wandb wandb login flexible integration python script import wandb 1 start wb run wandbinitprojectgpt3 2 save model input hyperparameters config wandbconfig configlearningrate 001 model training code 3 log metric time visualize performance range 10 wandblogloss loss try colab question please dont hesitate ask slack community explore wb dashboard academic researcher youd like free academic account research group reach u make easy cite wb published paper learn track model data pipeline hyperparameters set wandbconfig beginning script save hyperparameters input setting like dataset name model type independent variable experiment useful analyzing experiment reproducing work future setting configs also allows visualize relationship feature model architecture data pipeline model performance seen screenshot wandbinit wandbconfigepochs 4 wandbconfigbatchsize 32 wandbconfiglearningrate 0001 wandbconfigarchitecture resnet see set configs colab doc use favorite framework kera kera use callback automatically save metric tracked modelfit get started minimal example import wb import wandb wandbkeras import wandbcallback step1 initialize wb run wandbinitprojectprojectname 2 save model input hyperparameters config wandbconfig configlearningrate 001 model training code step 3 add wandbcallback modelfitxtrain ytrain validationdataxtest ytest callbackswandbcallback try colab learn doc pytorch wb provides first class support pytorch automatically log gradient store network topology call watch pas pytorch model use log anything else want track like import wandb 1 start new run wandbinitprojectgpt3 2 save model input hyperparameters config wandbconfig configdropout 001 3 log gradient model parameter wandbwatchmodel batchidx data target enumeratetrainloader batchidx argsloginterval 0 4 log metric visualize performance wandblogloss loss try colab learn doc tensorflow simplest way log metric tensorflow logging tfsummary tensorflow logger import wandb 1 start wb run wandbinitprojectgpt3 2 save model input hyperparameters config wandbconfig configlearningrate 001 model training 3 log metric time visualize performance tfsession sess wandbtensorflowlogtfsummarymergeall try colab doc fastai visualize compare iterate fastai model using weight bias wandbcallback import wandb fastai2callbackwandb import wandbcallback 1 start new run wandbinitprojectgpt3 2 automatically log model metric learnfit cbswandbcallback try colab doc huggingface run script using huggingfaces trainer environment wandb installed well automatically log loss evaluation metric model topology gradient 1 install wandb library pip install wandb 2 run script ha trainer automatically log metric model topology gradient python rungluepy modelnameorpath bertbaseuncased taskname mrpc datadir gluedirtaskname dotrain evaluateduringtraining maxseqlength 128 pergputrainbatchsize 32 learningrate 2e5 numtrainepochs 3 outputdir tmptaskname overwriteoutputdir loggingsteps 50 try colab doc optimize hyperparameters sweep use weight bias sweep automate hyperparameter optimization explore space possible model get started 5 min try sweep pytorch colab benefit using wb sweep quick setup line code run wb sweep transparent cite algorithm using code open source powerful sweep completely customizable configurable launch sweep across dozen machine easy starting sweep laptop common use case explore efficiently sample space hyperparameter combination discover promising region build intuition model optimize use sweep find set hyperparameters optimal performance kfold cross validation brief code example kfold cross validation wb sweep visualize sweep result hyperparameter importance plot surface hyperparameters best predictor highly correlated desirable value metric parallel coordinate plot map hyperparameter value model metric theyre useful honing combination hyperparameters led best model performance share insight report report let organize visualization describe finding share update collaborator common use case note add graph quick note collaboration share finding colleague work log track youve tried plan next step explore report gallery read doc experiment wb visualize document result report click quick demo video version control datasets model artifact git github make code version control easy theyre optimized tracking part ml pipeline datasets model large binary file wb artifact extra line code start tracking team output directly linked run try artifact colab common use case pipeline management track visualize input output run graph dont repeat prevent duplication compute effort sharing data team collaborate model datasets without headache learn artifact read doc testing run basic test use make test detailed information found contributingmd use circleci ci\n",
      "[1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1]\n",
      "douban conversation corpus data set release douban conversation corpus comprising training data set development set test set retrieval based chatbot statistic douban conversation corpus shown following table train val test sessionresponse pair 1m 50k 10k avg positive response per session 1 1 118 fless kappa na na 041 min turn per session 3 3 3 max ture per session 98 91 45 average turn per session 669 675 595 average word per utterance 1856 1850 2074 test data contains 1000 dialogue context context create 10 response candidate recruited three labelers judge candidate proper response session proper response mean response naturally reply message given context pair received three label majority label wa taken final decision far known first humanlabeled test set retrievalbased chatbots entire corpus link httpswwwdropboxcoms90t0qtji9ow20cadoubanconversaioncorpuszipdl0 data template label conversation utterance splited response source code also release source code help others reproduce result code ha tested ubuntu 1404 python 27 please first run preprocesspy edit code correct path give bin file please run smnlastpy generated bin file training loss printed screen set trainflag false give predicted score model tip 200d word embedding shared https1drvmsusatcxwlquqjw1jf0bjeakheunwita shared file list ha 3 element one word2vec file please download replace input path training data scripy tensorflow resource tensorflow code requires several data set ha uploaded following path resource file https1drvmsusatcxwlquqjw1jgn5kpzsh03lng6u worddict file https1drvmsusatcxwlquqjw1jgrcjg8lik1wen9 requirement tensorflow13 reference please cite paper use data code repos wu yu et al sequential matching network new archtechture multiturn response selection retrievalbased chatbots acl 2017\n",
      "[0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0\n",
      " 0 0 0]\n",
      "complexityreport note fork longer maintained use jareds fork instead software complexity analysis javascript project commandline frontend escomplex le attractive elder brother jscomplexityorg software complexity analysis work complexity metric result result installation usage commandline option output format license software complexity analysis complexity quality consisting many interrelated part software consists many interrelated part becomes difficult reason software difficult reason fertile breeding ground bug software simple every problem space contains level inherent complexity shared possible solution however programmer reduce complexity chosen solution limiting interrelatedness constituent component commonly referred favouring cohesion coupling form bedrock axiom single responsibility principle built codebases large andor unfamiliar difficult know whether region complexity exist might defining metric complexity search offending component automated brought existing build process alongside form static analysis unit test work complexityreport nodejsbased commandline wrapper around escomplex library performs actual analysis work code passed escomplex form syntax tree generated esprima popular javascript parser example report complexity metric readme escomplex contains brief overview metric produce result number returned tool interpreted definitive indicator whether piece software complex whatever might mean software development varied field every project subject unique set environmental factor attempt set generic hard limit complexity metric must essentially arbitrary fail consider specific requirement given project complexity amorphous multidimensional continuum attempting pigeonhole chunk code discrete point along single axis intrinsically crude approach result better use tool fuzzy highlevel mechanism identify region interest concern programming domainexpertise take comprehensive analysis although metric perfect help identify area code warrant closer inspection also tracked time indicator direction overall code quality may moving tool configured fail complexity metric pas specified threshold aid usefulness automated environment ci also option controlling metric calculated format report output installation must nodejs installed projectbased install npm install complexityreport globally project sudo npm install g complexityreport usage cr option path tool recursively read file directory encounter automatically commandline option h help output usage information c config path specify configuration json file output path specify output file report f format format specify output format report e ignoreerrors ignore parser error allfiles include hidden file report p filepattern pattern specify file process using regular expression match file name p dirpattern pattern specify directory process using regular expression match directory name x excludepattern pattern specify directory exclude using regular expression match directory name maxfiles number specify maximum number file open point f maxfod firstorder density specify perproject firstorder density threshold maxcost change cost specify perproject change cost threshold maxsize core size specify perproject core size threshold minmi maintainability index specify permodule maintainability index threshold c maxcyc cyclomatic complexity specify perfunction cyclomatic complexity threshold maxcycden cyclomatic density specify perfunction cyclomatic complexity density threshold maxhd halstead difficulty specify perfunction halstead difficulty threshold v maxhv halstead volume specify perfunction halstead volume threshold e maxhe halstead effort specify perfunction halstead effort threshold silent dont write output console l logicalor disregard operator source cyclomatic complexity w switchcase disregard switch statement source cyclomatic complexity forin treat forin statement source cyclomatic complexity trycatch treat catch clause source cyclomatic complexity n newmi use microsoftvariant maintainability index scale 0 100 coffeescript include coffeescript file configuration file default complexityreport attempt read configuration option json file called complexrc current working directory file contain json object property name matching longform option name command line one follow option set file overridden option specified command line see example configuration file also specify alternative path file using c commandline option output format currently five output format supported plain markdown minimal json xml loaded srcformats subdirectory format file found directory second attempt made load module without subdirectory prefix easily enabling use custom format desired adding new format simple one must commonjs module export function named format format function take report object defined escomplex return string representation report see plain formatter example development see contribution guideline license mit\n",
      "[0 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0\n",
      " 0 0 1]\n",
      "supporting vuejs vuejs mitlicensed open source project ongoing development made possible entirely support awesome backer youd like join please consider become backer sponsor patreon become backer sponsor open collective onetime donation via paypal cryptocurrencies whats difference patreon opencollective fund donated via patreon go directly support evan yous fulltime work vuejs fund donated via opencollective managed transparent expense used compensating work expense core team member sponsoring community event namelogo receive proper recognition exposure donating either platform special sponsor platinum sponsor platinum sponsor china gold sponsor sponsor via open collective platinum gold introduction vue pronounced vju like view progressive framework building user interface designed ground incrementally adoptable easily scale library framework depending different use case consists approachable core library focus view layer ecosystem supporting library help tackle complexity large singlepage application browser compatibility vuejs support browser es5compliant ie8 supported ecosystem project status description vuerouter singlepage application routing vuex largescale state management vuecli project scaffolding vueloader single file component vue file loader webpack vueserverrenderer serverside rendering support vueclasscomponent typescript decorator classbased api vuerx rxjs integration vuedevtools browser devtools extension documentation check live example doc visit vuejsorg question question support please use official forum community chat issue list repo exclusively bug report feature request issue please make sure read issue reporting checklist opening issue issue conforming guideline may closed immediately changelog detailed change release documented release note stay touch twitter blog job board contribution please make sure read contributing guide making pull request vuerelated projectcomponenttool add pull request curated list thank people already contributed vue license mit copyright c 2013present yuxi evan\n",
      "[1 0 1 1 0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0\n",
      " 0 0 1]\n",
      "home assistant configuration home assistant configuration installed ha intel nuc skullcanyon 32gb ram 500gb nvme ssd currently running ubuntu 1604 lts nuc used virtual environment approach install ha regularly update configuration file check current ha version like anything sure repo thing run nuc home assistant homebridge plex medium server docker container using command docker create name plex nethost restartalways e tzamericanew york e puid1000 e pgid1000 e plexclaimclaim p 3240032400 v dockercontainersplexconfigconfig v dockercontainersplextranscodetranscode v mntmusicdatamusicshared v mntmediatv showsdatatvshowsshared v mntbollywooddatabollywoodshared v mnthollywooddatamoviesshared plexincpmsdockerplexpass machinebox image tagging service docker container using following command first obtain api key assign mbkey run container using access tagbox interface httpipaddres8081 sudo docker run namemachinebox p 80818080 e mbkeymbkey machineboxtagbox device service use ha aeotec zstick gen5 zwave control use zwave dry contact relay along tilt sensor automating garage door xiaomi aqara zigbee sensor currently using water temperaturehumidity doorwindow human body sensor also using mi magic cube volume brightness automation presence detection cornerstone setup use elaborate approach explained currently combine information following device tracker using pythonscript bayesian binary sensor component use presence unifi wap networkbased device tracking owntracks geofency life360 customcomponent tracking io device io app security abode home security almost entirely automated using presence four hikvision ds2cd2042wdi camera across house integrated using synology camera component three arlo camera indoor monitoring ring doorbell networking ubiquiti unifi cloud key ubiquiti unifi 80211ac pro ap pihole sensor light switch lifx wifi light wemo switch porch driveway wemo plug miscellaneous automation including smart charging prevent overcharging humidifier christmas light etc ge zwave dimmer 12724 kitchen light voice interaction google home google assistant dialogflow component amazon echo dot ha cloud medium sonos speaker component plex medium consumption along plex component plex activity monitor track pm google cast nvidia shield tv notification io pushbullet basic notification telegram io actionable notification tt sonos notification android tv send visual notification shield weather climate related ecobee thermostat main floor kid room wunderground integrate weather station bloomsky weather station darksky weather data forecast pollen sensor allergy related information home assistant dashboard moved entire configuration lovelace screenshots please note may updated image get idea useful link ha cheat sheet miscellaneous tip trick\n",
      "[0 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1\n",
      " 0 0 0]\n",
      "lineprofiler kernprof lineprofiler module linebyline profiling function kernprof convenient script running either lineprofiler python standard library cprofile profile module depending available available bsd license content installation lineprofiler kernprof frequently asked question bug change 21 20 11 10 10b3 10b2 10b1 installation note version 212 pip install lineprofiler doe work please install follows fixed next release git clone httpsgithubcomrkernlineprofilergit find lineprofiler name pyx exec cython cd lineprofiler pip install user release lineprofiler installed using pip pip install lineprofiler source release binary downloaded pypi link httppypipythonorgpypilineprofiler check development source use git git clone httpsgithubcomrkernlineprofilergit may also download source tarballs snapshot url source release require c compiler order build lineprofiler addition git checkout also require cython 010 source release pypi contain pregenerated c source cython required case kernprof singlefile pure python script doe require compiler wish use run cprofile linebyline profiling may copy directory path manually avoid trying build c extension lineprofiler current profiling tool supported python 27 later time function call good first step locating hotspot one program frequently one need optimize program however sometimes cause hotspot actually single line function line may obvious reading source code case particularly frequent scientific computing function tend larger sometimes legitimate algorithmic complexity sometimes programmer still trying write fortran code single statement without function call trigger lot computation using library like numpy cprofile time explicit function call special method called syntax consequently relatively slow numpy operation large array like alargeindexarray someotherlargearray hotspot never get broken cprofile explicit function call statement lineprofiler given function profile time execution individual line inside function typical workflow one care line timing function wading result timing every single line code would overwhelming however lineprofiler doe need explicitly told function profile easiest way get started use kernprof script kernprof l scripttoprofilepy kernprof create instance lineprofiler insert builtins namespace name profile ha written used decorator script decorate function want profile profile profile def slowfunctiona b c default behavior kernprof put result binary file scripttoprofilepylprof tell kernprof immediately view formatted result terminal vview option otherwise view result later like python lineprofiler scripttoprofilepylprof example result profiling single function decorated version pystonepy benchmark first two line output pystonepy kernprof pystone11 time 50000 pass 248 machine benchmark 201613 pystonessecond wrote profile result pystonepylprof timer unit 1e06 file pystonepy function proc2 line 149 total time 0606656 line hit time per hit time line content 149 profile 150 def proc2intpario 151 50000 82003 16 135 intloc intpario 10 152 50000 63162 13 104 1 153 50000 69065 14 114 char1glob 154 50000 66354 13 109 intloc intloc 1 155 50000 67263 13 111 intpario intloc intglob 156 50000 65494 13 108 enumloc ident1 157 50000 68001 14 112 enumloc ident1 158 50000 63739 13 105 break 159 50000 61575 12 101 return intpario source code function printed timing information line six column information line line number file hit number time line wa executed time total amount time spent executing line timer unit header information table see line timer unit giving conversion factor second may different different system per hit average amount time spent executing line timer unit time percentage time spent line relative total amount recorded time spent function line content actual source code note always read disk formatted result viewed code wa executed edited file meantime line match formatter may even able locate function display using ipython implementation lprun magic command let specify function profile statement execute also add lineprofiler instance builtins typically would use like ipython 011 install editing ipython configuration file ipythonprofiledefaultipythonconfigpy add lineprofiler item extension list cterminalipythonappextensions lineprofiler get usage help lprun use standard ipython help mechanism 1 lprun two method expected frequent userlevel way using lineprofiler usually easiest however building tool lineprofiler need use api two way inform lineprofiler function profile pas argument constructor use addfunctionf method instantiation profile lineprofilerf g profileaddfunctionh lineprofiler ha run runctx runcall method cprofileprofile well enable disable noted though enable disable entirely safe nested nesting common using lineprofiler decorator order support nesting use enablebycount disablebycount function increment decrement counter actually enable disable profiler count transition 0 profiling dumpstatsfilename method pickle result given file printstatsstream print formatted result sysstdout whatever stream specify getstats return linestats object hold two attribute dictionary containing result timer unit kernprof kernprof also work cprofile thirdparty incarnation lsprof purepython profile module depending available ha main feature encapsulation profiling concern modify script order initiate profiling save result unless want use advanced builtins feature course robust script execution many script require thing like name file syspath set relative naive approach encapsulation would use execfile many script rely information fail kernprof set variable correctly executing script easy executable location profiling application installed path give name executable kernprof doe find given script current directory search path inserting profiler builtins sometimes want profile small part code bbuiltin argument profiler instantiated inserted builtins name profile like lineprofiler may used decorator enableddisabled enablebycount disablebycount even context manager profile statement preprofiling setup ssetup option provide script executed without profiling executing main script typically useful case import large library like wxpython vtk interfering result modify source code builtins approach may easier result profile scripttoprofilepy written scripttoprofilepyprof default typical marshalled file read pstatsstats may interactively viewed command python pstats scripttoprofilepyprof file may also viewed graphical tool like kcachegrind converter program pyprof2calltree runsnakerun frequently asked question name kernprof didnt manage come meaningful name named use hotshot instead lineprofile hotshot linebyline timing however deprecated may disappear standard library also take long time process result want quick turnaround workflow hotshot pay processing time order make minimally intrusive code profiling code doe network operation example may even go different code path profiling slows execution much use case think many people linebyline profiling affected much concern allow using hotshot kernprofpy dont use hotshot accept contribution vein though linebyline timing dont add one profiled function call another whats let say function f calling function g using lineprofiler total time reported g le time reported line f call g reason im reasonably clever possibly clever recording time basically try prevent recording time spent inside lineprofiler bookkeeping line time python tracing facility issue line event happens line actually get executed lineprofiler find two timestamps one beginning doe anything tbegin one close end possible tend almost overhead lineprofilers data structure happens two time line event come lineprofiler find function belongs first line function record line number tend associated function next time see line event belonging function take tbegin new event subtract old tend find amount time spent old line record new tend active line function way removing lineprofilers overhead result well almost one profiled function f call another profiled function g line f call g basically record total time spent executing line includes time spent inside profiler inside g first time question wa asked questioner g function call part larger expression wanted try estimate much time wa spent function opposed rest expression response wa even could remove effect might still misleading g might called elsewhere relevant line f workaround would modify code split two line one assigns result g temporary variable rest expression open suggestion make robust simple admonition trying clever list comprehension many hit use lineprofiler lineprofiler record line list comprehension iteration list comprehension kernprof distributed lineprofiler work cprofile right partly kernprofpy essential using lineprofiler effectively mostly im lazy dont want maintain overhead two project module small however kernprofpy standalone pure python script used function profiling python standard library may grab install without lineprofiler need c compiler build lineprofiler kernprofpy need c compiler lineprofiler kernprofpy pure python script installed separately though need cython build lineprofiler building released source tarball contain generated c source already running problem may bug let know building git checkout snapshot need cython generate c source probably need version 010 higher bug earlier version handle null pyobject pointer version python need lineprofiler kernprof tested python 27 3234 cprofile us neat rotating tree data structure minimize overhead looking recording entry lineprofiler us python dictionary extension object thanks cython mostly started prototype wanted play quickly possible passed stealing rotating tree usual got working seems acceptable performance much le motivated use different strategy maybe later contribution accepted bug bug pull requested submitted github change 21 enh add support python 35 coroutines enh documentation update enh ci recent python version 35 36 36dev 37dev nightly enh add timer unit argument output time granularity spec 20 bug added support ipython 50 removed support ipython 012 11 bug read source file byte 10 enh kernprofpy installed kernprof enh python 3 support thanks longsuffering mikhail korobov patient dropped 26 wa annoying enh stripzeros addmodule option thanks erik tollerud contributing enh support ipython cell block thanks michael forbes adding feature enh better warning building without cython thanks david cournapeau spotting 10b3 enh profile generator bug update compatibility newer version cython thanks ondrej certik spotting bug bug update ipython compatibility 011 thanks yaroslav halchenko others providing updated import 10b2 bug fixed line timing overflow window doc improved readme 10b1 initial release\n",
      "[1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1]\n",
      "v012 gita commandline tool manage multiple git repos tool doe two thing display status multiple git repos branch modification commit message side side batch delegate git commandsaliases working directory several repos related help see status together also hate change directory execute git command screenshot gita remote nowhub command translates git remote v nowhub repo see predefined subcommands run gita h take look cmdsyml add subcommands see customization section run arbitrary git command see superman mode section branch color distinguishes 5 situation local remote branch white local ha remote green local remote red local ha diverged remote purple local ahead remote good push yellow local behind remote good merge choice purple ahead yellow behind motivated blueshift redshift using green baseline change color scheme using gita color subcommand see customization section additional status symbol denote staged change unstaged change untracked filesfolders bookkeeping subcommands gita add repopaths add repos gita gita context context subcommand gita context show current context gita context none remove context gita context groupname set context groupname operation apply repos group gita color color subcommand gita color show available color current coloring scheme gita color set situation color use specified color localremote situation gita group group subcommand gita group add reponames n groupname add repos new group existing group gita group display existing group repos gita group l display existing group name gita group rename groupname newname change group name gita group rm groupnames delete group gita info info subcommand gita info display used unused information item gita info add infoitem enable information item gita info rm infoitem disable information item gita display status repos gita groupname display status repos group gita l display name repos gita l reponame display absolute path one repo gita rename reponame newname rename repo gita rm reponames remove repos gita wont remove file disk gita v display gita version git delegating subcommands two format gita subcommand reponames groupnames optional repo group input input mean repos gita subcommand reponames groupsnames required repo name group name input translate git subcommand corresponding repos default fetch pull take optional input word gita fetch gita pull apply repos see predefined subcommands run gita h take look cmdsyml add subcommands see customization section run arbitrary git command see superman mode section one repos specified git command run asynchronously exception log difftool mergetool require nontrivial user input repo path saved xdgconfighomegitarepopath likely configgitarepopath installation install latest version run pip3 install u gita prefer development mode download source code run pip3 install e gitasourcefolder either case calling gita terminal may work put following line bashrc file alias gitapython3 gita window user may need enable ansi escape sequence terminal branch color work see stackoverflow post detail autocompletion download gitacompletionbash gitacompletionzsh source rc file superman mode superman mode delegate git command alias usage gita super reponames groupnames anygitcommandwithorwithoutoptions reponames groupnames optional absence mean repos example gita super checkout master put repos master branch gita super frontendrepo backendrepo commit implement new feature executes git commit implement new feature frontendrepo backendrepo customization userdefined subcommand using yaml file custom delegating subcommands defined xdgconfighomegitacmdsyml likely configgitacmdsyml shadow default one name collision exist default delegating subcommands defined cmdsyml example gita stat reponames registered stat cmd diff stat help show edit statistic executes git diff stat specified repos delegated git command single word cmd tag omitted see push example disable asynchronous execution set disableasync tag true see difftool example want custom command behave like gita fetch ie apply command repos repo specified set allowall option true example following snippet creates new command gita comaster reponames optional repo name input comaster cmd checkout master allowall true help checkout master branch customize information displayed gita command customize information displayed gita used unused information item shown gita info configuration saved xdgconfighomegitainfoyml example default information item setting corresponds branch commitmsg customize localremote relationship coloring displayed gita command see default color scheme available color via gita color change color coding use gita color set situation color configuration saved xdgconfighomegitacoloryml requirement gita requires python 36 higher due use fstring asyncio module hood gita us subprocess run git commandsaliases thus installed git version may matter git 1831 2172 2201 machine result agree contributing contribute reportfix bug requestimplement feature starrecommend project chat room available run test locally simply pytest implementation detail designmd stepbystep guide reproduce project also sponsor github amount appreciated contributor multirepo tool havent tried heard good thing myrepos repo\n",
      "[1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1\n",
      " 1 0 1]\n",
      "repo deprecated mixed mode found httpsgithubcomfamousengine looking old website support material version famous please visit httpdeprecatedfamousorg repo moved deprecated organization coming month question concern pelase join u famous community slack signup httpslackfamousorgsignup\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0]\n",
      "react native storybook content repo wa moved storybook monorepo npm package name ha changed old name package wa kadirareactnativestorybook new name package storybookreactnative location code httpsgithubcomstorybooksstorybooktreemasterappreactnative repo youre looking date longer maintained\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "persona rl sl method envs quantitative trading persona repo implement paper proposed method deep reinforcement learning supervised learning applies financial market persona includes 4 rl 3 sl implement simulate financial market supporting stock future short sale still implementing rl sl method updating warning repo reconstructing start 20180824 20180901 timestamp successfully found job attention feature input naive day frequency clearly enough recommended could replace feature content deep deterministic policy gradient ddpg implement ddpg tensorflow arxiv150902971 continuous control deep reinforcement learning double dqn implement doubledqn tensorflow arxiv150906461 deep reinforcement learning double qlearning duelingdqn implement duelingdqn tensorflow arxiv151106581 dueling network architecture deep reinforcement learning policy gradient implement policy gradient tensorflow nip vol 99 1999 policy gradient method reinforcement learning function approximation darnn dualattnrnn implement arxiv170402971 darnn tensorflow arxiv170402971 dualstage attentionbased recurrent neural network time series prediction trenet hnn implement trenet tensorflow ijcai 2017 hybrid neural network learning trend time series naivelstm lstm implement simple lstm based model tensorflow arxiv150602078 visualizing understanding recurrent network environment basic simulate environment financial market implemented market implement market trader position gym env gym required give env regression sequence data generating rl sl model market support stock data future data also function updating experiment deep deterministic policy gradient ddpg doubledqn duelingdqn policy gradient pg train agent trade stock market using stock data set 20120101 20180101 70 training data 30 testing data total profit baseline profit test set darnn dualattnrnn naivelstm lstm trenet hnn train predictor predict stock price using stock data set 20080101 20180101 70 training data 30 testing data price prediction experiment 4 bank stock test set requirement start testing following requirement needed python35 tensorflow14 numpy scipy panda rqalpha sklearn tushare matplotlib mongoengine cuda option talib option docker option pytorch option best docker user run whole project without installing dependency manually also use ansible run cudaplaybook dockerplaybook install cuda nvidiadocker want run test docker container use use docker base image image repo ceruleanwangpersonae persona inherited ceruleanwangquantbase image ceruleanwangquantbase inherited nvidiacuda80cudnn6runtime please make sure cuda version cudnn version correct instruction first make sure stock data mongodb dont use spider writen repo crawl stock future data start make sure mongodb service running dont mongodb service running also use mongodb container option following code docker run p 2701727017 v datadbdatadb networkyournetwork mongo use spider crawl stock data following code docker run v localprojectdirdockerprojectdir networkyournetwork ceruleanwangpersonae spiderstockspiderpy also crawl future data following code docker run v localprojectdirdockerprojectdir networkyournetwork ceruleanwangpersonae spiderfuturespiderpy remember set stock future code want crawl default stock code stockcodes 600036 601328 601998 601398 default future code futurecodes au88 rb88 cu88 al88 modified default args parser run model docker run v localprojectdirdockerprojectdir networkyuornetwork ceruleanwangpersonae algorithmrl slalgorithmnamepy use conda create env install python35 dependency required run algorithm way one thing noticed hostname mongoengine config training testing model implemented tensorflow support persistence edit many parameter training testing model example following code show parameter could edited env marketcodes startdate20080101 enddate20180101 market market mixindexstate true trainingdataratio trainingdataratio algorithm algorithmtfsessionconfigconfig env envtraderactionspace envdatadim mode mode episode episode enablesaver true enablesummarywriter true savepath ospathjoincheckpointsdir rl modelname market model summarypath ospathjoincheckpointsdir rl modelname market summary todo implementation paper highfrequency stock data\n",
      "[0 0 0 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 0]\n",
      "diyhue hue bridge emulator project emulates philip hue bridge able control zigbee light using raspbee module original hue bridge ikea tradfri gateway milight bulb using milight hub neopixel strip ws2812b sk6812 cheap esp8266 based bulb replacing firmware custom one written python run small device raspberry pi arduino sketch provided hue dimmer switch hue tap switch hue motion sensor light twoway synchronized change made original philipstradfri sensor switch also applied bridge emulator masterrefactor detail newest version diyhue ha numerous change compare old version understand using version result thing breaking breaking change made listed something doe break listed please make issue debug log look config incompatible master branch migrated comparing old new config manually config stored config please use mounting config directory docker installation method besides docker unsupported docker available platform including raspberry pi getting started documentation instruction found diyhuereadthedocsio requirement python 3 python module ws4py request astral pahomqtt see requirementstxt docker recommendation hue essential phone app remote control entertainment effect ws2812 strip wemos d1 mini board cool entertainment affect raspberrypi 3b connected via ethernet port network bridge emulation avoid using 2 interface time working hue feature control light function control group function scene function routine wake go sleep switch custom esp8266 switch autodiscover light hue entertainment working device application amazon alexa control light logitech harmony tradfri gateway hue bridge original emulator home assistant domoticz openhab philip ambilight tv kodi hue ambilight jeedom hue sync pc deconz zigbee2mqtt see mqtt working smartphone application hue official application hue essential recommended huemanic onswitch hueswitcher lampshade working home away future hue app requires remote api google home requires remote api eneco toon likely us cloud service detection supported light device ws2812b sk6812 smart led strip milight yeelight lyt8266 phillips hue ikea tradfri pwm rgbcct pwm rgbw pwm rgb pwm cct pwm dimming 6 light every esp8266 onoff plugslights 6 light every esp8266 onoff 433mhz device multiple device every esp8266 mqtt light see mqtt hyperionng sonsoff tx t3 u 123c 1 3 button esp8266 alarm horn schematic alarm email notification eps8266 horn support need help diyhue get support user aswell maintainer fast live support board might already fix answer ready look since slack faster providing live support good come save show known issue kindly ask open topic discourse group provide help others future note please provide log make easier u enable debug manually starting diyhue additional debug true argument diyhue opensource maintained volunteer free time welcome contribute become recognised member diyhue community stability light house controlled solution stability important turning back classic illumination switch replaced ikea tradfri remote hole covered however dont use function im unable perform full test every change currently use deconz tradfri device light sensor xiaomi motion sensor native esp8266 bulb esp8266 ws2812b strip xiaomi yeelight color bulb please post slack team deviceapplication find work emulator check doc detail push update fast want notified watch repo contribution welcome hue living color light project 3d printing thingiverse 2773413 qthue also may want see new project qthue provides simple user interface controlling light credit ben cheesemarathon fancy github integration stephan van rooij zigbee2mqtt integration avinashraja98 hue entertainment server federico zivolo fezvrasta internal webgui j3n50m4t yeelight integration martin cerny mcer12 yeelight color bulb probonopd httpsgithubcomprobonopdesp8266hueemulator sidoh httpsgithubcomsidohesp8266milighthub stefanbruens httpsgithubcomstefanbruensesp8266newpwm cedric ticed35 linkbutton implementation cheesemarathon help docker image mevel 433mhz device nikfinn99 pcb design crankyoldgit ir remote library\n",
      "[0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1\n",
      " 1 0 1]\n",
      "lain lain docker paas devops startup iaa idc latest release 211 release note quick start curl fssl httpsgithubcomlaincloudlainarchivev211targz tar xf cd lain211 vagrant config dns local shell sudo bash c echo 19216877201 consolelainlocal etchosts console httpconsolelainlocal install lain lain app demo lain contributor qiangning hong jia mi flex tachikoma cloudfly baijian pan li meng wenbin chaoyiwang zhuoyun wei xu tao chang cheng xu yunnan zhang kai xu zhuofu luo libin license lain licensed mit license\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "archived content repo merged ipfsjsipfs please open issue submit pr javascript http client library ipfs implementation client library ipfs http api implemented javascript client library implement interfaceipfscore enabling application change embedded jsipfs node remote ipfs node without change code addition client library implement set utility function lead maintainer alan shaw table content lead maintainer table content install running daemon right port importing module usage importing submodule usage web browser cors custom header global timeouts usage api file graph network node management additional option instance utils static type utils glob source globsourcepath option example url source urlsourceurl example development testing contribute historical context license install module us nodejs installed npm npm install save ipfshttpclient support current active lts version nodejs please see nodejsorg currently running daemon right port interact api need local daemon running need open right port 5001 default used example set whatever need show ipfs config api port check correct ipfs config addressesapi ip4127001tcp5001 set doe match output ipfs config addressesapi ip4127001tcp5001 restart daemon changing config run daemon ipfs daemon importing module usage const ipfsclient requireipfshttpclient connect ipfs daemon api server const ipfs ipfsclienthttplocalhost5001 default nodejs connect multiaddr const ipfs ipfsclientip4127001tcp5001 using option const ipfs ipfsclient host localhost port 5001 protocol http specifying specific api path const ipfs ipfsclient host 1111 port 80 apipath ipfsapiv0 importing submodule usage const bitswap requireipfshttpclientsrcbitswapip4127001tcp5001 const list await bitswapwantlistkey web browser browserify nodejs browserify code serving see browserify repo see example example folder get boilerplate webpack see example example folder get idea use jsipfshttpclient webpack cdn instead local installation browserification may request remote copy ipfs api unpkg cdn always request latest version use following script srchttpsunpkgcomipfshttpclientdistindexminjsscript note remove min url get humanreadable minified version maximum security may also decide reference specific version ipfs api prevent unexpected breaking change newer latest version published generate sri hash version use ensure integrity set cors setting attribute make anonymous request cdn example script srchttpsunpkgcomipfshttpclient900distindexjs integritysha3845bxrcw9kyxxnsmboohzraqa7z0pqwiaocgeg327zit1hz5lzcebimxlwkpreub crossoriginanonymousscript cdnbased ipfs api provides ipfshttpclient constructor method global window object example const ipfs windowipfshttpclient host localhost port 5001 omit host port client parse windowhost use information also work useful want write apps run multiple different gateway const ipfs windowipfshttpclient cors web browser ipfs http client either browserified cdnbased might encounter error saying origin allowed would cors cross origin resource sharing failure ipfs server designed reject request unknown domain default whitelist domain calling changing ipfs config like ipfs config json apihttpheadersaccesscontrolalloworigin httpexamplecom ipfs config json apihttpheadersaccesscontrolallowmethods put post get custom header wish send custom header request made library example authorization header use config const ipfs ipfsclient host localhost port 5001 protocol http header authorization bearer token global timeouts set global timeout request pas value timeout option timeout 10 second const ipfs ipfsclient timeout 10000 timeout 2 minute const ipfs ipfsclient timeout 2m see httpswwwnpmjscompackageparseduration valid string value usage api jsipfshttpclient follows spec defined interfaceipfscore concern interface expect ipfs implementation interface currently active endeavor use today consult method available file regular file api ipfsadddata option ipfscatipfspath option ipfsgetipfspath option ipfslsipfspath mf mutable file system specific ipfsfilescpfrom ipfsfilesflushpath ipfsfileslspath option ipfsfilesmkdirpath option ipfsfilesmvfrom ipfsfilesreadpath option ipfsfilesrmpath option ipfsfilesstatpath option ipfsfileswritepath content option explore mutable file system interactive coding challenge protoschool tutorial block ipfsblockgetcid option ipfsblockputblock option ipfsblockstatcid ref ipfsrefsipfspath option ipfsrefslocal graph dag ipfsdaggetcid path option ipfsdagputdagnode option ipfsdagtreecid path option explore dag api interactive coding challenge protoschool tutorial object ipfsobjectdatamultihash option ipfsobjectgetmultihash option ipfsobjectlinksmultihash option ipfsobjectnewtemplate ipfsobjectpatchaddlinkmultihash daglink option ipfsobjectpatchappenddatamultihash data option ipfsobjectpatchrmlinkmultihash daglink option ipfsobjectpatchsetdatamultihash data option ipfsobjectputobj option ipfsobjectstatmultihash option pin ipfspinaddhash option ipfspinlshash option ipfspinrmhash option network bootstrap ipfsbootstrapaddaddr option ipfsbootstraplist ipfsbootstraprmaddr option bitswap ipfsbitswapstat ipfsbitswapwantlistpeerid ipfsbitswapunwantcid dht ipfsdhtfindpeerpeerid ipfsdhtfindprovshash ipfsdhtgetkey ipfsdhtprovidecid ipfsdhtputkey value pubsub ipfspubsublstopic ipfspubsubpeerstopic ipfspubsubpublishtopic data ipfspubsubsubscribetopic handler option ipfspubsubunsubscribetopic handler swarm ipfsswarmaddrs ipfsswarmconnectaddr ipfsswarmdisconnectaddr ipfsswarmpeersoptions name ipfsnamepublishaddr option ipfsnamepubsubcancelarg ipfsnamepubsubstate ipfsnamepubsubsubs ipfsnameresolveaddr option node management miscellaneous operation ipfsdnsdomain ipfsid ipfspingid option ipfsstop alias ipfsshutdown ipfsversion config ipfsconfiggetkey ipfsconfigreplaceconfig ipfsconfigsetkey value ipfsconfigprofileslist ipfsconfigprofilesapplyname option stats ipfsstatsbitswap ipfsstatsbwoptions ipfsstatsrepooptions log ipfsloglevelsubsystem level option ipfslogls ipfslogtail repo ipfsrepogcoptions ipfsrepostatoptions ipfsrepoversion key ipfskeyexportname password ipfskeygenname option ipfskeyimportname pem password ipfskeylistoptions ipfskeyrenameoldname newname ipfskeyrmname additional option core api method take additional option specific http api header object header instance used set custom http header note option also configured globally via constructor option signal abortsignal used abort request demand timeout number string specifying timeout request timeout reached data received timeouterror thrown number specified interpreted millisecond string passed intepreted according parseduration note option also configured globally via constructor option searchparams object urlsearchparams instance used add additional query parameter query string sent request instance utils ipfsgetendpointconfig call client instance return object containing host port protocol apipath static type utils aside default export ipfshttpclient export various type utility included bundle buffer multiaddr multibase multicodec multihash cid globsource available browser urlsource accessed like example const cid requireipfshttpclient esmodule import cid ipfshttpclient glob source utility allow file file system easily added ipfs globsourcepath option path path single file directory glob option optional option optionsrecursive path directory use option recursive true add directory subdirectory optionsignore exclude file glob directory use option ignore ignorethisfolder andthisfile optionshidden hiddendot file file folder starting example git included default add use option hidden true return async iterable yield path content object suitable passing ipfsadd example const ipfshttpclient requireipfshttpclient const globsource ipfshttpclient const ipfs ipfshttpclient await const file ipfsaddglobsourcedocs recursive true consolelogfile path docsassetsanchorjs cid cidqmvhxrocowguchlevfeyduud6qj4phddl2dtlcpuy3dsc2 size 15347 path docsassetsbassaddonscss cid cidqmpilwkd6ysemwdtghegb8t7wvs7zwgygyvfj7dgnt2viq size 232 url source utility allow content internet easily added ipfs urlsourceurl url string url url instance send http get request return async iterable yield path content object suitable passing ipfsadd example const ipfshttpclient requireipfshttpclient const urlsource ipfshttpclient const ipfs ipfshttpclient await const file ipfsaddurlsourcehttpsipfsioimagesipfslogosvg consolelogfile path ipfslogosvg cid cidqmtqzhr6f7jzdhlgpardpnsbzpvvgxzczycxk7ywklxsyu size 3243 development testing run test executing npm test terminal window run nodejs browser test chrome phantomjs ensure module conforms interfaceipfscore spec run batch test provided interface module found contribute jsipfshttpclient work progress thing right help check existing issue perform code review eye help speed project along b ensure quality c reduce possible future bug add test never enough test note interface test exist inside interfaceipfscore contribute faq repository question ipfs relevant technology good example would asking merkledag tree dont know term odds someone else doesnt either eventually good understanding need improve communication teaching together make ipfs ipns better want hack ipfs historical context module started direct mapping goipfs cli javascript implementation although wa useful familiar lot developer coming ipfs first time also created confusion operate core ipfs access full capacity protocol much consideration decided create interfaceipfscore goal standardizing interface core implementation ipfs keep utility function ipfs community learned use love reading file disk storing directly ipfs license mit\n",
      "[1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 0 1]\n",
      "ng6 de facto starter repo building scalable apps angular es6 webpack repo serf minimal starter looking get upandrunning angular es6 using gulp webpack build process seed yeoman generator minimal starter task building boilerplate feature best practice directoryfile organization angular allowing infinite horizontal app scaling readytogo build system working es6 task generating additional boilerplate angular component full testing system place sas support via nodesass check jspm versionan alternative webpack es6 build system youre looking preliminary angular 2 build please use angular2webpackstarter table content walkthrough build system file structure testing setup getting started dependency installing running app gulp task testing generating component starter kit support question walkthrough build system ng6 us npm script gulp webpack together build system yes dont need gulp youre using webpack true build system responsible file manipulation however webpack handle filerelated concern transpiling es6 es5 babel loading html file module transpiling stylesheets appending dom refreshing browser rebuilding file change hot module replacement transpiled stylesheets bundling app loading module specjs file well gulp orchestrator starting calling webpack starting development server yes webpack generating boilerplate angular app check jspm versionan alternative webpack es6 build system file structure use componentized approach ng6 eventual standard particularly helpful using angulars new router well great way ensure tasteful transition angular 2 time ripe everythingor mostly everything well explore belowis component component selfcontained concernmay feature strictlydefined everpresent element ui header sidebar footer also characteristic component harness stylesheets template controller route service spec encapsulation allows u comfort isolation structural locality look client app appjs app entry file apphtml app template common functionality pertinent several component propagate directory component component live componentsjs component entry file home home component homejs home entry file route configuration declaration occur homecomponentjs home directive homecontrollerjs home controller homescss home style homehtml home template homespecjs home spec entry component controller testing setup test also written es6 use webpack take care logistics getting file run various browser like client file testing stack karma webpack babel mocha chai run test type npm test terminal read testing getting started dependency tool needed run app node npm installing fork repo clone fork npm install install dependency running app ng6 us gulp build launch development environment installed dependency may run app running npm start bundle app webpack launch development server watch file port displayed terminal task list available task npm run build run webpack transpile concatenate compress collectively bundle asset module distbundlejs also prepares indexhtml used application entry point link asset created dist version application npm run serve start dev server via webpackdevserver serving client folder npm run watch alias serve npm start default task run typing gulp without providing argument run serve npm run component scaffold new angular component read usage detail testing run test run npm test karma combined webpack run file matching specjs inside app folder allows u keep test file local componentwhich keep u good faith continuing build app modularly file specbundlejs bundle file spec file karma run sure define specjs file within corresponding component directory must name spec file like namespecjs dont want use specjs suffix must change regex specbundlejs look whatever file want mocha testing suite chai assertion library would like change see karmaconfjs example always easier learn something example list repos based starter todomvc example app generating component following consistent directory structure component offer u certainty predictability take advantage certainty creating gulp task automate instantiation component component boilerplate task generates componentname componentnamejs entry file dependency load componentnamecomponentjs componentnamecontrollerjs componentnamehtml componentnamescss scoped affect template componentnamespecjs contains passing demonstration test may course create file manually every time new module needed get quickly tedious generate component run npm run component name componentname parameter following name flag name component created ensure unique overwrite preexisting identicallynamed component component created default inside clientappcomponents change apply parent flag followed path relative clientappcomponents example running npm run component name signup parent auth create signup component clientappcomponentsauthsignup running npm run component name footer parent common creates footer component clientappcommonfooter argument name applies folder name actual component name make sure camelcase component name starter kit support question contact u anytime regarding anything project gitter angularclassng6starter twitter patrickjs enjoy patrickjs\n",
      "[0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1\n",
      " 1 1 0]\n",
      "gitrepo git service cli utility get source httpsgithubcomguyzmogitrepo httpsgitlabcomguyzmogitrepo httpsbitbucketorgguyzmogitrepo issue httpsgithubcomguyzmogitrepoissues meet community come chat irc gitrepo freenode matrix gitrepomatrixorg gitter gitservicesgitrepo looking help past month ive really busy coding stuff put food table sadly cannot give project love deserves taken month spend hour merge release pr featured repository im still using project daily im enough time keep putting effort needed make shine ssh key issue support id like share maintenance responsibility someone people youre interested please ping irc mail commits im always happy guide code design usage main command control remote git hosting service git commandline usage simple full usage list source clone new project github issue git hub clone guyzmogitrepo work also project gitlab bitbucket gitlab gogs git lab clone guyzmogitrepo git bb clone guyzmogitrepo git myprecious clone guyzmogitrepo git gg clone guyzmogitrepo want choose default branch clone git lab clone guyzmogitrepo master though sometimes youre starting new project want create new repository push git hub create guyzmogitrepo actually namespace facultative per default want create new repository within account might also want add existing remote ref workspace easily done git lab add guyzmogitrepo add httpsgitlabcomguyzmogitrepo gitlab remote also fork repository using git hub fork neovimneovim course delete using git bb delete guyzmogitrepo also open repository page using open command git lab open guyzmogitrepo successfully fetched branch 2 guyzmogitrepo request2 request merges aka pull request aka merge request youre set repository check request merge aka pull request github using request command git hub request guyzmogitrepo list list open request merge id title url 2 prefer gitrepotargettoken privatekey doc httpsapigithubcomreposguyzmogitrepoissues2 fetch locally check andor amend merging git hub request guyzmogitrepo fetch 2 create request git hub request create guyzmogitrepo myfeature master neat feature much say feature create request also simply calling git hub request create command ha bit automagic lookup namespace project current branch least github remote called hub take source request target request lookup take parent current project ha parent doe take currently loaded branch source default one target call service ask request merge source onto target gist snippet finally another extra feature play gist handling git hub gist list id title httpsgistgithubcom4a0dd9177524b2b125e9166640666737 test gist list file within git hub gist list a7ce4fddba7744ddf335 language size name python 1048 unicodecombinedpy git hub v gist list httpsgistgithubcom4a0dd9177524b2b125e9166640666737 language size name markdown 16 readmemd text 14 license restructuredtext 17 readmerst output locally use fetch command specify file one git hub gist fetch httpsgistgithubcoma7ce4fddba7744ddf335 mygistpy git hub gist fetch 4a0dd9177524b2b125e9166640666737 license licensefromgist thorough modification consulting well clone git hub gist clone 4a0dd9177524b2b125e9166640666737 pulling github successfully cloned 4a0dd9177524b2b125e9166640666737 4a0dd9177524b2b125e9166640666737 youre done get rid git hub gist f delete 4a0dd9177524b2b125e9166640666737 successfully deleted gist nota bene thanks git cli flexibility installing gitrepo directly access tool using gitrepo hub git repo hub git hub call set alias see configure remote traditionally origin used remote name code hosted service nature gitrepo single origin encourages use multiple one also leave control wherever origin point clone service create new repo service using special remote carry name service git hub clone foobar cd bar git status sb head 1 mastergithubmaster git lab create bar git push gitlab master bonus time adding new remote updating remote push code remote repository one command git push master another special remote upstream fork project current special remote service name renamed upstream newly forked project one service name git lab clone foobar cd bar git remote gitlab git lab fork git remote gitlab upstream finally want link existing project add command git bb add foobar name identical current project dont need add name git hub add git gg add foobar gitea alone use alone switch dont want add project special remote course command sugar around regular git command also done git remote add gitbucket httpsgitbucketlocal8080foobar command append url remote alone skip step git remote seturl add httpsgitbucketlocal8080foobar remove remote git remote remove github installation get tool using pypi use pip3 python2 python3 installed pip install gitrepo getting source running python3 setuppy install configuration configure gitrepo simply call following command git repo config wizard run getting authentication token service add command alias name remote though configuring custom service still handled wizard prefer manual configuration youll tweak gitconfig service youve got account make section gitconfig gitrepo gitlab token yourverysecretkey gitrepo github token yourotherverysecretkey gitrepo bitbucket username fordprefect token yoursecretappkey gitrepo gogs fqdn urlofyourgogs token yourverysecretkey setting basic private token notice token needed bitbucket apptoken confused oauthtoken also avaiable butbucket setting also ability set alias gitrepo bitbucket alias bit username fordprefect token yoursecretappkey change command use name youll prefer handle action service use gitrepo bit clone guyzmogitrepo also setup gitlab selfhosted server using configuration gitrepo myprecious type gitlab token yoursuperprivatekey fqdn gitlabexampleorg set use selfsigned certificate experience problem insecure true finally make really cool make alias gitconfig alias hub repo hub lab repo lab bb repo bb perso repo perso run tool git subcommand git hub clone guyzmogitrepo like keep dotfiles git repository itd horrendous store token offer access social account repository im even talking want share dotfiles dont worry configured fire favorite editor move gitrepo section new file like gitconfigrepos run following command automagically python gitrepoextractconfig want use another path change default python gitrepoextractconfig gitconfigrepos gitconfig configuring gerrit please note configuration wizard ask password provide gerrit account password enter http password instead setup setting http password page may also need tweak gitconfig set rosuffix gerrit isnt served server root example set rosuffix r gerrit hosted httpsreviewhostcomr set sshport parameter set custom port ssh connection gerrit default 29418 set authtype basic default digest development development start virtualenv within install devel requirement virtualenv var varbinpip install r requirementstesttxt youll executable bin varbingitrepo help run test varbinpytest covgitrepo covreport termmissing capturesys test nb buildout longer supported development verbose running repeat v argument several time increase level verbosity gitrepo argument give detail youll v set debugging level debug giving execution info vv print git command executed vvv give verbose insight git layer vvvv output http exchange different apis vvvvv printout parsed argument testing run test binpytest use following option pytest help debug test fail v show detail upon error x stop upon first failure pdb launch debugger exception ha launched test use recording exchanged http data dont need real credential real connection testing api minor change recording called cassette thanks betamax framework use test suite running existing test based provided cassette dont need setting also youve got configuration gitconfig test use anyway use environment variable setting environment variable precedence configuration setting use credential setup following environment variable githubnamespace default notconfigured name account use github gitlabnamespace default notconfigured name account use gitlab bitbucketnamespace default notconfigured name account use bitbucket gogsnamespace default notconfigured name account use gogs privatekeygithub private token youve setup github account privatekeygitlab private token youve setup gitlab account privatekeybitbucket private token youve setup bitbucket account privatekeygogs private token youve setup gogs account todo make gitrepo fork action make possible choose method ssh http handle default branch properly make nice way push remote refactor code multiple module add regression test actually find smart way implement add travis build show nice progress bar fetching cf 15 add support handling gist cf 12 cf 13 add support handling pull request cf 10 11 add application token support bitbucket cf 14 add support gogs cf 18 add support gitbucket cf 142 add support managing ssh key cf 22 add support issue cf 104 add support gerrit cf 19 whats needed make nice documentation 146 feature write issue even better pr contributor project original idea ha brought maintained bernard guyzmo pratz commits code contribution coming pyhedgehog commits guyhughes commits buaazp commits peterazmanov commits crazybus commits rnestler commits jayvdb commits kounoike commits amandacameron commits fa7ad commits license copyright 20162017 bernard guyzmo pratz guyzmogitrepopubm0gnet program free software redistribute andor modify term gnu general public license published free software foundation either version 2 license option later version program distributed hope useful without warranty without even implied warranty merchantability fitness particular purpose see gnu general public license detail received copy gnu general public license along program write free software foundation inc 51 franklin street fifth floor boston 021101301 usa see license file full license\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1]\n",
      "php report reporting framework managing displaying nice looking exportable report data source including sql mongodb major feature include display report data source output tabular data sql mongodb php etc output report html xml csv json custom format add customizable parameter report eg start date end date add graph chart google data visualization api support multiple database environment eg production staging dev fully extendable customizable installation instruction documentation check httpjdorngithubiophpreports question post official forum httpostiojdornphpreports basic introduction report organized grouped directory report file report consists header containing metadata eg name description actual report sql query javascript php code report return row data displayed sortablesearchable html table report exported number format including csv xl json xml php report framework tie together different report type output format metadata consistent interface example report example sql report product cost least x variable name minprice select name price product price minprice set sql comment top report header first row always report name variable header tell report framework prompt user value running report provided passed report body minprice example executed mongodb report list food option mongodatabase mydatabase variable name includeinactive display include inactive type select option yesno var query type food ifincludeinactive querystatus active var result dbproductsfindquery printjsonresult see structure similar mongodb report use javascript style comment header everything else remains populate db variable specifying mongodatabase option php report php list payment charge connects stripe payment api show list charge include stripephp variable name count display number display ifcount 100 count 1 throw new exceptioncount must 1 100 charge stripechargeallarraycount count row array foreachcharges charge row array charge idchargeid amountnumberformatchargeamount1002 datedateymdchargecreated echo jsonencoderows header format similar include header includes another report within running one example content stripephp php stripe php included report header even nested include header header even bubble parent variable header include stripe api client requireoncelibstripestripephp set stripe api key stripesetapikey123456 hopefully begin see power php report full documentation information getting started check httpjdorngithubiophpreports\n",
      "[1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0\n",
      " 0 0 0]\n",
      "celebration 1k star repo starhistory chrome extension 67 099 star history missing star history graph github repos website extension note load extension folder chrome install extension access token starhistory use github api retrieve repository metadata user exceed rate limit unauthenticated request starhistory need personal access token unlimit dont already one create one add starhistory scope personal data needed develop website npm run startwebsite extension npm run buildextension load extension folder unpacked extension chrome view build deploy website deploy starhistoryt9tio npm run deploywebsite extension npm run buildextension zip extension folder publish chrome web store update 2019828 use chartxkcd plot graph 2019306 add personal access token update style mono repo 2016630 alert notie 2016628 add clear btn 2016628 better view many star repos use current star number last point graph 2016626 store repo info url hash 2016626 multiple kind input style eg githubcomtimqianstarhistory 2016626 better view le star repos 28 2016614 toggle search hit enter 26 prevent crash searching existing repo 2016526 update mobile view\n",
      "[1 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0]\n",
      "dockercasts companion repo course udemycom\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "djangoreportbuilder gui django orm build custom query display result target sys admins capable end user might able program gain direct interactive shell access call sponsorship fan report builder using workplace please consider sponsorship may donate liberapay directly contact sponsoring feature right need better documentation get profile company logo added readme sponsor paid commercial support also available email infoburkesoftwarecom infomation news 64 added django 30 31 support django 111 22 still supported likely last release support 111 632 fixed admin widget thanks predatell angular updated version 8 63 added django 22 support django 111 21 still supported unit test finally run python 37 thanks celery supporting angular updated version 7 view changelog django report builder feature add filter add display field preview create xlsx report us django permission model staff user must change view permission view report unprivileged user still build report see database schema report builder intended generally trusted staff user requires isstaff set export report global admin action scheduled report generate send user cron like schedule optional asynchronous report generation documentation httpdjangoreportbuilderreadthedocsorg google group contributing development quick start package us django docker angular cli development purpose start docker dockercompose migrate create admin user dockercompose run rm web managepy migrate start angular cli server ensure node installed cd j yarn yarn start django run port 8000 default go localhost8000admin log angular run port 4200 logged go localhost4200 detailed instruction\n",
      "[1 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1\n",
      " 0 0 0]\n",
      "urwid urwid console user interface library python includes many feature useful text console application developer including application resize quickly smoothly automatic programmable text alignment wrapping simple markup setting text attribute within block text powerful list box programmable content scrolling widget type choice event loop twisted glib tornado selectbased loop prebuilt widget include edit box button check box radio button display module include raw curse experimental lcd web display support utf8 simple 8bit cjk encoding 24bit true color 256 color 88 color mode support compatible python 27 35 pypy home page httpurwidorg installation install using pip pip install urwid alternatively debian ubuntu aptget install pythonurwid testing run test locally install run tox must appropriate python version installed run tox test code python version tox test version specified toxini tox e py36 test python 36 tox e py27py36pypy test python 27 python 36 pypy supported python version 27 35 36 37 38 pypy author creator wardi maintainer and3rson tonycpsu ulidtko contributor 1in7billion abadger agrenott akorb alethiophile aleufroy alobbs amjltc295 andsemakin andrewshadura andyz anttin2020 apteryks arfrever autoawesome belak berney bk2204 bkphcgql3v bwesterb carlosjenkins certseeds chipsterjulien chrisspen cltrudeau codebergasgithubalternativebuhtz cortesi d0cs4vage derdon dholth dimays dlo dnaeon doddo douglaslarocca drestebon dsotr dwf edwardbetts elenril enricobilla extempore fabiand floppym flowblok fmoreau goncalopp gordin gregingelmo grzaks gurupras harveyhunt hoolean hukka hydratim ids1024 imrek isovector itaisod ixxra jeblair johndeaton jonblack jspricke kedder kelketek kennethnielsen kesipyc kkrolczyk kwpolska lahorde laike9m larsks lfam lgbaldoni lighth7015 livibetter lothiraldan madness madebr magniff marloxouda mattymo mdtrooper mgk mimi1vx mobyte0 monaaraj monthlypython mountainstorm mselee mwhudson naquad nchavez324 neumond nolash ntamas nyov ocarneiro okayzed pquentin rbanffy reddykilowatt regebro renegarcia rianhunter roburban rrmoelker rwarren scopatz seanhussey seonon shadedke sithglan sjc1000 sporkexec squrky ssbr techdragon thehunmonkgroup thisch thornycrackers tomastomecek tompickering tony ttanner tu500 uspike vega0 vit1251 waveform80 wesmania xandfury xndcn zhongshangwu zrax\n",
      "[0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1\n",
      " 0 0 0]\n",
      "deepgcns gcns go deep cnns work present new way successfully train deep gcns borrow concept cnns mainly residualdense connection dilated convolution adapt gcn architecture extensive experiment show positive effect deep gcn framework project paper slide tensorflow code pytorch code overview extensive experiment show different component layer filter nearest neighbor dilation etc effect deepgcns also provide ablation study different type deep gcns mrgcn edgeconv graphsage gin information detail please contact guohao li matthias muller requirement tensorflow 1120 h5py vtk needed visualization jupyter notebook needed visualization conda environment order setup conda environment neccessary dependency run conda env create f environmentyml getting started find detailed instruction use code semantic segmentation 3d point cloud folder semseg currently provide following conda environment setup s3dis dataset training code evaluation code several pretrained model visualization code citation please cite paper find anything helpful inproceedingsli2019deepgcns titledeepgcns gcns go deep cnns authorguohao li matthias muller ali thabet bernard ghanem booktitlethe ieee international conference computer vision iccv year2019 miscli2019deepgcnsjournal titledeepgcns making gcns go deep cnns authorguohao li matthias muller guocheng qian itzel c delgadillo abdulellah abualshour ali thabet bernard ghanem year2019 eprint191006849 archiveprefixarxiv primaryclasscscv license mit license acknowledgement code heavily borrowed pointnet edgeconv would also like thank 3dsemanticsegmentation visualization code\n",
      "[0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 1 1]\n",
      "deprecated use headless ui instead tailwinduivue project still prealpha state could change dramatically time production set completely unstyled fully accessible ui component vuejs designed integrate beautifully tailwind cs bring style markup handle complex keyboard interaction aria management installation npm npm install tailwinduivue yarn yarn add tailwinduivue usage listbox basic example template listbox vmodelselectedwrestler vslot isopen listboxlabel classsronly select wrestler listboxlabel listboxbutton classrounded p3 border selectedwrestler listboxbutton listboxlist vshowisopen listboxoption vforwrestler wrestler keywrestler valuewrestler vslot isactive isselected div classp3 classisactive bgblue600 textwhite bgwhite textgray900 wrestler img vshowisselected srccheckmarksvg div listboxoption listboxlist listbox template script import listbox listboxlabel listboxbutton listboxlist listboxoption tailwinduivue export default component listbox listboxlabel listboxbutton listboxlist listboxoption data return selectedwrestler ultimate warrior wrestler ultimate warrior randy savage hulk hogan bret hart undertaker mr perfect ted dibiase bam bam bigelow yokozuna script\n",
      "[1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 0 0 0]\n",
      "react react javascript library building user interface declarative react make painless create interactive uis design simple view state application react efficiently update render right component data change declarative view make code predictable simpler understand easier debug componentbased build encapsulated component manage state compose make complex uis since component logic written javascript instead template easily pas rich data app keep state dom learn write anywhere dont make assumption rest technology stack develop new feature react without rewriting existing code react also render server using node power mobile apps using react native learn use react project installation react ha designed gradual adoption start use little much react need use online playground get taste react add react website script tag one minute create new react app youre looking powerful javascript toolchain use react script tag cdn react package npm documentation find react documentation website check getting started page quick overview documentation divided several section tutorial main concept advanced guide api reference get support contributing guide improve sending pull request repository example several example website first one get started function hellomessage name return divhello namediv reactdomrender hellomessage nametaylor documentgetelementbyidcontainer example render hello taylor container page youll notice used htmllike syntax call jsx jsx required use react make code readable writing feel like writing html youre using react script tag read section integrating jsx otherwise recommended javascript toolchains handle automatically contributing main purpose repository continue evolving react core making faster easier use development react happens open github grateful community contributing bugfixes improvement read learn take part improving react code conduct facebook ha adopted code conduct expect project participant adhere please read full text understand action tolerated contributing guide read contributing guide learn development process propose bugfixes improvement build test change react good first issue help get foot wet get familiar contribution process list good first issue contain bug relatively limited scope great place get started license react mit licensed\n",
      "[1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0\n",
      " 0 0 0]\n",
      "createopenapirepo generate organized multifile openapi repository hello need write contribute openapi definition read recommend docslikecode approach openapi definition write using favorite texteditor ide love vscode organize multiple file folder make easy navigate store using source control github continuously validate using free openapicli tool free continuous validation service coming soon bundle smaller footprint use tool tool support multifile format advantage hosting api definition github community engagement pr issue public repo advertisment github community hosting github page perfect uptime cdn jekyll custom domain cname revision history branching ci review approval workflow using pull request fast onboarding time developer tech writer know use github fully compatible redocly api reference also advantage multifile yaml format openapi definition reuse schema object keep thing dry dont repeat smaller diffs compared json especially markdown description easier navigate easier edit confidence feature generator help create github repo following feature split big small openapi definition smaller file organized folder bundle single file deployment continuous integrationdeployment travis redocly workflow code sample separate file automate deployment openapi definition doc openapi definition validated commit live editing editor choice structure structure similar redoclyyaml license readmemd doc faviconpng indexhtml openapi readmemd codesamples c echo postcs php echo postphp readmemd component readmemd path readmemd packagejson however adjust structure prefer openapi folder openapi definition live inside subfolders readmemd file help guide also entrypoint openapiyaml live component folder organize subfolders schema define schema path folder organize path readmemd file suggestion organize specially named file folder use place file cannot character also able use path parameter wrapping curly brace example redoclyyaml file universal configuration various redocly tool including lint tool reference doc engine command generated repository includes installing dependency openapicli tool support command validate bundle scripted shortcut defined repository packagejson example generated repository httpsgithubcomrebillyrebillyapi httpsgithubcomthingfulopenapispec httpsgithubcomtwinehealthtwinedeveloperdocs generate repository assume already nodejs installed install createopenapirepo globally npm install g createopenapirepo use npx well use npx example however remove npx installed globally npx createopenapirepo presented question create new definition use existing definition initialize project please note start new one remember create github repo openapi definition live use prior version generated repository please read following upgrade instruction upgrading prior version migrate repository previous structure openapi repo newer structure migration tool run root folder repo npx createopenapirepo migrate23 note migration tool doe migrate plugins automatically would need manually add transformer folder support thank wanting support u idea support u star u tell friend colleague u tweet u write article let u know open issue let u know link consider commercial product looking automation ease docslike code workflow hosting along convenience like custom domain access control preview api reference documentation full developer portal httpsredocly\n",
      "[1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1\n",
      " 0 0 0]\n",
      "practical tensorflow repository deepctr deepfmwidendeepfnnpnnnfmafmdeep cross networkctr deeprl deepreinforcement learing deepmtl multitask learning deeptxt dssm welcome pull request\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "rasa core deprecated code part rasa repo httpsgithubcomrasahqrasa please create pull request issue license licensed apache license version 20 copyright 2019 rasa technology gmbh copy license list license dependency project found bottom library summary\n",
      "[0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0]\n",
      "nature code book project repo longer active follow project visit nocbook2 hello found way found raw source material nature code book book sale pdf print form natureofcodecom youll also find free version book available html may notice book content illustration raw text html well design element cs book licensed creative common attributionnoncommercial 30 unported license free share remix book long provide attribution attempt resell book code example licensed mit license using github host raw material book hope able easily manage correction revision please use github issue bug report typo suggestion etc also welcome fork repo make correction submit pull request repository progress new edition book generating magic book previous version book check nature code archived repo step build nature code install nodejs terminal prompt info npm install magicbook g clone download repo terminal navigate directory cloned repo enter command npm install magicbook build navigate build directory look generated file build note mac osx need install princexml along nodeprince brew cask install prince download via information magic book readme\n",
      "[0 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 1 0 0 1 1\n",
      " 0 1 0]\n",
      "mongocasts example course found within repo either look file completed state check change made particular section clicking one link\n",
      "[0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "halloffame halloffame help show love contributor automatically highlight new trending top contributor update every hour put widget anywhere inside readme eg contributing section maintenance required work every hour halloffame look recent commits repo using github api selects three category contributor new made first commit repo last 7 day trending commits last 7 day top commits time selects three new contributor 4 trending contributor total le 7 fill remaining spot top contributor contributor halloffame represented avatar badge newtrendingtop corresponding number commits avatar link contributor profile mean anyone ha chance prominently featured readme time halloffame work sourcerer httpssourcererio required contributor contributor ha sourcerer profile sourcerer avatar halo used avatar link sourcerer profile dont avatar based github used linked github profile live example iterativedvc ironmussaoptimus epicmaxcovuesticadmin getting started halloffame code entirely open source run google cloud already order add halloffame repository sign sourcererio github httpssourcereriostart go settingshalloffame httpssourcereriosettingshof add repository see code insert readmemd look something like httpssourcereriofameuserownerrepoimages0httpssourcereriofameuserownerrepolinks0 httpssourcereriofameuserownerrepoimages7httpssourcereriofameuserownerrepolinks7 paste code readmemd good go halloffame take care rest note halloffame use github token hourly update via github api count towards github api limit large repo shoud expect dozen request every hour small percentage 5000 hourly limit github set faq q show 7 entry 7 lucky number seriously recognition mean stand hard stand crowd limit 7 strongly feel different number better file issue well consider q reason show new trending top order want halloffame change frequently hence emphasis change last week want immediately exciting first time contributor need new contributor right better make excited q commited dont see face halloffame going refreshes hour sometimes take bit longer wait another possibility enough contributor commits week contributor sorted number commits push another commit increase chance show halloffame contributing contribute halloffame mean live halloffame repo\n",
      "[1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0\n",
      " 1 0 1]\n",
      "spot sdk documentation best viewed via developer site devbostondynamicscom spot sdk develop application payload spot using boston dynamic spot sdk sdk consists conceptual documentation document explain key abstraction used spot api python client library application using python library control spot read sensor health information spot wide variety example program quickstart guide also included payload developer documentation payload add additional sensing communication control capability beyond base platform provides payload icd cover mechanical electrical software interface spot support spot api protocol definition reference guide cover detail protocol application used communicate spot application developer wish use language python implement client speak protocol spot sdk repository github repo spot sdk code hosted version 210 sdk please review release note see ha changed content concept python payload api protocol release note sdk repository\n",
      "[1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1\n",
      " 0 0 0]\n",
      "git filterrepo versatile tool rewriting history includes capability found anywhere else roughly fall space tool git filterbranch without capitulationinducing poor performance far capability design scale usabilitywise beyond trivial rewriting case git filterrepo recommended git project instead git filterbranch user probably use filterrepo simple command line tool likely use flag core filterrepo contains library creating history rewriting tool user specialized need leverage quickly create entirely new history rewriting tool table content prerequisite install use filterrepo instead alternative filterbranch bfg repo cleaner simple example comparison solving filterrepo solving bfg repo cleaner solving filterbranch solving fastexportfastimport design rationale behind filterrepo contribute code conduct upstream improvement prerequisite filterrepo requires git 2220 minimum feature require git 2240 later python3 35 install gitfilterrepo singlefile python script wa done make installation basic use trivial copy path see installmd thing beyond basic usage special case involved instruction needed working python3 executable named something python3 want install documentation beyond builtin doc shown h want run contrib example want create python filtering script using filterrepo modulelibrary use see user manual prefer learning example simple example may interest user manual ha extensive example section cheat sheet converting filterbranch command cover every example filterbranch manual cheat sheet converting bfg repo cleaner command cover every example bfg website filterrepo instead alternative wa covered detail git rev news article filterrepo highlight main competitor filterbranch filterbranch extremely unusably slow multiple order magnitude slower nontrivial repository filterbranch riddled gotchas silently corrupt rewrite least thwart cleanup effort giving something problematic messy started filterbranch onerous use rewrite even slightly nontrivial git project ha stated issue filterbranch cannot backward compatibly fixed recommend stop using filterbranch diehard fan filterbranch may interested filterlamely aka filterbranchish reimplementation filterbranch based filterrepo performant though nearly fast safe filterrepo cheat sheet available showing convert example command manual filterbranch filterrepo command bfg repo cleaner great tool time make thing simple limited kind rewrite architecture amenable handling type rewrite architecture present shortcoming bug even intended usecase fan bfg may interested bfgish reimplementation bfg based filterrepo includes several new feature bugfixes relative bfg cheat sheet available showing convert example command manual bfg repo cleaner filterrepo command simple example comparison let say want extract piece repository intent merging piece bigger repo extraction want extract history single directory src mean path src remain repo commits touched path outside directory removed rename file new leading directory mymodule eg srcfooc becomes mymodulesrcfooc rename tag extracted repository mymodule prefix avoid conflict later merge repo something else solving filterrepo filterrepo simple following command git filterrepo path src tosubdirectoryfilter mymodule tagrename mymodule single quote unnecessary make clearer human replacing empty string prefix mymodule solving bfg repo cleaner bfg repo cleaner capable kind rewrite fact three type wanted change outside capability solving filterbranch filterbranch come pile caveat even figure necessary invocation git filterbranch treefilter mkdir p mymodule git lsfiles grep v src xargs git rm f q l grep v mymodule xargs file mv file mymodule tagnamefilter echo mymodulecat &#9; pruneempty git clone filepwd newcopy cd newcopy git foreachref formatdelete refname refstags grep v refstagsmymodule git updateref stdin git gc prunenow might notice filterbranch invocation really slow due using treefilter could alternatively use indexfilter option filterbranch changing command git filterbranch indexfilter git lsfiles grep v src xargs git rm q cached git lsfiles sed sprintf tmymodule git updateindex indexinfo git lsfiles grep v mymodule xargs git rm q cached tagnamefilter echo mymodulecat pruneempty git clone filepwd newcopy cd newcopy git foreachref formatdelete refname refstags grep v refstagsmymodule git updateref stdin git gc prunenow however either filterbranch command pile caveat first may wondering list five command filterbranch despite use tagnamefilter filterbranchs manpage claiming clone enough get rid old object extra step delete tag another gc still required clean old object avoid mixing new old history pushing somewhere caveat commit message rewritten commit message refer prior commits abbreviated sha1 rewrite message refer commits longer part history would better rewrite abbreviated sha1 reference refer new commit id pruneempty flag sometimes miss commits pruned also prune commits started empty rather ended empty due filtering repository intentionally use empty commits versioning publishing related purpose detrimental command osspecific gnu v bsd issue sed xargs command often trip user think failed get folk use indexfilter since example filterbranch manpage us show move everything subdirectory linuxspecific obvious reader ha portability issue since silently misbehaves rather failing loudly indexfilter version filterbranch command may two three time faster treefilter version filterbranch command going multiple order magnitude slower filterrepo command assume filename composed entirely ascii character even special ascii character tab double quote wreak havoc likely result missing file misnamed file solving fastexportfastimport one kind hack together something like git fastexport nodata reencodeyes marktags fakemissingtagger signedtagsstrip tagoffilteredobjectrewrite grep vp 09 09af src grep vp src perl pe sm 09 09af 1mymodule2 perl pe sd 1mymodule2 perl pe srefstagsrefstagsmymodule git c coreignorecasefalse fastimport dateformatrawpermissive force quiet git foreachref formatdelete refname refstags grep v refstagsmymodule git updateref stdin git reset hard git reflog expire expirenow git gc prunenow come nasty caveat limitation various greps regex replacement operate entire fastexport stream thus might accidentally corrupt unintended portion commit message needed edit file content thus dropped nodata flag could also end corrupting file content command assumes filename repository composed entirely ascii character also exclude special character tab double quote special filename exists within old src directory pruned even though wa intended kept slightly different repository rewrite type editing also risk corrupting filename special character adding extra double quote near end filename leading directory name command leave behind huge number useless empty commits ha realistic way pruning tried combine technique another tool prune empty commits way distinguish commits made empty filtering want remove commits empty filtering process thus may want keep commit message reference commits hash reference old commits longer exist attempting edit commit message update extraordinarily difficult add kind direct rewrite design rationale behind filterrepo none existing repository filtering tool wanted came short need tool provided first eight trait wanted failed provide least one last four trait well starting report provide user analysis repo help get started prune rename instead expecting guess find tool figure triggered eg running first time special flag analyze keep v remove instead providing way user easily remove selected path also provide flag user keep certain path sure user could workaround specifying remove path one want keep need specify path ever existed version repository could sometimes quite painful filterbranch using pipeline like git lsfiles grep v xargs r git rm might reasonable workaround get unwieldy isnt straightforward user plus command often operatingsystem specific spot gnuism snippet provided renaming easy rename path example addition allowing one treat subdirectory root repository also provide option user make root repository become subdirectory generally allow file directory easily renamed provide sanity check renaming cause multiple file exist path add special handling commit merely copied oldnamenewname without modification filtering oldnamenewname doesnt trigger sanity check die commit intelligent safety writing copy original ref special namespace within repo doe provide userfriendly recovery mechanism many would struggle recover using almost everyone ive ever seen repository filtering operation ha done fresh clone wiping clone case error vastly easier recovery mechanism strongly encourage workflow detecting bailing fresh clone unless user override force auto shrink automatically remove old cruft repack repository user filtering unless overridden simplifies thing user help avoid mixing old new history together avoids problem multistep process shrinking repo documented manpage doesnt actually work case im looking filterbranch clean separation avoid confusing user prevent accidental repushing old stuff due mixing old repo rewritten repo together particularly problem filterbranch using tagnamefilter option sometimes also issue filtering subset branch versatility provide user ability extend tool even write new tool leverage existing capability provide extensibility way avoids need fork separate process would destroy performance b avoids making user specify osdependent shell command would prevent user sharing command c take advantage rich data structure hash dicts list array prohibitively difficult shell provides reasonable string manipulation capability sorely lacking shell old commit reference provide way user use old commit id new repository particular via mapping old new hash refsreplace reference commit message consistency commit message refer commits id eg reverts commit 01234567890abcdef commit 0013deadbeef9a commit message rewritten refer new commit id becomeempty pruning commits become empty due filtering pruned parent commit pruned first nonpruned ancestor need become new parent nonpruned ancestor exists commit wa merge becomes new root commit nonpruned ancestor exists commit wa merge merge one le parent thus make likely become nonmerge commit would pruned file change one special thing note prune commits become empty commits start empty project intentionally create empty commits versioning publishing reason removed special case commits started empty whose parent wa pruned away also considered become empty becomedegenerate pruning pruning commits become empty potentially cause topology change lot special case normally merge commits removed since needed preserve graph topology pruning parent ancestor ultimately result loss one parent simple case wa already noted merge commit loses enough parent become nonmerge commit ha file change pruned merge commits also topology becomes degenerate could end mergebase serving parent intervening commits original repo pruned could end one parent ancestor parent case merge ha file change merge commit also pruned however much empty pruning prune merge commits started degenerate indicates may intentional noff merges merge commits become degenerate file change speed filtering reasonably fast contribute see contributing guideline code conduct participant filterrepo community expected adhere standard git project git code conduct applies upstream improvement work filterrepo predecessor ha also driven numerous improvement fastexport fastimport occasionally command core git based thing filterrepo need work git2280 fastimport add new dateformatrawpermissive format git2240 fastexport handle nested tag t9350 add test tag thing commit fastexport allow user request tag marked marktags fastexport add support importmarksifexists fastimport add support new alias command fastimport allow tag identified mark label fastimport fix handling deleted tag fastexport fix exporting tag nothing else gitfastimporttxt clarify multiple merge commits allowed git2230 t9350 fix encoding test actually test reencoding fastimport support encoding commit header fastexport avoid stripping encoding header cannot reencode fastexport differentiate explicitly utf8 implicitly utf8 fastexport automatic reencoding commit message requested git2220 logdifftree add combinedallpaths option t9300 demonstrate bug getmark empty orphan commits gitfastimporttxt fix wording l command appear fastimport check prominent command first fastimport allow catblob request make sense fastimport fix erroneous handling getmark empty orphan commits honor coreprecomposeunicode place git2210 fastexport convert sha1 oid gitfastimporttxt fix documentation quiet option gitfastexporttxt clarify misleading documentation revlist args fastexport use value correct enum fastexport avoid dying filtering path old tag exist fastexport move commit rewriting logic function reuse fastexport using path avoid corrupt stream nonexistent mark fastexport ensure export requested ref fastexport add referenceexcludedparents option fastimport remove unmaintained duplicate documentation fastexport add showoriginalids option show original name gitshowreftxt fix order flag git2200 updateref fix type updateflags variable match usage updateref allow noderef stdin git173 fastexport fix dropping file importmarks path limiting fastexport add fulltree option fastexport fix output order df change fastimport improve robustness df change provided wrong order git164 fastexport set revstopoorder calling setuprevisions fastexport omit tag tag tree fastexport make sure show actual ref name instead null fastexport parent rewriting avoid dropping relevant commits fastexport add tagoffilteredobject option newly dangling tag add new fastexport testcases fastexport document fact gitrevlist argument accepted git163 gitfilterbranch avoid collision variable evaled command correct missing sp character grammar comment top fastimportc fastexport avoid dropping file commits git1614 fastexport ensure traverse commits topological order\n",
      "[1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1]\n",
      "knowledge repo knowledge repo project focused facilitating sharing knowledge data scientist technical role using data format tool make sense profession provides various data store utility manage knowledge post particular focus notebook r markdown jupyter ipython notebook better promote reproducible research information motivation inspiration behind project encourage read medium post documentation httpknowledgereporeadthedocsio source httpsgithubcomairbnbknowledgerepo bug report httpsgithubcomairbnbknowledgerepoissues screenshots\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0]\n",
      "taxitracker repo nyc taxi day life data visualization show movement earnings single nyc taxi 24 hour made 2013 nyc taxi trip data obtained foil request taxi limousine commission\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "script analyze git repos produce cool looking graph like running git installing run pip install gitoftheseus running first need run gitoftheseusanalyze path repo see gitoftheseusanalyze help bunch config analyze repository might take quite time generate plot way run gitoftheseusstackplot cohortsjson write stackplotpng run gitoftheseussurvivalplot survivaljson write survivalplotpng run help option want plot multiple repository run gitoftheseusanalyze separately project store data separate directory using outdir flag run gitoftheseussurvivalplot foosurvivaljson barsurvivaljson optionally expfit flag fit exponential decay help attributeerror unknown property label upgrade matplotlib seeing pip install matplotlib upgrade pic survival line code set interesting repos curve produced gitoftheseussurvivalplot script show percentage line commit still present x year aggregate commits matter point time made x0 includes commits whereas x0 commits counted would look future survival curve estimated using kaplanmeier also add exponential fit linux stack plot curve produced gitoftheseusstackplot script show total number line repo broken cohort year code wa added node stack plot rail stack plot plotting stuff gitoftheseusanalyze write extsjson cohortsjson authorsjson run gitoftheseusstackplot authorsjson plot author statistic well gitoftheseusstackplot extsjson plot file extension statistic author statistic might want create mailmap file deduplicate author instance author statistic kubernetes also normalize 100 author statistic git stuff markovtsev vadim implemented similar analysis claim 206x faster git theseus named hercules great blog post complexity going analysis git history\n",
      "[1 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 1 0 0 1 0 0 0 1 0\n",
      " 1 1 0]\n",
      "mexican government report text analysis repository document process extracting text pdf cleaning passing nlp pipeline presenting result graph pdf government report 2019 wa released september 1st pdf data folder requirement project us following python library pypdf2 extracting text pdf file spacy passing extracted text nlp pipeline numpy fast matrix operation panda analysing getting insight datasets matplotlib creating graph plot seaborn enhancing style matplotlib plot geopandas plotting map window strongly recommend use anaconda install geopandas using command conda install c condaforge geopandas conda install c condaforge descartes pdf extraction government report process downloaded following url httpswwwgobmxprimerinforme convenience added pdf file data folder extracting text pdf file bit unreliable lose original formatting time dont get text fortunately pdf file simple enough extracting text wasnt complex encountered challenge go detail section task use pypdf2 wellknown pdf library reader pypdf2pdffilereaderinformepdf fulltext page number pdf reported number page use variable keep track pdfpagenumber 3 retrieve first 3 section government report page 14 326 reason 3 first section contain substantial amount text range14 327 block used remove page number start page first remove page number one digit second remove page number 2 digit else statement remove page number 3 digit pdfpagenumber 9 pagetext readergetpageiextracttextstrip1 elif pdfpagenumber 10 pdfpagenumber 99 pagetext readergetpageiextracttextstrip2 else pagetext readergetpageiextracttextstrip3 fulltext pagetextreplacen pdfpagenumber 1 previous code block ensures get cleanest possible output remove page number build u full transcript single string small issue decoding pdf file manually fix weird character correct equivalent item replacement charactersitems fulltext fulltextreplaceitem replacement actually took hour complete manually map weird character correct equivalent example character c e e e remove extra white space finally save cleaned text txt file look weird thats practical way remove double quad white space fulltext fulltextreplace replace replace opentranscriptcleantxt w encodingutf8 tempfile tempfilewritefulltext transcript cleaned well encoded ready run nlp pipeline nlp pipeline step make use spacy library well built easy use installing pip must install spanish model running following command cmd terminal python spacy download escorenewsmd point made decision save pipeline result csv file way csv file loaded statistical toolkit start preparing corpus loading spanish model corpus opentranscriptcleantxt r encodingutf8read nlp spacyloadescorenewsmd corpus bigger default limit set new limit equal length nlpmaxlength lencorpus doc nlpcorpus note script take minute complete also need gigabyte ram properly run feel free skip use csv file data folder everything loaded save result csv file text token code pretty straight forward initialize list header row iterate doc object add token text lemma partofspeech property data list save csv using csvwriter datalist text textlower lemma lemmalower partofspeech isalphabet isstopword token doc datalistappendtokentext tokenlower tokenlemma tokenlemmalower tokenpos tokenisalpha tokenisstop csvwriteropentokenscsv w encodingutf8 newlinewriterowsdatalist important note token always word punctuation mark number thats also save isalpha property later filter nonalphabetic token also saved lowercase form token lemma dont every time want process panda text entity almost previous code block main difference iterate docent object datalist text textlower label ent docent datalistappendenttext entlower entlabel csvwriteropenentitiescsv w encodingutf8 newlinewriterowsdatalist entity refer real world person organization location since model wa trained wikipedia get broad amount text sentence function bit different previous one part counted number positive negative word per sentence used following dataset positive negative word httpswwwkagglecomrtatmansentimentlexiconsfor81languages download require register kaggle free zip file require 2 txt file negativewordsestxt positivewordsestxt required file workspace load memory turn content list openpositivewordsestxt r encodingutf8 tempfile positivewords tempfilereadsplitlines opennegativewordsestxt r encodingutf8 tempfile negativewords tempfilereadsplitlines iterate docsents object keep score sentence save result csv datalist text score sent docsents take account real sentence lensenttext 10 score 0 start scoring sentence word sent wordlower positivewords score 1 wordlower negativewords score 1 datalistappendsenttext score csvwriteropensentencescsv w encodingutf8 newlinewriterowsdatalist running 3 function 3 csv file ready analyzed panda plotted matplotlib plotting data creating plot use seaborn matplotlib reason seaborn applies subtle yet nice looking effect plot project going use bar plot 1 horizontal 1 vertical helpful comparing different value category plot map use geopandas shape file mexico first thing set custom color apply globally plot snssetstyleticks rc figurefigsize 12 7 textcolor white axeslabelcolor white axesedgecolor white xtickcolor white ytickcolor white axesfacecolor 5c0e10 figurefacecolor 5c0e10 style declared ready plot data used word start loading token csv file dataframe df pdreadcsvdatatokenscsv small issue lemma programas program fix grouping together programa programar dflocdflemmalower programa lemmalower programar take account top 20 alphabet token longer 1 character stop word word dfdfisalphabet true dfisstopword false dflemmalowerstrlen 1lemmalowervaluecounts20 use seaborn barplot allows u apply gradient color value without effort snsbarplotxwordsvalues ywordsindex palettebluesd linewidth0 add final customizations pltxlabelocurrences count plttitlemost frequent word pltshow table added lemma count closest english equivalent lemma spanish lemma english total count nacional national 806 junio june 783 mexico mexico 646 programar program 584 millon million 564 peso mexican peso 460 diciembre december 407 publico public population 386 servicio service 357 accionar action 349 desarrollar develop 338 personar people 298 federal federal government 283 educacion education 279 salud health 278 realizar perform 274 pais country 274 social social program 266 atencion aid 256 apoyar support 248 mention per state window require use anaconda python distribution come bundled hundred data science oriented library install anaconda require install 2 package running command cmd terminal conda install c condaforge geopandas conda install c condaforge descartes dont try use pip install geopandas window wont work work well linux macos though geopandas installed require shape file mexico download following link httpswwwarcgiscomhomeitemhtmlidac9041c51b5c49c683fbfec61dc03ba8 require unzip file rename folder mexicostates folder contains various file metadata others coordinate start loading entity csv file loading shape file df pdreadcsvdataentitiescsv mexicodf geopandasreadfilemexicostates shape file loaded folder instead specific file iterate state detail shape file contains state name without accent mark us old name ciudad de mexico wa named distrito federal modifying shape file dataframe clean state name matched state state remove accent mark rename ciudad de mexico former name cleanname cleanwordstate cleanname ciudad de mexico cleanname distrito federal elif cleanname estado de mexico cleanname mexico insert count value row matching adminname state name mexicodflocmexicodfadminname cleanname count lendfdftextlower statelower shape file dataframe ha new column count state use plot method dataframe specify column name color map enable legend mexicodfplotcolumncount cmapplasma legendtrue add final customizations plttitlementions state pltaxisoff plttightlayout pltshow sentiment analysis sentiment analysis used lexiconbased method consists counting positive negative word per sentence method ha consideration important doesnt know context sentence sentence like reduced crime level 10 considered negative way around train model use machine learning evaluate sentence unfortunately timeconsuming task use method first thing load sentence csv file take account score 10 10 case score go beyond boundary df pdreadcsvdatasentencescsv df dfdfscore 10 dfscore 10 make bar score zero yellow bar score zero blue first create array length dataframe element array tuple 3 decimal value representing rgb color color nparray0811 0913 0145lendfscore use boolean mask set different rgb value score equal higher zero colorsdfscore 0 0529 0870 0972 use bar plot pas x previously calculated color pltbardfindex dfscore colorcolors linewidth0 set yticks step 2 10 10 ytickslabels formatinti nparange12 12 2 pltyticksnparange12 12 2 ytickslabels add final customizations pltxlabelsentence number pltylabelscore plttitlesentiment analysis pltshow conclusion previous project used nlp workflow tokenizing word sentence time wanted something bit complex learned several new thing best practice new knowledge come handy future project next step build machine learning model sentiment analysis evaluate next year report\n",
      "[1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 0\n",
      " 1 1 1]\n",
      "home heroimage herotext actiontext actionlink meta true dortanialogoclearpng dortanias opencore install guide getting started prerequisitesmd name content description current supported version 063 opencore guide opencore refer boot loader complex piece software use prepare system macos specifically injecting new data macos smbios acpi table kexts tool differs others like clover ha designed security quality mind allowing u use many security feature found real mac sip filevault indepth look found opencore clover others guide specifically focus two main thing installing macos x86based pc teaching make hack work expected read learn even use google simple oneclick install setup please remember opencore still new currently beta quite stable arguably much stable clover pretty much every way still frequently updated chunk configuration change quite often ie new quirk replacing old one lastly issue visit rhackintosh subreddit rhackintosh discord help\n",
      "[0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 1]\n",
      "nano minimalistic couchdb driver nodejs nano feature minimalistic minimum abstraction couchdb pipe proxy request couchdb directly end user error error proxied directly couchdb know couchdb already know nano installation install npm npm install nano table content getting started tutorial screencasts configuration database function nanodbcreatename callback nanodbgetname callback nanodbdestroyname callback nanodblistcallback nanodbcompactname designname callback nanodbreplicatesource target opts callback nanodbchangesname params callback nanodbfollowname params callback nanodbinfocallback nanousename nanorequestopts callback nanoconfig nanoupdatesparams callback nanofollowupdatesparams callback document function dbinsertdoc params callback dbdestroydocname rev callback dbgetdocname params callback dbheaddocname callback dbcopysrcdoc destdoc opts callback dbbulkdocs params callback dblistparams callback dbfetchdocnames params callback dbfetchrevsdocnames params callback multipart function dbmultipartinsertdoc attachment params callback dbmultipartgetdocname params callback attachment function dbattachmentinsertdocname attname att contenttype params callback dbattachmentgetdocname attname params callback dbattachmentdestroydocname attname params callback view design function dbviewdesignname viewname params callback dbshowdesignname showname docid params callback dbatomicdesignname updatename docname body callback dbsearchdesignname viewname params callback using cookie authentication advanced feature extending nano pipe test getting started use nano need connect couchdb install var nano requirenanohttplocalhost5984 create new database nanodbcreatealice use var alice nanodbusealice example didnt specify callback function absence callback mean ignore happens nano callback function receives always three argument err error body http response body couchdb error json parsed body binary non json response header http response header couchdb error simple complete example using callback var nano requirenanohttplocalhost5984 clean database created previously nanodbdestroyalice function create new database nanodbcreatealice function specify database going use var alice nanousealice insert document aliceinsert crazy true rabbit functionerr body header err consolelogaliceinsert errmessage return consolelogyou inserted rabbit consolelogbody run exampleafter starting couchdb see inserted rabbit ok true id rabbit rev 16e4cb465d49c0368ac3946506d26335d also see document futon configuration configuring nano use database server simple var nano requirenanohttplocalhost5984 db nanousefoo however dont need instrument database object simply nano par url know database var db requirenanohttplocalhost5984foo also pas option require nano par url know database var db requirenanohttplocalhost5984foo specify configuration option pas object literal instead nano par url know database var db requirenano url httplocalhost5984foo requestdefaults proxy httpsomeproxy log function id args consolelogid args please check request information default support feature like cookie jar proxy ssl etc tell nano parse url maybe server behind proxy accessed rewrite rule nano doe parse url return server api httplocalhost5984prefix couchdb server root var couch requirenano url httplocalhost5984prefix parseurl false var db couchusefoo pool size open socket important configuration parameter high traffic website using nano setting poolsize default nodejs http global agent client ha certain size active connection run simultaneously others kept queue pooling disabled setting agent property requestdefaults false adjust global pool size using httpglobalagentmaxsockets 20 also increase size calling context using requestdefaults problematic refer request documentation example clarification example explicitly using keep alive agent installed using npm install agentkeepalive especially useful limit open socket highvolume access couchdb localhost var agentkeepalive requireagentkeepalive var myagent new agentkeepalive maxsockets 50 maxkeepaliverequests 0 maxkeepalivetime 30000 var db requirenano url httplocalhost5984foo requestdefaults agent myagent database function nanodbcreatename callback creates couchdb database given name nanodbcreatealice functionerr body err consolelogdatabase alice created nanodbgetname callback get information name nanodbgetalice functionerr body err consolelogbody nanodbdestroyname callback destroys name nanodbdestroyalice even though example look sync async function nanodblistcallback list database couchdb nanodblistfunctionerr body body array bodyforeachfunctiondb consolelogdb nanodbcompactname designname callback compact name designname specified also compact view nanodbreplicatesource target opts callback replicates source target option opts target ha exist add createtargettrue opts create prior replication nanodbreplicatealice httpadminpasswordotherhostcom5984alice createtargettrue functionerr body err consolelogbody nanodbchangesname params callback asks change feed name params contains addition query string nanodbchangesalice functionerr body err consolelogbody nanodbfollowname params callback us follow create solid change feed please consult follow documentation information complete api var feed dbfollowsince feedonchange function change consolelogchange change feedfollow processnexttickfunction dbinsertbar baz bar nanodbinfocallback get database information nanodbinfofunctionerr body err consoleloggot database info body nanousename creates scope operate inside name var alice nanousealice aliceinsert crazy true rabbit functionerr body something nanodbusename alias nanouse nanodbscopename alias nanouse nanoscopename alias nanouse nanorequestopts callback make request couchdb available opts optsdb database name optsmethod http method default get optspath full path request override optsdoc optsatt optsdoc document name optsatt attachment name optsqs query string parameter appended existing optspath optsdoc optsatt optscontenttype content type request default json optsheaders additional http header override existing one optsbody document attachment body optsencoding encoding attachment optsmultipart array object multipart request nanorelaxopts callback alias nanorequest nanodinosauropts callback alias nanorequest wat u say l nanoconfig object containing nano configuration possible key url couchdb url db database name nanoupdatesparams callback listen db update available params paramsfeed type feed one longpoll close connection first event continuous send line json per event keep socket open timeout eventsource like continuous sends event eventsource format paramstimeout number second couchdb close connection default 60 paramsheartbeat whether couchdb send newline character n timeout default true nanofollowupdatesparams callback changed version 6 use follow create solid dbupdates feed please consult follow documentation information complete api var feed nanofollowupdatessince feedonchange function change consolelogchange change feedfollow processnexttickfunction nanodbcreatealice document function dbinsertdoc params callback insert doc database optional params params string assumed intended document name params object passed query string parameter docname checked defining document name var alice nanousealice aliceinsert crazy true rabbit functionerr body err consolelogbody insert function also used method signature dbinsertdoccallback doc contains id field eg var alice nanousealice aliceinsert id myid crazy true functionerr body err consolelogbody also used update existing document including rev token document saved var alice nanousealice aliceinsert id myid rev 123202479633c2b380f79507a776743d5 crazy false functionerr body err consolelogbody dbdestroydocname rev callback remove revision rev docname couchdb alicedestroyrabbit 366c01cdf99e84c83a9b3fe65b88db8c0 functionerr body err consolelogbody dbgetdocname params callback get docname database optional query string addition params alicegetrabbit revsinfo true functionerr body err consolelogbody dbheaddocname callback get lightweight version return header aliceheadrabbit functionerr header err consolelogheaders dbcopysrcdoc destdoc opts callback copy content attachment document new document overwrite existing target document alicecopyrabbit rabbit2 overwrite true functionerr header err consolelogheaders dbbulkdocs params callback bulk operationsupdatedeleteinsert database refer couchdb doc dblistparams callback list doc database optional query string addition params useful searching aliceliststartkeycat limit3 functionerr body err bodyrowsforeachfunctiondoc consolelogdoc full list params see couchdb doc dbfetchdocnames params callback bulk fetch database document docnames specified per couchdb doc additional query string params specified includedocs always set true dbfetchrevsdocnames params callback changed version 6 bulk fetch revision database document docnames specified per couchdb doc additional query string params specified method fetch includedocs automatically set true multipart function dbmultipartinsertdoc attachment params callback insert doc together attachment params params string assumed intended document name params object passed query string parameter docname checked defining document name refer doc detail attachment must array object name data contenttype property var f requirefs fsreadfilerabbitpng functionerr data err alicemultipartinsert foo bar name rabbitpng data data contenttype imagepng mydoc functionerr body err consolelogbody dbmultipartgetdocname params callback get docname together attachment via multipartrelated request optional query string addition params refer doc detail multipart response body buffer alicemultipartgetrabbit functionerr buffer err consolelogbuffertostring attachment function dbattachmentinsertdocname attname att contenttype params callback insert attachment attname docname case paramsrev required refer doc detail var f requirefs fsreadfilerabbitpng functionerr data err aliceattachmentinsertrabbit rabbitpng data imagepng rev 12150985a725ec88be471921a54ce91452 functionerr body err consolelogbody using pipe var f requirefs fscreatereadstreamrabbitpngpipe aliceattachmentinsertnew rabpng null imagepng dbattachmentgetdocname attname params callback get docnames attachment attname optional query string addition params var f requirefs aliceattachmentgetrabbit rabbitpng functionerr body err fswritefilerabbitpng body using pipe var f requirefs aliceattachmentgetrabbit rabbitpngpipefscreatewritestreamrabbitpng dbattachmentdestroydocname attname params callback changed version 6 destroy attachment attname docnames revision rev aliceattachmentdestroyrabbit rabbitpng rev 14701d73a08ce5c2f2983bf7c9ffd3320 functionerr body err consolelogbody view design function dbviewdesignname viewname params callback call view specified design optional query string addition params youre looking filter view result key pas array key eg key key1 key2 keyn params aliceviewcharacters crazyones functionerr body err bodyrowsforeachfunctiondoc consolelogdocvalue dbviewwithlistdesignname viewname listname params callback call list function feeded given view specified design document aliceviewwithlistcharacters crazyones mylist functionerr body err consolelogbody dbshowdesignname showname docid params callback call show function specified design document specified docid optional query string addition params aliceshowcharacters formatdoc 3621898430 functionerr doc err consolelogdoc take look couchdb wiki possible query paramaters information show function dbatomicdesignname updatename docname body callback call design update function specified doc input dbatomicupdate inplace foobar field foo value bar function error response assertequalerror undefined failed update assertequalresponsefoo bar update worked note data sent body request example update handler follows update inplace functiondoc req var field reqbodyfield var value reqbodyvalue var message set field value docfield value return doc message dbsearchdesignname searchname params callback call view specified design optional query string addition params alicesearchcharacters crazyones q cat functionerr doc err consolelogdoc check test fully functioning example using cookie authentication nano support making request using couchdbs cookie authentication functionality example coffeescript essentially var nano requirenanohttplocalhost5984 username user userpass pas callback consolelog would normally callback cooky store cooky normally redis something nanoauthusername userpass function err body header err return callbackerr header headerssetcookie cookiesuser headerssetcookie callbacknull worked reusing cookie var auth stored cookie callback consolelog would normally callback alice requirenano url httplocalhost5984alice cookie authsession auth aliceinsertdoc function err body header err return callbackerr change cookie couchdb tell u header headerssetcookie auth headerssetcookie callbacknull worked getting current session var nano requirenanourl httplocalhost5984 cookie authsession auth nanosessionfunctionerr session err return consolelogoh consoleloguser ha role j sessionuserctxname sessionuserctxroles advanced feature extending nano nano minimalistic add feature nanorequestopts callback example create function retrieve specific revision rabbit document function getrabbitrevrev callback nanorequest db alice doc rabbit method get params rev rev callback getrabbitrev42e6cdc4c7e26b745c2881a24e0eeece2 functionerr body err consolelogbody pipe pipe nano like stream example rabbit document ha attachment name picturepng picture white rabbit course pipe writable stream var f requirefs nano requirenanohttp1270015984 var alice nanousealice aliceattachmentgetrabbit picturepngpipefscreatewritestreamtmprabbitpng open tmprabbitpng see rabbit picture tutorial example wild screencasts article nano minimalistic couchdb client nodejs article getting started nodejs couchdb article document update handler support article nano 3 article securing site couchdb cookie authentication using nodejs nano article adding copy nano article update document nano article thought development using couchdb nodejs example wild nanoblog roadmap check issue test run configure test suite simply cd nano npm install npm test adding new test run individually verbose output using nanoenvtesting node testsdoclistjs listdocparams listdocparams test name meta roar im vegan cannes est superb code git clone gitgithubcomdscapenanogit home httpgithubcomdscapenano bug httpgithubcomdscapenanoissues build deps chat httpsgitterimdscapenano oo caos license copyright 2011 nuno job nunojobcom oo licensed apache license version 20 license may use file except compliance license may obtain copy license httpwwwapacheorglicenseslicense20html unless required applicable law agreed writing software distributed license distributed basis without warranty condition kind either express implied see license specific language governing permission limitation license\n",
      "[1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1\n",
      " 0 0 0]\n",
      "deepgcns gcns go deep cnns work present new way successfully train deep gcns borrow concept cnns mainly residualdense connection dilated convolution adapt gcn architecture extensive experiment show positive effect deep gcn framework project paper slide tensorflow code pytorch code overview extensive experiment show different component layer filter nearest neighbor dilation etc effect deepgcns also provide ablation study different type deep gcns mrgcn edgeconv graphsage gin requirement pytorch140 pytorchgeometric130 tensorflow graphic used tensorboard visualization install enviroment runing source deepgcnenvinstallsh code architecture misc misc image utils common useful module gcnlib gcn library dense gcn library dense data b x c x n x 1 sparse gcn library sparse data n x c example modelnetcls code point cloud classification modelnet40 semsegdense code point cloud semantic segmentation s3dis data type dense semsegsparse code point cloud semantic segmentation s3dis data type sparse partsemseg code part segmentation partnet ppi code node classification ppi dataset ogb code nodegraph property prediction ogb datasets train test evaluate model please look detail readmemd task inside example folder information code data pretrained model found citation please cite paper find anything helpful inproceedingsli2019deepgcns titledeepgcns gcns go deep cnns authorguohao li matthias muller ali thabet bernard ghanem booktitlethe ieee international conference computer vision iccv year2019 miscli2019deepgcnsjournal titledeepgcns making gcns go deep cnns authorguohao li matthias muller guocheng qian itzel c delgadillo abdulellah abualshour ali thabet bernard ghanem year2019 eprint191006849 archiveprefixarxiv primaryclasscscv miscli2020deepergcn titledeepergcn need train deeper gcns authorguohao li chenxin xiong ali thabet bernard ghanem year2020 eprint200607739 archiveprefixarxiv primaryclasscslg license mit license contact information please contact guohao li matthias muller guocheng qian\n",
      "[0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 1 1]\n",
      "analytics reporter lightweight system publishing analytics data google analytics profile us google analytics core reporting api v3 google analytics real time api v3 used combination 18fanalyticsusagov power government analytics hub analyticsusagov available report named described reportsjson theyre hardcoded repository installation docker build docker image computer run export nodeenvdevelopment needed developing image export nodeenvproduction build image production docker build buildarg nodeenvnodeenv analyticsreporter create alias order analytics command available alias analyticsdocker run v homehome e analyticsreportemail e analyticsreportids e analyticskey analyticsreporter make command working expected export env var follows export analyticsreportemail yourreportemail export analyticsreportidsyourreportids export analyticskeyyourkey npm run utility computer install npm npm install g analyticsreporter youre developing locally inside repo npm install sufficient setup create api service account google developer dashboard visit apis section google developer dashboard project enable analytics api go credential section generate service account credential using new service account download json private key file give grab generated client email address end gserviceaccountcom content json file grant email address read analyze collaborate permission google analytics profile whose data wish publish set environment variable apps generated email address profile authorized export analyticsreportemailyyyyyyydevelopergserviceaccountcom export analyticsreportidsgaxxxxxx may wish manage using autoenv exampleenv file copy env get started find google analytics view id sign analytics account select admin tab select account dropdown account column select property dropdown property column select view dropdown view column click view setting copy view id youll need enter ga prefix specify private key environment variable either file path content key helpful heroku herokulike system specify file path useful development linux server environment export analyticskeypathpathtosecretkeyjson alternatively specify key directly useful paas environment paste content json file privatekey field directly exactly quote rendering actual line break n example ha sanitized export analyticskeybegin private key content key end private key multiple account profile set analyticscredentials variable json encoded array credential theyll used authorize api request roundrobin style export analyticscredentials key begin private keyncontents keynend private key email email1examplecom key begin private keyncontents keynend private key email email2examplecom make sure computer server syncing time world ntp computer time need match google server authentication work test configuration printing report stdout binanalytics user see nicely formatted json file set optional authorize s3 publishing plan use project lightweight s3 publishing system youll need add 6 environment variable export awsregionuseast1 export awsaccesskeyidyourkey export awssecretaccesskeyyoursecretkey export awsbucketyourbucket export awsbucketpathyourpath export awscachetime0 case want use custom object storage server compatible amazon s3 apis like minio specific case set extra env variable export awss3endpointhttpyourstorageserverport configuration use single domain analytics data profile likely set return relative path eg faq absolute path accessing realtime report set default domain returned data realtime data point export analyticshostnamehttpskonklonecom produce point similar following page postwhygoogleishurryingthewebtokillsha1 pagetitle google hurrying web kill sha1 activevisitors 1 domain httpskonklonecom use report created published using analytics command analytics run every report sequence print resulting json stdout two newlines report report might look something like name device query dimension gadate gadevicecategory metric gasessions startdate 90daysago enddate yesterday sort gadate meta name device description weekly desktopmobiletablet visit day site data date 20141014 device desktop visit 11495462 date 20141014 device mobile visit 2499586 date 20141014 device tablet visit 976396 total device mobile 213920363 desktop 755511646 tablet 81874189 startdate 20141014 enddate 20150111 option output output directory analytics output pathtodata note using docker image use absolute path example homeyouruserpathtodata publish publish s3 bucket requires aws environment variable set described analytics publish writetodatabase write data database requires postgres configuration set environment variable described run one specific report multiple report comma separated analytics device analytics devicestoday slim supported use total omit data array applies json report slim true analytics device slim csv give csv instead json analytics csv frequency limit report frequency value analytics frequencyrealtime debug print debug detail stdout analytics publish debug saving data postgres analytics reporter write data pull google analytics postgres database postgres configuration set using environment variable export postgreshost mydbhostcom export postgresuser postgres export postgrespassword 123abc export postgresdatabase analytics database expects particular schema described api server consumes data write report database use writetodatabase option starting reporter deploying govcloud analytics reporter run gov please refer manifestyml file root repository application information ensure youre targeting proper org space cf target deploy application following command cf push f manifestyml set environmental variable based local env file cf setenv analyticsreporter awsaccesskeyid 123abc cf setenv analyticsreporter awssecretaccesskey 456def restage application use environment variable cf restage analyticsreporter developing docker repo contains docker compose configuration reporter configured run container running govcloud helpful seeing reporter behave deployed without pushing cloudgov start reporter first run dockerupdate script install necessary dependency bindockerupdate note script need run new dependency added update docker volume dependency stored dependency installed reporter started using docker compose dockercompose public domain project worldwide public domain stated contributing project public domain within united state copyright related right work worldwide waived cc0 10 universal public domain dedication contribution project released cc0 dedication submitting pull request agreeing comply waiver copyright interest\n",
      "[1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0\n",
      " 1 0 1]\n",
      "dash user contributed docsets report bug request docset open issue install docset install docsets dash preference downloads user contributed contribute new docset contribute docset follow step get stuck point question open issue ill help generate docset following instruction httpkapelicomdocsets note ignore instruction regarding docset feed wont need plan contribute repo make sure docset fulfils required criterion docset contribution checklist many optional one possible check versioning guideline understand docset versioning work dash fork clone repo set directory structure copy sampledocset folder docsets folder rename use name docset replace whitespaces underscore note dont add docset end name use docset name eg extjs nothing else archive docset using tar excludedsstore cvzf docset nametgz docset namedocset copy docset archive note dont worry repos size getting huge soon docset get distributed cdn get removed repo automatically docset exceeds githubs file limit 100 mb open issue well figure different way submit docset include iconpng icon2xpng size 16x16 32x32 simply delete sample icon dont want icon edit docsetjson file make sure follow naming rule sample ie docset name archive name replace whitespaces underscore edit readmemd submit pull request\n",
      "[1 0 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0\n",
      " 1 1 1]\n",
      "simple demonstration get basic understanding kubernetes work working step step learnt kubernetes like made repo solve problem faced learning experience might help beginner wont going depth docker see sufficient content get basic understanding learn work kubernetes hope enjoy learning like please give important seeing size readme might second thought honest work start finish wont experience problem learn along way content requirement docker docker creating web server building docker image getting docker image running container image accessing application listing running container running shell inside existing container exploring container within stopping removing container pushing image image registry pushing image docker hub kubernetes kubernetes splitting apps microservice scaling microservices deploying microservices working kubernetes setting kubernetes cluster running local single node kubernetes cluster minikube starting kubernetes cluster minikube checking status cluster deploying node app listing pod accessing web application creating service object listing service horizontally scaling application increasing desired replica count seeing result scale displaying pod ip pod node listing pod accessing dashboard using minikube pod examining yaml descriptor existing pod introducing main part pod definition creating simple yaml descriptor pod using kubectl create create pod retrieving pod log kubectl log forwarding local network port pod introducing label specifying label creating pod modifying label existing pod listing subset pod label selector listing pod using label selector using multiple condition label selector using label selector constrain pod scheduling using label categorizing worker node scheduling pod specific node scheduling one specific node annotating pod looking object annotation adding modifying annotation using namespace group resource discovering namespaces pod creating namespace managing object namespaces understanding isolation provided namespaces stopping removing pod deleting pod name deleting pod using label selector deleting pod deleting whole namespace deleting pod namespace keeping namespace delete almost resource namespace replication controller deploying managed pod keeping pod healthy introducing liveness probe creating http based liveness probe seeing liveness probe action configuring additional property liveness probe creating effective liveness probe introducing replicationcontrollers operation replicationcontroller introducing controller reconciliation loop creating replicationcontroller seeing replicationcontroller action understanding exactly caused controller create new pod moving pod scope replicationcontroller changing pod template horizontally scaling pod deleting replicationcontroller using replicasets instead replicationcontrollers defining replicaset using replicasets expressive label selector running exactly one pod node daemonsets using daemonset run pod every node explaning daemon set example creating daemonset running pod perform single completable task introducing job resource defining job resource seeing job run pod todo requirement need docker installed minikube installed running locally kubectl installed simple concept start docker docker platform packaging distribution running application allows package application together whole environment either library app requires even file usually available filesystem installed operating system docker make possible transfer package central repository transferred computer running docker executed three main concept docker comprise scenario image docker based container image something package application environment contains filesystem available application metadata path executable executed image run registry docker registry repository store docker image facilitates easy sharing image different user computer build image either run computer youve built push upload image registry pull download another computer run certain registry public allowing anyone pull image others private accessible certain people machine container dockerbased container regular linux container created dockerbased container image running container process running host running docker completely isolated host process running process also resourceconstrained meaning access use number resource cpu ram allocated learning working creating web server first need create container image use docker creating simple web server see kubernetes work create file appjs copy code const http requirehttp const requireos consolelogkubia server starting var handler function request response consolelogreceived request requestconnectionremoteaddress responsewritehead200 responseendyouve hit oshostname n var www httpcreateserverhandler wwwlisten8080 create docker file run cluster create docker image create file named dockerfile copy code node8 run npm add appjs appjs entrypoint node appjs building docker image make sure docker server running create docker image local machine open terminal current project folder run docker build kubia youre telling docker build image called kubia based content current directory note dot end build command docker look dockerfile directory build image based instruction file check docker image created running docker image getting docker image docker image command list image running container image docker run name kubiacontainer p 80808080 kubia tell docker run new container called kubiacontainer kubia image container detached console flag mean run background port 8080 local machine mapped port 8080 inside container p 80808080 option access app localhost accessing application run terminal curl localhost8080 youve hit 44d76963e8e1 listing running container list running container command docker p docker p command show basic information container get additional information container run command docker inspect kubiacontainer see container running docker p running shell inside existing container nodejs image youve based image contains bash shell run shell inside container like docker exec kubiacontainer bash run bash inside existing kubiacontainer container bash process linux namespaces main container process allows explore container within see nodejs app see system running inside container option shorthand two option make sure stdin kept open need entering command shell allocates pseudo terminal tty exploring container within let see use shell following listing see process running container rootc61b9b509f9a p aux user pid cpu mem vsz r tty stat start time command root 1 04 13 872872 27832 ssl 0601 000 node appjs root 11 01 01 20244 3016 pts0 0602 000 bash root 16 00 00 17504 2036 pts0 r 0602 000 p aux see three process dont see process host like isolated process tree container also ha isolated filesystem listing content root directory inside container show file container include file image plus file created container running log file similar shown following listing rootc61b9b509f9a l appjs bin boot dev etc home lib lib64 medium mnt opt packagelockjson proc root run sbin srv sys tmp usr var contains appjs file system directory part node8 base image youre using exit container exit shell running exit command youll returned host machine like logging ssh session example stopping removing container docker stop kubiacontainer stop main process running container consequently stop container process running inside container container still exists see docker p option print container running stopped truly remove container need remove docker rm command docker rm kubiacontainer deletes container content removed cant started pushing image image registry image youve built ha far available local machine allow run machine need push image external image registry sake simplicity wont set private image registry instead push image docker hub need retag image according docker hub rule docker hub allow push image image repository name start docker hub id create docker hub id registering hubdocker ill use id knrt10 following example please change every occurrence id know id youre ready rename image currently tagged kubia knrt10kubia replace knrt10 docker hub id docker tag kubia knrt10kubia doesnt rename tag creates additional tag image confirm listing image stored system docker image command shown following listing docker image head see kubia knrt10kubia point image id theyre fact one single image two tag pushing image docker hub push image docker hub need log user id docker login command youre logged finally push youridkubia image docker hub like docker push knrt10kubia kubernetes year ago software application big monolith running either single process small number process spread across handful server today big monolithic legacy application slowly broken smaller independently running component called microservices microservices decoupled developed deployed updated scaled individually enables change component quickly often necessary keep today rapidly changing business requirement bigger number deployable component increasingly larger datacenters becomes increasingly difficult configure manage keep whole system running smoothly much harder figure put component achieve high resource utilization thereby keep hardware cost manually hard work need automation including automatic scheduling component server automatic configuration supervision failurehandling kubernetes come kubernetes enables developer deploy application often want without requiring assistance operation ops team kubernetes doesnt solely benefit developer also help ops team automatically monitoring rescheduling apps event hardware failure focus system administrator sysadmins shift supervising individual apps mostly supervising managing kubernetes rest infrastructure kubernetes take care apps splitting apps microservice microservice run independent process communicates microservices simple welldefined interface apis refer image image taken source microservices communicate synchronous protocol http usually expose restful representational state transfer apis asynchronous protocol amqp advanced message queueing protocol protocol simple well understood developer tied specific programming language microservice written language thats appropriate implementing specific microservice microservice standalone process relatively static external api possible develop deploy microservice separately change one doesnt require change redeployment service provided api doesnt change change backwardcompatible way scaling microservices scaling microservices unlike monolithic system need scale system whole done perservice basis mean option scaling service require resource leaving others original scale refer image image taken source monolithic application cant scaled one part unscalable splitting app microservices allows horizontally scale part allow scaling part dont scale horizontally scaled vertically instead deploying microservices always microservices also drawback system consists small number deployable component managing component easy trivial decide deploy component arent many choice number component increase deploymentrelated decision become increasingly difficult doe number deployment combination increase number interdependency component increase even greater factor microservices also bring problem making hard debug trace execution call span multiple process machine luckily problem addressed distributed tracing system zipkin multiple application running host may conflicting dependency working kubernetes app packaged inside container image made available docker hub deploy kubernetes cluster instead running docker directly first need set cluster setting kubernetes cluster setting fullfledged multinode kubernetes cluster isnt simple task especially youre wellversed linux networking administration proper kubernetes install span multiple physical virtual machine requires networking set properly container running inside kubernetes cluster connect flat networking space running local single node kubernetes cluster minikube simplest quickest path fully functioning kubernetes cluster using minikube minikube tool set singlenode cluster thats great testing kubernetes developing apps locally starting kubernetes cluster minikube minikube installed locally immediately start kubernetes cluster following command minikube start starting local kubernetes cluster starting vm sshing file vm kubectl configured use cluster starting cluster take minute dont interrupt command completes checking see cluster kubernetes talk interact kubernetes also need kubectl cli client installing easy verify cluster working use kubectl clusterinfo command shown following listing kubectl clusterinfo kubernetes master running https192168991008443 kubernetesdashboard running https192168991008443apiv1 kubedns running https192168991008443apiv1namespaceskubesystemserviceskubednsdnsproxy show cluster show url various kubernetes component including api server web console deploying node app simplest way deploy app use kubectl run command create necessary component without deal json yaml kubectl run kubia imageknrt10kubia port8080 generatorrunv1 imageknrt10kubia part obviously specifies container image want run port8080 option tell kubernetes app listening port 8080 last flag generator doe require explanation though usually wont use youre using kubernetes creates replicationcontroller instead deployment listing pod cant list individual container since theyre standalone kubernetes object list pod instead yes let see tell kubectl list pod following listing kubectl get pod kubectl get pod name ready status restarts age kubia5k788 11 running 1 7d accessing web application pod running access pod get ip address address internal cluster isnt accessible outside make pod accessible outside youll expose service object youll create special service type loadbalancer create regular service clusterip service pod would also accessible inside cluster creating loadbalancertype service external load balancer created connect pod load balancer public ip creating service object create service youll tell kubernetes expose replicationcontroller created earlier kubectl expose rc kubia typeloadbalancer name kubiahttp service kubiahttp exposed important using abbreviation rc instead replicationcontroller resource type abbreviation like dont type full name example po pod svc service listing service expose command output mention service called kubiahttp service object like pod node see newly created service object running kubectl get service svc command shown following listing kubectl get svc name type clusterip externalip port age kubernetes clusterip 109601 none 443tcp 7d kubiahttp loadbalancer 10969992 pending 808030126tcp 7d important minikube doesnt support loadbalancer service service never get external ip access service anyway external port external ip always pending case using minikube get ip port access service running minikube service kubiahttp horizontally scaling application running application monitored kept running replicationcontroller exposed world service let make additional magic happen one main benefit using kubernetes simplicity scale deployment let see easy scale number pod youll increase number running instance three pod managed replicationcontroller let see kubectl get command kubectl get rc name desired current ready age kubia 1 1 1 7d increasing desired replica count scale number replica pod need change desired replica count replicationcontroller like kubectl scale rc kubia replicas3 replicationcontroller kubia scaled youve told kubernetes make sure three instance pod always running notice didnt instruct kubernetes action take didnt tell add two pod set new desired number instance let kubernetes determine action need take achieve requested state seeing result scale back replica count increase let list replicationcontrollers see updated replica count kubectl get rc name desired current ready age kubia 3 3 3 7d actual number pod ha already increased three evident current column listing pod show three pod instead one kubectl get pod name ready status restarts age kubia5k788 11 running 1 7d kubia7zxwj 11 running 1 3d kubiabsksp 11 running 1 3d see three pod exist instead one currently running pending would ready moment soon container image downloaded container started see scaling application incredibly simple app running production need scale app arises add additional instance single command without install run additional copy manually keep mind app need support scaled horizontally kubernetes doesnt magically make app scalable make trivial scale app displaying pod ip pod node listing pod youve paying close attention probably noticed kubectl get pod command doesnt even show information node pod scheduled usually important piece information request additional column display using wide option listing pod option show pod ip node pod running kubectl get pod wide name ready status restarts age ip node kubia5k788 11 running 1 7d 1721704 minikube kubia7zxwj 11 running 1 3d 1721705 minikube kubiabsksp 11 running 1 3d 1721706 minikube accessing dashboard using minikube open dashboard browser using minikube run kubernetes cluster run following command minikube dashboard pod pod kubernetes resource usually created posting json yaml manifest kubernetes rest api endpoint also use simpler way creating resource kubectl run command usually allow configure limited set property additionally defining kubernetes object yaml file make possible store version control system benefit brings examining yaml descriptor existing pod youll use kubectl get command yaml option get whole yaml definition pod use json get whole json definition shown following listing kubectl get po kubiabsksp yaml introducing main part pod definition pod definition consists part first kubernetes api version used yaml type resource yaml describing three important section found almost kubernetes resource metadata includes name namespace label information pod spec contains actual description pod content pod container volume data status contains current information running pod condition pod description status container pod internal ip basic info status part contains readonly runtime data show state resource given moment creating new pod never need provide status part three part described previously show typical structure kubernetes api object object anatomy make understanding new object relatively easy going individual property previous yaml doesnt make much sense instead let see basic yaml creating pod look like creating simple yaml descriptor pod youre going create file called kubiamanualyaml create directory want copy repo youll find file filename kubiamanualyaml following listing show entire content file apiversion v1 kind pod metadata name kubiamanual spec container image knrt10kubia name kubia port containerport 8080 protocol tcp let examine descriptor detail conforms v1 version kubernetes api type resource youre describing pod name kubiamanual pod consists single container based knrt10kubia image youve also given name container indicated listening port 8080 using kubectl create create pod create pod yaml file use kubectl create command kubectl create f kubiamanualyaml podkubiamanual created kubectl create f command used creating resource pod yaml json file retrieving pod log kubectl log little nodejs application log process standard output containerized application usually log standard output standard error stream instead writing log file allow user view log different application simple standard way see pod log precisely container log run following command local machine need ssh anywhere kubectl log kubiamanual kubia server starting havent sent web request nodejs app log show single log statement server starting see retrieving log application running kubernetes incredibly simple pod contains single container specifying container name getting log multiple container pod pod includes multiple container explicitly specify container name including c container name option running kubectl log kubiamanual pod set container name kubia additional container exist pod youd get log like kubectl log kubiamanual c kubia note retrieve container log pod still existence pod deleted log also deleted forwarding local network port pod want talk specific pod without going service debugging reason kubernetes allows configure port forwarding pod done kubectl portforward command following command forward machine local port 8888 port 8080 kubiamanual pod kubectl portforward kubiamanual 88888080 different terminal use curl send http request pod kubectl portforward proxy running localhost8888 curl localhost8888 youve hit kubiamanual using port forwarding like effective way test individual pod introducing label organizing pod kubernetes object done label label simple yet incredibly powerful kubernetes feature organizing pod kubernetes resource label arbitrary keyvalue pair attach resource utilized selecting resource using label selector resource filtered based whether include label specified selector specifying label creating pod youll see label action creating new pod two label create new file called kubiamanualwithlabelsyaml content following listing also copy kubiamanualwithlabelsyaml apiversion v1 kind pod metadata name kubiamanualv2 label creationmethod manual env prod spec container image knrt10kubia name kubia port containerport 8080 protocol tcp youve included label creationmethodmanual envdatalabels section youll create pod kubectl create f kubiamanualwithlabelsyaml podkubiamanualv2 created kubectl get po command doesnt list label default see using showlabels switch kubectl get po showlabels name ready status restarts age label kubia5k788 11 running 1 8d runkubia kubia7zxwj 11 running 1 5d runkubia kubiabsksp 11 running 1 5d runkubia kubiamanual 11 running 0 7h none kubiamanualv2 11 running 0 3m creationmethodmanualenvprod instead listing label youre interested certain label specify l switch displayed column list pod show column two label youve attached kubiamanualv2 pod kubectl get po l creationmethodenv modifying label existing pod label also added modified existing pod kubiamanual pod wa also created manually let add creationmethodmanual label kubectl label po kubiamanual creationmethodmanual let also change envprod label envdebug kubiamanualv2 pod see existing label changed need use overwrite option changing existing label kubectl label po kubiamanualv2 envdebug overwrite listing subset pod label selector attaching label resource see label next resource listing isnt interesting label go hand hand label selector label selector allow select subset pod tagged certain label perform operation pod label selector select resource based whether resource contains doesnt contain label certain key contains label certain key value contains label certain key value equal one specify listing pod using label selector let use label selector pod youve created far see pod created manually labeled creationmethodmanual following kubectl get po l creationmethodmanual name ready status restarts age kubiamanual 11 running 0 22h kubiamanualv2 11 running 0 14h dont env label kubectl get po l env name ready status restarts age kubia5k788 11 running 1 9d kubia7zxwj 11 running 1 5d kubiabsksp 11 running 1 5d kubiamanual 11 running 0 22h make sure use single quote around env bash shell doesnt evaluate exclamation mark using multiple condition label selector selector also include multiple commaseparated criterion resource need match match selector execute command given kubectl get po l env creationmethod showlabels using label selector constrain pod scheduling pod youve created far scheduled pretty much randomly across worker node certain case exist however youll want least little say pod scheduled good example hardware infrastructure isnt homogenous never want say specifically node pod scheduled would couple application infrastructure whereas whole idea kubernetes hiding actual infrastructure apps run using label categorizing worker node pod arent kubernetes resource type attach label label attached kubernetes resource including node let imagine one node cluster contains gpu meant used generalpurpose gpu computing want add label node showing feature youre going add label gputrue one node pick one list returned kubectl get node kubectl label node minikube gputrue nodeminikube labeled use label selector listing node like pod list node include label gputrue kubectl get node l gputrue name status role age version minikube ready master 9d v1100 expected one node ha label also try listing node tell kubectl display additional column showing value node gpu label kubectl get node l gpu name status role age version gpu minikube ready master 9d v1100 true scheduling pod specific node imagine want deploy new pod need gpu perform work ask scheduler choose among node provide gpu youll add node selector pod yaml create file called kubiagpuyaml following listing content use kubectl create f kubiagpuyaml create pod content file apiversion v1 kind pod metadata name kubiagpu spec nodeselector gpu true container image luksakubia name kubia youve added nodeselector field spec section create pod scheduler choose among node contain gputrue label single node case scheduling one specific node similarly could also schedule pod exact node node also ha unique label key kubernetesiohostname value set actual hostname node example shown kubectl get node showlabels name status role age version label minikube ready master 9d v1100 betakubernetesioarchamd64betakubernetesiooslinuxgputruekubernetesiohostnameminikubenoderolekubernetesiomaster setting nodeselector specific node hostname label may lead pod unschedulable node offline annotating pod addition label pod object also contain annotation also key value pair essence similar label arent meant hold identifying information cant used group object way label object selected label selector thing annotation selector hand annotation hold much larger piece information primarily meant used tool certain annotation automatically added object kubernetes others added user manually great use annotating pod add desciption pod api object everyone using cluster quickly look information individual object looking object annotation let see example annotation kubernetes added automatically pod created previous section see annotation youll need request full yaml pod use kubectl describe command youll use first option following listing kubectl get po kubiazb95q yaml apiversion v1 kind pod metadata annotation kubernetesiocreatedby kindserializedreference apiversionv1 referencekindreplicationcontroller namespacedefault without going many detail see kubernetesiocreatedby annotation hold json data object created pod thats something youd want put label label short whereas annotation contain relatively large blob data 256 kb total important kubernetesiocreatedby annotation wa deprecated version 18 removed 19 longer see yaml adding modifying annotation annotation obviously added pod creation time way label also add using following command let try adding kubiamanual pod kubectl annotate pod kubiamanual knrt10githubiosomeannotationmessi ronaldo added annotation knrt10githubiosomeannotation value messi ronaldo good idea use format annotation key prevent key collision different tool library add annotation object may accidentally override others annotation dont use unique prefix like check pod using following command kubectl describe po kubiamanual using namespace group resource previously saw label organize pod object group object multiple label group object overlap plus working cluster kubectl example dont explicitly specify label selector youll always see object discovering namespaces pod let u first list namespaces cluster type following command kubectl get n name status age default active 9h kubepublic active 9h kubesystem active 9h point youve operated default namespace listing resource kubectl get command youve never specified namespace explicitly kubectl always defaulted default namespace showing object namespace see list kubepublic kubesystem namespaces also exist let look pod belong kubesystem namespace telling kubectl list pod namespace kubectl get po n kubesystem name ready status restarts age etcdminikube 11 running 0 4h kubeaddonmanagerminikube 11 running 1 9h kubeapiserverminikube 11 running 0 4h kubecontrollermanagerminikube 11 running 0 4h kubedns86f4d74b45w8mqv 33 running 4 9h kubeproxy25t92 11 running 0 4h kubeschedulerminikube 11 running 0 4h kubernetesdashboard5498ccf6772zcw5 11 running 2 9h storageprovisioner 11 running 2 9h explain pod later dont worry pod shown dont match one system exactly clear name namespace resource related kubernetes system separate namespace keep everything nicely organized default namespace mixed resource create youd hard time seeing belongs might inadvertently delete system resource namespaces enable separate resource dont belong together nonoverlapping group several user group user using kubernetes cluster manage distinct set resource use namespace way dont need take special care inadvertently modify delete user resource dont need concern name conflict namespaces provide scope resource name ha already mentioned creating namespace namespace kubernetes resource like create posting yaml file kubernetes api server let see youre going create file called customnamespaceyaml create directory want copy repo youll find file filename customnamespaceyaml following listing show entire content file apiversion v1 kind namespace metadata name customnamespace type following command kubectl create f customnamespaceyaml namespacecustomnamespace created managing object namespaces create resource namespace youve created either add namespace customnamespace entry metadata section specify namespace creating resource kubectl create command kubectl create f kubiamanualyaml n customnamespace podkubiamanual created two pod name kubiamanual one default namespace customnamespace listing describing modifying deleting object namespaces need pas namespace n flag kubectl dont specify namespace kubectl performs action default namespace configured current kubectl context current context namespace current context changed kubectl config command understanding isolation provided namespaces wrap section namespaces let explain namespaces dont provide least box although namespaces allow isolate object distinct group allows operate belonging specified namespace dont provide kind isolation running object example may think different user deploy pod across different namespaces pod isolated cant communicate thats necessarily case whether namespaces provide network isolation depends networking solution deployed kubernetes solution doesnt provide internamespace network isolation pod namespace foo know ip address pod namespace bar nothing preventing sending traffic http request pod stopping removing pod created number pod running followed start 5 pod default namespace one customnamespace going stop dont need anymore deleting pod name let first delele kubiagpu pod name kubectl delete po kubiagpu deleting pod using label selector instead specifying pod delete name youll use youve learned label selector stop kubiamanual kubiamanualv2 pod pod include creationmethodmanual label delete using label selector kubectl delete po l creationmethodmanual pod kubiamanual deleted pod kubiamanualv2 deleted earlier microservices example ten possibly hundred pod could instance delete canary pod specifying relcanary label selector kubectl delete po l relcanary deleting pod deleting whole namespace okay back real pod pod customnamespace longer need either pod namespace namespace delete whole namespace using following command pod inside workspace automatically deleted kubectl delete n customnamespace namespace customnamespace deleted deleting pod namespace keeping namespace suppose want keep namespace delete pod approach follow cleaned almost everything pod running ran kubectl run command time instead deleting specific pod tell kubernetes delete pod current namespace using option kubeclt delete po pod kubiapjxrs deleted pod kubiaxvfxp deleted pod kubiazb95q deleted double check pod left running kubectl get po kubia5gknm 11 running 0 48s kubiah62k7 11 running 0 48s kubiax4nsb 11 running 0 48s wait pod terminating new pod werent ha appeared matter many time delete pod new pod called kubiasomething emerge may remember created first pod kubectl run command mentioned doesnt create pod directly instead creates replicationcontroller creates pod soon delete pod created replicationcontroller immediately creates new one delete pod also need delete replicationcontroller delete almost resource namespace delete replicationcontroller pod well service youve created deleting resource current namespace single command kubectl delete pod kubia5gknm deleted pod kubiah62k7 deleted pod kubiax4nsb deleted replicationcontroller kubia deleted service kubernetes deleted service kubiahttp deleted first command specifies youre deleting resource type option specifies youre deleting resource instance instead specifying name already used option ran previous delete command deletes resource kubectl print name every resource deletes list see kubia replicationcontroller kubiahttp service created note kubectl delete command also deletes kubernetes service recreated automatically moment replication controller deploying managed pod far might understood pod represent basic deployment unit kubernetes know create supervise manage manually realworld use case want deployment stay running automatically remain healthy without manual intervention never almost create pod directly instead create type resource like replicationcontrollers deployment create manage actual pod create unmanaged pod one created previously cluster node selected run pod container run node well learn kubernetes monitor container automatically restarts fail whole node fails pod node lost replaced new one unless pod managed previously mentioned replicationcontrollers similar well learn kubernetes check container still alive restarts isnt well also learn run managed podsboth run indefinitely perform single task stop keeping pod healthy one main benefit using kubernetes ability give list container let keep container running somewhere cluster creating pod resource letting kubernetes pick worker node run pod container node one container dy container pod die soon pod scheduled node kubelet node run container keep running long pod exists container main process crash kubelet restart container application ha bug cause crash every kubernetes restart automatically even without anything special app running app kubernetes automatically give ability heal sometimes apps stop working without process crashing example java app memory leak start throwing outofmemoryerrors jvm process keep running would great way app signal kubernetes longer functioning properly kubernetes restart weve said container crash restarted automatically maybe youre thinking could catch type error app exit process occur certainly still doesnt solve problem example situation app stop responding fall infinite loop deadlock make sure application restarted case must check application health outside depend app internally introducing liveness probe kubernetes check container still alive liveness probe specify liveness probe container pod specification kubernetes probe container using one three mechanism http get probe performs http get request container ip address port path specify probe receives response response code doesnt represent error word http response code 2xx 3xx probe considered successful server return error response code doesnt respond probe considered failure container restarted result tcp socket probe try open tcp connection specified port container connection established successfully probe successful otherwise container restarted exec probe executes arbitrary command inside container check command exit status code status code 0 probe successful probe considered failure creating http based liveness probe let see add liveness probe nodejs app web app make sense add liveness probe check whether web server serving request particular nodejs app simple ever fail youll need make app fail artificially properly demo liveness probe youll modify app slightly make return 500 internal server error http status code request fifth oneyour app handle first five client request properly return error every subsequent request thanks liveness probe restarted happens allowing properly handle client request ive pushed container image docker hub dont need build want see folder kubiaunhealthy information youll create new pod includes http get liveness probe following listing show yaml pod youre going create file called kubialivenessprobeyaml create directory want copy repo youll find file filename kubialivenessprobeyaml following listing show entire content file apiversion v1 kind pod metadata name kubialiveness spec container image knrt10kubiaunhealthy name kubia livenessprobe httpget path port 8080 pod descriptor defines httpget liveness probe tell kubernetes periodically perform http get request path port 8080 determine container still healthy request start soon container run five request actual client request app start returning http status code 500 kubernetes treat probe failure thus restart container seeing liveness probe action see liveness probe doe try creating pod minute half container restarted see running kubectl get kubectl get po kubialiveness name ready status restarts age kubialiveness 11 running 1 2m restarts column show pod container ha restarted wait another minute half get restarted cycle continues indefinitely see container restarted looking kubectl describe print see container currently running previously terminated error exit code wa 137 ha special meaning denotes process wa terminated external signal number 137 sum two number 128x x signal number sent process caused terminate example x equal 9 number sigkill signal meaning process wa killed forcibly container killed completely new container created container restarted configuring additional property liveness probe may noticed kubectl describe also display additional information liveness probe liveness httpget http8080 delay0s timeout1s period10s success1 failure3 beside liveness probe option specified explicitly also see additional property delay timeout period delay0s part show probing begin immediately container started timeout set 1 second container must return response 1 second probe counted failed container probed every 10 second period10s container restarted probe fails three consecutive time failure3 dont set initial delay prober start probing container soon start usually lead probe failing app isnt ready start receiving request number failure exceeds failure threshold container restarted even able start responding request properly tip always remember set initial delay account apps startup time ive seen many occasion user confused container wa restarted theyd used kubectl describe theyd seen container terminated exit code 137 143 telling pod wa terminated externally additionally listing pod event would show container wa killed failed liveness probe see happening pod startup failed set initialdelayseconds appropriately creating effective liveness probe pod running production always define liveness probe without one kubernetes ha way knowing whether app still alive long process still running kubernetes consider container healthy liveness probe check simplistic liveness probe simply check server responding may seem overly simple even liveness probe like doe wonder cause container restarted web server running within container stop responding http request compared liveness probe major improvement may sufficient case better liveness check youd configure probe perform request specific url path health example app perform internal status check vital component running inside app ensure none ha died unresponsive tip make sure health http endpoint doesnt require authentication otherwise probe always fail causing container restarted indefinitely sure check internals app nothing influenced external factor example frontend web server liveness probe shouldnt return failure server cant connect backend database underlying cause database restarting web server container fix problem liveness probe fail youll end container restarting repeatedly database becomes accessible keeping probe light liveness probe shouldnt use many computational resource shouldnt take long complete default probe executed relatively often allowed one second complete probe doe heavy lifting slow container considerably later book youll also learn limit cpu time available container probe cpu time counted container cpu time quota heavyweight liveness probe reduce cpu time available main application process dont bother implementing retry loop probe youve already seen failure threshold probe configurable usually probe must fail multiple time container killed even set failure threshold 1 kubernetes retry probe several time considering single failed attempt therefore implementing retry loop probe wasted effort liveness probe wrapup understand kubernetes keep container running restarting crash liveness probe fail job performed kubelet node hosting pod kubernetes control plane component running master part process node crash control plane must create replacement pod went node doesnt pod create directly pod arent managed anything except kubelet kubelet run node cant anything node fails make sure app restarted another node need pod managed replicationcontroller similar mechanism later readme introducing replicationcontrollers replication controllerrc kubernetes resource ensures pod always kept running pod disappers reason like case node disappearing cluster pod wa evicted node rc note pod missing creates replacement pod please refer image node fails pod backed replicationcontroller recreated rc figure manage single pod general meant create manage mutiple copy replica pod thats rc got name operation replicationcontroller rc contantly monitor list running pod make sure actual number pod type always match desire number pod running creates new replica pod template much pod running remove excess replica might wondering desired number replica happen reason someone creates pod type manually someone change existing pod type someone decrease desired number pod ive used term pod type time thing exists replication controller dont operate pod type set pod match certain label selector told previously introducing controller reconciliation loop replicationcontrollers job make sure exact number pod always match label selector doesnt replicationcontroller take appropriate action reconcile actual desired number replicationcontroller ha three essential part label selector determines pod replicationcontrollers scope replica count specifies desired number pod running pod template used creating new pod replica three key part replicationcontroller pod selector replica count pod template replicationcontrollers replica count label selector even pod template modified time change replica count affect existing pod change label selector pod template effect existing pod changing label selector make existing pod fall scope replicationcontroller controller stop caring replicationcontrollers also dont care actual content pod container image environment variable thing create pod template therefore affect new pod created replicationcontroller think cookie cutter cutting new pod benefit make sure pod multiple pod replica always running starting new pod existing one go missing cluster node fails creates replacement replica pod running failed node replication controller control enables easy horizontal scaling podsboth manual automatic note pod instance never relocated another node instead replicationcontroller creates completely new pod instance ha relation instance replacing creating replicationcontroller youre going create file called kubiarcyaml create directory want copy repo youll find file filename kubiarcyaml following listing show entire content file apiversion v1 kind replicationcontroller metadata name kubia spec replica 3 selector app kubia template metadata label app kubia spec container name kubia image knrt10kubia port containerport 8080 post file api server kubernetes creates new replicationcontroller named kubia make sure three pod instance always match label selector appkubia arent enough pod new pod created provided pod template content template almost identical pod defination created pod label template must obviously match label selector replicationcontroller otherwise controller would create new pod indefinitely spinning new pod wouldnt bring actual replica count closer desired number replica prevent scenario api server verifies replicationcontroller definition accept misconfigured specifying selector also option case configured automatically label pod template create replicationcontroller use kubectl create command already know kubectl create f kubiarcyaml replicationcontroller kubia created seeing replicationcontroller action pod exist appkubia label replicationcontroller spin three new pod pod template list pod see replicationcontroller ha done supposed kubectl get po name ready status restarts age kubia53thy 01 containercreating 0 6 kubiak0xz6 01 containercreating 0 6 kubiaq3vkg 01 containercreating 0 6 indeed ha wanted three pod created three pod managing three pod next well mess little see replicationcontroller responds try deleting pod rc spawn another pod automatically replicationcontroller ha done job nice little helper isnt understanding exactly caused controller create new pod controller responding deletion pod creating new replacement pod well technically isnt responding deletion resulting statethe inadequate number pod replicationcontroller immediately notified pod deleted api server allows client watch change resource resource list thats cause create replacement pod notification trigger controller check actual number pod take appropriate action pod disappears replicationcontroller see pod creates new replacement pod seeing replicationcontroller respond manual deletion pod isnt interesting let look better example youre using google kubernetes engine run example threenode kubernetes cluster youre going disconnect one node network simulate node failure note youre using minikube cant exercise one node act master worker node node fails nonkubernetes world ops team would need migrate application running node machine manually kubernetes hand doe automatically soon replicationcontroller detects pod spin new pod replace let see action need ssh one node gcloud compute ssh command shut network interface sudo ifconfig eth0 shown following gcloud compute ssh gkekubiadefaultpoolb46381f1zwko enter passphrase key homeknrt10sshgooglecomputeengine welcome kubernetes v1162 knrt10gkekubiadefaultpoolb46381f1zwko sudo ifconfig eth0 shut network interface ssh session stop responding need open another terminal hardexit ssh session new terminal list node see kubernetes ha detected node take minute node status shown notready list pod youll still see three pod kubernetes wait rescheduling pod case node unreachable temporary network glitch kubelet restarting node stay unreachable several minute status pod scheduled node change unknown point replicationcontroller immediately spin new pod see listing pod looking age pod see kubiadmdck pod new three pod instance running mean replicationcontroller ha done job bringing actual state system desired state thing happens node fails either break becomes unreachable immediate human intervention necessary system heals automatically bring node back need reset following command gcloud compute instance reset gkekubiadefaultpoolb46381f1zwko node boot status return ready pod whose status wa unknown deleted moving pod scope replicationcontroller pod created replicationcontroller arent tied replicationcontroller way moment replicationcontroller manages pod match label selector changing pod label removed added scope replicationcontroller even moved one replicationcontroller another tip although pod isnt tied replicationcontroller pod doe reference metadataownerreferences field use easily find replicationcontroller pod belongs change pod label longer match replicationcontrollers label selector pod becomes like manually created pod longer managed anything node running pod fails pod obviously rescheduled keep mind changed pod label replication controller noticed one pod wa missing spun new pod replace kubectl label po kubiadmdck appkubia2 overwrite overwrite argument necessary otherwise kubectl print warning wont change label prevent inadvertently changing existing label value intent add new one four pod altogether one isnt managed replicationcontroller three among newly created pod removing pod scope replicationcontroller changing label replicationcontroller spin pod kubia2qneh bring number back three pod kubiadmdck completely independent keep running delete manually dont need anymore removing pod controller practice removing pod scope replicationcontroller come handy want perform action specific pod example might bug cause pod start behaving badly specific amount time specific event know pod malfunctioning take replicationcontrollers scope let controller replace new one debug play pod way want youre done delete pod changing pod template replicationcontrollers pod template modified time changing pod template like replacing cookie cutter another one affect cooky cut afterward effect one youve already cut see figure modify old pod youd need delete let replication controller replace new one based new template changing replicationcontrollers pod template affect pod created afterward ha effect existing pod exercise try editing replicationcontroller adding label pod template edit replicationcontroller following command kubectl edit rc kubia open replicationcontrollers yaml definition default text editor find pod template section add additional label metadata save change exit editor kubectl update replicationcontroller print following message replicationcontroller kubia edited list pod label confirm havent changed delete pod wait replacement created youll see new label editing replicationcontroller like change container image pod template deleting existing pod letting replaced new one new template could used upgrading pod youll learn better way later horizontally scaling pod scaling number pod easy changing value replica field replicationcontroller resource change replicationcontroller either see many pod exist scaling delete part see scaling create additional pod already know command kubectl scale rc kubia replicas10 instead using kubectl scale command youre going scale declarative way editing replicationcontrollers definition kubectl edit rc kubia text editor open find specreplicas field change value 10 check listing kubectl get rc name desired current ready age kubia 10 10 4 21m scale back 3 use kubectl scale command kubectl scale rc kubia replicas3 horizontally scaling pod kubernetes matter stating desire want x number instance running youre telling kubernetes youre specifying desired state declarative approach make interacting kubernetes cluster easy imagine manually determine current number running instance explicitly tell kubernetes many additional instance run thats work much errorprone changing simple number much easier later youll learn even done kubernetes enable horizontal pod autoscaling deleting replicationcontroller delete replicationcontroller kubectl delete pod also deleted pod created replicationcontroller arent integral part replicationcontroller managed delete replicationcontroller leave pod running shown may useful initially set pod managed replicationcontroller decide replace replicationcontroller replicaset without affecting pod keep running without interruption replace replicationcontroller manages deleting replicationcontroller kubectl delete keep pod running passing cascadefalse option command try kubectl delete rc kubia cascadefalse youve deleted replicationcontroller pod longer managed always create new replicationcontroller proper label selector make managed using replicasets instead replicationcontrollers initially replicationcontrollers kubernetes component replicating pod rescheduling node failed later similar resource called replicaset wa introduced new generation replicationcontroller replaces completely replicationcontrollers eventually deprecated could started section creating replicaset instead replicationcontroller felt would good idea start wa initially available kubernetes please dont report plus well still see replicationcontrollers used wild good know said always create replicasets instead replicationcontrollers theyre almost identical shouldnt trouble using instead replicaset behaves exactly like replicationcontroller ha expressive pod selector whereas replicationcontrollers label selector allows matching pod include certain label replicasets selector also allows matching pod lack certain label pod include certain label key regardless value also example single replicationcontroller cant match pod label envproduction label envdevel time match either pod envproduction label pod envdevel label single replicaset match set pod treat single group similarly replicationcontroller cant match pod based merely presence label key regardless value whereas replicaset example replicaset match pod include label key env whatever actual value isyou think env defining replicaset youre going create replicaset see orphaned pod created replicationcontroller abandoned earlier adopted replicaset youre going create file called kubiareplicasetyaml create directory want copy repo youll find file filename kubiareplicasetyaml following listing show entire content file apiversion appsv1 kind replicaset metadata name kubia spec replica 3 selector matchlabels app kubia template metadata label app kubia spec container name kubia image knrt10kubia port containerport 8080 first thing note replicasets arent part v1 api need ensure specify proper apiversion creating resource youre creating resource type replicaset ha much content replicationcontroller created earlier difference selector instead listing label pod need directly selector property youre specifying selector matchlabels simpler le expressive way defining label selector replicaset still three pod matching appkubia selector running earlier creating replicaset cause new pod created replicaset take existing three pod wing create replicaset using kubectl create command examine using kubectl describe command see replicaset isnt different replicationcontroller showing ha three replica matching selector list pod youll see theyre still three pod replicaset didnt create new one using replicasets expressive label selector main improvement replicasets replicationcontrollers expressive label selector intentionally used simpler matchlabels selector first replicaset example see replicasets different replicationcontrollers add additional expression selector example expression must contain key operator possibly depending operator list value youll see four valid operator inlabels value must match one specified value notinlabels value must match specified value existspod must include label specified key value isnt important using operator shouldnt specify value field doesnotexistpod must include label specified key value property must specified specify multiple expression expression must evaluate true selector match pod specify matchlabels matchexpressions label must match expression must evaluate true pod match selector wa quick introduction replicasets alternative replicationcontrollers remember always use instead replicationcontrollers may still find replicationcontrollers people deployment delete replicaset clean cluster little delete replicaset way youd delete replicationcontroller kubectl delete r kubia replicaset kubia deleted deleting replicaset delete pod list pod confirm thats case running exactly one pod node daemonsets rc r used running specific number pod deployed anywhere kubernetes cluster certain case exist want pod run every node cluster node need run exactly one instance pod case include infrastructure related pod perform systemlevel operation example youll want run log collector resource monitor every node another good example kubernetes kubeproxy process need run node make service work daemonsets run single pod replica node whereas replicasets scatter around whole cluster randomly using daemonset run pod every node run pod cluster node create daemonset object much like replicationcontroller replicaset except pod created daemonset already target node specified skip kubernetes scheduler arent scattered around cluster randomly daemonset make sure creates many pod node deploys one node shown whereas replicaset replicationcontroller make sure desired number pod replica exist cluster daemonset doesnt notion desired replica count doesnt need job ensure pod matching pod selector running node node go daemonset doesnt cause pod created elsewhere new node added cluster daemonset immediately deploys new pod instance also doe someone inadvertently deletes one pod leaving node without daemonsets pod like replicaset daemonset creates pod pod template configured explaning daemon set example let imagine daemon called ssdmonitor need run node contain solidstate drive ssd youll create daemonset run daemon node marked ssd cluster administrator added diskssd label node youll create daemonset node selector selects node label youll create daemonset run mock ssdmonitor process print ssd ok standard output every five second ive already prepared mock container image pushed docker hub use instead building youre going create file called ssdmonitordaemonsetyaml create directory want copy repo youll find file filename ssdmonitordaemonsetyaml following listing show entire content file apiversion appsv1 kind daemonset metadata name ssdmonitor spec selector matchlabels app ssdmonitor template metadata label app ssdmonitor spec nodeselector disk ssd container name main image knrt10ssdmonitor youre defining daemonset run pod single container based knrt10ssdmonitor container image instance pod created node ha diskssd label creating daemonset use kubectl create command know kubectl create f ssdmonitordaemonsetyaml let see created daemonset kubectl get name desired current ready uptodate available node selector age ssdmonitor 0 0 0 0 0 diskssd 18 zero look strange didnt daemonset deploy pod list pod kubectl get po resource found pod know whats going yes forgot label node diskssd label problemyou daemonset detect node label changed deploy pod node matching label let see thats true daemonset created one pod let see kubectl label node minikube diskssd name ready status restarts age ssdmonitorzs6sr 11 running 0 6 okay far good multiple node add label node youll see daemonset spin pod imagine youve made mistake mislabeled one node ha spinning disk drive ssd happens change node label pod terminated knew wa going happen right wrap exploration daemonsets may want delete ssdmonitor daemonset still daemon pod running youll see deleting daemonset deletes pod well running pod perform single completable task far told pod run continuously well case need terminate task completed replicationcontollers relicasets daemonsets run continuously task never considered completed process task restarted exit want want stop process completed introducing job resource kubernetes includes support job resource similar resource discussed far allows run pod whose container isnt restarted process running inside finish successfully doe pod considered complete event node failure pod node managed job reschduled node way replicasets event failure process process return error exit code job configured either restart container shown tell pod created job rescheduled new node node wa initially scheduled fails also show managed pod isnt rescheduled pod backed replicaset example job useful ad hoc task crucial task finish properly could run task unmanaged pod wait finish event node failing pod evicted node performing task youd need manually recreate manually doesnt make sense especially job take hour complete example job would data stored somewhere needed transform export somewhere youre going emulate running container image built top busybox image invokes sleep command two minute ive already built image pushed docker hub peek dockerfile book code archive pod managed job rescheduled finish successfully defining job resource create job manifest following listing youre going create file called exporteryaml create directory want copy repo youll find file filename exporteryaml following listing show entire content file apiversion batchv1 kind job metadata name batchjob spec template metadata label app batchjob spec restartpolicy onfailure container name main image knrt10batchjob job part batch api group v1 api version yaml defines resource type job run knrt10batchjob image invokes process run exactly 120 second exit image already pushed dockerhub pod specification specify kubernetes process running container finish done restartpolicy pod spec property default always job pod cant use default policy theyre meant run indefinitely therefore need explicitly set restart policy either onfailure never setting prevents container restarted finish fact pod managed job resource seeing job run pod create job kubectl create command see start pod immediately kubectl get job name desired successful age batchjob 1 0 2 todo write pod write yaml file write ingres routing write volume write config map secret write updating running pod write statefulsets securing pod container implement write gcp\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1]\n",
      "note repo going updated anymore tensorflow version used repo wa old july 19th 2018 mytensorflowtutorials repo contains tensorflow deep learning project deep learning well traditional machine learning data mining tensorflow kera youtube httpswwwyoutubecomckevinxu fun\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0]\n",
      "topstarreddevsandrepostofollow topstarred python github devs orgs repos follow alltime trending follow topstarred python github devs following influencers usually good practice ha helped multiple way whenever run inspiration look influencers see achieved brings back energy back project follow influencers see event attending reading working quickly become wealth knowledge extent also provides human touch influencers looking profile might come across one world start following regularly tend relate influencers inspired following reddit post reading post wa curious see similar list python github devs orgs repos topstarred definitive way determine top devs orgs repos language every metric ha flaw list look total number star python repository seems decent metric readily availableeasy mine dev stats individual contributor org stats also provided viewing org link show devs part org sure youd measure stats dev part org similarly devs contributing project github perfect classifying repos python list try manually filter misclassified repos found interesting track time trending stats list included source provided list topstarred python github devs follow alltime format dev top repo total dev star kennethreitz request 44472 jkbrzt httpie 26428 nvbn thefuck 23493 donnemartin datascienceipythonnotebooks 20648 rg3 youtubedl 19759 valloric youcompleteme 11875 apenwarr sshuttle 9628 faif pythonpatterns 9033 fchollet kera 8742 tomchristie djangorestframework 8575 jonathanslenders pythonprompttoolkit 7826 binux pyspider 7796 soimort youget 7402 pew maybe 7133 miguelgrinberg flasky 6771 alexjc neuraldoodle 6505 toastdriven restless 6481 coleifer peewee 6437 nvie rq 6229 nicolargo glance 5775 source githubawards last updated 20160821 topstarred python github devs follow trending format dev top repo total dev star donnemartin gitsome 8495 alexjc neuraldoodle 6392 pew maybe 5985 eliangcs httpprompt 5513 0x5e wechatdeletedfriends 4497 a1studmuffin spaceshipgenerator 4284 samshadwell trumpscript 3923 jayfk statuspage 3261 reinderien mimic 3079 pavelgonchar colornet 2825 juanpotato legofy 2783 diafygi acmetiny 2636 cyrusand gdbdashboard 2625 awentzonline imageanalogies 2560 programthink zhao 2361 nlintz tensorflowtutorials 2321 gongjianhui appledns 2009 ujjwalkarn datasciencepython 1986 mchristopher pokemongodesktopmap 1979 yenchenlin deeplearningflappybird 1759 source github search aggregating repos dev last updated 20160821 trending 20150821 20160821 topstarred python github orgs alltime format org top repo total org star pallet flask 33572 openstack nova 24591 django django 24490 google yapf 23552 ansible ansible 21169 scrapy scrapy 17881 docker compose 17070 certbot certbot 16023 shadowsocks shadowsocks 14934 facebook chisel 14082 getsentry sentry 13703 scikitlearn scikitlearn 12993 tornadoweb tornado 11958 reddit reddit 11752 ipython ipython 10567 pydata panda 10079 yelp mrjob 9879 airbnb caravel 9842 kivy kivy 9674 xxnet xxnet 9267 source githubawards last updated 20160821 topstarred python github orgs trending format org top repo total org star rochesternrt rocalphago 7224 tensorflow magenta 5663 cmusatyalab openface 4973 zulip zulip 4005 pokemongof pokemongobot 3990 awslabs awsshell 3742 reverseshell routersploit 3680 tflearn tflearn 3471 magicstack uvloop 3469 openai gym 3399 lektor lektor 1960 pokemongomap pokemongomap 1930 eastlakeside interpyzh 1552 zerodb zerodb 1477 digitalocean netbox 1426 commaai research 1412 nerevu riko 1129 ascribe imagematch 1039 cachebrowser cachebrowser 1024 ansible ansiblecontainer 1003 source github search aggregating repos org last updated 20160821 trending 20150821 20160821 topstarred python github repos alltime jkbrzthttpie 25585cli http client userfriendly curl replacement intuitive ui json support syntax highlighting wgetlike downloads extension etc palletsflask 22167a microframework based werkzeug jinja2 good intention nvbnthefuck 21504magnificent app corrects previous console command djangodjango 20841the web framework perfectionist deadline kennethreitzrequests 20420python http request human rg3youtubedl 19722commandline program download video youtubecom video site ansibleansible 18399ansible radically simple automation platform make application system easier deploy avoid writing script custom code deploy update application automate language approach plain english using ssh agent install remote system certbotcertbot 16024certbot previously let encrypt client effs tool obtain cert let encrypt optionally autoenable http server also act client ca us acme protocol scrapyscrapy 15535scrapy fast highlevel web crawling scraping framework python scikitlearnscikitlearn 12923scikitlearn machine learning python tornadowebtornado 11958tornado python web framework asynchronous networking library originally developed friendfeed valloricyoucompleteme 11558a codecompletion engine vim redditreddit 11269the code power redditcom getsentrysentry 10107sentry crossplatform crash reporting built love ipythonipython 9911official repository ipython repos ipython organization contain thing like website documentation build etc xxnetxxnet 9131a web proxy tool faifpythonpatterns 9028a collection design patternsidioms python dockercompose 8074define run multicontainer application docker fcholletkeras 7706deep learning library python convnets recurrent neural network run theano tensorflow fabricfabric 7517simple pythonic remote execution deployment source github search last updated 20160821 topstarred python github repos trending rochesternrtrocalphago 7224an independent studentled replication deepminds 2016 nature publication mastering game go deep neural network tree search nature 529 484489 28 jan 2016 detail found website httpsdeepmindcompublicationshtml alexjcneuraldoodle 6392turn twobit doodle fine artwork deep neural network generate seamless texture photo transfer style one image another perform examplebased upscaling wait implementation semantic style transfer pewmaybe 5985 see program doe deciding whether really want happen eliangcshttpprompt 5513httpie prompttoolkit interactive commandline http client featuring autocomplete syntax highlighting cmusatyalabopenface 4973face recognition deep neural network 0x5ewechatdeletedfriends 4497 a1studmuffinspaceshipgenerator 4284a blender script procedurally generate 3d spaceship zulipzulip 4005zulip server powerful open source group chat samshadwelltrumpscript 3923make python great reverseshellroutersploit 3680the router exploitation framework pokemongofpokemongobot 3564the pokemon go bot baking community tflearntflearn 3471deep learning library featuring higherlevel api tensorflow jayfkstatuspage 3261a statuspage generator let host statuspage free github donnemartingitsome 3249a supercharged gitgithub command line interface cli openaigym 3131a toolkit developing comparing reinforcement learning algorithm reinderienmimic 3079abusing unicode create tragedy tensorflowmagenta 3008magenta music art generation machine intelligence donnemartinsaws 2955a supercharged aws command line interface cli pavelgoncharcolornet 2825neural network colorize grayscale image juanpotatolegofy 2783make image look made 1x1 lego block source github search last updated 20160821 trending 20150821 20160821 contribution sure license\n",
      "[0 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0\n",
      " 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Show sentences and vector space representation.\n",
    "# purely to visualize what's happening.\n",
    "for i, v in zip(train.text_filtered, bow_array):\n",
    "    print(i)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow = bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '00 uploading',\n",
       " '000',\n",
       " '000 gb',\n",
       " '0000',\n",
       " '0000 0100',\n",
       " '0000 gb',\n",
       " '0004',\n",
       " '0004 10000',\n",
       " '0005',\n",
       " '0005 1000',\n",
       " '0026',\n",
       " '0026 gb',\n",
       " '0045',\n",
       " '0045 download',\n",
       " '0050',\n",
       " '0050 gb',\n",
       " '006',\n",
       " '006 complete',\n",
       " '006 gigabyte',\n",
       " '006 ongoing',\n",
       " '006 storage',\n",
       " '006 using',\n",
       " '0070',\n",
       " '0070 gb',\n",
       " '0085',\n",
       " '0085 gb',\n",
       " '0090',\n",
       " '0090 gb',\n",
       " '01',\n",
       " '01 2018',\n",
       " '01 building',\n",
       " '010',\n",
       " '010 initial',\n",
       " '0100',\n",
       " '0100 pdt',\n",
       " '02',\n",
       " '02 2018',\n",
       " '02 handling',\n",
       " '020',\n",
       " '020 introduces',\n",
       " '022435',\n",
       " '022435 gmt0600',\n",
       " '03',\n",
       " '03 implement',\n",
       " '030',\n",
       " '030 introduces',\n",
       " '04',\n",
       " '04 2010',\n",
       " '04 extending',\n",
       " '040',\n",
       " '040 feature',\n",
       " '041',\n",
       " '041 bug',\n",
       " '05',\n",
       " '05 implementing',\n",
       " '050',\n",
       " '050 feature',\n",
       " '0510',\n",
       " '0510 123456',\n",
       " '0513',\n",
       " '0513 11',\n",
       " '0513 16',\n",
       " '0513 18',\n",
       " '0513 s3publics3toolsorgsomewheredir1file12txt',\n",
       " '0513 s3publics3toolsorgsomewheredir2file22txt',\n",
       " '055',\n",
       " '055 061',\n",
       " '06',\n",
       " '06 error',\n",
       " '060',\n",
       " '060 bug',\n",
       " '061',\n",
       " '061 fix',\n",
       " '062',\n",
       " '062 npm',\n",
       " '070',\n",
       " '070 breaking',\n",
       " '080',\n",
       " '080 fix',\n",
       " '10',\n",
       " '10 2019',\n",
       " '10 fix',\n",
       " '10 tb',\n",
       " '100',\n",
       " '100 3575',\n",
       " '100 5175',\n",
       " '100 bucket',\n",
       " '100 note',\n",
       " '100 tb',\n",
       " '1000',\n",
       " '1000 copy',\n",
       " '10000',\n",
       " '10000 request',\n",
       " '101',\n",
       " '101 script',\n",
       " '1024',\n",
       " '1024 byte',\n",
       " '104',\n",
       " '104 remove',\n",
       " '11',\n",
       " '11 2018',\n",
       " '11 configpaperclipdefaults',\n",
       " '11 s3publics3toolsorgsomewheredir2file21bin',\n",
       " '12',\n",
       " '12 s3credentials',\n",
       " '120',\n",
       " '120 diskpath',\n",
       " '120 frame',\n",
       " '120 remove',\n",
       " '122',\n",
       " '122 updated',\n",
       " '1234',\n",
       " '1234 s3publics3toolsorg',\n",
       " '123456',\n",
       " '123456 100',\n",
       " '123456 123456',\n",
       " '123456 s3publics3toolsorgsomefilexml',\n",
       " '123456789012',\n",
       " '123456789012 displayroleaccountnumber',\n",
       " '13',\n",
       " '13 2018',\n",
       " '13 2019',\n",
       " '13 bucket',\n",
       " '135',\n",
       " '135 thanks',\n",
       " '14',\n",
       " '14 accesskeyid',\n",
       " '140',\n",
       " '140 added',\n",
       " '141',\n",
       " '141 new',\n",
       " '144',\n",
       " '144 154',\n",
       " '148',\n",
       " '148 157',\n",
       " '15',\n",
       " '15 2019',\n",
       " '15 secretaccesskey',\n",
       " '150',\n",
       " '150 155',\n",
       " '150 tb',\n",
       " '1500mb',\n",
       " '1500mb file',\n",
       " '154',\n",
       " '154 new',\n",
       " '155',\n",
       " '155 added',\n",
       " '157',\n",
       " '157 161',\n",
       " '16',\n",
       " '16 17',\n",
       " '16 2018',\n",
       " '16 2019',\n",
       " '16 s3publics3toolsorgsomewheredir1file13log',\n",
       " '161',\n",
       " '161 added',\n",
       " '17',\n",
       " '17 2019',\n",
       " '17 contributing',\n",
       " '177',\n",
       " '177 rationale',\n",
       " '178',\n",
       " '178 177',\n",
       " '18',\n",
       " '18 s3publics3toolsorgsomewheredir1file11txt',\n",
       " '19',\n",
       " '19 2014',\n",
       " '197',\n",
       " '197 c13aca8',\n",
       " '1gb',\n",
       " '1gb month',\n",
       " '1month',\n",
       " '1month loosen',\n",
       " '1st',\n",
       " '1st january',\n",
       " '20',\n",
       " '20 2013',\n",
       " '20 2019',\n",
       " '20 license',\n",
       " '200',\n",
       " '200 type',\n",
       " '2000',\n",
       " '2000 duration',\n",
       " '20072020',\n",
       " '20072020 tgrmn',\n",
       " '2008',\n",
       " '2008 recently',\n",
       " '20090128',\n",
       " '20090128 1234',\n",
       " '20090210',\n",
       " '20090210 0510',\n",
       " '20090210 0513',\n",
       " '2010',\n",
       " '2010 022435',\n",
       " '2010 apr',\n",
       " '20121017',\n",
       " '20121017 statement',\n",
       " '2013',\n",
       " '2013 korea',\n",
       " '2014',\n",
       " '2014 httpsblogalyaccokr1640',\n",
       " '2014 rocketman',\n",
       " '2015',\n",
       " '2015 rolling',\n",
       " '2016',\n",
       " '2016 0000',\n",
       " '2016 2015',\n",
       " '2016 data',\n",
       " '2016 donne',\n",
       " '2016 github',\n",
       " '2016 manual',\n",
       " '2016 repos',\n",
       " '2016 run',\n",
       " '2016 stats',\n",
       " '2016 track',\n",
       " '2016 viz',\n",
       " '2017',\n",
       " '2017 baby',\n",
       " '2018',\n",
       " '2018 freemilk',\n",
       " '2018 group123',\n",
       " '2018 httpsblogalyaccokr1963',\n",
       " '2018 httpsresearchcheckpointcomsilivaccinealookinsidenorthkoreasantivirus',\n",
       " '2018 httpswwwfireeyecomblogthreatresearch201808fin7pursuinganenigmaticandevasiveglobalcriminaloperationhtml',\n",
       " '2019',\n",
       " '2019 attack',\n",
       " '2019 group123',\n",
       " '2019 httpsasecahnlabcom1209',\n",
       " '2019 httpsblogalyaccokr2061',\n",
       " '2019 httpsblogalyaccokr2209',\n",
       " '2019 httpsblogalyaccokr2223',\n",
       " '2019 httpsblogalyaccokr2234',\n",
       " '2019 httpsblogalyaccokr2243',\n",
       " '2019 httpsblogalyaccokr2299',\n",
       " '2019 httpsblogalyaccokr2308',\n",
       " '2019 httpsblogalyaccokr2315',\n",
       " '2019 httpsblogalyaccokr2336',\n",
       " '2019 httpsblogalyaccokr2338',\n",
       " '2019 httpsblogalyaccokr2347',\n",
       " '2019 httpsmpweixinqqcomsltcvlpoomhp0ndgdqhknq',\n",
       " '2019 httpsmpweixinqqcomsxpsexp2j5ie7wnsmevc24a',\n",
       " '2019 httpsresearchcheckpointcomdeobfuscatingapt32flowgraphswithcutterandradare2',\n",
       " '2019 httpsthreatvectorcylancecomenushomereportoceanlotusaptgroupleveragingsteganographyhtml',\n",
       " '2019 httpsthreatvectorcylancecomenushomethreatspotlightratsnifnewnetworkverminfromoceanlotushtml',\n",
       " '2019 httpsunit42paloaltonetworkscombabysharkmalwareparttwoattackscontinueusingkimjongratandpcrat',\n",
       " '2019 httpsunit42paloaltonetworkscomnewbabysharkmalwaretargetsusnationalsecuritythinktanks',\n",
       " '2019 httpswwwcarbonblackcom20190405cbthreatintelligencenotificationhuntingapt28downloaders',\n",
       " '2019 httpswwwfireeyecomblogthreatresearch201904carbanakweekpartonearareoccurrencehtml',\n",
       " '2019 httpswwwfireeyecomblogthreatresearch201904picksixinterceptingafin6intrusionhtml',\n",
       " '2019 httpswwwreuterscomarticleusbayercyberbayersayshasdetectedcontainedcyberattackiduskcn1rg0nn',\n",
       " '2019 httpswwwwelivesecuritycom20190409oceanlotusmacosmalwareupdate',\n",
       " '2019 httpswwwwelivesecuritycom20190529turlapowershellusage',\n",
       " '2019 operation',\n",
       " '2019 pdf',\n",
       " '2019 rocketman',\n",
       " '2019 winnti',\n",
       " '202019',\n",
       " '202019 httpsblogtalosintelligencecom201905recentmuddywaterassociatedblackwaterhtml',\n",
       " '21',\n",
       " '21 2019',\n",
       " '22',\n",
       " '22 2018',\n",
       " '22 2019',\n",
       " '23',\n",
       " '23 2019',\n",
       " '24',\n",
       " '24 2019',\n",
       " '26',\n",
       " '26 2019',\n",
       " '26 newer',\n",
       " '27',\n",
       " '27 python',\n",
       " '272',\n",
       " '272 308',\n",
       " '272019',\n",
       " '272019 httpblogs360cnpostanalysisofaptc38html',\n",
       " '28',\n",
       " '28 2014',\n",
       " '28 2019',\n",
       " '28 online',\n",
       " '29',\n",
       " '29 2019',\n",
       " '2g877batsewopowrjhah9ta',\n",
       " '2g877batsewopowrjhah9ta testfixturesintegrationdirwithsecretsfoofoojson',\n",
       " '2gb',\n",
       " '2gb data',\n",
       " '2gb photo',\n",
       " '2gb storage',\n",
       " '2x',\n",
       " '2x imp',\n",
       " '2x try',\n",
       " '308',\n",
       " '308 online',\n",
       " '308 sequence',\n",
       " '308 subfolders',\n",
       " '3575',\n",
       " '3575 kb',\n",
       " '36',\n",
       " '36 308',\n",
       " '36 newer',\n",
       " '38',\n",
       " '38 install',\n",
       " '39bcb6992e461b269b95b3bda303addf',\n",
       " '39bcb6992e461b269b95b3bda303addf somefile2xml',\n",
       " '39bcb6992e461b269b95b3bda303addf somefilexml',\n",
       " '3x',\n",
       " '3x sending',\n",
       " '3x version',\n",
       " '40',\n",
       " '40 tb',\n",
       " '409',\n",
       " '409 bucketnotempty',\n",
       " '49',\n",
       " '49 million',\n",
       " '500mb',\n",
       " '500mb trainingdatapath',\n",
       " '5175',\n",
       " '5175 kb',\n",
       " '530e5a4a7ea00814db8845dd0cae5efaa4b974a3ce1c76d0384ba715248a5dc1',\n",
       " '530e5a4a7ea00814db8845dd0cae5efaa4b974a3ce1c76d0384ba715248a5dc1 mytestcredential',\n",
       " '60',\n",
       " '60 command',\n",
       " '6months',\n",
       " '6months stats',\n",
       " '80',\n",
       " '80 report',\n",
       " '8010',\n",
       " '8010 run',\n",
       " '8bit',\n",
       " '8bit youll',\n",
       " '90',\n",
       " '90 day',\n",
       " '90 flow',\n",
       " '90 reporttypes',\n",
       " 'aardvark',\n",
       " 'aardvark remove',\n",
       " 'aardvark rest',\n",
       " 'aardvarkapilocation',\n",
       " 'aardvarkapilocation location',\n",
       " 'abbreviation',\n",
       " 'abbreviation gitup',\n",
       " 'ability',\n",
       " 'ability run',\n",
       " 'ability stsassumerole',\n",
       " 'able',\n",
       " 'able catch',\n",
       " 'able easily',\n",
       " 'able generate',\n",
       " 'able inference',\n",
       " 'able submit',\n",
       " 'abstraction',\n",
       " 'abstraction chapter',\n",
       " 'accented',\n",
       " 'accented utf8',\n",
       " 'accept',\n",
       " 'accept lot',\n",
       " 'accept pr',\n",
       " 'accept pull',\n",
       " 'accepting',\n",
       " 'accepting contribution',\n",
       " 'access',\n",
       " 'access advisor',\n",
       " 'access control',\n",
       " 'access file',\n",
       " 'access github',\n",
       " 'access gitup',\n",
       " 'access key',\n",
       " 'access picture',\n",
       " 'access run',\n",
       " 'access secret',\n",
       " 'access token',\n",
       " 'access unused',\n",
       " 'accessdenied',\n",
       " 'accessdenied error',\n",
       " 'accessed',\n",
       " 'accessed using',\n",
       " 'accesskeyid',\n",
       " 'accesskeyid xxxxxxxxxxxxxxxxxxxx',\n",
       " 'according',\n",
       " 'according format',\n",
       " 'account',\n",
       " 'account add',\n",
       " 'account amazon',\n",
       " 'account auth0',\n",
       " 'account aws',\n",
       " 'account contact',\n",
       " 'account endpoint',\n",
       " 'account getting',\n",
       " 'account globally',\n",
       " 'account language',\n",
       " 'account library',\n",
       " 'account linkedin',\n",
       " 'account login',\n",
       " 'account managed',\n",
       " 'account need',\n",
       " 'account number',\n",
       " 'account page',\n",
       " 'account primary',\n",
       " 'account projected',\n",
       " 'account queried',\n",
       " 'account repokid',\n",
       " 'account role',\n",
       " 'account roleid',\n",
       " 'account user',\n",
       " 'accountnumber',\n",
       " 'accountnumber 123456789012',\n",
       " 'accountnumber aardvarkapilocation',\n",
       " 'accountnumber display',\n",
       " 'accountnumber globpattern',\n",
       " 'accountnumber role',\n",
       " 'accountnumber rolename',\n",
       " 'accountnumber scheduling',\n",
       " 'accountnumber1',\n",
       " 'accountnumber1 rolename2',\n",
       " 'accountnumber2',\n",
       " 'accountnumber2 accountnumber3',\n",
       " 'accountnumber3',\n",
       " 'accountnumber3 exclusive',\n",
       " 'accurately',\n",
       " 'accurately youll',\n",
       " 'acknowledgement',\n",
       " 'acknowledgement work',\n",
       " 'acl',\n",
       " 'acl access',\n",
       " 'acl altered',\n",
       " 'acl metadata',\n",
       " 'aclprivate',\n",
       " 'aclprivate command',\n",
       " 'aclprivate option',\n",
       " 'aclpublic',\n",
       " 'aclpublic aclprivate',\n",
       " 'action',\n",
       " 'action action',\n",
       " 'action bitbucket',\n",
       " 'action carefully',\n",
       " 'action circle',\n",
       " 'action deep',\n",
       " 'action delete',\n",
       " 'action dispatched',\n",
       " 'action doe',\n",
       " 'action easily',\n",
       " 'action far',\n",
       " 'action iamdeleteinstanceprofile',\n",
       " 'action list',\n",
       " 'action network',\n",
       " 'action observed',\n",
       " 'action occur',\n",
       " 'action occurs',\n",
       " 'action payload',\n",
       " 'action performed',\n",
       " 'action playback',\n",
       " 'action redux',\n",
       " 'action repository',\n",
       " 'action set',\n",
       " 'action type',\n",
       " 'action unrelatedmeta',\n",
       " 'actionmetaredactfrombugreporter',\n",
       " 'actionmetaredactfrombugreporter true',\n",
       " 'actionmetaredactfrombugreporterfn',\n",
       " 'actionmetaredactfrombugreporterfn redactfrombugreporterfn',\n",
       " 'actionscheckoutv2',\n",
       " 'actionscheckoutv2 fetchdepth',\n",
       " 'actionsensitivefield',\n",
       " 'actionsensitivefield return',\n",
       " 'activate',\n",
       " 'activate dashboard',\n",
       " 'activate filter',\n",
       " 'active',\n",
       " 'active directory',\n",
       " 'active filter',\n",
       " 'active fork',\n",
       " 'active github',\n",
       " 'active make',\n",
       " 'activefilters',\n",
       " 'activefilters config',\n",
       " 'activefilters hook',\n",
       " 'activeforks',\n",
       " 'activeforks active',\n",
       " 'activity',\n",
       " 'activity revealed',\n",
       " 'actor',\n",
       " 'actor recently',\n",
       " 'actual',\n",
       " 'actual state',\n",
       " 'actually',\n",
       " 'actually work',\n",
       " 'ad',\n",
       " 'ad google',\n",
       " 'add',\n",
       " 'add api',\n",
       " 'add article',\n",
       " 'add authentication',\n",
       " 'add bookmark',\n",
       " 'add config',\n",
       " 'add contribution',\n",
       " 'add entry',\n",
       " 'add ggshield',\n",
       " 'add gitguardian',\n",
       " 'add ignored',\n",
       " 'add line',\n",
       " 'add link',\n",
       " 'add list',\n",
       " 'add macro',\n",
       " 'add manually',\n",
       " 'add new',\n",
       " 'add parameter',\n",
       " 'add repos',\n",
       " 'add reposfoo',\n",
       " 'add repository',\n",
       " 'add s3listallmybuckets',\n",
       " 'add skiphookid',\n",
       " 'add support',\n",
       " 'add update',\n",
       " 'add user',\n",
       " 'added',\n",
       " 'added different',\n",
       " 'added excludenonflow',\n",
       " 'added new',\n",
       " 'added optional',\n",
       " 'added percentdecimals',\n",
       " 'added s3cmd',\n",
       " 'added support',\n",
       " 'added time',\n",
       " 'added warning',\n",
       " 'adding',\n",
       " 'adding blocklist',\n",
       " 'adding example',\n",
       " 'adding new',\n",
       " 'adding step',\n",
       " 'adding support',\n",
       " 'addition',\n",
       " 'addition readme',\n",
       " 'additional',\n",
       " 'additional configuration',\n",
       " 'additional data',\n",
       " 'additional generated',\n",
       " 'additional metric',\n",
       " 'additional parameter',\n",
       " 'additional query',\n",
       " 'additionally',\n",
       " 'additionally feature',\n",
       " 'additionally public',\n",
       " 'additionally repokid',\n",
       " 'additionally type',\n",
       " 'address',\n",
       " 'address bar',\n",
       " 'adfs',\n",
       " 'adfs saml',\n",
       " 'adjust',\n",
       " 'adjust output',\n",
       " 'administrator',\n",
       " 'administrator modify',\n",
       " 'adonis',\n",
       " 'adonis jan',\n",
       " 'adversarial',\n",
       " 'adversarial network',\n",
       " 'advice',\n",
       " 'advice support',\n",
       " 'advisor',\n",
       " 'advisor provided',\n",
       " 'affect',\n",
       " 'affect ggshield',\n",
       " 'affiliated',\n",
       " 'affiliated github',\n",
       " 'afterrepo',\n",
       " 'afterrepo role',\n",
       " 'afterreporoles',\n",
       " 'afterreporoles role',\n",
       " 'afterschedulerepo',\n",
       " 'afterschedulerepo role',\n",
       " 'age',\n",
       " 'age filter',\n",
       " 'agent',\n",
       " 'agent docker',\n",
       " 'agent extensible',\n",
       " 'agent stage',\n",
       " 'agreed',\n",
       " 'agreed writing',\n",
       " 'aim',\n",
       " 'aim decrease',\n",
       " 'aimed',\n",
       " 'aimed korea',\n",
       " 'albrecht',\n",
       " 'albrecht boris',\n",
       " 'albrecht bug',\n",
       " 'albrecht fix',\n",
       " 'albrecht help',\n",
       " 'albrecht jason',\n",
       " 'albrecht karolis',\n",
       " 'alert',\n",
       " 'alert giving',\n",
       " 'allow',\n",
       " 'allow amazon',\n",
       " 'allow anonymous',\n",
       " 'allow javascript',\n",
       " 'allow public',\n",
       " 'allow redaction',\n",
       " 'allow redux',\n",
       " 'allow resource',\n",
       " 'allowing',\n",
       " 'allowing repokidinstanceprofile',\n",
       " 'allows',\n",
       " 'allows active',\n",
       " 'allows generate',\n",
       " 'allows interact',\n",
       " 'allows reject',\n",
       " 'allows review',\n",
       " 'allows scan',\n",
       " 'allows scanning',\n",
       " 'allows specifying',\n",
       " 'allows use',\n",
       " 'allowtransparencytrue',\n",
       " 'allowtransparencytrue frameborder0',\n",
       " 'allpolicies',\n",
       " 'allpolicies false',\n",
       " 'allpolicies present',\n",
       " 'allpolicies toggle',\n",
       " 'alltime',\n",
       " 'alltime stats',\n",
       " 'alongside',\n",
       " 'alongside bug',\n",
       " 'alphanumeric',\n",
       " 'alphanumeric character',\n",
       " 'alter',\n",
       " 'alter passed',\n",
       " 'altered',\n",
       " 'altered existing',\n",
       " 'altering',\n",
       " 'altering actual',\n",
       " 'alternatively',\n",
       " 'alternatively acl',\n",
       " 'alternatively setting',\n",
       " 'amadey',\n",
       " 'amadey russia',\n",
       " 'amazing',\n",
       " 'amazing youve',\n",
       " 'amazon',\n",
       " 'amazon account',\n",
       " 'amazon aws',\n",
       " 'amazon charge',\n",
       " 'amazon obviously',\n",
       " 'amazon s3',\n",
       " 'amazon simple',\n",
       " 'amazon storing',\n",
       " 'amazon using',\n",
       " 'amazon web',\n",
       " 'america',\n",
       " 'america april',\n",
       " 'amont',\n",
       " 'amont enterprise',\n",
       " 'analysis',\n",
       " 'analysis report',\n",
       " 'analysis smoke',\n",
       " 'analysis white',\n",
       " 'analytics',\n",
       " 'analytics user',\n",
       " 'analyze',\n",
       " 'analyze google',\n",
       " 'andor',\n",
       " 'andor modify',\n",
       " 'andrew',\n",
       " 'andrew lawson',\n",
       " 'andy',\n",
       " 'andy mackay',\n",
       " 'angularjs',\n",
       " 'angularjs usage',\n",
       " 'angularjs v100',\n",
       " 'angularmodulemyapp',\n",
       " 'angularmodulemyapp ui',\n",
       " 'angularui',\n",
       " 'angularui companion',\n",
       " 'angularui master',\n",
       " 'annotate',\n",
       " 'annotate code',\n",
       " 'annotated',\n",
       " 'annotated considered',\n",
       " 'annotated file',\n",
       " 'annotation',\n",
       " 'annotation 050',\n",
       " 'annotation multiple',\n",
       " 'annotation percentdecimals',\n",
       " 'annotation strict',\n",
       " 'annotation type',\n",
       " 'announcement',\n",
       " 'announcement new',\n",
       " 'anonymous',\n",
       " 'anonymous read',\n",
       " 'antidetection',\n",
       " 'antidetection techniquesmay',\n",
       " 'antivirus',\n",
       " 'antivirus 2018',\n",
       " 'anymore',\n",
       " 'anymore script',\n",
       " 'apache',\n",
       " 'apache license',\n",
       " 'api',\n",
       " 'api geocoder',\n",
       " 'api gitguardianapiurl',\n",
       " 'api gitguardiandontloadenv',\n",
       " 'api interested',\n",
       " 'api key',\n",
       " 'api leverage',\n",
       " 'api like',\n",
       " 'api pygitguardian',\n",
       " 'api python',\n",
       " 'api rate',\n",
       " 'api star',\n",
       " 'api stateless',\n",
       " 'api url',\n",
       " 'api view',\n",
       " 'apis',\n",
       " 'apis flow',\n",
       " 'apiurl',\n",
       " 'apiurl gitguardianyaml',\n",
       " 'apiurl httpsapigitguardiancom',\n",
       " 'app',\n",
       " 'app review',\n",
       " 'app wrapped',\n",
       " 'append',\n",
       " 'append listen3000',\n",
       " 'appjs',\n",
       " 'appjs working',\n",
       " 'applicable',\n",
       " 'applicable law',\n",
       " 'applicable update',\n",
       " 'application',\n",
       " 'application heavy',\n",
       " 'application know',\n",
       " 'application maintains',\n",
       " 'application preliminary',\n",
       " 'application redux',\n",
       " 'application reinforces',\n",
       " 'application run',\n",
       " 'application thats',\n",
       " 'application usually',\n",
       " 'applicationjson',\n",
       " 'applicationjson event',\n",
       " 'applied',\n",
       " 'applied initial',\n",
       " 'applies',\n",
       " 'applies language',\n",
       " 'applymiddlewaremiddleware',\n",
       " 'applymiddlewaremiddleware return',\n",
       " 'appropriate',\n",
       " 'appropriate doc',\n",
       " 'appropriate error',\n",
       " 'appropriate parameter',\n",
       " 'appropriate tokenizer',\n",
       " 'apps',\n",
       " 'apps active',\n",
       " 'apr',\n",
       " 'apr 19',\n",
       " 'april',\n",
       " 'april 17',\n",
       " 'april 2019',\n",
       " 'april 22',\n",
       " 'april 24',\n",
       " 'april 26',\n",
       " 'apt',\n",
       " 'apt attack',\n",
       " 'apt attacker',\n",
       " 'apt campaign',\n",
       " 'apt disguised',\n",
       " 'apt group',\n",
       " 'apt organization',\n",
       " 'apt report',\n",
       " 'apt target',\n",
       " 'apt28',\n",
       " 'apt28 cb',\n",
       " 'apt28 downloaders',\n",
       " 'apt32',\n",
       " 'apt32 flow',\n",
       " 'aptc38',\n",
       " 'aptc38 attack',\n",
       " 'aptget',\n",
       " 'aptget install',\n",
       " 'aptreport',\n",
       " 'aptreport collected',\n",
       " 'archive',\n",
       " 'archive supplement',\n",
       " 'args',\n",
       " 'args command',\n",
       " 'args gitup',\n",
       " 'args option',\n",
       " 'argument',\n",
       " 'argument abbreviation',\n",
       " 'argument commit',\n",
       " 'argument gitup',\n",
       " 'argument list',\n",
       " 'argument repo',\n",
       " 'argument save',\n",
       " 'armor',\n",
       " 'armor scale',\n",
       " 'arn1',\n",
       " 'arn1 arn2',\n",
       " 'arn2',\n",
       " 'arn2 rolename1',\n",
       " 'arns',\n",
       " 'arns arn1',\n",
       " 'art',\n",
       " 'art application',\n",
       " 'art source',\n",
       " 'article',\n",
       " 'article add',\n",
       " 'article article',\n",
       " 'article codebase',\n",
       " 'article contributing',\n",
       " 'article control',\n",
       " 'article copyright',\n",
       " 'article format',\n",
       " 'article markdown',\n",
       " 'article youd',\n",
       " 'asana',\n",
       " 'asana taiga',\n",
       " 'asdf',\n",
       " 'asdf taken',\n",
       " 'asia',\n",
       " 'asia muddywater',\n",
       " 'aside',\n",
       " 'aside address',\n",
       " 'ask',\n",
       " 'ask developer',\n",
       " 'asked',\n",
       " 'asked key',\n",
       " 'asked question',\n",
       " 'asset',\n",
       " 'asset content',\n",
       " 'associated',\n",
       " 'associated module',\n",
       " 'assume',\n",
       " 'assume redux',\n",
       " 'assumed',\n",
       " 'assumed application',\n",
       " 'assumerole',\n",
       " 'assumerole accountnumber',\n",
       " 'assumerole repokidrole',\n",
       " 'assumerole subsection',\n",
       " 'attack',\n",
       " 'attack 28',\n",
       " 'attack activity',\n",
       " 'attack attention',\n",
       " 'attack continue',\n",
       " 'attack impersonating',\n",
       " 'attack kimsuky',\n",
       " 'attack mobile',\n",
       " 'attack north',\n",
       " 'attack operation',\n",
       " 'attack printing',\n",
       " 'attack russiannorth',\n",
       " 'attack technology',\n",
       " 'attacker',\n",
       " 'attacker overseas',\n",
       " 'attempt',\n",
       " 'attempt attack',\n",
       " 'attempt load',\n",
       " 'attention',\n",
       " 'attention feb',\n",
       " 'attention httpsblogalyaccokr1521',\n",
       " 'attribute',\n",
       " 'attribute development',\n",
       " 'attribute global',\n",
       " 'audit',\n",
       " 'audit changed',\n",
       " 'audit failure',\n",
       " 'audit source',\n",
       " 'audit updated',\n",
       " 'aug',\n",
       " 'aug 22',\n",
       " 'august',\n",
       " 'august 01',\n",
       " 'auth0',\n",
       " 'auth0 auth0',\n",
       " 'auth0 click',\n",
       " 'auth0 create',\n",
       " 'auth0 help',\n",
       " 'auth0 issue',\n",
       " 'auth0 license',\n",
       " 'authentication',\n",
       " 'authentication multiple',\n",
       " 'authentication source',\n",
       " 'authentication traditional',\n",
       " 'author',\n",
       " 'author auth0',\n",
       " 'author author',\n",
       " 'author directory',\n",
       " 'author drew',\n",
       " 'author folder',\n",
       " 'author format',\n",
       " 'author ha',\n",
       " 'author license',\n",
       " 'author mengyu',\n",
       " 'author michal',\n",
       " 'author note',\n",
       " 'author tim',\n",
       " 'autogenerated',\n",
       " 'autogenerated config',\n",
       " 'automated',\n",
       " 'automated backup',\n",
       " 'automatic',\n",
       " 'automatic browser',\n",
       " 'automatic logging',\n",
       " 'automatically',\n",
       " 'automatically add',\n",
       " 'automatically automatic',\n",
       " 'automatically flowcoveragereport',\n",
       " 'automatically iam',\n",
       " 'automatically ignore',\n",
       " 'automatically include',\n",
       " 'automatically open',\n",
       " 'automatically pass',\n",
       " 'automatically pull',\n",
       " 'automatically update',\n",
       " 'available',\n",
       " 'available aws',\n",
       " 'available buildhtml',\n",
       " 'available dnsincompatible',\n",
       " 'available gnu',\n",
       " 'available link',\n",
       " 'available option',\n",
       " 'available replace',\n",
       " 'available replay',\n",
       " 'avoid',\n",
       " 'avoid duplication',\n",
       " 'aws',\n",
       " 'aws account',\n",
       " 'aws amazon',\n",
       " 'aws gitsecrets',\n",
       " 'aws hosted',\n",
       " 'aws key',\n",
       " 'aws lambda',\n",
       " 'aws s3',\n",
       " 'azure',\n",
       " 'azure ad',\n",
       " 'babel',\n",
       " 'babel build',\n",
       " 'babel v7',\n",
       " 'baby',\n",
       " 'baby attention',\n",
       " 'baby coin',\n",
       " 'baby giant',\n",
       " 'baby related',\n",
       " 'babyshark',\n",
       " 'babyshark malware',\n",
       " 'backend',\n",
       " 'backend redux',\n",
       " 'backend service',\n",
       " 'background',\n",
       " 'background gradual',\n",
       " 'backup',\n",
       " 'backup bad',\n",
       " 'backup precious',\n",
       " 'backup s3',\n",
       " 'bad',\n",
       " 'bad march',\n",
       " 'badge',\n",
       " 'badge flowbadgesvg',\n",
       " 'badge related',\n",
       " 'badge reporter',\n",
       " 'badgeup',\n",
       " 'badgeup npm',\n",
       " 'bar',\n",
       " 'bar baz',\n",
       " 'bar gitup',\n",
       " 'bar meta',\n",
       " 'bar paste',\n",
       " 'base',\n",
       " 'base folder',\n",
       " 'based',\n",
       " 'based codemirror',\n",
       " 'based file',\n",
       " 'based frvsr',\n",
       " 'based lpips1',\n",
       " 'baserevision',\n",
       " 'baserevision pipelinegitbaserevision',\n",
       " 'basic',\n",
       " 'basic alphanumeric',\n",
       " 'basic file',\n",
       " 'basic usage',\n",
       " 'basis',\n",
       " 'basis warranty',\n",
       " 'batch',\n",
       " 'batch script',\n",
       " 'baugsson',\n",
       " 'baugsson sigriarson',\n",
       " 'bayersayshasdetectedcontainedcyberattack',\n",
       " 'bayersayshasdetectedcontainedcyberattack april',\n",
       " 'baz',\n",
       " 'baz git',\n",
       " 'baz gitup',\n",
       " 'beforereporoles',\n",
       " 'beforereporoles accountnumber',\n",
       " 'begin',\n",
       " 'begin making',\n",
       " 'beginning',\n",
       " 'beginning role',\n",
       " 'beginning used',\n",
       " 'behavior',\n",
       " 'behavior enabling',\n",
       " 'behavior pre05',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create CountVectorizer, which create bag-of-words model.\n",
    "# stop_words : Specify language to remove stopwords. \n",
    "# min_df: ignore terms that have a document frequency strictly \n",
    "# lower than the given threshold. This value is also called cut-off in the literature. \n",
    "# If float, the parameter represents a proportion of documents, integer absolute counts. \n",
    "# ngram_range: the lower and upper boundary of the range of n-values for \n",
    "# different word n-grams or char n-grams to be extracted. \n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', \n",
    "                             #min_df=20, \n",
    "                             ngram_range=(1,2), \n",
    "                             binary=True)\n",
    "\n",
    "# Learn vocabulary in sentences. \n",
    "vectorizer.fit(validate.text_filtered)\n",
    "\n",
    "# Get dictionary. \n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform each sentences in vector space.\n",
    "v_bow = vectorizer.transform(validate.text_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is just to see the array of 0's and 1's\n",
    "v_bow_array = v_bow.toarray()\n",
    "v_bow_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viz index viz gallery viz interactive website faq viz gallery interact following visualization table viz website httpwwwdonnemartincomviz viz interactive website httpwwwdonnemartincomviz community visualization d3d3fc colineberhardt contribute faq viz viewing raw stats table tell part story viz help tell rest story interactive visualization continually updated help stay uptodate evolution viz viz getting started help spread word contribution feedback welcome feel free follow star fork check back update iframe srchttpsghbtnscomgithubbtnhtmluserdonnemartintypefollowcounttrue frameborder0 scrolling0 width145 height20iframe iframe idghstar srchttpsghbtnscomgithubbtnhtmluserdonnemartinrepoviztypestarcountfalse allowtransparencytrue frameborder0 scrolling0 width50 height20iframe iframe idghfork srchttpsghbtnscomgithubbtnhtmluserdonnemartinrepoviztypefork allowtransparencytrue frameborder0 scrolling0 width53 height20iframe navigate viz dashboard within viz offer different level interactivity try interacting filter hovering element view tooltip info clicking element highlight filter change activate dashboard following control viz offline yes youll need free reader download run latest viz workbook allows interact local copyyoull need download latest workbook update continually pushed depending setup youll likely see improved performance running viz locally doe online viz reset several minute inactivity session timeout inactivity detail view post tableau forum isnt online interactive viz loading visualization hosting service might issue check status also run viz offline see visualization javascript python r please check following ticket community visualization d3d3fc colineberhardt contribute data tracked although github trending great tool discover upandcoming project allows review one month data thirdparty site often show alltime stats relatively static dominated wellestablished repos viz meant supplement existing solution filtering newest popular repos created within specific timeframe example viz 2016 track repos created within year 2016 see stats time range 2016 viz currently provides stats 2016 2015 rolling 1 3 6months see stats older repos future viz extended track repos regardless creation date feedback ticket welcome mine data mining data directly github viz powered github api leverage following github3py access github api python panda following ipython notebook data wrangling google map api geocoder location data tableau public visualization future google bigquery along github archive could also supplement github api interested visualization javascript python r check following ticket find data data data table tableau workbook mine 2016 data viz 2016 stats mined january 1 2016 0000 0100 pdt include repos created year 2016 data preserved 2016 manual search result different viz 2016 github search manually run query similar would get github api view moststarred javascript repos created 2016 run following query created2016010120161231 stars100 languagejavascript check stats user orgs repos created 2016 run created2016010120161231 stars100 userusername star count search show data time performed search restrict search result stars100 stars500 viz 2016 repos stars100 tracked help filter githubs rapidly growing 49 million repository keep within github api rate limit visualization additional data pull request issue contributor commits filter repos stars500 viz 6 3 1month might loosen restriction le repos analyze google bigquery along github archive could also supplement github api star fork viz provides stats repos user orgs star many case fork star fork perfect metric yet simple fairly effective measure interest detailed discussion measuring repo popularity check popularity github application preliminary note concludes number star system tends correlate number fork also effective usage client application reinforces importance star real measure system popularity new support additional metric update viz includes additional data pull request issue contributor commits stats user orgs calculated provide stats user orgs viz group star fork user org note stars100 restriction still applies language tracked viz track popular language github plus unknown language option repo language identified githublinguist missing popular language feel free file request language javascript java objectivec python swift go php c c cs html ruby c shell scala clojure coffeescript lua haskell viml r perl julia unknown overall viz affiliated github viz affiliated github viz community project github community github community contribute please review contributing guideline detail submit issue submit pull request check issue tracker contact feel free contact discus issue question comment email donnemartingmailcom twitter donnemartin github donnemartin linkedin donnemartin website donnemartincom also file ticket issue tracker license viz providing code resource repository open source license personal repository license receive code resource employer facebook copyright 2016 donne martin licensed apache license version 20 license may use file except compliance license may obtain copy license httpwwwapacheorglicenseslicense20 unless required applicable law agreed writing software distributed license distributed basis without warranty condition kind either express implied see license specific language governing permission limitation license\n",
      "[0 0 0 ... 0 0 0]\n",
      "gitguardian shield protect secret gitguardian gitguardian shield ggshield cli application run local environment ci environment help detect 200 type secret well potential security vulnerability policy break gitguardian shield us public api pygitguardian scan file detect potential secret code v1scan endpoint public api stateless store file sending secret detected also use ggshield via precommit framework repository standalone precommit either globally locally youll need api key gitguardian use ggshield add api key environment variable gitguardianapikeygitguardian api key currently supported integration precommit hook prereceive hook gitlab github action bitbucket pipeline circle ci orb travis ci jenkins table content introduction installation configuration environment variable onpremises command scan install precommit precommit framework global local precommit hook prereceive hook gitlab github action circle ci travis ci jenkins output contributing license installation install update using pip pip install ggshield ggshield support python 36 newer package run macos linux window youll need api key gitguardian dashboard use ggshield add api key environment variable gitguardianapikeygitguardian api key command usage ggshield option command args option c configpath file set custom config file ignores local global config file v verbose verbose display mode h help show message exit command install command install precommit hook local global scan command scan various content scan command ggshield scan main command ggshield ha config option used override output behaviour usage ggshield scan option command args command scan various content option showsecrets show secret plaintext instead hiding exitzero always return 0 nonerror status code even incident foundthe env var gitguardianexitzero also used set option json json output result default false allpolicies present fails policy filename fileextensions secret detection default secret detection shown v verbose verbose display mode output path route ggshield output file h help show message exit command ci scan ci environment commitrange scan defined commitrange git path scan file directory precommit scan precommit git hook repo clone scan repository ggshield scan ha different subcommands type scan ci scan commit since last build ci ggshield scan ci option argument commit range scan commit given commit range usage ggshield scan commitrange option commitrange scan defined commitrange git git revlist commitrange list several commits scan example ggshield scan commitrange head1 path scan file directory recursive option usage ggshield scan path option path scan file directory option r recursive scan directory recursively yes confirm recursive scan h help show message exit precommit scan every change staged git repository ggshield scan precommit option argument repo scan commits git repository usage ggshield scan repo option repository scan repository given url path repository clone uri path repository scan example ggshield scan repo gitgithubcomgitguardianggshieldgit ggshield scan repo repositoriesggshield install command install command allows use ggshield precommit hook machine either locally globally repository find detail precommit part documentation usage ggshield install option command install precommit hook local global option mode localglobal hook installation mode required f force force override h help show message exit configuration configuration ggshield follows globallocalcli configuration scheme meaning option local overwrite extend global option cli overwrite extend local ggshield search global config file user home directory example gitguardianyml linux userprofilegitguardian window ggshield recognize well local config file user working directory example gitguardianyml also use option configpath main command set another config file case neither local global config file evaluated example ggshield configpathdesktoponlyconfigyaml scan path r sample config file found gitguardianexample exclude file path globbing pathsignore readmemd doc license ignore policy break sha256 policy break obtained output secret matchesignore 530e5a4a7ea00814db8845dd0cae5efaa4b974a3ce1c76d0384ba715248a5dc1 mytestcredential showsecrets false default false set true desired exit code cli always 0 otherwise exit code 1 incident found environment variable gitguardianexitzerotrue also used toggle behaviour exitzero false default false default secret detected use allpolicies toggle behaviour allpolicies false default false apiurl httpsapigitguardiancom gitguardianapiurl environment variable override setting verbose false default false environment variable configuration ggshield done environment variable environment variable override setting set config file overridden command line option startup ggshield attempt load environment variable different environment file following order path pointed environment variable gitguardiandotenvpath env current work directory env root current git directory one file loaded three reference current environment variable affect ggshield gitguardianapikey required api key gitguardian api gitguardianapiurl custom url scanning api gitguardiandontloadenv set value environment variable wont loaded file gitguardiandotenvpath set path ggshield attempt load environment specified file onpremises configuration gitguardian shield configured run onpremises dashboard request api key dashboard administrator modify environment variable include gitguardianapikeygitguardian api key gitguardianapiurlgitguardian onpremises api url alternatively setting gitguardianapiurl environment variable set apiurl gitguardianyaml precommit precommit framework order use ggshield precommit framework need following step make sure precommit installed pip install precommit create precommitconfigyaml file root repository repos repo httpsgithubcomgitguardianggshield rev main hook id ggshield languageversion python3 stage commit install hook command precommit install precommit installed githooksprecommit youre good go want skip precommit check add n parameter git commit commit message n another way add skiphookid command skipggshield git commit commit message global local precommit hook install precommit globally current future repos need execute following command ggshield install mode global following check global hook folder defined global git configuration create githooks folder needed create precommit file executed every commit give executable access file also install hook locally desired repository need go repository execute ggshield install mode local precommit executable file already exists overridden force override force option ggshield install mode local force already precommit executable file want use ggshield need add line file ggshield scan precommit want try precommit scanning docker image docker run e gitguardianapikey v pwddata rm gitguardianggshield ggshield scan precommit forget add gitguardian api key gitguardianapikey environment variable project development environment git prereceive hook prereceive hook allows reject commits pushed git repository validate every check find ggshields prereceive hook sample docprereceivesample docprereceivepythonsample python git prereceive hook prereceive hook requires host machine python36 pip installed prereceivepythonsample install ggshield pip pip install ggshield move prereceivepythonsample githooksprereceive forget chmod x githooksprereceive either set environment variable machine wide gitguardianapikey set githooksprereceive instructed sample file add ignored match use custom config prereceive hook create gitguardianyaml somewhere system example config file available replace prereceive hook ggshield scan commitrange span continue ggshield c insert path gitguardianyaml scan commitrange span continue docker git prereceive hook prereceive hook requires host machine docker installed prereceivesample move prereceivesample githooksprereceive forget chmod x githooksprereceive either set environment variable machine wide gitguardianapikey set githooksprereceive instructed sample file add ignored match use custom config prereceive hook create gitguardianyaml somewhere system example config file available replace prereceive hook docker run rm v pwddata e gitguardianapikey gitguardianggshieldlatest ggshield scan commitrange span continue docker run rm v pwddata v insert path gitguardianyaml directoryconfig e gitguardianapikey gitguardianggshieldlatest ggshield c configgitguardianyaml scan commitrange span continue gitlab may interested using gitguardians gitlab integration ensure full coverage gitlab project well full git history scan reporting configuring gitlab pipeline use ggshield simple adding step project pipeline stage scanning gitguardian scan image gitguardianggshieldlatest stage scanning script ggshield scan ci forget add gitguardian api key gitguardianapikey environment variable project setting github may interested using gitguardians github integration ensure full coverage github project well full git history scan reporting ggshields support github come form github action action repository hosted ggshieldaction configuring github workflow use ggshield simple adding step project workflow name gitguardian scan push pullrequest job scanning name gitguardian scan runson ubuntulatest step name checkout us actionscheckoutv2 fetchdepth 0 fetch history multiple commits scanned name gitguardian scan us gitguardianggshieldactionmaster env githubpushbeforesha githubeventbefore githubpushbasesha githubeventbase githubpullbasesha githubeventpullrequestbasesha githubdefaultbranch githubeventrepositorydefaultbranch gitguardianapikey secretsgitguardianapikey forget add gitguardian api key gitguardianapikey secret project setting bitbucket bitbucket pipeline support commit range therefore latest commit pushed group new branch scanned configuring bitbucket pipeline use ggshield simple adding step project workflow pipeline default step image gitguardianggshieldlatest service docker script ggshield scan ci forget add gitguardian api key gitguardianapikey environment variable project setting circle ci circle ci supported ggshield ggshieldorb add ggshield pipeline configure circleciconfigyml add ggshield orb orb ggshield gitguardianggshield workflow main job ggshieldscan name ggshieldscan best practice name orb job baserevision pipelinegitbaserevision revision pipelinegitrevision forget add gitguardian api key gitguardianapikey environment variable project setting travis ci add ggshield pipeline configure travisyml add ggshield scanning job job include name gitguardian scan language python python 38 install pip install ggshield script ggshield scan ci forget add gitguardian api key gitguardianapikey environment variable project setting defining encrypted variable travisyml jenkins add ggshield pipeline configure jenkinsfile add ggshield stage pipeline agent none stage stagegitguardian scan agent docker image gitguardianggshieldlatest environment gitguardianapikey credentialsgitguardianapikey step sh ggshield scan ci forget add gitguardian api key gitguardianapikey credential project setting output secret policy break found exit code 0 ggshield scan precommit secret issue found staged code ci alert giving type policy break filename policy break ha found patch giving position policy break file ggshield scan precommit 2 policy break found file productionrb 11 configpaperclipdefaults 12 s3credentials 13 bucket xxx 14 accesskeyid xxxxxxxxxxxxxxxxxxxx aws key 15 secretaccesskey xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx aws key 16 17 contributing question would like ask developer feedback would like provide feel free create issue issue tracker would love hear additionally feature would like suggest feel free create issue issue tracker related open source project trufflehog gitleaks gitrob githound aws gitsecrets detectsecrets license gitguardian shield mit licensed\n",
      "[0 0 0 ... 0 0 0]\n",
      "make8bitart make8bitartcom webbased pixel art application thats super fun free open source install run web make8bitartcom locally machine downloading compressed export gliltch unzipping directing browser indexhtml project root directory contribute remix project glitch send link changed app review merge downloaded project work locally run npm install grunt build grunt used concatenate minify j cs file build folder dependency make8bitartcom us jquery jquery plugin wrote draggybits local dev dependency express grunt along various grunt plugins misc note yes know isnt technically 8bit youll get project ha v chill development cycle im poppin feature come folk request expect change often shocked find gross code suggestion im totally open hear learn youre nerf dart made jenn schiffer designed built created graphic passion project dinosaur art source wa found variety geocities website feature request email jenndotbizinfo tweetdm jennschiffer huge shout everyone ha contributed wild project tessa thornton tim branyen vlad filippov mike taylor brian brennan zach leatherman tyler benziger samir zahran phillip calvin monica dinculescu greg smith dominick guzzo andrew lawson noelle leigh xoxo j jennmoneybiz\n",
      "[0 0 0 ... 0 0 0]\n",
      "tecogan repository contains source code material tecogan project ie code temporally coherent gan video superresolution author mengyu chu xie laura lealtaixe nil thuerey technical university munich repository far contains code tecogan inference training data generation ie download follow soon pretrained model also available find link downloading instruction video preprint paper found video httpswwwyoutubecomwatchvpzxfxtfdak preprint httpsarxivorgpdf181109393pdf additional generated output method generates fine detail persist course long generated video sequence eg mesh structure armor scale pattern lizard dot back spider highlight capability method spatiotemporal discriminator play key role guide generator network towards producing coherent detail running tecogan model find quick start guide running trained tecogan model explanation parameter take look runganpy file note evaluation test case 2 currently requires nvidia gpu cuda tkinter also required may installed via python3tk package install tensorflow18 pip3 install ignoreinstalled upgrade tensorflowgpu tensorflow install pytorch necessary metric evaluation thing pip3 install r requirementstxt download tecogan model vid4 tos scene shown paper video python3 runganpy 0 run inference mode calendar scene take look parameter explanation runganpy feel free try scene python3 runganpy 1 evaluate result 4 metric psnr lpips1 temporal metric tof tlp pytorch take look paper detail python3 runganpy 2 train tecogan model 1 prepare training data training validation dataset downloaded following command chosen directory trainingdatapath note online video downloading requires youtubedl install youtubedl online video downloading pip install user upgrade youtubedl take look parameter first python3 datapreparepy help safe side want see happen following line wont download anything save information log file trainingdatapath still important directory log saved trainingdatapathloglogfilemmddhhmmtxt python3 datapreparepy startid 2000 duration 120 diskpath trainingdatapath test create 308 subfolders trainingdatapath 120 frame 28 online video take long time python3 datapreparepy startid 2000 duration 120 remove diskpath trainingdatapath ready please update parameter trainingdatapath runganpy case 3 case 4 start training downloaded data note data 272 308 sequence one used published model 36 308 online anymore hence script downloads suitable replacement 2 train model section give command train new tecogan model detail additional parameter found runganpy file note tensorboard gif summary requires ffmpeg install ffmpeg gif summary sudo aptget install ffmpeg conda install ffmpeg train tecogan model based frvsr model please check update following parameter vggpath us model default vgg model ca 500mb trainingdatapath see mainpy also adjust output directory testwhiletrain function like write train sub directory default python3 runganpy 3 train without dst ie frvsr model python3 runganpy 4 view log via tensorboard tensorboard logdirextecoganmmddhhlog port8008 tensorboard gif summary example acknowledgement work wa funded erc starting grant realflow erc stg2015637014 part code based lpips1 photorealistic sisr2 gifsummary3 reference 1 unreasonable effectiveness deep feature perceptual metric lpips 2 photorealistic single image superresolution using generative adversarial network 3 gifsummary tum i15 httpsgeintumde tum httpswwwtumde\n",
      "[0 0 0 ... 0 0 0]\n",
      "howtonodeorg community supported blog program nodejs powered new static blog engine written node called wheat run local version blog simply install wheat dependency nodejs v01101 later spark installed type spark directory append listen3000 right closing semicolon run node appjs get working wheat environment box ivy contributing best way contribute fork repository add article first article please add entry author directory well article format every article markdown file metadata top file title control flow node part ii author tim caswell date thu feb 04 2010 022435 gmt0600 cst node v0191 much fun writing last article control flow decided first section display javascript file display content external javascript file path relative markdown file testcodetestfilejs display content external javascript file evaluate content testcodeevaluatefilejs content go author format every author ha markdown file located author folder name file name surname name surnamemarkdown github yourgithubaccount email youremaildomaincom homepage httpyourhomepagecom twitter yourtwitteraccount location city state country word starting project local machine please check project still working add contribution run project three easy step install npmpackages npm install start server node serverserverjs enjoy local blog clone httplocalhost8080 doc come soon licensing article copyright individual author author put note license copyright individual bio page wish\n",
      "[0 0 0 ... 0 0 0]\n",
      "ethereumcasts companion repo ethereumsolidity course udemy\n",
      "[0 0 0 ... 0 0 0]\n",
      "angularui companion suite angularjs usage requirement angularjs v100 currently required jquery plugins depends directive check specific directive dependency information installation repository come module prebuilt compressed build directory angularmodulemyapp ui module found directive filter folder check readme file associated module specific module usage information development need build project use see working need know requirement install nodejs npm come install local dependency npm install install global dependency grunt coffeescript testacular npm install g testacular coffeescript grunt build file run test commit always run grunt build test everything grunt test develop module come unit test run change certainly commiting change project unit test also provide insight usage module first start testacular server grunt server open browser httplocalhost8080 run watch command rerun test every save grunt watch publishing core team wish publish new version follow step bump version number inside packagejson build test commit updated packagejson build folder commit tag commit git tag vmajminpatch push tag git push angularui master tag\n",
      "[0 0 0 ... 0 0 0]\n",
      "letsbuildexpress series chapter teach create express library scratch help u understand express actually work behind scene use code variable name forth express people read tutorial feel free contribute express directly find people often get confused next work route order work express building express library gain solid understanding also fun chapter build express step step running example toc chapter 01 building express abstraction chapter 02 handling route box chapter 03 implement next function chapter 04 extending response object chapter 05 implementing sendjson response chapter 06 error handling wip come note work progress minimal working library corresponding tutorial done contribution welcome feel free improve repo grammar mistake technical glitch maybe translation happy accept pr license mit\n",
      "[0 0 0 ... 0 0 0]\n",
      "chrome extension display repository size github automatically add repository size githubs repository summary screenshot private repository enable viewing size private repository install extension chrome webstore havent go httpsgithubcomsettingstokens generate personal access token check repo scope enable extension private repo click github repo size extension extension icon aside address bar paste access token prompt box temporarily override token set xgithubtoken localstorage access token extension use value even youve previously set token localstoragesetitemxgithubtoken yourpersonalaccesstoken remove use previously set token localstorageremoveitemxgithubtoken development clone repo go chrome extension chromeextensions enable developer mode click load unpacked extension select cloned repo license mit\n",
      "[0 0 0 ... 0 0 0]\n",
      "gitup gitrepoupdater gitup tool updating multiple git repository smart enough handle several remote dirty working directory diverged local branch detached head wa originally created manage large collection project deal sporadic internet access gitup work macos linux window latest version git either python 27 python 3 installed installation pip pip install gitup homebrew brew install gitup source first git clone gitgithubcomearwiggitrepoupdatergit cd gitrepoupdater install everyone sudo python setuppy install make sure localbin path python setuppy install user finally simply delete gitrepoupdater directory youre done note using window may wish add macro invoke gitup directory note cpython27 refers directory python installed doskey gitupcpython27pythonexe cpython27scriptsgitup usage two way update repos pas command argument save bookmark example gitup reposfoo reposbar reposbaz automatically pull foo bar baz git repository additionally type gitup repos automatically update git repository directory add bookmark either work gitup add reposfoo reposbar reposbaz gitup add repos update bookmark run gitup without args gitup delete bookmark gitup delete repos view current bookmark gitup list mix match bookmark command argument gitup add reposfoo reposbar gitup reposbaz update baz gitup update foo bar gitup reposbaz update update three update git repository current directory gitup control deep gitup look repository given directory directory git repo depth option depth 0 disable recursion entirely meaning provided path must repos depth 1 descend one level old behavior pre05 gitup depth 1 recurse indefinitely recommended default depth 3 default gitup fetch remote repository pas currentonly c make fetch remote tracked current branch also default gitup try fastforward branch upstreams configured always skip branch possible eg dirty working directory mergerebase required pas fetchonly f skip step fetch remote fetching gitup keep remotetracking branch longer exist upstream pas prune p delete set fetchprune remotenameprune git config default full list command argument abbreviation gitup help\n",
      "[0 0 0 ... 0 0 0]\n",
      "generate personal youtube report getting started 1 install python 3 dont already python 3 installed computer download httpswwwpythonorgdownloads 2 get youtube data find download google data httpssupportgooglecomaccountsanswer3024190hlen download data google ha stored httpstakeoutgooglecom use script need select download youtube google provide zip file default 3 clone repository httpsgithubcoma3m4personalyoutubereportgenerator click green clone download button top right page click download zip button extract zip somewhere computer note make sure set google account language english downloading 4 extract takeout file extract takeout filefrom step 2 move repository folderfrom step 3 file repository folder look like 5 install dependency open command prompt terminal window repository folder type following press enter pip install r requirementstxt 6 run script command prompt terminal window type following press enter python reportpy 7 result script generate file named youtubereportpdf file automatically open browser script completes besides find image make report image folder\n",
      "[0 0 0 ... 0 0 0]\n",
      "github doc repository contains documentation website code markdown source file docsgithubcom githubs doc team work preproduction content private repo regularly syncs public repo article contributing readmes license contributing start contributing right accept lot different contribution including dont require write single line code click make contribution doc youre using github doc may find something article youd like add update change click make contribution navigate directly article codebase begin making contribution open issue youve found problem open issue using template solve issue solution one open issue need fork repository submit pr using template visible automatically pull request body detail process please check getting started contributing join u discussion use github discussion talk sort topic related documentation site example youd like help troubleshooting pr great new idea want share something amazing youve learned doc join u discussion thats thats get started easily member github documentation community want know youre making complex contribution check getting started contributing thing know youre getting started repo youre trouble github account contact support accept pull request translated content see contributingmd information readmes addition readme youre reading right repo includes readmes describe purpose subdirectory detail contentreadmemd contributingreadmemd datareadmemd datareusablesreadmemd datavariablesreadmemd includesliquidtagsreadmemd includesreadmemd javascriptsreadmemd layoutsreadmemd libliquidtagsreadmemd middlewarereadmemd scriptreadmemd stylesheetsreadmemd testsreadmemd license github product documentation asset content data folder licensed ccby license code repository licensed mit license using github logo sure follow github logo guideline\n",
      "[0 0 0 ... 0 0 0]\n",
      "opencv2pythonguide repo contains tutorial opencvpython library using new cv2 interface imp tutorial meant opencv 3x version opencv 2x imp tutorial meant opencv 3x version opencv 2x imp tutorial meant opencv 3x version opencv 2x please try example opencv 3x sending bug report data file input data used tutorial given data folder online official tutorial please visit httpdocsopencvorgtrunkdocpytutorialspytutorialshtml httpsopencvpythontutroalsreadthedocsorgenlatestindexhtml checking may contain lot error please stick official tutorial offline build doc source install sphinx downloadclone repo navigate base folder run command make html html doc available buildhtml folder\n",
      "[0 0 0 ... 0 0 0]\n",
      "repokid repokid us access advisor provided aardvark remove permission granting access unused service inline policy iam role aws account getting started install mkvirtualenv repokid git clone gitgithubcomnetflixrepokidgit cd repokid pip install e repokid config configjson dynamodb need dynamodb table called repokidroles specify account endpoint dynamodb config file table following property roleid string primary partition key primary sort key global secondary index named account primary partition key account roleid account projected attribute global secondary index named rolename primary partition key rolename roleid rolename projected attribute development run dynamo locally run locally java djavalibrarypathdynamodblocallib jar dynamodblocaljar shareddb inmemory port 8010 run development version table index created automatically iam permission repokid need iam role account queried additionally repokid need launched role user stsassumerole different account role repokidinstanceprofile create one need ability call stsassumerole repokidroles dynamodb permission repokidroles table index specified assumerole subsection dynamodb config ability run dynamodblisttables repokidrole must exist every account managed repokid must trust policy allowing repokidinstanceprofile name must specified connectioniam config file ha permission version 20121017 statement action iamdeleteinstanceprofile iamdeleterole iamdeleterolepolicy iamgetaccountauthorizationdetails iamgetinstanceprofile iamgetrole iamgetrolepolicy iamlistinstanceprofiles iamlistinstanceprofilesforrole iamlistrolepolicies iamputrolepolicy iamupdateroledescription effect allow resource monitoring n account always need n1 role n repokidroles 1 repokidinstanceprofile editing configjson running repokid config configjson creates file need edit find update field dynamodb using dynamo locally set endpoint httplocalhost8010 using aws hosted dynamo set region assumerole accountnumber aardvarkapilocation location aardvark rest api something like httpsaardvarkyourcompanynetapi1advisors connectioniam set assumerole repokidrole whatever called optional config repokid us filter decide role candidate repoed filter may configured suit environment described blocklist filter role may excluded adding blocklist filter one common reason exclude role corresponding workload performs occasional action may observed known required two way exclude role exclude role name account add list config filterconfigblocklistfilterall exclude role name specific account add list config filterconfigblocklistfilteraccountnumber blocklists also maintained s3 blocklist file following form arns arn1 arn2 name rolename1 accountnumber1 rolename2 accountnumber2 accountnumber3 exclusive filter prefer repo certain role use exclusive filter maybe want consider role used production certain team select role repoing may list name configuration file shell style glob pattern also supported role selection specified per individual account globally activate filter put repokidfiltersexclusiveexclusivefilterin section activefilters config file configure start autogenerated config file ha example config filterconfig section exclusivefilter globpattern accountnumber globpattern age filter default age filter excludes role younger 90 day change edit config setting filterconfigagefilterminimumage active filter new filter created support internal logic netflix several specific use case make active make sure python path add config list section activefilters hook repokid extensible via hook called various operation listed hook name context afterrepo role error afterreporoles role error beforereporoles accountnumber role afterschedulerepo role duringrepoablecalculation accountnumber rolename potentiallyrepoablepermissions minimumage duringrepoablecalculationbatch rolebatch potentiallyrepoablepermissions minimumage example hook implementation found repokidhooksloggers use repokid configured use follows standard flow update role cache repokid updaterolecache accountnumber display role cache repokid displayrolecache accountnumber display information specific role repokid displayrole accountnumber rolename repo specific role repokid reporole accountnumber rolename repo role account repokid repoallroles accountnumber c scheduling rather running repo right schedule one schedulerepo command duration scheduling eligibility configurable default role repoed 7 day scheduling run command reposcheduledroles repo role already scheduled targeting specific permission say find given permission especially dangerous environment ill use s3putobjectacl example use repokid find role permission even hidden wildcard remove single permission find remove ensure role cache updated beginning find role given permission repokid findroleswithpermissions permission outputrolefile remove permission role repokid removepermissionsfromroles rolefilerolefile permission c example repokid findroleswithpermissions s3putobjectacl stsassumerole outputmyrolesjson repokid removepermissionsfromroles rolefilemyrolesjson s3putobjectacl stsassumerole c rolling back repokid store copy version inline policy know added different version policy found updaterolecache time repo action occurs restore previous version run see version role repokid rollbackrole accountnumber rolename restore specific version repokid rollbackrole accountnumber rolename selectionnumber c stats repokid keep count total permission role stats added time updaterolecache reporole action occur output stats csv file run repokid repostats outputfilename optional account number specified output stats specific account library new v0142 repokid called library using repokidlib module repokidlib import displayrole reporole updaterolecache accountnumber 123456789012 displayroleaccountnumber supercoolrolename updaterolecacheaccountnumber reporoleaccountnumber supercoolrolename committrue dispatcher repokid dispatcher designed listen message queue perform action far action list repoable service role set remove optout list perform rollback role repokid respond configurable sn topic information success failure dispatcher component exists help operationalization repo lifecycle across organization may choose expose queue directly developer likely guarded rolling back destructive action done carefully\n",
      "[0 0 0 ... 0 0 0]\n",
      "typescripthandbook repo deprecated handbook ha moved new typescript website repo find revised updated handbook page packagesdocumentation repo typescripthandbook typescript handbook comprehensive guide typescript language meant read online typescript website directly repository formal description language see latest typescript language specification contribute typescripthandbook accepting contribution youve submitted pr existing issue please post comment issue avoid duplication effort see contributing file information also contains guideline submit pr\n",
      "[0 0 0 ... 0 0 0]\n",
      "aptreport collected blackorbird httpstwittercomblackorbird interesting apt report sample malware technology intellegence collection apt group country group123 scarcruft continues evolve introduces bluetooth harvester httpssecurelistcomscarcruftcontinuestoevolveintroducesbluetoothharvester90729 may 13 2019 group123 attempt attack printing paper apt disguised guide organization conference httpsblogalyaccokr2287 may 2 2019 group123 apt attack impersonating unification ministry spread malicious code google drive httpsblogalyaccokr2268 april 22 2019 group123 apt organization operation high expert httpsblogalyaccokr2226 april 2 2019 rocketman apt campaign returned operation holiday wiper httpsblogalyaccokr2089 jan 23 2019 operation blackbird mobile invasion httpsblogalyaccokr2035 dec 13 2018 group123 operation korean sword underway httpsblogalyaccokr1985 nov 16 2018 group123 group latest apt campaign operation rocket man httpsblogalyaccokr1853 aug 22 2018 group123 flash player zeroday cve20184878 attack attention httpsblogalyaccokr1521 feb 02 2018 group123 group survey total number discovery separated family north south httpsblogalyaccokr1767 july 28 2014 rocketman apt campaign operation golden bird httpsblogalyaccokr2205 march 20 2013 korea crosshairs httpsblogtalosintelligencecom201801koreaincrosshairshtml jan 16 2018 freemilk highly targeted spear phishing campaign httpsunit42paloaltonetworkscomunit42freemilkhighlytargetedspearphishingcampaign oct 5 2017 baby related kimsuky babyshark malware part two attack continue using kimjongrat pcrat april 26 2019 httpsunit42paloaltonetworkscombabysharkmalwareparttwoattackscontinueusingkimjongratandpcrat operation giant baby giant threat march 28 2019 httpsblogalyaccokr2223 malicious code installed coin purse programalibaba march 15 2019 httpsasecahnlabcom1209 new babyshark malware target u national security think tank feb 22 2019 httpsunit42paloaltonetworkscomnewbabysharkmalwaretargetsusnationalsecuritythinktanks korea latest apt attack operation mystery baby attention feb 11 2018 httpsblogalyaccokr1963 returned korea operation baby coin apt attacker overseas target 2010 apr 19 2014 httpsblogalyaccokr1640 kimsuky kimsuky blue house green support sangchunjae estimate httpsblogalyaccokr2645 kimsuky cyber security bureau cryptographic case may 28 2019 httpsblogalyaccokr2338 kimsuky korea cryptographic exchange event impersonation apt attack may 28 2019 httpsblogalyaccokr2336 kimsuky fake striker apt campaign aimed korea may 20 2019 httpsblogalyaccokr2315 analysis smoke screen apt campaign aimed korea america april 17 2019 httpsblogalyaccokr2243 encrypted apt attack kimsuky organization smoke screen part 2 may 13 2019 httpsblogalyaccokr2299 kimsuky organization operation stealth power silence operation april 3 2019 httpsblogalyaccokr2234 kimsuky organization watering hole started operation low kickmarch 21 2019 httpsblogalyaccokr2209 jaku silivaccine inside north korea antivirus may 1 2018 httpsresearchcheckpointcomsilivaccinealookinsidenorthkoreasantivirus lazarus lazarus group go filelessan implant w remote download inmemory execution httpsobjectiveseecomblogblog0x51html lazarus apt target mac user poisoned word document httpswwwsentinelonecombloglazarusapttargetsmacuserspoisonedworddocument konni konnis apt group conduct attack russiannorth korean trade economic investment document httpsblogalyaccokr2535 apt campaign konni kimsuky find commonality organization june 10 2019 httpsblogalyaccokr2347 korean kusa konni organization blue sky utilizing amadey russia botnet may 16 2019 httpsblogalyaccokr2308 konni apt campaign operation hunter adonis jan 1 2019 httpsblogalyaccokr2061 oceanlotus threat spotlight ratsnif new network vermin oceanlotus july 1 2019 httpsthreatvectorcylancecomenushomethreatspotlightratsnifnewnetworkverminfromoceanlotushtml analysis report attack mobile device oceanlotus may 24 2019 httpsmpweixinqqcomsltcvlpoomhp0ndgdqhknq oceanlotus first quarter 2019 attack technology chinaapril 24 2019 httpsmpweixinqqcomsxpsexp2j5ie7wnsmevc24a deobfuscating apt32 flow graph cutter radare2 april 24 2019 httpsresearchcheckpointcomdeobfuscatingapt32flowgraphswithcutterandradare2 oceanlotus steganography malware analysis white paper april 2 2019 httpsthreatvectorcylancecomenushomereportoceanlotusaptgroupleveragingsteganographyhtml oceanlotus macos malware updateapril 9 2019 httpswwwwelivesecuritycom20190409oceanlotusmacosmalwareupdate apt28 cb tau threat intelligence notification hunting apt28 downloaders april 5 2019 httpswwwcarbonblackcom20190405cbthreatintelligencenotificationhuntingapt28downloaders turla dive turla powershell usage may 29 2019 httpswwwwelivesecuritycom20190529turlapowershellusage tick tick group new campaign attack north korean japan httpswwwahnlabcomkrsitesecurityinfosecunewssecunewsviewdocurpage1menudist2seq28186 april 1 2019 winnti bayersayshasdetectedcontainedcyberattack april 5 2019 httpswwwreuterscomarticleusbayercyberbayersayshasdetectedcontainedcyberattackiduskcn1rg0nn httpswwwtagesschaudeinlandhackerangriffbayer101html middle east asia muddywater recent muddywaterassociated blackwater campaign show sign new antidetection techniquesmay 202019 httpsblogtalosintelligencecom201905recentmuddywaterassociatedblackwaterhtml zoopark aptc38 attack activity revealed may 272019 httpblogs360cnpostanalysisofaptc38html apt group finance carbanak carbanak week part one rare occurrence april 22 2019 httpswwwfireeyecomblogthreatresearch201904carbanakweekpartonearareoccurrencehtml londonblue nigeria evolving tactic london blue start spoofing target domain april 4 2019 pdf folder httpswwwagaricomemailsecuritybloglondonblueevolvingtactics fin6 picksix intercepting fin6 intrusion actor recently tied ryuk lockergoga ransomwareapril 5 2019 httpswwwfireeyecomblogthreatresearch201904picksixinterceptingafin6intrusionhtml fin7 hunt fin7 pursuing enigmatic evasive global criminal operation august 01 2018 httpswwwfireeyecomblogthreatresearch201808fin7pursuinganenigmaticandevasiveglobalcriminaloperationhtml\n",
      "[0 0 0 ... 0 1 1]\n",
      "s3cmd tool amazon simple storage service s3 author michal ludvig michallogixcz project homepage c tgrmn software contributor s3tools s3cmd mailing list announcement new release s3toolsannouncelistssourceforgenet general question discussion s3toolsgenerallistssourceforgenet bug report s3toolsbugslistssourceforgenet s3cmd requires python 26 newer python 3 also supported starting s3cmd version 2 s3cmd s3cmd s3cmd free command line tool client uploading retrieving managing data amazon s3 cloud storage service provider use s3 protocol google cloud storage dreamhost dreamobjects best suited power user familiar command line program also ideal batch script automated backup s3 triggered cron etc s3cmd written python open source project available gnu public license v2 gplv2 free commercial private use pay amazon using storage lot feature option added s3cmd since first release 2008 recently counted 60 command line option including multipart uploads encryption incremental backup s3 sync acl metadata management s3 bucket size bucket policy amazon s3 amazon s3 provides managed internetaccessible storage service anyone store amount data retrieve later s3 paid service operated amazon storing anything s3 must sign aws account aws amazon web service obtain pair identifier access key secret key need give key s3cmd think username password s3 account amazon s3 pricing explained time writing cost using s3 usd 0026 per gb per month storage space used plus 000 per gb data uploaded plus 0000 per gb first 1gb month data downloaded 0090 per gb 10 tb month data downloaded 0085 per gb next 40 tb month data downloaded 0070 per gb next 100 tb month data downloaded 0050 per gb data downloaded month 150 tb plus 0005 per 1000 put copy list request 0004 per 10000 get request instance 1st january upload 2gb photo jpeg holiday new zealand end january charged 006 using 2gb storage space month 00 uploading 2gb data cent request come slightly 006 complete backup precious holiday picture february dont touch data still s3 server pay 006 two gigabyte single cent charged transfer come 006 ongoing cost backup bad march allow anonymous read access picture friend download say 1500mb file owned responsible cost incurred mean end march youll charged 006 storage plus 0045 download traffic generated friend minimum monthly contract setup fee use pay beginning bill used like us003 even nil thats pricing model amazon s3 nutshell check amazon s3 homepage detail needle say money charged amazon obviously payment using s3cmd amazon s3 basic file stored s3 called object name officially called key since sometimes confusing user often refer object file remote file object belongs exactly one bucket describe object s3 storage invented urilike schema following form s3bucket s3bucketobject bucket bucket sort like directory folder restriction user 100 bucket bucket name must unique amongst user s3 bucket nested deeper hierarchy name bucket consist basic alphanumeric character plus dot dash space accented utf8 letter etc good idea use dnscompatible bucket name instance mean use upper case character dns compliance strictly required feature described available dnsincompatible named bucket one step using fully qualified domain name fqdn bucket ha even benefit example s3mybucket dns compatible hand s3mybucket dns compatible fqdn finally s3mybuckets3toolsorg dns compatible fqdn provided s3toolsorg domain create domain record mybuckets3toolsorg look virtual host later text detail regarding fqdn named bucket object file stored amazon s3 unlike bucket almost restriction object name utf8 string 1024 byte long interestingly enough object name contain forward slash character thus myfunnypicturejpg valid object name note directory bucket called funny really single object name called myfunnypicturejpg s3 doe care look like directory structure full uri image could example s3mybucketmyfunnypicturejpg public v private file file stored s3 either private public private one readable user uploaded public one read anyone additionally public file accessed using http protocol using s3cmd similar tool acl access control list file set time upload using aclpublic aclprivate option s3cmd put s3cmd sync command see alternatively acl altered existing remote file s3cmd setacl aclpublic aclprivate command simple s3cmd howto register amazon aws s3 go httpawsamazoncoms3 click sign web service button right column work registration supply credit card detail order allow amazon charge s3 usage end access secret key set separate iam user user access key must least following permission anything s3listallmybuckets s3getbucketlocation s3listbucket example policy found httpsdocsawsamazoncomamazons3latestdevexamplepoliciess3html run s3cmd configure asked two key copy paste confirmation email amazon account page careful copying case sensitive must entered accurately youll keep getting error invalid signature similar remember add s3listallmybuckets permission key get accessdenied error testing access run s3cmd l list bucket started using s3 bucket owned output empty make bucket s3cmd mb s3mynewbucketname mentioned bucket name must unique amongst user s3 mean simple name like test asdf already taken must make something original demonstrate many feature possible let create fqdnnamed bucket s3publics3toolsorg s3cmd mb s3publics3toolsorg bucket s3publics3toolsorg created list bucket s3cmd l see freshly created bucket s3cmd l 20090128 1234 s3publics3toolsorg list content bucket s3cmd l s3publics3toolsorg empty indeed upload single file bucket s3cmd put somefilexml s3publics3toolsorgsomefilexml somefilexml s3publics3toolsorgsomefilexml 1 1 123456 123456 100 2 5175 kb done upload twodirectory tree bucket virtual directory s3cmd put recursive dir1 dir2 s3publics3toolsorgsomewhere file dir1file11txt stored s3publics3toolsorgsomewheredir1file11txt 1 5 file dir1file12txt stored s3publics3toolsorgsomewheredir1file12txt 2 5 file dir1file13log stored s3publics3toolsorgsomewheredir1file13log 3 5 file dir2file21bin stored s3publics3toolsorgsomewheredir2file21bin 4 5 file dir2file22txt stored s3publics3toolsorgsomewheredir2file22txt 5 5 see didnt create somewhere directory fact filename prefix real directory doesnt created way beforehand instead using put recursive option could also use sync command s3cmd sync dir1 dir2 s3publics3toolsorgsomewhere list bucket content s3cmd l s3publics3toolsorg dir s3publics3toolsorgsomewhere 20090210 0510 123456 s3publics3toolsorgsomefilexml use recursive r list remote file s3cmd l recursive s3publics3toolsorg 20090210 0510 123456 s3publics3toolsorgsomefilexml 20090210 0513 18 s3publics3toolsorgsomewheredir1file11txt 20090210 0513 8 s3publics3toolsorgsomewheredir1file12txt 20090210 0513 16 s3publics3toolsorgsomewheredir1file13log 20090210 0513 11 s3publics3toolsorgsomewheredir2file21bin 20090210 0513 8 s3publics3toolsorgsomewheredir2file22txt retrieve one file back verify hasnt corrupted s3cmd get s3publics3toolsorgsomefilexml somefile2xml s3publics3toolsorgsomefilexml somefile2xml 1 1 123456 123456 100 3 3575 kb done md5sum somefilexml somefile2xml 39bcb6992e461b269b95b3bda303addf somefilexml 39bcb6992e461b269b95b3bda303addf somefile2xml checksum original file match one retrieved one look like worked retrieve whole directory tree s3 use recursive get s3cmd get recursive s3publics3toolsorgsomewhere file s3publics3toolsorgsomewheredir1file11txt saved somewheredir1file11txt file s3publics3toolsorgsomewheredir1file12txt saved somewheredir1file12txt file s3publics3toolsorgsomewheredir1file13log saved somewheredir1file13log file s3publics3toolsorgsomewheredir2file21bin saved somewheredir2file21bin file s3publics3toolsorgsomewheredir2file22txt saved somewheredir2file22txt since destination directory wasnt specified s3cmd saved directory structure current working directory important difference get s3publics3toolsorgsomewhere get s3publics3toolsorgsomewhere note trailing slash s3cmd always us last path part ie word last slash naming file case s3somewhere last path part somewhere therefore recursive get name local file somewheredir1 somewheredir2 etc hand s3somewhere last path part empty s3cmd create dir1 dir2 without somewhere prefix s3cmd get recursive s3publics3toolsorgsomewhere file s3publics3toolsorgsomewheredir1file11txt saved dir1file11txt file s3publics3toolsorgsomewheredir1file12txt saved dir1file12txt file s3publics3toolsorgsomewheredir1file13log saved dir1file13log file s3publics3toolsorgsomewheredir2file21bin saved dir2file21bin see dir1 somewheredir1 wa previous example clean delete remote file remove bucket remove everything s3publics3toolsorgsomewhere s3cmd del recursive s3publics3toolsorgsomewhere file s3publics3toolsorgsomewheredir1file11txt deleted file s3publics3toolsorgsomewheredir1file12txt deleted try remove bucket s3cmd rb s3publics3toolsorg error s3 error 409 bucketnotempty bucket tried delete empty ouch forgot s3publics3toolsorgsomefilexml force bucket removal anyway s3cmd rb force s3publics3toolsorg warning bucket empty removing object first may take time file s3publics3toolsorgsomefilexml deleted bucket s3publics3toolsorg removed hint basic usage simple described previous section increase level verbosity v option youre really keen know program doe bonnet run see debugging output configuring configure available option spitted s3cfg file text file ready modified favourite text editor transfer command put get cp mv sync continue transferring even object fails failure occurs failure output stderr exit status expartial 2 option stoponerror specified config option stoponerror true transfer stop appropriate error code returned information refer s3cmd s3tools homepage license copyright c 20072020 tgrmn software httpwwwtgrmncom contributor program free software redistribute andor modify term gnu general public license published free software foundation either version 2 license option later version program distributed hope useful without warranty without even implied warranty merchantability fitness particular purpose see gnu general public license detail\n",
      "[1 1 1 ... 0 0 0]\n",
      "flowcoveragereport flowcoveragereport node command line tool help project using flow type javascript code keep track visualize coverage flow type check generate flow coverage report project install command line tool globally dev dependency project npm install g flowcoveragereport npm install savedev flowcoveragereport run flow reporter configures include glob x exclude pattern threshold configure minimum coverage build fail default 80 report type enabled flowcoveragereport srcjs srcjsx x srctest html json text threshold 90 flow executable path specified using f option flowcoveragereport f pathtoflow customize output dir default flowcoverage use option though default output type text meaning ouputs console use conjunction save desired format flowcoveragereport mycustomflowcoveragedir customize type use option flowcoveragereport html load default option json config file config flag allows specifying path config file config file json file following structure concurrentfiles 1 globexcludepatterns nodemodules flowcommandpath pathtoflowbin globincludepatterns srcjs outputdir pathtooutput projectdir pathtoproject threshold 90 reporttypes text type one text html json default text load default option packagejson npm package default option also configured including flowcoveragereport packagejson property property name mynpmpackage version 101 script flowcoverage flowcoveragereport flowcoveragereport globincludepatterns srclibjs srclibjsx reporttypes text html json background gradual typing system javascript flow help statically check part javascript code supporting syntax annotate code type supporting syntax declare export import new type implicitly explicitly inferencing type identifier used code much possible unfortunately even good amount powerful inferencing strategy sometimes flow able inference type chunk code thats usually source meh moment blame flow able catch issue thought would catch statically fortunately flow ha coverage command give u quantitative info flow type coverage optionally colorbased visualization part source file covered single file generate quantitative info useful visualization uncoverage part source entire project found changelog 080 fix upgraded production dependency 197 c13aca8 unpinned dependency fix 122 updated babel v7 updated parsejson v5 updated react reactdom v16 updated stripjsoncomments v3 updated yargs v16 070 breaking change dropped support nodejs 10 fix npm audit updated mkdirp dependency version 104 remove minimist dependency fix npm audit failure due cve20207598 062 npm audit updated mkdirp dependency version 055 061 fix npm audit changed badgeup npm dependency rplbadgeup forked original currently unmantained package update svgo dependency detected npm audit source moderate security vulnerability 178 see 177 rationale 060 bug fix added support new flow annotation strict strictlocal 150 155 added warning deprecated config name improve cliconfig type check feature added percentdecimals cli option 148 157 161 added excludenonflow cli option 144 154 new release fix issue new flow annotation eg strict strictlocal introduces two new command line option excludenonflow automatically ignore file match pattern flow annotation percentdecimals n include n decimal digit coverage percent value thanks ville saukkonen ben style contributing new excludenonflow percentdeciments option xandor schiefer adding support new flow annotation 050 feature added new badge reporter 140 added new strictcoverage option enforce strict coverage reporting mode 141 new badge reporter implicitly executed html report enabled generates two badge flowbadgesvg badge related flow validation check flowcoveragebadgesvg badge related flow coverage level reached project new strictcoverage option enables strict coverage reporting flow annotated file considered covered non annotated file flow weak annotated one considered fully uncovered thanks runar berg baugsson sigriarson contributing new badge reporter desmond brand matt sprague contributing new strictcoverage option 041 bug fix fixed wrong annotation multiple pragmas line 135 thanks ryan albrecht karolis grinkevicius help bugfix release 040 feature collect report flow preamble annotation type along coverage information thanks ryan albrecht bug fix fixed bug related ignored custom threshold rendered html report thanks boris egorov fixed coverage percent 0 rendered nan report text upgraded flow v0573 fixed new flow error julien wajsberg fix flow coverage escaped special char filename thanks ryan albrecht boris egorov julien wajsberg help new release 030 introduces new command line option submit 1 concurrent file flow using c nummanconcurentfilessubmitted default 1 load option specific config file using config filepath disable config loading using noconfig flowcoveragereport v030 load configuration automatically flowcoveragereport section target project packagejson flowcoveragereportjson file project dir going help reduce number command line option explicitly passed command line version flowcoveragereport npm package also switching mit license feature enhancement html report template thanks jason laster added optional cconcurrentfiles option submit multiple file flow optionally load config packagejson json config file bug fix fixed missing error exit code text reporter fixed link github cli help saved collected coverage data temp json file support larger project thanks ryan albrecht jason laster guillaume claret steven luscher help new release 020 introduces new command line option excluded file pattern using x pattern customize output dir using reportdirpath flowcoveragereport v020 also introduces fix needed able generate flow coverage report larger project project flow issue new command line option fix fixed nan percent react falsepositive mutation warning thanks ilium saulenko feat new cli option customize output dir thanks ryan albrecht fix cleanup old dirs new babel build thanks ryan albrecht fix fixed issue larger project project flow issue thanks ilium saulenko ryan albrecht help hunting issue feat new x cli option exclude file coverage report fix fixed reporttext rendering issue larger number file feat highlight file error coverage data report feat included url generated html report console output thanks jason laster thanks ilium saulenko ryan albrecht jason laster help new release 010 initial prototype release collect report coverage data json text html navigable sourcefile coverage html view based codemirror run unit test travis thanks kumar mcmillan andy mackay advice support project github repo wouldnt exist without\n",
      "[0 0 0 ... 0 0 0]\n",
      "activeforks find active github fork project project allows find active fork repository find active fork bookmarklet would like use tool bookmarklet saving following javascript code bookmarklet since github doesnt allow javascript markdown add manually hit ctrld create new bookmark paste javascript url location entry may click see url field time youre github repo click bookmarklet itll bring active fork repo javascriptthingdocumenturlmatchgithubcomazwazwif thingvar newpage httpstechgaungithubioactiveforksindexhtmlthing1opennewpage20targetname2020else20windowalertnot20a20valid20github20page\n",
      "[0 0 0 ... 0 0 0]\n",
      "redux bug reporter author drew schuster greg mathews demo demo prototype demo video feature easy bug filing user able easily file bug right application redux logging bug filed automatically pass along everything needed recreate bug initial redux state action performed final redux state redaction customizable hook allow redaction sensitive information redux state action payload bug submission easy playback bug global function windowbugreporterplayback available replay bug automatic logging browser error call consoleerror windowonerror filed bug automatically automatic browser info logging bug filed automatically include window dimension window location user agent extensible extra property passed meta redux bug reporter component filed alongside bug submit property either url custom function return promise allow redux bug reporter work development environment integration bug tracker ship integration jira github issue asana taiga google sheet via sheetsu easy write custom integration bug tracker integration documentation installation easiest way use redux bug reporter install npm include build process webpack browserify etc npm install save reduxbugreporter umd build also available link relstylesheet hrefreduxbugreporterdistreduxbugreportermincss script srcreduxbugreporterdistreduxbugreporterminjsscript performance production use redux bug reporter put minimal overhead redux action however doe keep copy initial state final state bug submission full copy action dispatched application heavy action network request large payload frequent action redux bug reporter gradually take memory probably good idea disable production default example demonstrate expected common behavior enabling redux bug reporter nonproduction environment serverside rendering redux bug reporter disables default window undefined negatively impact server side render run production redux bug reporter run production assumed application usually wouldnt want bug reporter displayed page allow public user file bug desired behavior redux bug reporter doe work production usage 1 use redux update configure store function configurestoreinitialstate const store createstorereducer initialstate compose applymiddlewaremiddleware return store becomes es6 import storeenhancer reduxbugreporter es5 var storeenhancer requirereduxbugreporterstoreenhancer function configurestoreinitialstate const store createstorereducer initialstate compose processenvnodeenv production storeenhancer f f applymiddlewaremiddleware return store dont store enhancer middlewares es6 import storeenhancer reduxbugreporter es5 var storeenhancer requirereduxbugreporterstoreenhancer function configurestoreinitialstate const store createstorereducer initialstate processenvnodeenv production storeenhancer f f return store 2 render ui component es6 import reduxbugreporter reduxbugreporter import reduxbugreporterdistreduxbugreportercss es5 var reduxbugreporter requirereduxbugreporterdefault requirereduxbugreporterdistreduxbugreportercss const parentcontainer return div app already wrapped provider reactredux processenvnodeenv production reduxbugreporter submithttplocalhostpathtopostbugto projectnametest div 3 integrate backend service redux bug reporter need able submit bug sort backend redux bug reporter ship integration many common bug tracker see integration doc set one backend service doesnt exist temporary solution try redux bug reporter log bug console instead submitting import submitfn reduxbugreporterlibintegrationsconsole later render reduxbugreporter submitsubmitfn projectnameexample 4 replay filed bug replay filed bug call global bugreporterplayback function appropriate parameter windowbugreporterplaybackactions initialstate state delay delay parameter amount time action playback default value 100 note setting delay value 1 skip playback set redux store state equal final state bug useful situation application maintains critical state outside redux playback doe work prop type property type default description submit function string required string url post bug function function called submit bug note function must return promise projectname string required name project bug filed used scope bug different initiative redactstorestate function optional function receives state return redacted state bug submission warning alter passed state see redacting sensitive data name string optional application know name user used prepopulate submission form meta optional meta exists passed along bug submission customencode function optional function receives state return new encoded state bug submission useful serializing immutable object customdecode function optional function receives state return new decoded state bug playback useful deserializing immutable object redacting sensitive data since redux bug reporter log redux state action could easily sensitive information submitted bug two way redact information submission redacting information store state pas redaction function redactstorestate prop reduxbugreporter component applied initial store state final store state bug submission let redactstorestate function state deep clone state prevent altering actual state let newstate clonedeepstate newstate newstateidentity newstateidentityname newstateidentityname redacted return newstate later render reduxbugreporter submithttplocalhostpathtopostbugto projectnametest redactstorestateredactstorestate redacting information action payload order redact information payload action set actionmetaredactfrombugreporter true boolean exists custom redaction function specified logged action type custom redaction function specified creating actionmetaredactfrombugreporterfn redactfrombugreporterfn exists action deep cloned passed redaction function return sanitized action payload let action type simpleaction sensitivefield secret meta redactfrombugreporter true unrelatedmeta true redacted action type simpleaction meta unrelatedmeta true let action type customredactionaction sensitivefield secret nonsensitivefield foo bar meta redactfrombugreporter true redactfrombugreporterfn function action delete actionsensitivefield return action unrelatedmeta true redacted action type customredactionaction nonsensitivefield foo bar meta unrelatedmeta true working immutablejs similar library file replay bug reduxbugreporter need submit redux state json object receive redux state json object part redux store using library immutable need pas customencode customdecode property reduxbugreporter assume redux state form immutablestate immutableobject normalmutablestate foo true import fromjs immutable const customencode state return immutablestate stateimmutablestatetojson mutablestate statemutablestate const customdecode state return immutablestate fromjsstateimmutablestate mutablestate statemutablestate later rendering redux bug reporter reduxbugreporter submithttplocalhostpathtopostbugto projectnametest customencodecustomencode customdecodecustomdecode contribution fork project make change double check change work adding example confirm test still pas write new test applicable update readme appropriate doc commit create pr license mit\n",
      "[0 0 0 ... 0 0 0]\n",
      "reposupervisor reposupervisor tool help detect secret password code easy install adding new webhook github repository work two separate mode first one allows u scan github pull request second one work command line scan local directory reposupervisor usage prerequisite command line mode github pull request mode supported file security check frequently asked question doe work doesnt find secret add support new file type auth0 create free account auth0 issue reporting author license usage prerequisite start using tool download latest release github release page two bundle available aws lambda deployment well cli mode using cli mode doesnt require additional configuration whereas use pr mode necessary deploy bundle aws lambda first aws lambda deployment using docker image command line mode cli mode allows scanning local directory source code detect secret password file simplest deployment option could become part ci pipeline finding might either returned plaintext json format npm ci npm run build node distclijs testfixturesintegrationdirwithsecrets testfixturesintegrationdirwithsecretsfoobarjs zjd55qmsy6ld53crtqncrg gm5ybhjwros7zjtiyujtbu gxc56b6x67anequgynpswtl mltkbugs8s6tx9ik5zal8aw 2g877batsewopowrjhah9ta testfixturesintegrationdirwithsecretsfoofoojson d7kyociu24p9hjsyvkqzoke q28wt3namlt3ngpqi2qzjq7 jsonoutput1 node distclijs testfixturesintegrationdirwithsecrets resultfilepathtestfixturesintegrationdirwithsecretsfoobarjssecretszjd55qmsy6ld53crtqncrggm5ybhjwros7zjtiyujtbugxc56b6x67anequgynpswtlmltkbugs8s6tx9ik5zal8aw2g877batsewopowrjhah9tafilepathtestfixturesintegrationdirwithsecretsfoofoojsonsecretsd7kyociu24p9hjsyvkqzokeq28wt3namlt3ngpqi2qzjq7 github pull request mode running tool pull request mode requires add new webhook github repository webhook triggered pull request event whenever someone open update close pr therefore scan triggered update pr status either success failure depending finding webhook configuration detail setting value payload url aws lambda url content type applicationjson event type pull request whenever tool find security issue set pr status error add link view report link report url aws lambda deployment additional query parameter idjwt allows generate html report check sample report depending success failure scan set proper pr status error issue detected success issue found false positive wa reported supported file reposupervisor aim decrease number false positive much possible mean doesnt scan file type extension file parsed according format extract string contextaware process requires use language tokenizer currently supported file type json json javascript j yaml yaml plan add new file type future read documentation add new file type learn security check list currently implemented check tool module detail entropy meter find string high entropy detect secret password supported file type frequently asked question doe work cli mode scan directory provided argument get list file return matching supported extension like json j process every supported file tokenizer different one file type iterate extracted string run security check entropy meter calculate entropy value see go defined threshold maxallowedentropy print detected issue either plaintext json format pull request mode receive webhook payload process payload extract modified file iterate file use appropriate tokenizer based file type extract string file run security check string tool detects issue set ci status error link report issue found set ci status success read ci status definition doesnt find secret verify secret want find inside supported file type read supported file section add support new file type support new file type need create new parser file type might require use external tokenizers complex structure like javascript file hand simple file type pretty straightforward wa json file read add new file type auth0 auth0 help add authentication multiple authentication source either social like google facebook microsoft account linkedin github twitter box salesforce amont others enterprise identity system like window azure ad google apps active directory adfs saml identity provider add authentication traditional usernamepassword database add support linking different user account user support generating signed json web token call apis flow user identity securely analytics user logging pull data source add user profile javascript rule create free account auth0 go auth0 click sign use google github microsoft account login issue reporting found bug feature request please report repository issue section please report security vulnerability public github issue tracker responsible disclosure program detail procedure disclosing security issue author auth0 license project licensed mit license see license file info\n",
      "[0 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Show sentences and vector space representation.\n",
    "# purely to visualize what's happening.\n",
    "for i, v in zip(validate.text_filtered, v_bow_array):\n",
    "    print(i)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow_v = v_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advancedreactnative companion repo course hosted udemycom\n",
      "[0 0 0 ... 0 0 0]\n",
      "emotion recognition conversation update date announcement 06102020 new paper sota emotion recognition conversation refer directory cosmic code read paper cosmic commonsense knowledge emotion identification conversation 30092020 new paper baseline utterancelevel dialogue understanding released read paper utterancelevel dialogue understanding empirical study fork code 26072020 new dialoguegcn code ha released please visit httpsgithubcomdeclarelabconvemotiontreemasterdialoguegcnmianzhang credit go mian zhang httpsgithubcommianzhang 11072020 interested reading paper erc related task sarcasm detection conversation compiled comprehensive reading list paper please visit httpsgithubcomdeclarelabawesomeemotionrecognitioninconversations 07062020 new stateoftheart result erc task released soon 07062020 convemotion repo maintained httpsgithubcomdeclarelab 22122019 code dialoguegcn ha released 11102019 new paper conversational transfer learning emotion recognition 09082019 new paper emotion recognition conversation erc 06032019 feature code train dialoguernn meld dataset released 20112018 endtoend version icon dialoguernn released repository contains implementation three conversational emotion detection method namely emotion recognition conversation data format tlerc pytorch dialoguegcn pytorch dialoguernn pytorch dialoguegcnmianzhang pytorch icon tensorflow cmn tensorflow bclstmpytorch pytorch bclstm kera unlike emotion detection model technique consider partystates interparty dependency modeling conversational context relevant emotion recognition primary purpose technique pretrain emotion detection model empathetic dialogue generation fig 1 interaction among different controlling variable dyadic conversation person b grey white circle represent hidden observed variable respectively p represents personality u represents utterance represents interlocutor state represents interlocutor intent e represents emotion topic represents topic conversation easily extended multiparty conversation emotion recognition useful empathetic affective dialogue generation data format network expect emotionsentiment label speaker info utterance present dialogue like party 1 hate girlfriend angry party 2 got girlfriend surprise party 1 yes angry however code adpated perform task preceding utterance available without corresponding label context goal label presenttarget utterance example context party 1 hate girlfriend party 2 got girlfriend target party 1 yes angry target emotion angry moreover code also molded train network endtoend manner soon push useful change present sota result method iemocap dailydialog meld emorynlp wavg f1 macro f1 micro f1 wavg f1 3cls wavg f1 7cls wavg f1 3cls wavg f1 7cls roberta 5455 4820 5516 7212 6202 5528 3729 roberta dialoguernn 6476 4965 5732 7214 6361 5536 3744 roberta cosmic 6528 5105 5848 7320 6521 5651 3811 cosmic commonsense knowledge emotion identification conversation cosmic address task utterance level emotion recognition conversation using commonsense knowledge new framework incorporates different element commonsense mental state event causal relation build upon learn interaction interlocutor participating conversation current stateoftheart method often encounter difficulty context propagation emotion shift detection differentiating related emotion class learning distinct commonsense representation cosmic address challenge achieves new stateoftheart result emotion recognition four different benchmark conversational datasets execution first download roberta comet feature keep appropriate directory cosmicerctraining training evaluation four datasets done follows iemocap python trainiemocappy activelistener dailydialog python traindailydialogpy activelistener classweight residual meld emotion python trainmeldpy activelistener classweight residual meld sentiment python trainmeldpy activelistener classweight residual classify sentiment emorynlp emotion python trainemorynlppy activelistener classweight residual emorynlp sentiment python trainemorynlppy activelistener classweight residual classify sentiment citation please cite following paper find code useful work cosmic commonsense knowledge emotion identification conversation ghosal n majumder gelbukh r mihalcea poria finding emnlp 2020 tlerc emotion recognition conversation transfer learning generative conversation modeling tlerc transfer learningbased framework erc pretrains generative dialogue model transfer contextlevel weight include affective knowledge target discriminative model erc setting setup environment conda conda env create f environmentyml conda activate tlerc cd tlerc python setuppy download dataset file iemocap dailydialog store datasets download pretrained weight hred cornell ubuntu datasets store generativeweights optional train new generative weight dialogue model refer httpsgithubcomctr4siahierarchicallatentstructureforvariationalconversationmodeling run erc classifier pretrained weight cd bertmodel python trainpy loadcheckpointgenerativeweightscornellweightspkl dataiemocap change cornell ubuntu iemocap dailydialog dataset combination drop loadcheckpoint avoid initializing contextual weight modify hyperparameters check configspy optional create erc dataset split set glove path preprocessing file python iemocappreprocesspy similarly dailydialog citation please cite following paper find code useful work conversational transfer learning emotion recognition hazarika poria zimmermann r mihalcea r 2020 information fusion dialoguegcn graph convolutional neural network emotion recognition conversation dialoguegcn dialogue graph convolutional network graph neural network based approach erc leverage self interspeaker dependency interlocutor model conversational context emotion recognition graph network dialoguegcn address context propagation issue present current rnnbased method dialoguegcn naturally suited multiparty dialogue requirement python 3 pytorch 10 pytorch geometric 13 panda 023 scikitlearn 020 tensorflow optional required tensorboard tensorboardx optional required tensorboard execution note pytorch geometric make heavy usage cuda atomic operation source nondeterminism reproduce result reported paper recommend use following execution command note script execute cpu obatined weighted average f1 score 6467 machine 6444 google colaboratory iemocap dataset following command iemocap dataset python trainiemocappy basemodel lstm graphmodel nodalattention dropout 04 lr 00003 batchsize 32 classweight l2 00 nocuda citation please cite following paper find code useful work dialoguegcn graph convolutional neural network emotion recognition conversation ghosal n majumder poria n chhaya gelbukh emnlpijcnlp 2019 hong kong china dialoguegcnmianzhang dialoguegcn implementation mian zhang pytorch implementation paper dialoguegcn graph convolutional neural network emotion recognition conversation running run whole process easily take iemocap corpus example step 1 preprocess scriptsiemocapsh preprocess step 2 train scriptsiemocapsh train requirement python 3 pytorch 10 pytorch geometric 143 panda 023 scikitlearn 020 performance comparision dataset weighted f1 original iemocap 6418 implementation iemocap 6410 credit mian zhang github mianzhang citation please cite following paper find code useful work dialoguegcn graph convolutional neural network emotion recognition conversation ghosal n majumder poria n chhaya gelbukh emnlpijcnlp 2019 hong kong china dialoguernn attentive rnn emotion detection conversation dialoguernn basically customized recurrent neural network rnn profile speaker conversationdialogue fly model context conversation time model easily extended multiparty scenario also used pretraining model empathetic dialogue generation note default setting hyperparameters commandline argument code meant bidialoguernnatt user need optimize setting variant change requirement python 3 pytorch 10 panda 023 scikitlearn 020 tensorflow optional required tensorboard tensorboardx optional required tensorboard dataset feature please extract content dialoguernnfeatureszip execution iemocap dataset python trainiemocappy commandline argument avec dataset python trainavecpy commandline argument commandline argument nocuda doe use gpu lr learning rate l2 l2 regularization weight recdropout recurrent dropout dropout dropout batchsize batch size epoch number epoch classweight class weight applicable avec activelistener explicit lisnener mode attention attention type tensorboard enables tensorboard log attribute attribute 1 4 avec 1 valence 2 activationarousal 3 anticipationexpectation 4 power citation please cite following paper find code useful work dialoguernn attentive rnn emotion detection conversation n majumder poria hazarika r mihalcea e cambria g alexander aaai 2019 honolulu hawaii usa icon interactive conversational memory network icon multimodal emotion detection framework extract multimodal feature conversational video hierarchically model textitself textitinterspeaker emotional influence global memory memory generate contextual summary aid predicting emotional orientation utterancevideos requirement python 365 pandas0233 tensorflow190 numpy1150 scikitlearn0200 execution cd icon unzip data follows download feature iemocap using link unzip folder place location iconiemocapdata sample command achieve unzip pathtozipfile iemocap train icon model python trainiemocappy iemocap citation icon interactive conversational memory networkfor multimodal emotion detection hazarika poria r mihalcea e cambria r zimmermann emnlp 2018 brussels belgium cmn cmn neural framework emotion detection dyadic conversation leverage mutlimodal signal text audio visual modality specifically incorporates speakerspecific dependency architecture context modeling summary generated context using multihop memory network requirement python 365 pandas0233 tensorflow190 numpy1150 scikitlearn0200 execution cd cmn unzip data follows download feature iemocap using link unzip folder place location cmniemocapdata sample command achieve unzip pathtozipfile iemocap train icon model python trainiemocappy iemocap citation please cite following paper find code useful work hazarika poria zadeh cambria e morency lp zimmermann r 2018 conversational memory network emotion recognition dyadic dialogue video proceeding 2018 conference north american chapter association computational linguistics human language technology volume 1 long paper vol 1 pp 21222132 bclstmpytorch bclstmpytorch network using context detection emotion utterance dialogue model simple efficient us lstm model temporal relation among utterance repo gave data semeval 2019 task 3 used provided data released semeval 2019 task 3 emotion recognition context organizer task 3 utterance provided utterance1 user1 utterance2 user2 utterance3 user1 consecutively task predict emotion label utterance3 emotion label utterance provided however data contains emotion label utterance still use code adapt accordingly hence code still aplicable datasets like mosi mosei iemocap avec dailydialogue etc bclstm doe make use speaker information like cmn icon dialoguernn requirement python 365 pandas0233 pytorch 10 numpy1150 scikitlearn0200 execution cd bclstmpytorch train bclstm model python trainiemocappy iemocap citation please cite following paper find code useful work poria cambria e hazarika majumder n zadeh morency lp 2017 contextdependent sentiment analysis usergenerated video proceeding 55th annual meeting association computational linguistics volume 1 long paper vol 1 pp 873883 bclstm kera implementation bclstm requirement python 365 pandas0233 tensorflow190 numpy1150 scikitlearn0200 keras21 execution cd bclstm train bclstm model python baselinepy config testbaselineconfig iemocap citation please cite following paper find code useful work poria cambria e hazarika majumder n zadeh morency lp 2017 contextdependent sentiment analysis usergenerated video proceeding 55th annual meeting association computational linguistics volume 1 long paper vol 1 pp 873883\n",
      "[1 1 1 ... 0 0 0]\n",
      "openworm openworm aim build first comprehensive computational model caenorhabditis elegans c elegans microscopic roundworm thousand cell solves basic problem feeding matefinding predator avoidance despite extremely wellstudied biology deep principled understanding biology organism remains elusive using bottomup approach aimed observing worm behaviour emerge simulation data derived scientific experiment carried past decade incorporating data available scientific community software model also forging new collaboration university research institute collect data fill gap earn badge u simply trying package click image get started quickstart put together docker container pull together major component simulation run machine get running doe following run nervous system model known c302 computer parallel run 3d worm body model known sibernetic computer using output nervous system model produce graph nervous system body model demonstrate behavior computer inspect produce movie showing output body model example output note running simulation full amount time would produce content like however order run reasonable amount time default run time simulation limited see partial output equivalent 5 run time compared example extend run time use argument described installation prerequisite least 60 gb free space machine least 2gb ram able clone git repository machine install git gui may useful install install docker system system doe enough free space use external hard disk macos x location image storage specified advanced tab preference see thread addition linux instruction running ensure docker daemon running background macoswindows icon docker whale logo showing menu barsystem tray open terminal run git clone httpgithubcomopenwormopenworm cd openworm optional run buildsh buildcmd window skip step download latest released docker image openworm docker hub run runsh runcmd window 510 minute output display screen step run simulation end run stopsh stopcmd window system clean running container inspect output output directory local machine advanced argument num use modify duration simulation millisecond default 15 use 5000 run time make full movie ie 5 second thing try open terminal run runshellonlysh runshellonlycmd window let log container ha run masteropenwormpy inspect internals various checked code base installed system modify thing afterwards youll still need run stopsh clean wish modify get installed modify dockerfile want modify run modify masteropenwormpy either way need run buildsh order rebuild image locally afterwards run normally faq docker container docker container selfcontained environment run openworm simulation fully set get started following step moment run simulation produce visualization visualization must viewed outside docker container need know much docker use openworm planning working extensively platform may benefit understanding basic docker curriculum excellent tutorial beginner straightforward work section 1 25 plenty sufficient possible modify simulation without run buildsh yes marginally complex easiest way modify anything docker container inside work like bash shell want modify code container youll need use editor run terminal like nano youve modified something container dont need rebuild however run stopsh exit change gone access data already output simulation default output figure movie home system outside docker container want access entire output simulation need copy docker container example say want extract worm motion data contained file wormmotionlogtxt found homeowsiberneticsimulationsspecifictimestampeddirectorywormmotionlogtxt directory specifictimestampeddirectory name like c2fw20180212183632 name found checking output directory actually main output directory simulation contains output including cell modelling worm movement simulation end exit container exit run stopsh run following command openwormdockermaster folder docker cp openwormhomeowsiberneticsimulationsspecifictimestampeddirectorywormmotionlogtxt wormmotionlogtxt copy file docker container whose default name openworm crucial run stopsh trying get data see difference exit stopsh docker container openworm done interacting type exit return system shell stop execution anything container container status exited try restart process using runshellonlysh get error saying container already exists choose point run stopsh remove container file associated allowing run new simulation however dont want remove container instead want reenter enter container exited run stopsh youll delete data reset container new run however dont want reenter docker container like docker start openworm restarts container docker exec openworm binbash run bash inside container tell docker start container execute command exec interactive tty bash bash shell container openworm youll able interact container documentation find openworm documentation available httpdocsopenwormorg join u slack repository reference projectwide tracking via highlevel issue milestone\n",
      "[0 0 0 ... 0 0 0]\n",
      "fullstackreactcode companion repo course udemycom see httpswwwudemycomnodewithreactfullstackwebdevelopment\n",
      "[0 0 0 ... 0 0 0]\n",
      "meilix beautiful customizable linux build box feature internet kiosk use meilix generator web app make linux brandevent also add apps feature need preinstalled create iso image linux use live boot install pc meilix heavy development alpha stage yet recommended productive use index introduction feature architecture ecosystem usage pre requisite development file structure build metapackages testing contribution community guideline branch best practice resource gallery license introduction project serf solution wish preconfigured custom linux needed appsfeatures already installed example use case event every event organizer need system configured equally need specific apps run event configuring system one one time taking difficult task using meilix create custom linux iso runlive boot many system want save countless hour also make process costefficient feature meilix light weight beautiful fast linux feature ubuntudebian distro custom meilix build commissioned meilixgenerator web app architecture meilix based ubuntudebian architecture meilix us lxqt standard desktop environment ecosystem following projectsdependency part meilix ecosystem name meilix repo standalone build backend webapp meilixgenerator webapp generates iso image meilix linux meilixsystemlock program freeze system meilixartwork boot screen splash theme meilix usage create linux event kiosk trying use meilixgenerator web app ha option customize generate iso pre requisite prerequisite develop meilix exposure terminal basic command basic comprehension shell script experience working debian system lpic1 huge plus development meilix fetch ubuntu source customizes add feature build distro us shell script perform task build made local machine via travis ci file structure basic understanding file structure required development level 2 file structure project buildsh licensemd sourcesxeniallist sourcesbioniclist readmemd systemlock011alldeb imageamd64tarlzma imagei386tarlzma ubiquityslideshow slide polkit1 action conf distribution pool main systemlock01 debian etc makefile usr meilixdefaultsettings debian etc makefile usr script aptrepoupdatersh archsh browserurish chrootsh debuildsh legacyinitrdextsh mailfailpy mailpy meilixchecksh mewsh package releasesmaintainersh chroot bin boot dev etc home lib lib64 medium mnt opt proc root run sbin srv sys tmp usr var build building locally make build script executable chmod x buildsh execute script buildsh testing isos local installation qemukvm run live cd virtualbox oracle build using travis update travisyml according api key explained push change repo start build process contribution code contribution always appreciated keep experience good suggest read guideline thoroughly also take time understand workflow project contribution expected follow best practice community guideline following thing contribute meilix report bug think encountered bug know feel free report community take care request feature also request feature community feel viable picked development create pull request cant get better pull request really appreciated community get started picking open issue make pull request community meilix ha contributor around world constantly improving meilix helping others well get touch community use following communication channel gitter httpsgitterimfossasiameilix mailing list httpsgroupsgooglecomforumforummeilix scrum mail meilixgooglegroupscom twitter httpstwittercommeilix guideline fossasia open source guideline found branch meilix us agile continuous integration methodology version frequently updated development really fast master development branch always built generator legacy branch keep reference time chrooted master branch iso release made change requested meilixgenerator app repackaged customized iso branch created main repository step create pull request make pr master branch comply best practice guideline eg pr concern visual element image showing effect must pas continuous integration check get positive review change merged best practice commits commit proper documentation comment code make easy others understand make sure commit message crisp clear read refering issue pull request use special word automatically close related issue like fix 234 keep pr limited scope make easy review correct squash commits resource lubuntu linux operating system lxdelxqt meilix blog andre talk tarun talk license project currently licensed gnu lesser general public license v30 lgpl30 copy licensemd present along source code obtain software different license please contact fossasia\n",
      "[0 0 0 ... 0 0 0]\n",
      "introduction reposado set tool written python replicate key functionality mac x server software update service license reposado licensed new bsd license discussion group discussion user developer reposado feature capability reposado together python curl binary tool web server apache 2 enables host local apple software update server hardware choice reposado contains tool reposync download software update catalog optionally update package apple server enabling host local web server additionally reposado provides commandline tool repoutil enables create arbitrary number branch apple catalog branch contain subset available update example one could create testing release branch set client use testing branch catalog test newlyreleased update would set client use release branch catalog would contain update testing process configure reposado also download actual update well catalog continue offer update superseded recent update example currently offering 1067 update client apple release 1068 update continue offer deprecated 1067 update ready release newer update client even offer 1067 update release client offering 1068 update testing client offering deprecated apple software update feature difficult apple tool limitation dependency apple software update service doe thing primarily replicates software update apple server downloading local machine secondly function web server actually serve update client machine reposado doe duplicate web server portion apple software update service instead may use existing web server wish reposado also currently relies commandline curl binary download update apple server curl available x redhat linux many os including win32 win64 version see httpcurlhaxxse information info information basic documentation available httpsgithubcomwdasreposadotreemasterdocs\n",
      "[0 0 0 ... 0 0 0]\n",
      "toolingreport quick way determine best build tool next web project tooling migration worth adopt tool best practice existing configuration code base get set npm install dev npm run dev start build watch mode start http server build production npm run build project shape lib various script plugins build staticbuild script run end build process generates html client clientside j go doesnt need go keep separate static generation j test markdown test result see test structure test directory contains indexmd describes test test category must include title frontmatter result tool folder rollup webpack parcel browserify optional folder contains indexmd describing particular build tool performs result present directory considered category result file requires result frontmatter must pas fail partial folder also contains minimal project respective tool showing pas current test build artifact placed folder called build folder globally ignored test ha subtests folder must named subtests contain structure special import client bundle import bundleurl import clientbundleclienthomeindexts clientbundle followed path script bundle minify script entry point two entry point share module itll codesplit bundleurl url bundled script import url script imported script eg preloading style import used staticbuild cs module import tabbutton promo feature stylescss import ending cs assumed cs module export derived classnames cs cs contains tabbutton tabbutton one export cs bundle import cssurl inline cssbundlestylescss cs support cs module sassstyle nesting import inlined output minified cssurl url cs resource inline text cs markdown import html meta mdwhatevermd md followed path markdown give following html markdown html meta metadata markdown front matter asset import asseturl asseturlfoopng asseturl followed path file add file build asseturl url asset constant import isproduction constsisproduction want add constant value add object passed constsplugin rollupconfigjs youll also need add entry missingtypesdts test data import test testdata return object representation everything test directory see staticbuildmissingtypesdts structure object\n",
      "[0 0 0 ... 0 0 0]\n",
      "visual studio documentation welcome repo contains source file visual studio technical documentation topic published docsmicrosoftcom repo wa moved june 23 2017 httpsgithubcommicrosoftvsdocs documentation visual basic visual c located dotnet doc repo visual c documentation located c doc repo contribute documentation welcome contribution help u improve visual studio doc article repository use githubflavored markdown several feature area visual studio folder repo debugger topic debugging ide topic visual studio interactive development environment ide forth medium subfolder folder contains art file topic information contributing see contributing guide microsoft open source code conduct project ha adopted microsoft open source code conduct information see code conduct faq contact opencodemicrosoftcom question comment\n",
      "[0 0 0 ... 0 0 0]\n",
      "repo maintains list repository defining ro distribution implementation rep 143 also home rosdep rule guide contributing please see contributingmd review guideline please see review guideline look criterion get pull request merged repository\n",
      "[0 0 0 ... 0 0 0]\n",
      "freecodecamporgs opensource codebase curriculum freecodecamporg friendly community learn code free run donorsupported 501c3 nonprofit help million busy adult transition tech community ha already helped 10000 people get first developer job fullstack web development machine learning curriculum completely free selfpaced thousand interactive coding challenge help expand skill table content certification learning platform reporting bug issue reporting security issue responsible disclosure contributing platform build deployment status license certification freecodecamporg offer several free developer certification certification involves building 5 required web app project along hundred optional coding challenge help prepare project estimate certification take beginner programmer around 300 hour earn 50 project freecodecamporg curriculum ha agile user story automated test help build project incrementally ensure youve fulfilled user story submit pull test suite freecodecamps cdn mean build project website like codepen glitch even local computer development environment youve earned certification always always able link linkedin resume prospective employer freelance client click link theyll see verified certification specific one exception discover violation academic honesty policy catch people unambiguously plagiarizing submitting people code project without citation rigorous institution learning revoke certification ban people ten core certification 1 responsive web design certification basic html html5 basic cs applied visual design applied accessibility responsive web design principle cs flexbox cs grid project tribute page survey form product landing page technical documentation page personal portfolio webpage 2 javascript algorithm data structure certification basic javascript es6 regular expression debugging basic data structure algorithm scripting objectoriented programming functional programming intermediate algorithm scripting project palindrome checker roman numeral converter caesar cipher telephone number validator cash register 3 front end library certification bootstrap jquery sas react redux react redux project random quote machine markdown previewer drum machine javascript calculator 25 5 clock 4 data visualization certification data visualization d3 json apis ajax project bar chart scatterplot graph heat map choropleth map treemap diagram 5 apis microservices certification managing package npm basic node express mongodb mongoose project timestamp microservice request header parser url shortener exercise tracker file metadata microservice 6 quality assurance certification quality assurance testing chai advanced node express project metricimperial converter issue tracker personal library sudoku solver american british translator 7 scientific computing python certification introduction python everybody project arithmetic formatter time calculator budget app polygon area calculator probability calculator 8 data analysis python certification data analysis python course numpy project meanvariancestandard deviation calculator demographic data analyzer medical data visualizer page view time series visualizer sea level predictor 9 information security certification information security helmetjs python penetration testing project stock price checker anonymous message board port scanner sha1 password cracker secure real time multiplayer game 10 machine learning python certification tensorflow neural network work project rock paper scissors cat dog image classifier book recommendation engine using knn linear regression health cost calculator neural network sm text classifier legacy full stack development certification earned responsive web design algorithm data structure front end library data visualization apis microservices legacy information security quality assurance certification youll able claim freecodecamporg full stack development certification distinction signifies youve completed around 1800 hour coding wide range web development tool legacy certification also 4 legacy certification dating back 2015 curriculum still available required project legacy certification remain available freecodecamporg legacy front end development certification legacy data visualization certification legacy back end development certification legacy information security quality assurance certification learning platform code running live freecodecamporg community also ha forum usually get programming help project feedback within hour youtube channel free course python sql android wide variety technology technical publication thousand programming tutorial article math computer science discord chat room hang talk developer people learning code join community reporting bug issue think youve found bug first read report bug article follow instruction youre confident new bug confirmed someone else facing issue go ahead create new github issue sure include much information possible reproduce bug reporting security issue responsible disclosure think found vulnerability please report responsibly dont create github issue security issue instead please send email securityfreecodecamporg well look immediately appreciate responsible disclosure vulnerability might impact integrity platform user offer bounty swag moment well happy list name hall fame security researcher contributing freecodecamporg community possible thanks thousand kind volunteer like welcome contribution community excited welcome aboard please follow step contribute platform build deployment status general platform status application available statusfreecodecamporg build deployment status code available devops guide license copyright 2020 freecodecamporg content repository bound following license computer software licensed bsd3clause license learning resource curriculum directory including subdirectory thereon licensed ccbysa40 license\n",
      "[0 0 0 ... 0 0 0]\n",
      "babelstandalone part babel go check babelstandalone babelstandalone standalone build babel use nonnodejs environment including browser bundled standard babel plugins presets build babili babelminify optionally available true using babel webpack browserify gulp sufficient use case however valid use case babelstandalone site like jsfiddle j bin repl babel site etc site compile userprovided javascript realtime apps embed javascript engine v8 directly want use babel compilation apps want use javascript scripting language extending app including goody es2015 provides integration babel nonnodejs environment reactjsnet rubybabeltranspiler phpbabeltranspiler etc installation several way get copy babelstandalone pick whichever one like use via unpkg httpsunpkgcombabelstandalone6babelminjs simple way embed webpage without setup install via bower bower install babelstandalone install via npm npm install save babelstandalone manually grab babeljs andor babelminjs github release page every release includes file install via git use repo httpsgithubcomdaniel15babelstandalonebower pull prebuilt version git note generally advised system must pull artifact git bower usage load babeljs babelminjs environment expose babel api babel object var input const getmessage hello world var output babeltransforminput presets es2015 code loaded browser babelstandalone automatically compile execute script tag type textbabel textjsx div idoutputdiv load babel script srchttpsunpkgcombabelstandalone6babelminjsscript custom script script typetextbabel const getmessage hello world documentgetelementbyidoutputinnerhtml getmessage script use dataplugins datapresets attribute specify babel pluginspresets use script typetextbabel datapresetses2015stage2 loading external script via src attribute supported script typetextbabel srcfoojsscript note babelrc doesnt work babelstandalone file system access available presets andor plugins use must specified option passed babeltransform customisation custom plugins presets added using registerplugin registerpreset method respectively simple plugin convert every identifier lol function lolizer return visitor identifierpath pathnodename lol babelregisterpluginlolizer lolizer registered use name plugin var output babeltransform function helloworld alerthello plugins lolizer return function lol lollol custom plugins also work inline script script typetextbabel datapluginslolizer manually building want manually upgrade babel version used babelstandalone build release follow step upgrade babel version packagejson done npmcheckupgrades eg npmcheckupdates u packagefile packagejson babel delete nodemodules npm often produce inefficient directory layout upgrade inplace run npm install npm run build run npm run test ensure work open examplesexamplehtm ensure work\n",
      "[0 0 0 ... 0 0 0]\n",
      "meta meta tool managing multiproject system library answer conundrum choosing mono repo many repos saying meta repo meta powered plugins wrap common command letting execute repos solution meta built loop inherits loop ability easily target particular set directory executing common command eg meta git status includeonly dir1dir2 see loop available option getting started installing npm g meta install meta command system initializing create new meta project create new directory meta project mkdir mymetarepo initialize new git repository new dir cd mymetarepo git init initialize new repository meta repo meta init meta created meta file hold reference child repository add create new project use meta project create folder repo url b import existing project use meta project import folder repo url project added meta update gitignore file meta file reference new child repo meta git clone clone existing meta repo need execute meta git clone meta repo url meta clone meta repo child repository working meta meta plugins wrap common command shouldnt much new syntax memorize crazy new utility nobody know instance want check git status repository type meta git status view branch exist repos meta git branch creating new feature crosscut number service site api create new branch repos meta git checkout b branchname revert modified file remote status meta git checkout track progress branch meta git status remove unwanted untracked file repos meta git clean fd really working meta plugins meta functionality contributed plugins node module begin meta either installed globally meta repos nodemodules directory recommend install devdependencies meta repos packagejson plugins add additional sub command meta leverage loop metaloop easily execute common command meta repo child repos easy install metanpm plugin gain ability meta npm install repos prefer speediness yarn try metayarn npm install savedev metayarn meta clone manyproject architecture one line give every engineer team project setup regardless cloned npm yarn install project execute arbitrary command many repos manage project super simple plugin architecture using commanderjs easily wrap command working platform node meta repo keep code per project repos benefiting deployment reuse use tool always use strange side effect git submodules subtree give different team different slice architecture multiple metarepos available plugins metainit metaproject metagit metaexec metagh metaloop metanpm metayarn metatemplate thirdparty plugins metabump metarelease metasearch available template metaplugin want help develop meta locally best way get started following npm g meta meta git clone gitgithubcommateodelnortemetagit cd meta npm install meta npm install meta npm link npm link clone meta project meta enter directory use meta perform npm install npm link directory listed project meta json configuration file link meta used global command write command test using binmeta git gh subcommand run single command meta git clone gitgithubcommateodelnortemetagit cd meta npm meta npm install meta npm link npm link yarn lover npm g meta meta git clone gitgithubcommateodelnortemetagit cd meta yarn meta yarn install meta yarn link yarn link meta git clone gitgithubcommateodelnortemetagit cd meta yarn meta yarn install meta yarn link yarn link see discussion detail resource monorepo multirepo choose one patrickleet developing plugin meta patrickleet\n",
      "[0 0 0 ... 0 0 0]\n",
      "npmhub npmhub browser extension let explore npm dependency github gitlab repos viewing repository file list containing packagejson extension display link description dependency bottom page github enterprise gitlab enterprise community edition also supported rightclicking npmhubs icon toolbar selecting enable npmhub domain installation chrome extension firefox addon chrome version also work opera using edge design npmhub look like see also packagehub extension displaying dependency different package manager github ghubio jump straight github repo npm package eg ghubioexpress\n",
      "[0 0 0 ... 0 0 0]\n",
      "ui docker repo deprecated development continues portainer githubcomportainerportainer ui docker web interface docker remote api goal provide pure client side implementation effortless connect manage docker goal minimal dependency really want keep project pure htmljs app consistency web ui consistent command found docker cli quickstart run docker run p 90009000 privileged v varrundockersockvarrundockersock uifduifordocker open browser httpdockerd host ip9000 bind mounting unix socket ui docker container much secure exposing docker daemon tcp privileged flag required host using selinux still secure ui docker instance behind type auth direction using nginx auth specify socket connect docker daemon default ui docker connects docker daemon withvarrundockersock work need bind mount unix socket container v varrundockersockvarrundockersock use h flag change socket connect tcp socket docker run p 90009000 privileged uifduifordocker h tcp1270012375 change addressport ui docker served ui docker listens port 9000 default run ui docker inside container bind container internal port external address port expose ui docker 102030180 docker run p 1020301809000 privileged v varrundockersockvarrundockersock uifduifordocker access docker engine protected via tl ensure access ca tl certificate tl key used access docker engine file need named capem certpem keypem respectively store somewhere disk mount volume containing file inside ui container docker run p 90009000 uifduifordocker v pathtocertscerts h tcpmydockerhostdomain2376 tlsverify want specify different name ca certificate public key respectively use tlscacert tlscert tlskey docker run p 90009000 uifduifordocker v pathtocertscerts h tcpmydockerhostdomain2376 tlsverify tlscacert certsmycapem tlscert certsmycertpem tlskey certsmykeypem note replace pathtocerts path certificate file disk check wiki info using ui docker stack angularjs bootstrap gritter spinjs golang visjs todo full repository support search push file container unit test license mit ui docker code licensed mit license ui docker copyright c 20132016 michael crosby crosbymichaelcom kevan ahlquist kevanahlquistcom permission hereby granted free charge person obtaining copy software associated documentation file software deal software without restriction including without limitation right use copy modify merge publish distribute sublicense andor sell copy software permit person software furnished subject following condition copyright notice permission notice shall included copy substantial portion software software provided without warranty kind express implied including limited warranty merchantability fitness particular purpose noninfringement event shall author copyright holder liable claim damage liability whether action contract tort otherwise arising connection software use dealing software\n",
      "[0 0 0 ... 0 0 0]\n",
      "youtubedl download video youtubecom video platform change installation description option configuration output template format selection video selection faq developer instruction embedding youtubedl bug copyright change view change made ytdlorgyoutubedl view archived tag youtubedlreleases view archived unmerged pull request youtubedltreearchiverecoveredgithubprs installation install right away unix user linux macos etc type sudo curl l httpsgithubcoml1vingyoutubedlreleaseslatestdownloadyoutubedl usrlocalbinyoutubedl sudo chmod arx usrlocalbinyoutubedl curl alternatively use recent wget sudo wget httpsgithubcoml1vingyoutubedlreleaseslatestdownloadyoutubedl usrlocalbinyoutubedl sudo chmod arx usrlocalbinyoutubedl window user download exe file place location path except systemrootsystem32 eg put cwindowssystem32 also use pip sudo h pip install upgrade youtubedl command update youtubedl already installed see pypi page information macos user install youtubedl homebrew brew install youtubedl macports sudo port install youtubedl alternatively refer developer instruction check work git repository option including pgp signature see youtubedl download page description youtubedl commandline program download video youtubecom site requires python interpreter version 26 27 32 platform specific work unix box window macos released public domain mean modify redistribute use however like youtubedl option url url option h help print help text exit version print program version exit u update update program latest version make sure sufficient permission run sudo needed ignoreerrors continue download error example skip unavailable video playlist abortonerror abort downloading video playlist command line error occurs dumpuseragent display current browser identification listextractors list supported extractor extractordescriptions output description supported extractor forcegenericextractor force extraction use generic extractor defaultsearch prefix use prefix unqualified url example gvsearch2 downloads two video google video youtubedl large apple use value auto let youtubedl guess autowarning emit warning guessing error throw error default value fixuperror repair broken url emits error possible instead searching ignoreconfig read configuration file given global configuration file etcyoutubedlconf read user configuration configyoutube dlconfig appdatayoutubedlconfigtxt window configlocation path location configuration file either path config containing directory flatplaylist extract video playlist list markwatched mark video watched youtube nomarkwatched mark video watched youtube nocolor emit color code output network option proxy url use specified httphttpssocks proxy enable sock proxy specify proper scheme example socks51270011080 pas empty string proxy direct connection sockettimeout second time wait giving second sourceaddress ip clientside ip address bind 4 forceipv4 make connection via ipv4 6 forceipv6 make connection via ipv6 geo restriction geoverificationproxy url use proxy verify ip address georestricted site default proxy specified proxy none option present used actual downloading geobypass bypass geographic restriction via faking xforwardedfor http header nogeobypass bypass geographic restriction via faking xforwardedfor http header geobypasscountry code force bypass geographic restriction explicitly provided twoletter iso 31662 country code geobypassipblock ipblock force bypass geographic restriction explicitly provided ip block cidr notation video selection playliststart number playlist video start default 1 playlistend number playlist video end default last playlistitems itemspec playlist video item download specify index video playlist separated comma like playlistitems 1258 want download video indexed 1 2 5 8 playlist specify range playlistitems 1371013 download video index 1 2 3 7 10 11 12 13 matchtitle regex download matching title regex caseless substring rejecttitle regex skip download matching title regex caseless substring maxdownloads number abort downloading number file minfilesize size download video smaller size eg 50k 446m maxfilesize size download video larger size eg 50k 446m date date download video uploaded date datebefore date download video uploaded date ie inclusive dateafter date download video uploaded date ie inclusive minviews count download video le count view maxviews count download video count view matchfilter filter generic video filter specify key see output template list available key match key present key check key present key number like commentcount 12 also work compare number key literal like uploader mike smith also work match string literal require multiple match value known excluded unless put question mark operator example match video liked 100 time disliked le 50 time dislike functionality available given service also description use matchfilter likecount 100 dislikecount 50 description noplaylist download video url refers video playlist yesplaylist download playlist url refers video playlist agelimit year download video suitable given age downloadarchive file download video listed archive file record id downloaded video includeads download advertisement well experimental download option r limitrate rate maximum download rate byte per second eg 50k 42m r retries retries number retries default 10 infinite fragmentretries retries number retries fragment default 10 infinite dash hlsnative ism skipunavailablefragments skip unavailable fragment dash hlsnative ism abortonunavailablefragment abort downloading fragment available keepfragments keep downloaded fragment disk downloading finished fragment erased default buffersize size size download buffer eg 1024 16k default 1024 noresizebuffer automatically adjust buffer size default buffer size automatically resized initial value size httpchunksize size size chunk chunkbased http downloading eg 10485760 10m default disabled may useful bypassing bandwidth throttling imposed webserver experimental playlistreverse download playlist video reverse order playlistrandom download playlist video random order xattrsetfilesize set file xattribute ytdlfilesize expected file size hlsprefernative use native hl downloader instead ffmpeg hlspreferffmpeg use ffmpeg instead native hl downloader hlsusempegts use mpegts container hl video allowing play video downloading player may able play externaldownloader command use specified external downloader currently support aria2cavconvaxelcurlffmpeghttpiewget externaldownloaderargs args give argument external downloader filesystem option batchfile file file containing url download stdin one url per line line starting considered comment ignored id use video id file name output template output filename template see output template info autonumberstart number specify start value autonumbers default 1 restrictfilenames restrict filename ascii character avoid space filename w nooverwrites overwrite file c continue force resume partially downloaded file default youtubedl resume downloads possible nocontinue resume partially downloaded file restart beginning nopart use part file write directly output file nomtime use lastmodified header set file modification time writedescription write video description description file writeinfojson write video metadata infojson file writeannotations write video annotation annotationsxml file loadinfojson file json file containing video information created writeinfojson option cooky file file read cooky dump cookie jar cachedir dir location filesystem youtubedl store downloaded information permanently default xdgcachehomeyoutubedl cacheyoutubedl moment youtube player file video obfuscated signature cached may change nocachedir disable filesystem caching rmcachedir delete filesystem cache file thumbnail image writethumbnail write thumbnail image disk writeallthumbnails write thumbnail image format disk listthumbnails simulate list available thumbnail format verbosity simulation option q quiet activate quiet mode nowarnings ignore warning simulate download video write anything disk skipdownload download video g geturl simulate quiet print url e gettitle simulate quiet print title getid simulate quiet print id getthumbnail simulate quiet print thumbnail url getdescription simulate quiet print video description getduration simulate quiet print video length getfilename simulate quiet print output filename getformat simulate quiet print output format j dumpjson simulate quiet print json information see output template description available key j dumpsinglejson simulate quiet print json information commandline argument url refers playlist dump whole playlist information single line printjson quiet print video information json video still downloaded newline output progress bar new line noprogress print progress bar consoletitle display progress console titlebar v verbose print various debugging information dumppages print downloaded page encoded using base64 debug problem verbose writepages write downloaded intermediary page file current directory debug problem printtraffic display sent read http traffic c callhome contact youtubedl server debugging nocallhome contact youtubedl server debugging workarounds encoding encoding force specified encoding experimental nocheckcertificate suppress http certificate validation preferinsecure use unencrypted connection retrieve information video currently supported youtube useragent ua specify custom user agent referer url specify custom referer use video access restricted one domain addheader fieldvalue specify custom http header value separated colon use option multiple time bidiworkaround work around terminal lack bidirectional text support requires bidiv fribidi executable path sleepinterval second number second sleep download used alone lower bound range randomized sleep download minimum possible number second sleep used along maxsleepinterval maxsleepinterval second upper bound range randomized sleep download maximum possible number second sleep must used along minsleepinterval video format option f format format video format code see format selection info allformats download available video format preferfreeformats prefer free video format unless specific one requested f listformats list available format requested video youtubeskipdashmanifest download dash manifest related data youtube video mergeoutputformat format merge required eg bestvideobestaudio output given container format one mkv mp4 ogg webm flv ignored merge required subtitle option writesub write subtitle file writeautosub write automatically generated subtitle file youtube allsubs download available subtitle video listsubs list available subtitle video subformat format subtitle format accepts format preference example srt asssrtbest sublang langs language subtitle download optional separated comma use list sub available language tag authentication option u username username login account id p password password account password option left youtubedl ask interactively 2 twofactor twofactor twofactor authentication code n netrc use netrc authentication data videopassword password video password vimeo smotri youku adobe pas option apmso mso adobe pas multiplesystem operator tv provider identifier use aplistmso list available msos apusername username multiplesystem operator account login appassword password multiplesystem operator account password option left youtubedl ask interactively aplistmso list supported multiplesystem operator postprocessing option x extractaudio convert video file audioonly file requires ffmpeg avconv ffprobe avprobe audioformat format specify audio format best aac flac mp3 m4a opus vorbis wav best default effect without x audioquality quality specify ffmpegavconv audio quality insert value 0 better 9 worse vbr specific bitrate like 128k default 5 recodevideo format encode video another format necessary currently supported mp4flvoggwebmmkvavi postprocessorargs args give argument postprocessor k keepvideo keep video file disk post processing video erased default nopostoverwrites overwrite postprocessed file postprocessed file overwritten default embedsubs embed subtitle video mp4 webm mkv video embedthumbnail embed thumbnail audio cover art addmetadata write metadata video file metadatafromtitle format parse additional metadata like song title artist video title format syntax output regular expression named capture group may also used parsed parameter replace existing value example metadatafrom title artist title match title like coldplay paradise example regex metadatafromtitle partist ptitle xattrs write metadata video file xattrs using dublin core xdg standard fixup policy automatically correct known fault file one never nothing warn emit warning detectorwarn default fix file warn otherwise preferavconv prefer avconv ffmpeg running postprocessors preferffmpeg prefer ffmpeg avconv running postprocessors default ffmpeglocation path location ffmpegavconv binary either path binary containing directory exec cmd execute command file downloading postprocessing similar find exec syntax example exec adb push sdcardmusic rm convertsubs format convert subtitle format currently supported srtassvttlrc configuration configure youtubedl placing supported command line option configuration file linux macos system wide configuration file located etcyoutubedlconf user wide configuration file configyoutubedlconfig window user wide configuration file location appdatayoutubedlconfigtxt cusersuser nameyoutubedlconf note default configuration file may exist may need create example following configuration file youtubedl always extract audio copy mtime use proxy save video movie directory home directory line starting comment always extract audio x copy mtime nomtime use proxy proxy 1270013128 save video movie directory home directory moviestitlesexts note option configuration file option aka switch used regular command line call thus must whitespace eg proxy proxy use ignoreconfig want disable configuration file particular youtubedl run also use configlocation want use custom configuration file particular youtubedl run authentication netrc file may also want configure automatic credential storage extractor support authentication providing login password username password order pas credential command line argument every youtubedl execution prevent tracking plain text password shell command history achieve using netrc file per extractor basis need create netrc file home restrict permission readwrite touch homenetrc chmod arwxurw homenetrc add credential extractor following format extractor name extractor lowercase machine extractor login login password password example machine youtube login myaccountgmailcom password myyoutubepassword machine twitch login mytwitchaccountname password mytwitchpassword activate authentication netrc file pas netrc youtubedl place configuration file window may also need setup home environment variable manually example set homeuserprofile output template option allows user indicate template output file name tldr navigate example basic usage set template argument downloading single file like youtubedl funnyvideoflv httpssomevideo however may contain special sequence replaced downloading video special sequence may formatted according python string formatting operation example name name05d clarify percent symbol followed name parenthesis followed formatting operation allowed name along sequence type id string video identifier title string video title url string video url ext string video filename extension alttitle string secondary title video displayid string alternative identifier video uploader string full name video uploader license string license name video licensed creator string creator video releasedate string date yyyymmdd video wa released timestamp numeric unix timestamp moment video became available uploaddate string video upload date yyyymmdd uploaderid string nickname id video uploader channel string full name channel video uploaded channelid string id channel location string physical location video wa filmed duration numeric length video second viewcount numeric many user watched video platform likecount numeric number positive rating video dislikecount numeric number negative rating video repostcount numeric number reposts video averagerating numeric average rating give user scale used depends webpage commentcount numeric number comment video agelimit numeric age restriction video year islive boolean whether video live stream fixedlength video starttime numeric time second reproduction start specified url endtime numeric time second reproduction end specified url format string humanreadable description format formatid string format code specified format formatnote string additional info format width numeric width video height numeric height video resolution string textual description width height tbr numeric average bitrate audio video kbit abr numeric average audio bitrate kbit acodec string name audio codec use asr numeric audio sampling rate hertz vbr numeric average video bitrate kbit fps numeric frame rate vcodec string name video codec use container string name container format filesize numeric number byte known advance filesizeapprox numeric estimate number byte protocol string protocol used actual download extractor string name extractor extractorkey string key name extractor epoch numeric unix epoch creating file autonumber numeric number increased download starting autonumberstart playlist string name id playlist contains video playlistindex numeric index video playlist padded leading zero according total length playlist playlistid string playlist identifier playlisttitle string playlist title playlistuploader string full name playlist uploader playlistuploaderid string nickname id playlist uploader available video belongs logical chapter section chapter string name title chapter video belongs chapternumber numeric number chapter video belongs chapterid string id chapter video belongs available video episode series programme series string title series programme video episode belongs season string title season video episode belongs seasonnumber numeric number season video episode belongs seasonid string id season video episode belongs episode string title video episode episodenumber numeric number video episode within season episodeid string id video episode available medium track part music album track string title track tracknumber numeric number track within album disc trackid string id track artist string artist track genre string genre track album string title album track belongs albumtype string type album albumartist string list artist appeared album discnumber numeric number disc physical medium track belongs releaseyear numeric year yyyy album wa released aforementioned sequence referenced output template replaced actual value corresponding sequence name note sequence guaranteed present since depend metadata obtained particular extractor sequence replaced na example titlesidsexts mp4 video title youtubedl test video id bawjenozkcj result youtubedl test videobawjenozkcjmp4 file created current directory numeric sequence use numeric related formatting example viewcount05d result string view count padded zero 5 character like 00042 output template also contain arbitrary hierarchical path eg playlistsplaylistindexs titlesexts result downloading video directory corresponding path template missing directory automatically created use percent literal output template use output stdout use current default template titlesidsexts case dont want special character space transferring downloaded filename window system filename 8bitunsafe channel case add restrictfilenames flag get shorter title output template window batch file using output template inside window batch file must escape plain percent character doubling titlesidsexts become titlesidsexts however touch plain character eg environment variable expansion stay intact chomepathdesktoptitlesexts output template example note window may need use double quote instead single youtubedl getfilename titlesexts bawjenozkc youtubedl test video amp4 kind weird character youtubedl getfilename titlesexts bawjenozkc restrictfilenames youtubedltestvideomp4 simple file name download youtube playlist video separate directory indexed video order playlist youtubedl playlistsplaylistindexs titlesexts httpswwwyoutubecomplaylistlistplwiyx1dc3p2jr9n8gqaqnbcvlslap7re download playlist youtube channeluser keeping playlist separate directory youtubedl uploadersplaylistsplaylistindexs titlesexts httpswwwyoutubecomuserthelinuxfoundationplaylists download udemy course keeping chapter separate directory myvideos directory home youtubedl u user p password myvideosplaylistschapternumbers chapterstitlesexts httpswwwudemycomjavatutorial download entire series season keeping series season separate directory cmyvideos youtubedl cmyvideosseriessseasonnumbers seasonsepisodenumbers episodesexts httpsvideomorerukinovdetalayah5sezon367617 stream video downloaded stdout youtubedl bawjenozkc format selection default youtubedl try download best available quality ie want best quality dont need pas special option youtubedl guess default sometimes may want download different format example slow intermittent connection key mechanism achieving socalled format selection based explicitly specify desired format select format based criterion criterion setup precedence much general syntax format selection format format shorter f format format selector expression ie expression describes format format would like download tldr navigate example simplest case requesting specific format example f 22 download format format code equal 22 get list available format code particular video using listformats f note format code extractor specific also use file extension currently 3gp aac flv m4a mp3 mp4 ogg wav webm supported download best quality format particular file extension served single file eg f webm download best quality format webm extension served single file also use special name select particular edge case format best select best quality format represented single file video audio worst select worst quality format represented single file video audio bestvideo select best quality videoonly format eg dash video may available worstvideo select worst quality videoonly format may available bestaudio select best quality audio onlyformat may available worstaudio select worst quality audio onlyformat may available example download worst quality videoonly format use f worstvideo want download multiple video dont format available specify order preference using slash note slash leftassociative ie format left hand side preferred example f 221718 download format 22 available otherwise download format 17 available otherwise download format 18 available otherwise complain suitable format available download want download several format video use comma separator eg f 221718 download three format course available sophisticated example combined precedence feature f 136137mp4bestvideo140m4abestaudio also filter video format putting condition bracket f bestheight720 f filesize10m following numeric meta field used comparison equal equal filesize number byte known advance width width video known height height video known tbr average bitrate audio video kbit abr average audio bitrate kbit vbr average video bitrate kbit asr audio sampling rate hertz fps frame rate also filtering work comparison equal start end contains following string meta field ext file extension acodec name audio codec use vcodec name video codec use container name container format protocol protocol used actual download lowercase http http rtsp rtmp rtmpe mm f4m ism httpdashsegments m3u8 m3u8native formatid short description format string comparison may prefixed negation order produce opposite comparison eg doe contain note none aforementioned meta field guaranteed present since solely depends metadata obtained particular extractor ie metadata offered video hoster format value known excluded unless put question mark operator combine format filter f height 720tbr500 selects 720p video video height known bitrate least 500 kbit merge video audio two format single file using f videoformataudioformat requires ffmpeg avconv installed example f bestvideobestaudio download best videoonly format best audioonly format mux together ffmpegavconv format selector also grouped using parenthesis example want download best mp4 webm format height lower 480 use f mp4webmheight480 since end april 2015 version 20150426 youtubedl us f bestvideobestaudiobest default format selection see 5447 5456 ffmpeg avconv installed result downloading bestvideo bestaudio separately muxing together single file giving best overall quality available otherwise fall back best result downloading best available quality served single file best also needed video dont come youtube dont provide audio video two different file want download dash format example interested getting video resolution higher 1080p add f bestvideoheight1080bestaudiobest configuration file note use youtubedl stream stdout likely pipe medium player ie explicitly specify output template youtubedl still us f best format selection order start content delivery immediately player wait bestvideo bestaudio downloaded muxed want preserve old format selection behavior prior youtubedl 20150426 ie want download best available quality medium served single file explicitly specify choice f best may want add configuration file order type every time run youtubedl format selection example note window may need use double quote instead single download best mp4 format available best mp4 available youtubedl f bestvideoextmp4bestaudioextm4abestextmp4best download best format available better 480p youtubedl f bestvideoheight480bestaudiobestheight480 download best video format bigger 50 mb youtubedl f bestfilesize50m download best format available via direct link httphttps protocol youtubedl f bestvideobestaudiobestprotocolhttp download best video format best audio format without merging youtubedl f bestvideobestaudio titlesfformatidsexts note last example output template recommended bestvideo bestaudio may file name video selection video filtered upload date using option date datebefore dateafter accept date two format absolute date date format yyyymmdd relative date date format nowtoday09dayweekmonthyears example download video uploaded last 6 month youtubedl dateafter now6months download video uploaded january 1 1970 youtubedl date 19700101 download video uploaded 200x decade youtubedl dateafter 20000101 datebefore 20091231 faq update youtubedl youve followed manual installation instruction simply run youtubedl u linux sudo youtubedl u used pip simple sudo pip install u youtubedl sufficient update installed youtubedl using package manager like aptget yum use standard system update mechanism update note distribution package often outdated rule thumb youtubedl release least month often weekly even daily simply go httpsytdlorg find current version unfortunately nothing youtubedl developer distribution serf really outdated version complain distribution bugtracker support forum last resort also uninstall version installed package manager follow manual installation instruction remove distribution package line like sudo aptget remove youtubedl afterwards simply follow manual installation instruction sudo wget httpsgithubcoml1vingyoutubedlreleaseslatestdownloadyoutubedl usrlocalbinyoutubedl sudo chmod arx usrlocalbinyoutubedl hash r youll able update sudo youtubedl u youtubedl extremely slow start window add file exclusion youtubedlexe window defender setting im getting error unable extract opengraph title youtube playlist youtube changed playlist format march 2014 later youll need least youtubedl 20140725 download youtube video installed youtubedl package manager pip setuppy tarball please use update note ubuntu package seem get updated anymore since affiliated ubuntu little feel free report bug ubuntu packaging people update package somewhat recent version see way update im getting error trying use output template error using output template conflict using title video id auto number make sure using option title id autonumber set command line configuration file remove latter always pas citw default youtubedl intends best option incidentally convincing case different please file issue explain therefore unnecessary sometimes harmful copy long option string webpage particular option citw regularly useful please put b option back people asking question aware youtubedl default downloading highest available quality reported youtube 1080p 720p case longer need b option specific video maybe youtube doe report available specific high quality format youre interested case simply request f option youtubedl try download get http error 402 trying download video whats apparently youtube requires pas captcha test download much considering provide way let solve captcha moment best course action pointing web browser youtube url solving captcha restart youtubedl need program youtubedl work fine site however want convert videoaudio youll need avconv ffmpeg site notably youtube video retrieved higher quality format without sound youtubedl detect whether avconvffmpeg present automatically pick best option video video format streamed via rtmp protocol downloaded rtmpdump installed downloading mm rtsp video requires either mplayer mpv installed downloaded video play video fully downloaded use video player mpv vlc mplayer extracted video url g doe play another machine web browser depends lot service many case request video downloadplay must come ip address cooky andor http header use cooky option write required cooky file advise downloader read cooky file site also require common user agent used use dumpuseragent see one use youtubedl also get necessary cooky http header json output obtained dumpjson may beneficial use ipv6 case restriction applied ipv4 service sometimes subset video restrict video url ip address cookie useragent exception rather rule please bear mind url protocol supported browser box including rtmp using g downloader must support well want play video machine running youtubedl relay video content machine run youtubedl use let youtubedl stream video stdout simply allow player download file written youtubedl turn error fmturlmap conn information found video info youtube ha switched new video info format july 2011 supported old version youtubedl see update youtubedl error unable download video youtube requires additional signature since september 2012 supported old version youtubedl see update youtubedl video url contains ampersand im getting strange output 1 2839 v recognized internal external command thats actually output shell since ampersand one special shell character interpreted shell preventing passing whole url youtubedl disable shell interpreting ampersand special character either put whole url quote escape backslash approach work depends shell example url httpswwwyoutubecomwatcht4vbawjenozkc end following command youtubedl httpswwwyoutubecomwatcht4vbawjenozkc youtubedl httpswwwyoutubecomwatcht4vbawjenozkc window use double quote youtubedl httpswwwyoutubecomwatcht4vbawjenozkc extractorerror could find j function uof february 2015 new youtube player contained character sequence string wa misinterpreted old version youtubedl see update youtubedl http error 429 many request 402 payment required two error code indicate service blocking ip address overuse usually soft block meaning gain access solving captcha open browser solve captcha service suggests pas cooky youtubedl note machine ha multiple external ip also pas exactly ip youve used solving captcha sourceaddress also may need pas useragent http header browser useragent case captcha suggested solve service contact service ask unblock ip address acquired whitelisted ip address already use proxy sourceaddress option select another ip address syntaxerror nonascii character error file youtubedl line 2 syntaxerror nonascii character x93 mean youre using outdated version python please update python 26 27 binary file ha code gone since june 2012 342 youtubedl packed executable zipfile simply unzip might need renaming youtubedlzip first system clone git repository laid modify code run executing mainpy file recompile executable run make youtubedl exe throw error due missing msvcr100dll run exe need install first microsoft visual c 2010 redistributable package x86 window set ffmpeg youtubedl put exe file put youtubedl ffmpeg directory youre running command work thats rather cumbersome make different directory work either ffmpeg youtubedl simply create directory say cbin cusersuser namebin put executables directly set path environment variable include directory restarting shell able access youtubedl ffmpeg youtubedl able find ffmpeg simply typing youtubedl ffmpeg matter directory youre put downloads specific folder use specify output template example homeuservideostitlesidsexts want downloads put option configuration file download video starting either prepend httpswwwyoutubecomwatchv separate id option youtubedl wnyeurxzfu youtubedl httpswwwyoutubecomwatchvwnyeurxzfu pas cooky youtubedl use cooky option example cooky pathtocookiesfiletxt order extract cooky browser use conforming browser extension exporting cooky example cookiestxt chrome cookiestxt firefox note cooky file must mozillanetscape format first line cooky file must either http cookie file netscape http cookie file make sure correct newline format cooky file convert newlines necessary correspond namely crlf rn window lf n unix unixlike system linux macos etc http error 400 bad request using cooky good sign invalid newline format passing cooky youtubedl good way workaround login particular extractor doe implement explicitly another use case working around captcha website require solve particular case order get access eg youtube cloudflare stream directly medium player first need tell youtubedl stream medium stdout also tell medium player read stdin must capable streaming pipe former latter example streaming vlc achieved youtubedl httpswwwyoutubecomwatchvbawjenozkcj vlc download new video playlist use downloadarchive feature feature initially download complete playlist downloadarchive pathtodownloadarchivefiletxt record identifier video special file subsequent run downloadarchive download new video skip video downloaded note successful downloads recorded file example first youtubedl downloadarchive archivetxt httpswwwyoutubecomplaylistlistplwiyx1dc3p2jr9n8gqaqnbcvlslap7re download complete plwiyx1dc3p2jr9n8gqaqnbcvlslap7re playlist create file archivetxt subsequent run download new video youtubedl downloadarchive archivetxt httpswwwyoutubecomplaylistlistplwiyx1dc3p2jr9n8gqaqnbcvlslap7re add hlsprefernative config youtubedl detects hl video download either builtin downloader ffmpeg since many hl stream slightly invalid ffmpegyoutubedl handle invalid case better option switch downloader needed youtubedl know one particular downloader work better given website downloader picked otherwise youtubedl pick best downloader general compatibility moment happens ffmpeg choice may change future version youtubedl improvement builtin downloader andor ffmpeg particular generic extractor used website list supported site youtubedl cannot mandate one specific downloader put either hlsprefernative hlspreferffmpeg configuration different subset video fail download correctly instead much better file issue pull request detail native ffmpeg hl downloader better choice use case add support anime video site site show current movie free matter policy well legality youtubedl doe include support service specialize infringing copyright rule thumb cannot easily find video service quite obviously allowed distribute ie ha uploaded creator creator distributor published free license service probably unfit inclusion youtubedl note service dont host infringing content link evidence service included youtubedl go dmca note whole front page service filled video allowed distribute fair use note equally unconvincing service show copyrightprotected video full without authorization support request service purchase right distribute content perfectly fine though doubt simply include source mention legitimate purchase content speed work issue also known help important issue solved youtubedl core developer team quite small best solve many issue possible sometimes take quite speed issue first please report issue issue tracker allows u coordinate effort user developer serf unified point unfortunately youtubedl project ha grown large use personal email effective communication channel please read bug reporting instruction lot bug lack necessary information offer proxy vpn shell access youtubedl developer able test issue multiple computer multiple country exclude local censorship misconfiguration issue nobody interested solving issue welcome take matter hand submit pull request coercepay somebody else feel free bump issue time time writing small comment issue still present youtubedl version france fixed belgium please month please declare issue important urgent detect whether given url supported youtubedl one look list supported site note sometimes happen site change url scheme say httpsexamplecomvideo1234567 httpsexamplecomv1234567 youtubedl report url service list unsupported case simply report bug possible detect whether url supported thats youtubedl contains generic extractor match url may tempted disable exclude remove generic extractor generic extractor allows user extract video lot website embed video another service may also used extract video service hosting therefore neither recommend support disabling excluding removing generic extractor want find whether given url supported simply call youtubedl get video back chance url either referring video unsupported find examining output run youtubedl console catching unsupportederror exception run python program need go much red tape filing bug issue template despite extensive bug reporting instruction 80 issue report got useless instance people used ancient version hundred release old simple syntactic error youtubedl general shell usage problem wa already reported multiple time people actually read error message even said please install ffmpeg people mention url trying download many simple easytoavoid problem many totally unrelated youtubedl youtubedl opensource project manned volunteer wed rather spend time fixing bug certain none simple problem apply reasonably confident able reproduce issue without asking reporter repeatedly output youtubedl v yoururlhere really thats required file issue issue template also guide basic step checking version youtubedl current developer instruction user need build youtubedl download build get distribution run youtubedl developer dont need build anything either simply execute python youtubedl run test simply invoke favorite test runner execute test file directly following work python unittest discover python testtestdownloadpy nosetests see item 6 new extractor tutorial run extractor specific test case want create build youtubedl youll need python make gnu make supported pandoc zip nosetests adding support new site want add support new site first make sure site dedicated copyright infringement youtubedl doe support site thus pull request adding support rejected ensured site distributing content legally follow quick list assuming service called yourextractor fork repository check source code git clone gitgithubcomyourgithubusernameyoutubedlgit start new git branch cd youtubedl git checkout b yourextractor start simple template save youtubedlextractoryourextractorpy coding utf8 future import unicodeliterals common import infoextractor class yourextractorieinfoextractor validurl rhttpswwwyourextractorcomwatchpid09 test url httpsyourextractorcomwatch42 md5 todo md5 sum first 10241 byte video file use test infodict id 42 ext mp4 title video title go thumbnail rrehttpsjpg todo property either value md5 checksum start string md5 regular expression start string python type example int float def realextractself url videoid selfmatchidurl webpage selfdownloadwebpageurl videoid todo code go example title selfhtmlsearchregexrh1h1 webpage title return id videoid title title description selfogsearchdescriptionwebpage uploader selfsearchregexrdividuploader webpage uploader fatalfalse todo property see youtubedlextractorcommonpy add import youtubedlextractorextractorspy run python testtestdownloadpy testdownloadtestyourextractor fail first continually rerun youre done decide add one test rename test test make list dictionary test named testdownloadtestyourextractor testdownloadtestyourextractor1 testdownloadtestyourextractor2 etc note test onlymatching key test dict counted look youtubedlextractorcommonpy possible helper method detailed description extractor may return add test code many want make sure code follows youtubedl coding convention check code flake8 flake8 youtubedlextractoryourextractorpy make sure code work python version claimed supported youtubedl namely 26 27 32 test pas add new file commit push result like git add youtubedlextractorextractorspy git add youtubedlextractoryourextractorpy git commit yourextractor add new extractor git push origin yourextractor finally create pull request well review merge case thank much contribution youtubedl coding convention section introduces guide line writing idiomatic robust futureproof extractor code extractor fragile nature since depend layout source data provided 3rd party medium hosters control layout tends change extractor implementer task write code extract medium link metadata correctly also minimize dependency source layout even make code foresee potential future change ready important allow extractor break minor layout change thus keeping old youtubedl version working even though breakage issue easily fixed emitting new version youtubedl fix incorporated previous version become broken repository distros package may prompt fetching update u needle say non rolling release distros may never receive update mandatory optional metafields extraction work youtubedl relies metadata extractor extract provides youtubedl expressed information dictionary simply info dict following meta field info dict considered mandatory successful extraction process youtubedl id medium identifier title medium title url medium download url format fact last option technically mandatory ie cant figure download location medium extraction doe make sense convention youtubedl also treat id title mandatory thus aforementioned metafields critical data extraction doe make sense without fail extracted extractor considered completely broken field apart aforementioned one considered optional mean extraction tolerant situation source field potentially unavailable even always available moment futureproof order break extraction general purpose mandatory field example say source dictionary meta youve fetched json http request ha key summary meta selfdownloadjsonurl videoid assume point metas layout summary fancy summary text assume want extract summary put resulting info dict description since description optional meta field ready key may missing meta dict extract like description metagetsummary correct like description metasummary incorrect latter break extraction process keyerror summary disappears meta later time former approach extraction go ahead description set none perfectly fine remember none equivalent absence data similarly pas fatalfalse extracting optional data webpage searchregex htmlsearchregex similar method instance description selfsearchregex rspanidtitle webpage description fatalfalse fatal set false searchregex fails extract description emit warning continue extraction also pas defaultsome fallback value example description selfsearchregex rspanidtitle webpage description defaultnone failure code silently continue extraction description set none useful metafields may may present provide fallback extracting metadata try multiple source example title present several place try extracting least make futureproof case source become unavailable example say meta previous example ha title extract since title mandatory meta field end something like title metatitle title disappears meta future due change hosters side extraction would fail since title mandatory thats expected assume another source extract title example ogtitle html meta webpage case provide fallback scenario title metagettitle selfogsearchtitlewebpage code try extract meta first fails try extracting ogtitle webpage regular expression dont capture group dont use capturing group must indication used somewhere code group used must non capturing example dont capture id attribute name since cant use anything anyway correct rididpidd incorrect rididpidd make regular expression relaxed flexible using regular expression try write fuzzy relaxed flexible skipping insignificant part likely change allowing single double quote quoted value example say need extract title following html code span styleposition absolute left 910px width 90px float right zindex 9999 classtitlesome fancy titlespan code task look similar title selfsearchregex rspanclasstitle webpage title even better title selfsearchregex rspanclasstitle1ptitle webpage title grouptitle note tolerate potential change style attribute value switch using double quote single class attribute code definitely look like title selfsearchregex rspan styleposition absolute left 910px width 90px float right zindex 9999 classtitlespan webpage title grouptitle long line policy soft limit keep line code 80 character long mean respected possible doe make readability code maintenance worse example never split long string literal like url often copied entity multiple line fit limit correct httpswwwyoutubecomwatchvfqztn594jqwlistplmyetvrpaqy00v9w81cwmzp6n6vzqfukd4 incorrect httpswwwyoutubecomwatchvfqztn594jqwlist plmyetvrpaqy00v9w81cwmzp6n6vzqfukd4 inline value extracting variable acceptable reducing code duplication improving readability complex expression however avoid extracting variable used moving opposite part extractor file make reading linear flow difficult example correct title selfhtmlsearchregexrtitletitle webpage title incorrect titlere rtitletitle line code title selfhtmlsearchregextitlere webpage title collapse fallback multiple fallback value quickly become unwieldy collapse multiple fallback value single expression via list pattern example good description selfhtmlsearchmeta ogdescription description twitterdescription webpage description defaultnone unwieldy description selfogsearchdescriptionwebpage defaultnone selfhtmlsearchmetadescription webpage defaultnone selfhtmlsearchmetatwitterdescription webpage defaultnone method supporting list pattern searchregex htmlsearchregex ogsearchproperty htmlsearchmeta trailing parenthesis always move trailing parenthesis last argument example correct lambda x xresultsetresult0videourlsetvideourl list incorrect lambda x xresultsetresult0videourlsetvideourl list use convenience conversion parsing function wrap extracted numeric data safe function youtubedlutilspy intornone floatornone use string number conversion well use urlornone safe url processing use tryget safe metadata extraction parsed json use unifiedstrdate uniform uploaddate yyyymmdd meta field extraction unifiedtimestamp uniform timestamp extraction parsefilesize filesize extraction parsecount count meta field extraction parseresolution parseduration duration extraction parseagelimit agelimit extraction explore youtubedlutilspy useful convenience function example safely extract optional description parsed json description trygetresponse lambda x xresultvideo0summary compatstr safely extract optional metadata video trygetresponse lambda x xresultvideo0 dict description videogetsummary duration floatornonevideogetdurationms scale1000 viewcount intornonevideogetviews embedding youtubedl youtubedl make best effort good commandline program thus callable programming language encounter problem parsing output feel free create report python program embed youtubedl powerful fashion like future import unicodeliterals import youtubedl ydlopts youtubedlyoutubedlydlopts ydl ydldownloadhttpswwwyoutubecomwatchvbawjenozkc likely youll want use various option list option available look youtubedlyoutubedlpy start want intercept youtubedls output set logger object complete example program output error short message download finished downloadsconverts video mp3 file future import unicodeliterals import youtubedl class myloggerobject def debugself msg pas def warningself msg pas def errorself msg printmsg def myhookd dstatus finished printdone downloading converting ydlopts format bestaudiobest postprocessors key ffmpegextractaudio preferredcodec mp3 preferredquality 192 logger mylogger progresshooks myhook youtubedlyoutubedlydlopts ydl ydldownloadhttpswwwyoutubecomwatchvbawjenozkc bug bug suggestion reported httpsgithubcomytdlorgyoutubedlissues unless prompted another pertinent reason eg github fails accept bug report please send bug report via personal email discussion join u irc channel youtubedl freenode webchat please include full output youtubedl run v ie add v flag command line copy whole output post issue body wrapped better formatting look similar youtubedl v command line debug system config debug user config debug commandline args uv uhttpswwwyoutubecomwatchvbawjenozkcj debug encoding locale cp1251 f mbcs cp866 pref cp1251 debug youtubedl version 20151206 debug git head 135392e debug python version 266 windows2003server523790sp2 debug exe version ffmpeg n75573g1d0487f ffprobe n75573g1d0487f rtmpdump 24 debug proxy map post screenshots verbose log plain text acceptable output including first line contains important debugging information issue without full output often reproducible therefore get solved short order ever please reread issue avoid couple common mistake use checklist description issue sufficient often get issue report cannot really decipher case eventually get required information asking back multiple time pose unnecessary drain resource many contributor including also native speaker may misread part please elaborate feature requesting bug want fixed make sure obvious problem could fixed proposed solution would look like report shorter two line almost certainly missing make hard u respond often polite close issue outright missing info make misinterpretation likely committer often get frustrated issue since possible way move forward ask clarification bug report mean report contain complete output youtubedl called v flag error message get bug even say would believe many bug report contain information server ha multiple ip suspect censorship adding callhome may good idea get diagnostics error error unable extract cannot reproduce multiple country add dumppages warning yield rather large output redirect file logtxt adding logtxt 21 commandline upload dump file get add writepages somewhere site support request must contain example url example url url might want download like httpswwwyoutubecomwatchvbawjenozkc obvious video present except special circumstance main page video service eg httpswwwyoutubecom example url using latest version reporting issue type youtubedl u report youre uptodate 20 report receive already fixed people using outdated version go feature request well issue already documented make sure someone ha already opened issue youre trying open search top window browse github issue repository issue feel free write something along line affect well version 20150101 information issue issue may old new post often spur rapid activity existing option enough requesting new feature please quick peek list supported option many feature request feature actually exist already please absolutely show work issue report detail existing similar option solve problem enough context bug report people want solve problem often think u favor breaking larger problem eg wanting skip already downloaded file specific request eg requesting u look whether file exists downloading info page however often happens break problem two step one simple one impossible extremely complicated one presented complicated request original problem could solved far easier eg recording downloaded video id separate file avoid must include greater context nonobvious particular every feature request doe consist adding support new site contain use case scenario explains situation missing feature would useful doe issue involve one problem one problem user seem think limit issue open limit issue open may seem appealing able dump issue one ticket mean someone solves one issue cannot mark issue closed typically reporting bunch issue lead ticket lingering since nobody want attack behemoth someone mercifully split issue multiple one particular every site support request issue pertain service one site generally common domain always using backend technology request support vimeo user video white house podcasts google plus page issue also make sure dont post bug report alongside feature request rule thumb feature request doe include output youtubedl immediately related feature hand post report network error alongside request new video service anyone going need feature post feature incapacitated friend personally talk require post feature seem like good idea really useful requested someone requires question youtubedl may sound strange bug report receive completely unrelated youtubedl relate different even reporter application please make sure actually using youtubedl using ui youtubedl report bug maintainer actual application providing ui hand ui youtubedl fails way believe related youtubedl mean go ahead report bug copyright youtubedl released public domain copyright holder readme file wa originally written daniel bolton likewise released public domain\n",
      "[0 0 0 ... 0 0 0]\n",
      "try newer example repo newer example demonstrating vue microfrontends found httpsgithubcomvuemicrofrontends httpsvuemicrofrontendsapp example better reflects microfrontends architecture encouraged use coexisting vue microfrontends demo httpcoexistingvuemicrofrontendssurgesh starterkit example repository people want multiple vue microfrontends coexist within single page vue application wa created vue cli us singlespa pull mean even add react angular framework additional microfrontends important note github repository ha four project one repo youll want one git repo per vue application roothtmlfile project also repo let different team developer charge different microfrontends local development one app time tutorial video singlespa preferred run npm run serve one singlespa application time using deployed version application make awesome developer experience boot one microfrontend time even clone npm install boot one try clone repo run following command cd app1 npm npm run serve go httpcoexistingvuemicrofrontendssurgesh browser browser console run localstoragesetitemoverridesui true refresh page click yellowish rectangle bottom right click app1 change module url httplocalhost8081jsappjs apply override reload page change app1 load localhost instead surgesh modify code locally reload page coexistingvuemicrofrontendssurgesh see httpsgithubcomjoeldenningimportmapoverrides info local development preferred run one app time need run locally following instruction first terminal tab cd roothtmlfile npm install npm run serve second terminal tab cd app1 npm install npm run serve third terminal tab cd app2 npm install npm run serve fourth terminal tab cd navbar npm install npm run serve go httplocalhost5000 browser note change port project modifying import map inside roothtmlfileindexhtml get serious deploying code youll want make longer necessary boot apps order anything get point check importmapoverrides let go deployed environment override import map one microfrontend time importmapoverrides library already loaded indexhtml roothtmlfile start using immediately make deployed environment overridable like override httpcoexistingvuemicrofrontendssurgesh documentation go httpssinglespajsorgdocsecosystemvuehtml learn work\n",
      "[0 0 0 ... 0 0 0]\n",
      "babelpresetenv ha stabilized ha moved main babel monorepo repo ha archived move make much easier release develop sync rest babel repo made readonly issueslabels moved well please report bug open pull request main monorepo babelpresetenv babel preset compiles es2015 es5 automatically determining babel plugins polyfills need based targeted browser runtime environment npm install babelpresetenv savedev without configuration option babelpresetenv behaves exactly babelpresetlatest babelpresetes2015 babelpresetes2016 babelpresetes2017 together however dont recommend using presetenv way doesnt take advantage greater capability targeting specific browser presets env also configure include polyfills transforms needed browser support compiling whats needed make bundle smaller life easier example includes polyfills code transforms needed coverage user 025 ignoring internet explorer 11 opera mini use browserslist parse information use valid query format supported browserslist presets env target refers global coverage user browserslist browser 025 ie 11 opmini also target individual version browser instead using query target chrome 52 similarly youre targeting nodejs instead browser configure babelpresetenv include polyfills transforms necessary particular version presets env target node 610 convenience use node current include necessary polyfills transforms nodejs version use run babel presets env target node current check many option especially usebuiltins polyfill le work install usage option example caveat cool project work determine environment support ecmascript feature use external data compattable determine browser support create pr necessary periodically run builddatajs generates pluginsjson ref 7 maintain mapping javascript feature babel plugins currently located pluginfeaturesjs straightforward case might case plugins split certain plugins arent standalone enough impossible support plugins babel considered latest default behavior without option babelpresetlatest wont include stagex plugins env support plugins consider latest version javascript matching babelpresetlatest ref 14 determine lowest common denominator plugins included preset targeting ie 8 chrome 55 include plugins required ie 8 since would need support still support target option node current compile currently running node version example building node 6 arrow function wont converted build node 012 support browser option like autoprefixer use browserslist declare supported environment performing query like 1 last 2 version ref 19 install npm npm install savedev babelpresetenv yarn yarn add babelpresetenv dev usage default behavior without option run transforms behaves babelpresetlatest presets env option information setting option preset refer pluginpreset option documentation target string number string default take object environment version support target environment take number string recommend using string specifying minor version like node 610 example environment chrome opera edge firefox safari ie io android node electron data generated running builddata script pull data compattable targetsnode number string current true want compile current node version specify node true node current would node processversionsnode targetsbrowsers arraystring string query select browser ex last 2 version 5 using browserslist note browser result overridden explicit item target targetsuglify true using uglifyjs minify code may run syntax error targeting later browser since uglifyjs doe support es2015 syntax prevent error set uglify option true enables transformation plugins result code fully compiled es5 however usebuiltins option still work include polyfills target need uglify ha support es2015 syntax via uglifyes using syntax unsupported uglifyes recommend using babelminify note option deprecated 2x replaced forcealltransforms option spec boolean default false enable spec compliant potentially slower transformation plugins preset support loose boolean default false enable loose transformation plugins preset allow module amd umd systemjs commonjs false default commonjs enable transformation es6 module syntax another module type setting false transform module debug boolean default false output targetsplugins used version specified plugin data version consolelog include arraystring default note whitelist deprecated removed next major favor array plugins always include valid option include babel plugins babelplugintransformes2015spread without prefix transformes2015spread supported builtins map set objectassign option useful bug native implementation combination nonsupported feature supported one doesnt work example node 4 support native class spread super used spread argument transformes2015classes transform need included possible transpile spread super otherwise note include exclude option work plugins included preset example including transformdoexpressions excluding transformfunctionbind throw error use plugin included preset add config directly exclude arraystring default array plugins always excluderemove possible option include option option useful blacklisting transform like transformregenerator dont use generator dont want include regeneratorruntime using usebuiltins using another plugin like fastasync instead babel asynctogen usebuiltins boolean default false way apply babelpresetenv polyfills via babelpolyfill note doe currently polyfill experimentalstagex builtins like regular babelpolyfill doe work npm 3 used babel 6 anyway npm install babelpolyfill save option enables new plugin replaces statement import babelpolyfill requirebabelpolyfill individual requires babelpolyfill based environment note use requirebabelpolyfill whole app multiple import requires babelpolyfill throw error since cause global collision issue hard trace recommend creating single entry file contains require statement import babelpolyfill different based environment import corejsmoduleses7stringpadstart import corejsmoduleses7stringpadend import corejsmoduleswebtimers import corejsmoduleswebimmediate import corejsmoduleswebdomiterable also work corejs directly import corejs npm install corejs save example export various target export class target chrome 52 babelrc presets env target chrome 52 class exportsa target chrome 52 webpack 2rollup loose mode babelrc presets env target chrome 52 module false loose true export class target specific browser via browserslist babelrc presets env target chrome 52 browser last 2 version safari 7 export var function classcallcheckthis target latest node via node true node current babelrc presets env target node current class exportsa show debug output babelrc presets env target safari 10 module false usebuiltins true debug true stdout using target safari 10 module transform false using plugins transformexponentiationoperator transformasynctogenerator using polyfills es7objectvalues es7objectentries es7objectgetownpropertydescriptors webtimers webimmediate webdomiterable include exclude specific pluginsbuiltins always include arrow function explicitly exclude generator presets env target browser last 2 version safari 7 include transformes2015arrowfunctions es6map exclude transformregenerator es6set caveat get syntaxerror unexpected token error using objectrestspread transform make sure plugin ha updated least v6190 cool project babelpresetmodernbrowsers\n",
      "[0 0 0 ... 0 0 0]\n",
      "repo2docker repo2docker fetch git repository build container image based configuration file found repository see repo2docker documentation information using repo2docker support question please search post httpsdiscoursejupyterorgcbinder see contributing guide information contributing repo2docker using repo2docker prerequisite docker build run repository community edition recommended python 36 supported linux macos see documentation note window support installation quick guide installing repo2docker see documentation full guide install pypi pip install jupyterrepo2docker install source git clone httpsgithubcomjupyterhubrepo2dockergit cd repo2docker pip install e usage core feature repo2docker fetch git repository github locally build container image based specification found repository optionally launch container use explore repository note docker need running machine work example jupyterrepo2docker httpsgithubcomnorvigpytudes building might take output terminal something like copypaste url browser connect first time login token http000036511tokenf94f8fabb92e22f5bfab116c382b4707fc2cade56ad1ace0 copy paste url browser see jupyter notebook content repository built information use repo2docker see usage guide repository specification repo2docker look configuration file source repository determine docker image built list configuration file repo2docker use see complete list configuration file philosophy repo2docker inspired heroku build pack\n",
      "[0 0 0 ... 0 0 0]\n",
      "browserpass important repository archived maintained anymore browserpass wa rewritten scratch split two repository browser extension browserpassextension native host app browserpassnative follow new repository installation instruction highly recommend read readme repository get acquainted new change faq 1 new version backwards compatible therefore need update browser extension native host time installed browser extension web store autoupdate must install browserpass native host v3 read browserpassnative installation section see provides updated package browserpass v3 follow manual installation step described section 2 upgrade wait autoupdate come use chromiumbased browser go browserpassextension release download latest browserpasswebstorecrx open chromeextensions enable developer mode dragndrop downloaded crx file finally proceed browserpassnative installation section install new version native host use firefox go browserpassextension release download latest firefoxzip file unpack folder firefox go aboutdebuggingaddons click load temporary addon install extension finally proceed browserpassnative installation section install new version native host unpack content firefoxzip usrsharemozillaextensionsec8030f7c20a464f9b0e13a3a9e97384browserpassmaximbazcom folder according experiment firefox treat persistent extension ignore whatever currently web store need load extension every firefox restart 3 keep old version dont time upgrade native host app hasnt updated browserpass package yet go latest v2 release download chromezip firefoxzip depending browser use unpack archive new directory load extension browser chromium go chromeextensions enable developer mode click load unpacked select folder unpacked content chromezip firefox go aboutdebuggingaddons click load temporary addon select folder unpacked content firefoxzip unpack content firefoxzip usrsharemozillaextensionsec8030f7c20a464f9b0e13a3a9e97384browserpassmaximbazcom folder according experiment firefox treat persistent extension ignore whatever currently web store need load extension every firefox restart 4 happened otp otp wa implemented browserpass v3 might implemented separate extension detail see support otp browserpass v3 browserpass chrome firefox extension zx2c4s pas unix based password manager retrieves decrypted password current domain allows autofill login form well copy clipboard multiple logins current site extension show list usernames choose us native binary written golang interfacing password store secure communication binary browser extension handled native messaging table content requirement installation update usage option security faq contributing license requirement recent version chrome chromium firefox 50 pas unix password filename must match username file must line starting login user username followed username example pas websitecomjohndoe thepassword pas websitecom thepassword login johndoe installation order install browserpass correctly install two component host application browser extension installing host application following browserpass package installed via package manager arch linux debian gnulinux macos make sure read instruction nixos make sure read instruction ubuntu listed proceed manual installation step download latest github release start downloading latest release package operating system verifying authenticity release release file signed pgp key verify signature given file use gpg verify filesig report gpg signature made gpg using rsa key 8053eb88879a68cb4873d32b011fdc52da839335 gpg good signature maxim baz gpg aka primary key fingerprint eb4f 9e5a 60d3 2232 bb52 150c 12c8 7a28 feac 6b20 subkey fingerprint 8053 eb88 879a 68cb 4873 d32b 011f dc52 da83 9335 installing host application extract package would like binary run installsh installps1 window install native messaging host want systemwide installation run script sudo window systemwide installation done running installps1 administrator specifying yes install user prompt desire noninteractive installation unix system pas name browser script eg installsh chrome installing binary registering browser installation script required allow browser extension talk local binary application installing host application window wsl already use pas wsl prefer single copy password store use browserpass wsl well install window host application see previous section well linux host application wsl create localappdatabrowserpassbrowserpasswslbat following content echo bash c browserpassbrowserpasslinux64 installed linux host application location different browserpass replace path script change path localappdatabrowserpassbrowserpassfirefoxjson chromejson point browserpasswslbat gpg key ha password host application running wsl wont able unlock since cant interactively prompt password mean cant decrypt password unless youve already got key loaded gpgagent workaround use key pas websitecom wsl terminal load key gpgagent browserpass work gpgagent time possible configure larger timeouts check manual gpgagent installing chrome extension either install chrome extension chrome web store drag chromebrowserpasscrx file release package chrome extension chromeextensions page installing firefox extension install firefox extension mozilla addons site please note need firefox 50 higher update important majority improvement require changing code browser extension host application trying maintain backwards compatibility expected make sure keep component date updating host application installed host application via package manager likely update way repeat installation instruction updating browser extension installed extension webstore receive update automatically repeat installation instruction extension usage click lock icon use ctrlshiftl open browserpass entry match current domain chrome allows changing shortcut via chromeextensions keyboard shortcut firefox unfortunately doe allow changing default shortcut firefox support keyboard shortcut since version 53 filter search mode browserpass ha two mode working password entry filter search opened browserpass automatically switch filter mode least one matching entry exists filter mode designed quickly refine search result example choose one several account given domain done client side filter always fuzzy always work real time browserpass filter mode see domain name input field exit filter mode press backspace search mode designed search password entry disk much expensive operation especially visible window thats real time instead search enter pressed search fuzzy default changed glob algorithm option want search everything interactively search use filter mode refine search real time fill submit login form click select entry want submit login form filled selected credential injected directly dom browserpass doe use clipboard focus input field hitting enter submit first entry list useful combination filter mode login button found focused hit enter submit form enable automatically submit form filling option login button pressed instead password entry ha otp configuration browserpass use point display code navigating entry navigate list available credential tab shifttab arrow key copy clipboard click username password button copy clipboard keyboard shortcut also available use ctrlc copy password selected entry shiftc copy username open url click globe button use g shortcut navigate url current tab hold shift open new tab instead also specify one following metadata field pas file control exactly url navigated url link website web site keep mind browserpass fill http basic auth credential open url using browserpass manual search prevent phishing attack browserpass prefills list password entry match current domain want search credential across entire password store exit filter mode backspace domain name input field disappear type search request hit enter start search instead using backspace also type search query filter mode soon matching result left browserpass automatically switch search mode await enter initiate search password store location deciding look password store browserpass us passwordstoredir environment variable defined check passwordstore folder however using custom store location setting option browser extension configure different location browserpass look even multiple location restriction define subfolders password store gopass mount folder ha pas entry one password store configured enabled order help distinguish password entry different location eg password work personal github account green badge next password entry appear indicating origin name password store option open setting configure browserpass right click lock icon option find browserpass list extension browser option list currently available option automatically submit form filling make browserpass automatically submit login form use fuzzy search whether manual search mode fuzzy filter mode always fuzzy custom store location allows configuring multiple password store location toggle fly security browserpass aim protect password computer malicious fraudulent website protect phishing password matching origin hostname suggested selected without explicit search term minimize attack surface website allowed trigger extension action without user invocation data selected password made available website given full control nonnative component extension attacker extract password stored configured repository obtain file elsewhere filesystem reach code execution faq doe work macos native host ha exited first install required dependency brew install gnupg pinentrymac important gpg binary usrlocalbingpg gpg another location create symlink sudo ln pathtoyourgpg usrlocalbingpg dont admin right create symlink workaround patch browser launcher edit gnupggpgconf comment remove line pinentrymode loopback add line useagent add following line gnupggpgagentconf pinentryprogram usrlocalbinpinentrymac restart gpgagent gpgconf kill gpgagent finally restart browser still experience issue try starting browser terminal help issue likely due absence usrlocalbingpg follow step make sure exists configuring browserpass nixos nix nixos wish stateless setup make sure etcnixosconfigurationnix rebuild system pkgs programsbrowserpassenable true environmentsystempackages pkgs browser work chromium firefox googlechrome vivaldi note firefoxbin version work statelessly require firefox version use stateful setup following section nix stateful install browserpass native messaging host nixenv ia nixpkgsbrowserpass install browser extension like normal link necessary file firefox mkdir p mozillanativemessaginghosts ln nixprofilelibmozillanativemessaginghostscomdannyvankootenbrowserpassjson mozillanativemessaginghosts chrome mkdir p configgooglechromenativemessaginghosts ln nixprofileetcchromehostjson configgooglechromenativemessaginghostscomdannyvankootenbrowserpassjson chromium mkdir p configchromiumnativemessaginghosts ln nixprofileetcchromehostjson configchromiumnativemessaginghostscomdannyvankootenbrowserpassjson vivaldi mkdir p configvivaldinativemessaginghosts ln nixprofileetcchromehostjson configvivaldinativemessaginghostscomdannyvankootenbrowserpassjson version firefox supported way installing browserpass macos homebrew browserpass isnt included main homebrew repository must installed adding third party tap requires one additional step brew tap dustinwilsontap brew install browserpass instead running installsh homebrew supply additional command called browserpasssetup handle work way installsh example install native host file firefox browserpasssetup firefox must install browser extension manually using conventional method browser information supplied running brew install browserpass configure otp easiest way add otp password entry use passotp dont configure anything extra browserpass automatically detect otp configured show code filling form contributing check contributing detail build browser extension host app source load browserpass unpacked extension browser license mit licensed\n",
      "[0 0 0 ... 0 1 1]\n",
      "edvr ha merged basicsr github repo mirror basicsr recommend use basicsr open issue pull request etc basicsr note version compatible previous version want use previous one please refer oldversion branch basicsr english github gitee google drive pretrained model reproduced experiment training curve wandb command training testing howtos basicsr open source image video superresolution toolbox based pytorch extend restoration task future esrgan edvr dni sftgan new feature sep 8 2020 add blind face restoration inference code dfdnet note slightly different official testing code blind face restoration via deep multiscale component dictionary xiaoming li chaofeng chen shangchen zhou xianhui lin wangmeng zuo lei zhang european conference computer vision eccv 2020 aug 27 2020 add stylegan2 training testing code stylegan2 analyzing improving image quality stylegan tero karras samuli laine miika aittala janne hellsten jaakko lehtinen timo aila computer vision pattern recognition cvpr 2020 aug 19 2020 brandnew basicsr v100 online howtos provides simple pipeline traintestinference model quick start pipelinescommands cannot cover case detail following section train stylegan2 test stylegan2 test dfdnet dependency installation python 37 recommend use anaconda miniconda pytorch 13 nvidia gpu cuda please run following command basicsr root path install basicsr make sure gcc version gcc 5 pip install r requirementstxt python setuppy develop note basicsr tested ubuntu may suitable window may try window wsl cuda support available insider build fast ring todo list please see project board dataset preparation please refer datasetpreparationmd detail description currently supported datasets torchutilsdatadataset class datasetsmd train test training testing command please see traintestmd basic usage optionsconfigs please refer configmd logging please refer loggingmd model zoo baseline description currently supported model modelsmd pretrained model log example available modelzoomd also provide training curve wandb codebase design convention please see designconventionmd design convention basicsr codebase figure show overall framework description component datasetsmd modelsmd configmd loggingmd license acknowledgement project released apache 20 license detail license acknowledgement license contact question please email xintaowangoutlookcom\n",
      "[0 0 0 ... 1 0 0]\n",
      "rncasts companion repo react native course udemy\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "### TEST ###\n",
    "\n",
    "vectorizer_t = CountVectorizer(stop_words='english', \n",
    "                             #min_df=20, \n",
    "                             ngram_range=(1,2), \n",
    "                             binary=True)\n",
    "\n",
    "# Learn vocabulary in sentences. \n",
    "vectorizer_t.fit(test.text_filtered)\n",
    "\n",
    "# Get dictionary. \n",
    "vectorizer_t.get_feature_names()\n",
    "\n",
    "# Transform each sentences in vector space.\n",
    "bow_t = vectorizer_t.transform(test.text_filtered)\n",
    "\n",
    "bow_array_t = bow_t.toarray()\n",
    "\n",
    "# Show sentences and vector space representation.\n",
    "# purely to visualize what's happening.\n",
    "for i, v in zip(test.text_filtered, bow_array_t):\n",
    "    print(i)\n",
    "    print(v)\n",
    "    \n",
    "X_bow_t = bow_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<63x40 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1046 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', min_df=20, \n",
    "                             ngram_range=(1,2), \n",
    "                             binary=True)\n",
    "\n",
    "tfidf_sparse_matrix = tfidf.fit_transform(train.text_filtered)\n",
    "tfidf_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>add</th>\n",
       "      <th>build</th>\n",
       "      <th>change</th>\n",
       "      <th>check</th>\n",
       "      <th>code</th>\n",
       "      <th>create</th>\n",
       "      <th>data</th>\n",
       "      <th>dont</th>\n",
       "      <th>example</th>\n",
       "      <th>feature</th>\n",
       "      <th>...</th>\n",
       "      <th>support</th>\n",
       "      <th>time</th>\n",
       "      <th>use</th>\n",
       "      <th>used</th>\n",
       "      <th>user</th>\n",
       "      <th>using</th>\n",
       "      <th>version</th>\n",
       "      <th>want</th>\n",
       "      <th>way</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.304740</td>\n",
       "      <td>0.330968</td>\n",
       "      <td>0.324006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.228164</td>\n",
       "      <td>0.269246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.326388</td>\n",
       "      <td>0.319523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.319523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.195641</td>\n",
       "      <td>0.212479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191822</td>\n",
       "      <td>0.188137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212479</td>\n",
       "      <td>0.159754</td>\n",
       "      <td>0.208010</td>\n",
       "      <td>0.222032</td>\n",
       "      <td>0.162554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.199604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.199604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.216499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245703</td>\n",
       "      <td>0.179884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220884</td>\n",
       "      <td>0.245703</td>\n",
       "      <td>0.220884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.161337</td>\n",
       "      <td>0.175223</td>\n",
       "      <td>0.171537</td>\n",
       "      <td>0.179072</td>\n",
       "      <td>0.134052</td>\n",
       "      <td>0.158188</td>\n",
       "      <td>0.155149</td>\n",
       "      <td>0.183101</td>\n",
       "      <td>0.155149</td>\n",
       "      <td>0.168002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164606</td>\n",
       "      <td>0.175223</td>\n",
       "      <td>0.131742</td>\n",
       "      <td>0.171537</td>\n",
       "      <td>0.183101</td>\n",
       "      <td>0.134052</td>\n",
       "      <td>0.158188</td>\n",
       "      <td>0.164606</td>\n",
       "      <td>0.183101</td>\n",
       "      <td>0.164606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176163</td>\n",
       "      <td>0.207881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216315</td>\n",
       "      <td>0.230267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216315</td>\n",
       "      <td>0.240620</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         add     build    change     check      code    create      data  \\\n",
       "0   0.304740  0.330968  0.324006  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.298240  0.000000  0.000000  0.228164  0.269246  0.000000   \n",
       "2   0.000000  0.352642  0.000000  0.000000  0.269784  0.000000  0.000000   \n",
       "3   0.000000  0.326388  0.319523  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "58  0.195641  0.212479  0.000000  0.000000  0.000000  0.191822  0.188137   \n",
       "59  0.216499  0.000000  0.000000  0.240297  0.000000  0.000000  0.000000   \n",
       "60  0.161337  0.175223  0.171537  0.179072  0.134052  0.158188  0.155149   \n",
       "61  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.412894   \n",
       "62  0.000000  0.230267  0.000000  0.000000  0.176163  0.207881  0.000000   \n",
       "\n",
       "        dont   example   feature  ...   support      time       use      used  \\\n",
       "0   0.345848  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.224234  0.000000   \n",
       "2   0.000000  0.312243  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.312938  ...  0.000000  0.000000  0.000000  0.319523   \n",
       "4   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "58  0.000000  0.188137  0.000000  ...  0.000000  0.212479  0.159754  0.208010   \n",
       "59  0.245703  0.000000  0.000000  ...  0.000000  0.000000  0.176785  0.000000   \n",
       "60  0.183101  0.155149  0.168002  ...  0.164606  0.175223  0.131742  0.171537   \n",
       "61  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.456507   \n",
       "62  0.000000  0.000000  0.000000  ...  0.216315  0.230267  0.000000  0.000000   \n",
       "\n",
       "        user     using   version      want       way      work  \n",
       "0   0.000000  0.000000  0.000000  0.310913  0.000000  0.000000  \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "58  0.222032  0.162554  0.000000  0.199604  0.000000  0.199604  \n",
       "59  0.245703  0.179884  0.000000  0.220884  0.245703  0.220884  \n",
       "60  0.183101  0.134052  0.158188  0.164606  0.183101  0.164606  \n",
       "61  0.000000  0.000000  0.420981  0.000000  0.000000  0.000000  \n",
       "62  0.000000  0.176163  0.000000  0.216315  0.240620  0.000000  \n",
       "\n",
       "[63 rows x 40 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_sparse_matrix.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repo': 24,\n",
       " 'source': 29,\n",
       " 'want': 37,\n",
       " 'run': 27,\n",
       " 'dont': 7,\n",
       " 'file': 10,\n",
       " 'build': 1,\n",
       " 'install': 13,\n",
       " 'add': 0,\n",
       " 'change': 2,\n",
       " 'following': 11,\n",
       " 'create': 5,\n",
       " 'issue': 14,\n",
       " 'project': 23,\n",
       " 'code': 4,\n",
       " 'use': 32,\n",
       " 'open': 22,\n",
       " 'license': 16,\n",
       " 'example': 8,\n",
       " 'request': 26,\n",
       " 'used': 33,\n",
       " 'library': 15,\n",
       " 'feature': 9,\n",
       " 'ha': 12,\n",
       " 'data': 6,\n",
       " 'version': 36,\n",
       " 'using': 35,\n",
       " 'make': 18,\n",
       " 'new': 20,\n",
       " 'set': 28,\n",
       " 'user': 34,\n",
       " 'time': 31,\n",
       " 'support': 30,\n",
       " 'work': 39,\n",
       " 'repository': 25,\n",
       " 'need': 19,\n",
       " 'note': 21,\n",
       " 'like': 17,\n",
       " 'way': 38,\n",
       " 'check': 3}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get vocabularies.\n",
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30474012, 0.33096751, 0.32400599, ..., 0.31091334, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.29824005, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.35264182, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.16133726, 0.17522272, 0.17153711, ..., 0.16460552, 0.18310075,\n",
       "        0.16460552],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.23026728, 0.        , ..., 0.2163148 , 0.24062012,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform to document-term matrix\n",
    "vector_spaces = tfidf.transform(train.text_filtered)\n",
    "vector_spaces.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight agnostic neural network repo contains source article want view page locally run python httpserver serve base directory view indexhtml local browser article draftmd main text article markdown draftappendixmd appendix markdown draftbibhtml citation draftheaderhtml start document indexhtml generated dont edit file instruction build test git clone httpsgithubcomweightagnosticweightagnosticgithubiogit cd weightagnosticgithubio npm install modify text editing draftmd content exists appendix content go draftappendixmd add bib entry draftbibhtml run binmake build document indexhtml identical run python httpserver serve base directory view indexhtml local browser debugging watch markdown file change compile run following brew install fswatch binwatch\n",
      "  (0, 37)\t0.3109133380966274\n",
      "  (0, 29)\t0.30474011923479\n",
      "  (0, 27)\t0.2670331602997981\n",
      "  (0, 24)\t0.23246914476455824\n",
      "  (0, 13)\t0.25320203347652864\n",
      "  (0, 11)\t0.3382385226275715\n",
      "  (0, 10)\t0.2821427460570418\n",
      "  (0, 7)\t0.3458478427718165\n",
      "  (0, 2)\t0.32400599465720087\n",
      "  (0, 1)\t0.33096750846815787\n",
      "  (0, 0)\t0.30474011923479\n",
      "github button showcase github repos success static button featuring link github repo profile page uptodate watch fork sponsor follower count get started checkout httpsghbtnscom bug tracker bug please create issue github httpsgithubcommdogithubbuttonsissues development clone project install dependency getting started github button require nodejs ruby bundler local development npm bundle github button source code split across three file srcthe html cs j use inlinesourcecli htmlminifer include compiled docsgithubbtnhtml file build file npm run build httpsghbtnscom site built jekyll installing dependency run local server bundle exec jekyll serve open http1270014000 browse locally see also ntkmegithubbuttons twitter account keep date announcement following mark twitter mdo author mark otto httpstwittercommdo httpsgithubcommdo copyright license copyright 20142020 mark otto released apache 20 license\n",
      "  (0, 32)\t0.22423354774123355\n",
      "  (0, 29)\t0.2746061314090817\n",
      "  (0, 27)\t0.2406277955524843\n",
      "  (0, 24)\t0.20948161560109163\n",
      "  (0, 23)\t0.24956364089548502\n",
      "  (0, 22)\t0.311648949925667\n",
      "  (0, 16)\t0.311648949925667\n",
      "  (0, 14)\t0.30479207143946285\n",
      "  (0, 13)\t0.2281643488638646\n",
      "  (0, 11)\t0.30479207143946285\n",
      "  (0, 10)\t0.2542432817654882\n",
      "  (0, 5)\t0.26924567497960966\n",
      "  (0, 4)\t0.2281643488638646\n",
      "  (0, 1)\t0.29824004581595487\n",
      "webpack cs example example repo showing automatically generate cs bundle explicitly required sas source webpack read blog post running yarn install npm install yarn run build npm run build take look generated cs build contributing please adhere existing code style javascript doesnt comply standard cause build fail issue pull request code contribution must comply contributor code conduct license webpack cs example released mit license\n",
      "  (0, 29)\t0.32469686111878604\n",
      "  (0, 27)\t0.28452055863760917\n",
      "  (0, 26)\t0.3452244151936163\n",
      "  (0, 24)\t0.24769302381832067\n",
      "  (0, 16)\t0.36849663659215454\n",
      "  (0, 14)\t0.3603889992640326\n",
      "  (0, 13)\t0.26978366256849867\n",
      "  (0, 8)\t0.31224279471524846\n",
      "  (0, 4)\t0.26978366256849867\n",
      "  (0, 1)\t0.35264182281532586\n",
      "ionicsite repo ionicframeworkcom site preview local ionic change follow instruction ionic repo doc ionic doc separate repo site primarily used general communication promotion ionic framework related product service local build run npm install run npm start first run step needed third party library 3rd part library concatenated site bundle adding via packagejson specifying file include assets3rdpartylibsjson file deploy change master automatically deployed stagingionicframeworkcom periodically ionic tean inspect staging promote ionicframeworkcom community follow ionicframework twitter subscribe ionic newsletter question thats feature request bug report discus ionic forum read blog feature request find bug submit issue see problem documentation submit issue see typo browser bug nondocs page submit issue\n",
      "  (0, 33)\t0.31952304679152677\n",
      "  (0, 27)\t0.2633384887326973\n",
      "  (0, 26)\t0.31952304679152677\n",
      "  (0, 24)\t0.22925270101492962\n",
      "  (0, 15)\t0.34106269103336717\n",
      "  (0, 14)\t0.3335586534643287\n",
      "  (0, 13)\t0.24969872941958096\n",
      "  (0, 10)\t0.2782390182183331\n",
      "  (0, 9)\t0.3129381440062983\n",
      "  (0, 2)\t0.31952304679152677\n",
      "  (0, 1)\t0.3263882410775512\n",
      "ironpython development ha moved httpsgithubcomironlanguagesironpython2\n",
      "  (0, 12)\t1.0\n",
      "python code data science code nlp deep learning reinforcement learning artificial intelligence welcome github repo data scientist code r python wolfram mathematica find machine learning deep learning natural language processing artificial intelligence model developed output model seen portfolio httpsdrivegooglecomfiled0b0rlknml54khdjrqwvbketvxshmviewuspsharing kera version used model keras110 autoencoder audio model compressed audio file used autoencoder reconstruct audio file use phoneme classification collaborative filtering recommender system algorithm predicts movie review based genre movie similarity among people watched movie convolutional nn lasagne convolutional neural network model lasagne solve mnist task ensembled machine learning py file 7 machine learning algorithm used classification task 3 class possible hyperparameters algorithm adjusted iris dataset scikitlearn gan generative adversarial model generative adversarial neural network hyperparameter tuning rl model hyperparameters neural network adjusted via reinforcement learning according reward hyperparameter tuning environment changed policy mechanization knowledge using boston dataset hyperparameters tuned learning rate epoch decay momentum number hidden layer node initial weight kera regularization l2 neural network model regression made kera l2 regularization wa applied prevent overfitting lasagne neural net regression neural network model based theano lasagne make linear regression continuous target variable reach 994 accuracy us dadosteselogitcsv sample file lasagne neural net weight neural network model based theano lasagne possible visualize weight x1 x2 hidden layer also adapted visualize weight hidden layer output us dadosteselogitcsv sample file multinomial regression regression model target variable ha 3 class neural network regression show multiple solution regression problem solved sklearn kera theano lasagne us boston dataset sample file sklearn reach 98 accuracy nlp naive bayes classifier model movie review labeled positive negative algorithm classifies totally new set review using logistic regression decision tree naive bayes reaching accuracy 92 nlp anger analysis doc2vec model associated word2vec model analyze level anger using synonym consumer complaint u retailer facebook post nlp consumer complaint model facebook post u computer retailer scraped tokenized lemmatized applied word2vec tsne latent dirichlet allocation developed order classify argument weight keyword used consumer complaint code also analyzes frequency word 100 post nlp convolutional neural network convolutional neural network text order classify movie review nlp doc2vec natural language procesing file cosine similarity among phrase measured doc2vec nlp document classification code document classification according latent dirichlet allocation nlp facebook analysis analyzes facebook post regarding word frequency topic modelling using lda nlp facebook scrap python code scraping data facebook nlp latent dirichlet allocation natural language processing model wikipedia page statistical inference classified regarding topic using latent dirichlet allocation gensim nltk tsne kmeans nlp probabilistic ann natural language processing model sentence vectorized gensim probabilistic neural network model deveoped using gensim sentiment analysis nlp semantic doc2vec neural network model positive negative movie review extracted semantically classified nltk beautifulsoup labeled positive negative text wa used input neural network model training training new sentence entered kera neural network model classified us zip file nlp sentiment positive model identifies website content positive neutral negative using beautifulsoup nltk library plotting result nlp twitter analysis id model extract post twitter based id user hashtag nlp twitter scrap model scrap twitter data show cleaned text output nlp twitter streaming model analysis realtime data twitter development nlp twitter streaming mood model evolution mood twitter post measured period time nlp wikipedia summarization python code summarizes given page sentence nlp word frequency model calculates frequency noun verb word facebook post probabilistic neural network probabilistic neural network time series prediction realtime twitter analysis model twitter streaming extracted word sentence tokenized word embeddings created topic modeling wa made classified using kmeans nltk sentimentanalyzer wa used classify sentence streaming positive neutral negative accumulated sum wa used generate plot code loop 1 second collecting new tweet resnet2 deep residual neural network roc curve multiclass py file naive bayes wa used solve iris dataset task roc curve different class plotted squeezenet simplified version alexnet stacked machine learning py notebook tsne principal component analysis factor analysis applied reduce dimensionality data classification performance measured applying kmeans support vector regression svm model non linear regression artificial dataset texttospeech py file python speaks given text save audio wav file time series arima arima model forecast time series error margin 02 time series prediction neural network kera neural network model forecast time series using kera adaptive learning rate depending upon derivative loss variational autoencoder vae made kera web crawler code scrap data different url hotel website tsne dimensionality reduction tsne model dimensionality reduction compared principal component analysis regarding discriminatory power tsne pca neural network model compare performance neural network made tsne pca kmeans tsne pca lda embeddings model tsne principal component analysis linear discriminant analysis random forest embeddings compared task classify cluster similar digit\n",
      "  (0, 36)\t0.25171860336910157\n",
      "  (0, 35)\t0.21331154618911505\n",
      "  (0, 34)\t0.2913615545455909\n",
      "  (0, 33)\t0.2729607608039863\n",
      "  (0, 32)\t0.2096366282214065\n",
      "  (0, 31)\t0.27882552916482084\n",
      "  (0, 30)\t0.26193077507949225\n",
      "  (0, 28)\t0.26193077507949225\n",
      "  (0, 24)\t0.19584500183560288\n",
      "  (0, 20)\t0.24221129895985152\n",
      "  (0, 18)\t0.23769282016074095\n",
      "  (0, 15)\t0.2913615545455909\n",
      "  (0, 12)\t0.2673354386492155\n",
      "  (0, 10)\t0.23769282016074095\n",
      "  (0, 6)\t0.2468829753922143\n",
      "  (0, 4)\t0.21331154618911505\n",
      "gitbanner generates git repo show cool banner github profile gitbanner work creating new git repository filling dummy commits date set correspond pixel github contribution graph see example iamtrasks profile httpsgithubcomiamtrask installing first might need install dependency nodecanvas cairo nodegit set npm install g gitbanner usage 1 generate repo gitbanner github email text notice gitbanner need email associated github account otherwise github wont think made commits see preview banner doesnt look great try using different font gitbanner f 7pt arial email text 2 create repo github 3 push repo github cd banner git push f gitgithubcomusernamereponamegit master note ever feel like removing banner profile simply delete repository github instantly update contribution graph want specify longer banner width gitbanner w x width longer 52 cut github banner slowly revealed week go\n",
      "  (0, 39)\t0.2944923345090841\n",
      "  (0, 37)\t0.2944923345090841\n",
      "  (0, 35)\t0.23982907390668493\n",
      "  (0, 28)\t0.2944923345090841\n",
      "  (0, 25)\t0.31348733641382537\n",
      "  (0, 24)\t0.2201912004230853\n",
      "  (0, 21)\t0.28864515649739964\n",
      "  (0, 20)\t0.27232145918522527\n",
      "  (0, 19)\t0.28864515649739964\n",
      "  (0, 17)\t0.28301065089826033\n",
      "  (0, 13)\t0.23982907390668493\n",
      "  (0, 8)\t0.27757388856554555\n",
      "  (0, 5)\t0.28301065089826033\n",
      "heroku repo plugin plugin add command heroku gem interact apps repo installation install heroku pluginsinstall herokurepo command clone heroku repoclone appname clone application repo local filesystem collaboration necessary download heroku repodownload appname download application repo tarball gc heroku repogc appname run git gc aggressive application repo done inside run process application purgecache heroku repopurgecache appname delete content build cache stored repository done inside run process application reset heroku reporeset appname empty remote repository\n",
      "  (0, 27)\t0.3771122931836908\n",
      "  (0, 25)\t0.4674023104381242\n",
      "  (0, 24)\t0.32829994663655343\n",
      "  (0, 13)\t0.35757955819384263\n",
      "  (0, 1)\t0.4674023104381242\n",
      "  (0, 0)\t0.43036319931457556\n",
      "deeplift deep learning important feature version deeplift ha tested kera 224 tensorflow 1140 see faq question information implementation deeplift may work different version tensorflowpytorch well wider range architecture see tag older version repository implement method learning important feature propagating activation difference shrikumar greenside kundaje well commonlyused method gradient gradienttimesinput equivalent version layerwise relevance propagation relu network guided backprop integrated gradient link slide video 15minute talk given icml link longer series video tutorial please see faq file github issue question note running deeplift certain computer vision task may get better result compute contribution score higher convolutional layer rather input pixel use argument findscoreslayeridx specify layer compute score please aware figuring optimal reference still open problem suggestion good heuristic different application welcome meantime feel free look github issue general idea httpsgithubcomkundajelabdeepliftissues104 please feel free follow repository stay abreast update table content installation quickstart example faq provide brief intuition deeplift work model architecture supported deeplift implementation similarity difference deepliftlike implementation deepexplain ancona et al iclr 2018 deepshapdeepexplainer shap repository doe deeplift compare integrated gradient doe implementation repository compare deeplift implementation poerner et al acl 2018 support nonkeras model negative score mean provide reference argument use reference get sense much input contributes across example multiple input mode get contribution score multiple input layer whats license heard deeplift pattern discovery right contact hood layer forward pas backward pas installation deeplift pypi installed using pip pip install deeplift want able make edits code recommended clone repository install using editable flag git clone httpsgithubcomkundajelabdeepliftgit clone deeplift repository pip install editable deeplift install deeplift cloned repository editable flag mean change code picked automatically deeplift doe require model trained particular library provided autoconversion function convert model trained using kera deeplift format used different library train model still use deeplift recreate model using deeplift layer implementation deeplift wa tested tensorflow 17 autoconversion wa tested using kera 20 quickstart example show autoconvert kera model obtain importance score nonkeras model converted deeplift saved kera 20 format convert kera sequential model import deeplift deepliftconversion import kerasapiconversion kc nonlinearmxtsmode defines method computing importance score nonlinearmxtsmodedeepliftgenomicsdefault us revealcancel rule dense layer rescale rule conv layer see paper rationale supported value nonlinearmxtsmoderevealcancel deepliftrevealcancel layer used mnist example nonlinearmxtsmoderescale deepliftrescale layer nonlinearmxtsmodegradient multiplier gradient nonlinearmxtsmodeguidedbackprop multiplier get guided backprop use deepliftutilgetintegratedgradientsfunction compute integrated gradient feel free email avanti dot shrikumargmailcom anything unclear deepliftmodel kcconvertmodelfromsavedfiles savedhdf5filepath nonlinearmxtsmodedeepliftlayersnonlinearmxtsmodedeepliftgenomicsdefault specify index layer compute importance score example find score input layer idx 0 deepliftmodelgetlayers findscoreslayeridx 0 compile function computes contribution score sigmoid softmax output targetlayeridx 2 default computes explanation wrt logits see 36 choice target layer httpsarxivorgabs170402685 justification regression task linear output targetlayeridx 1 simply refers last layer note case softmax output may good idea normalize softmax logits sum zero across task ensures feature contributing equally softmax logits effectly seen contributing none task adding constant logits softmax doe change output discussed httpsgithubcomkundajelabdeepliftissues116 one way efficiently acheive normalization meannormalize weight going softmax layer discussed eqn 21 section 25 httpsarxivorgpdf160501713pdf note softmax activation want deeplift multiplier instead contribution score use gettargetmultipliersfunc deepliftcontribsfunc deepliftmodelgettargetcontribsfunc findscoreslayeridxfindscoreslayeridx targetlayeridx1 also provide array index findscoreslayeridx get score multiple layer compute score input inputdatalist list containing data different input layer eg mnist one input layer dimension 1 x 28 x 28 example let x array dimension n x 1 x 28 x 28 n number example taskidx represents index node output layer wish compute score eg output 10way softmax taskidx 0 compute score first softmax class score nparraydeepliftcontribsfunctaskidx0 inputdatalistx batchsize10 progressupdate1000 work sequential model involving dense andor conv1dconv2d layer linearrelusigmoidsoftmax prelu activation please create github issue email avanti dot shrikumargmailcom readme interested support layer type syntax using functional model similar use deepliftmodelgetnametolayerkeys get list layer name figuring specify findscoreslayername preactivationtargetlayername deepliftmodel kcconvertmodelfromsavedfiles savedhdf5filepath nonlinearmxtsmodedeepliftlayersnonlinearmxtsmodedeepliftgenomicsdefault syntax obtaining score similar converted graph model see deepliftmodelgetnametolayerkeys see layer name provide array name findscoreslayername get score multiple layer deepliftcontribsfunc deepliftmodelgettargetcontribsfunc findscoreslayernamenameofinputlayer preactivationtargetlayernamenamegoeshere example notebook replicating result paper mnist examplesmnistmnistreplicatefiguresipynb notebook demonstrating use genomics model 1d convolution examplesgenomicsgenomicssimulationipynb faq provide brief intuition deeplift work 15minute talk icml give intuition method link slide video video truncates slide slide linked separately please file github issue question model architecture supported deeplift implementation first suggestion would look deepshapdeepexplainer lundberg lee deepexplain ancona et al captum using pytorch see satisfy need implemented overriding gradient operator thus support wider variety architecture however none implementation support revealcancel rule deal failure mode min function pro con deepshap v deepexplain discussed detail would really like revealcancel rule go ahead post github issue although energy currently focused project may able get time similarity difference deepliftlike implementation deepexplain ancona et al iclr 2018 deepshapdeepexplainer shap repository deepexplain ancona et al deepshapdeepexplainer work overriding gradient operator thus support wider variety architecture covered deeplift repo fact deepshapdeepexplainer implementation wa inspired ancona et al work build connection deeplift shap described shap paper set architecture described deeplift paper ie linear matrix multiplication convolution singleinput nonlinearities like relus implementation identical deeplift rescale rule however neither implementation support deeplift revealcancel rule rule wa developed deal failure case min function unfortunately easily implemented overriding gradient operator key difference follows 1 deepexplain us standard gradient backpropagation elementwise operation present lstmsgrusattention likely violate summationtodelta property ie property sum attribution input equal differencefromreference output elementwise operation recommend use deepshapdeepexplainer employ summationtodeltapreserving backprop rule technically true maxpooling operation nonuniform reference used though ha salient problem u practice deepshapdeepexplainer implementation guarantee summationtodelta satisfied maxpooling assigning creditblame either neuron max actual input neuron wa max reference different max attribution rule proposed shap paper attribution rule doe scale well 2 deepexplain ancona et al doe support dynamic reference demonstrated deeplift repo ie case different reference generated according property input example dinucleotide shuffled reference used genomics ive implemented dynamic reference feature deepshapdeepexplainer associated example notebook warning process generating dinucleotide shuffled sequence many application bottleneck running interpretation getting poor gpu usage may get around may good idea cache pregenerated shuffled sequence particular gc content retrieve example cache according gc content input sequence 3 deepshapdeepexplainer implemented multiple reference used single example final attribution averaged reference however way implemented gpu batch calculates attribution single example reference mean deepshapdeepexplainer implementation might slow case large number sample one reference contrast deepexplain ancona et al structured user provides single reference reference used example thus deepexplain ancona et al allows gpu batching across example doe allow gpu batching across different reference summary recommendation use deepshap elementwise operation eg gruslstmsattention need dynamic reference large number reference compared sample use deepexplain large number sample compared reference doe implementation repository compare deeplift implementation poerner et al acl 2018 poerner et al conducted series benchmark comparing deeplift explanation method nlp task implementation differs canonical deeplift implementation two main way first considered rescale rule deeplift according implementation second handle operation involve multiplication gating unit deeplift wa designed treat gating neuron weight similar approach arras et al assign importance nongating neuron note differs implementation deepshapdeepexplainer handle elementwise multiplication using backprop rule base shap would assign importance gating neuron studied appropriateness arras et al approach author find limsse lrp bach et al 2015 deeplift shrikumar et al 2017 effective explanation method 4 lrp deeplift consistent method limsse win hybrid document experiment compare deepshapdeepexplainer implementation doe deeplift compare integrated gradient illustrated deeplift paper revealcancel rule deeplift allow deeplift properly handle case integrated gradient may give misleading result independent researcher found deeplift rescale rule performs comparably integrated gradient write integrated gradient deeplift high correlation suggesting latter good faster approximation former practice finding wa consistent personal experience speed improvement deeplift relative integrated gradient becomes particularly useful using collection reference since collection reference per example increase runtime support nonkeras model moment however able convert model saved file format used kera 2 api use branch load deeplift format inspiration achieve look examplesconvertmodelskeras12to2 notebook demonstrating convert model saved keras12 format kera 2 deeplift conversion work directly kera saved file without ever actually loading model kera pytorch model may also interested captum implementation negative score mean negative contribution score input mean input contributed moving output reference value reference value output value ha provided reference input negative contribution doe mean input unimportant want find input deeplift considers unimportant ie deeplift think dont influence output model much would input contribution score near 0 provide reference argument supply inputdatalist argument scoring function also supply inputreferenceslist would dimension inputdatalist would contain reference image input use reference choice reference depends question wish ask data generally speaking reference retain property dont care scramble property care supplement deeplift paper appendix l look result cifar10 model two different choice reference youll notice blurred version input used reference outline object stand black reference used result confusing possibly net also highlighting color particular reference mind good idea check output model reference consistent expect another idea consider using multiple different reference interpret single image averaging result different reference use approach genomics generate collection reference per input sequence shuffling sequence demonstrated genomics example notebook get sense much input contributes across example fine average deeplift contribution score across example aware might considerable heterogeneity data ie input may important subset example others input may contribute positively example negatively others clustering may prove insightful averaging purpose feature selection reasonable heuristic would rank input descending order average magnitude deeplift contribution score multiple input mode yes rather providing single numpy array inputdatalist provide list numpy array containing input mode also provide dictionary inputdatalist key mode name value numpy array numpy array first axis sample axis get contribution score multiple input layer also yes provide list findscoreslayername rather single argument whats license mit license originally filed patent interpretability work since disbanded patent appears project ha enough interest community best distributed opensource format heard deeplift pattern discovery right likely thinking tfmodisco link code contact please email avanti dot shrikumar gmailcom question idea feature request etc dont respond keep emailing feel guilty respond also feel free email adviser anshul kundaje dot net guilt responding promise actually want respond im busy thing incentive structure academia doesnt reward maintenance project hood section explains finer aspect deeplift implementation layer layer deepliftlayerscorelayer basic unit deepliftlayerscoredense deepliftlayersconvolutionconv2d example layer layer implement following key method getactivationvars return symbolic variable representing activation layer understanding symbolic variable refer documentation symbolic computation package like theano tensorflow getposmxts getnegmxts return symbolic variable representing positivenegative multiplier layer selected output see paper detail gettargetcontribvars return symbolic variable representing importance score convenience function return selfgetposmxtsselfposcontribs selfgetnegmxtsselfnegcontribs see paper detail forward pas step necessary implement forward pas executed correctly result identical within numerical precision forward pas original model definitely worth sanity check note autoconversion described quickstart option skip step 1 2 create layer object every layer network tell layer input via setinputs function argument setinputs depends layer expects layer ha single layer input eg dense layer argument simply layer input layer take multiple layer input argument depends specific implementation example case concat layer argument list layer every layer linked input may compile forward propagation function deepliftbackendfunctioninputlayergetactivationvars outputlayergetactivationvars working model produced autoconversion access individual layer via modelgetlayers sequential model function would return list layer modelgetnametolayer graph model function would return dictionary mapping layer name layer first argument list symbolic tensor representing input net net ha one input layer list containing one tensor second argument output function example single tensor also list tensor want output one layer function compiled use deepliftutilrunfunctioninbatchesfunc inputdatalist run function batch would advisable want call function large number input wont fit memory func simply compiled function returned deepliftbackendfunction inputdatalist list numpy array containing data different input layer network case network one input list containing one numpy array optional argument runfunctioninbatches batchsize progressupdate backward pas step necessary implement backward pas importance score calculated ideally create model autoconversion described quickstart use modelgettargetcontribsfunc modelgettargetmultipliersfunc howver option read please also consider sending u message let u know enough demand feature consider adding note instruction assume done step 1 2 forward pas section layer wish compute importance score call resetmxtsupdated reset symbolic variable computing multiplier first time compiling backward pas step strictly necessary output layer containing neuron importance score calculated respect call setscoringmodedeepliftlayersscoringmodeoneandzeros briefly scoring mode used want find score respect single target neuron kind scoring mode may added later eg difference neuron point clarification eventually compile function function computes score single output neuron single layer every time called specific neuron layer toggled later runtime right step call setscoringmode target layer might conceivably want find score respect save recompile function allow different target layer later sigmoidsoftmax output layer output layer use linear layer usually dense layer come final nonlinear activation see 36 choice target layer paper justification final nonlinearity eg case many regression task output layer last linear layer softmax output may want subtract average contribution softmax class described adjustment softmax layer paper section 36 number softmax class large dont want calculate contribution class separately example contact avanti dot shrikumargmailcom implement efficient way calculation way havent coded yet layer wish compute importance score call updatemxts create symbolic variable compute multiplier respect layer specified step 2 compile importance score computation function deepliftbackendfunctioninputlayergetactivationvars inputlayergetreferencevars layertofindscoresforgettargetcontribvars first argument represents input function list one symbolic tensor activation input layer forward pas followed list one symbolic tensor reference input layer second argument represents output function example single tensor containing importance score single layer also list tensor wish compute score multiple layer instead gettargetcontribvars return importance score case nonlinearmxtsmodedeeplift called contribution score use getposmxts getnegmxts get multiplier ready call function find importance score select specific output layer compute importance score respect calling setactive layer select specific target neuron within layer calling updatetaskindextaskidx layer taskidx index neuron within layer call function compiled step 4 find importance score target neuron refer step 4 forward pas section tip using deepliftutilrunfunctioninbatches deselect output layer calling setinactive layer dont forget yes bundle single function point\n",
      "  (0, 39)\t0.16540433164034182\n",
      "  (0, 38)\t0.1839893123695707\n",
      "  (0, 37)\t0.16540433164034182\n",
      "  (0, 36)\t0.15895553830614526\n",
      "  (0, 35)\t0.13470220793211754\n",
      "  (0, 34)\t0.1839893123695707\n",
      "  (0, 33)\t0.17236955906048276\n",
      "  (0, 32)\t0.1323815667241593\n",
      "  (0, 31)\t0.17607304938404197\n",
      "  (0, 30)\t0.16540433164034182\n",
      "  (0, 28)\t0.16540433164034182\n",
      "  (0, 27)\t0.14206029781671653\n",
      "  (0, 26)\t0.17236955906048276\n",
      "  (0, 25)\t0.17607304938404197\n",
      "  (0, 24)\t0.12367241544598345\n",
      "  (0, 23)\t0.14733578499705735\n",
      "  (0, 22)\t0.1839893123695707\n",
      "  (0, 21)\t0.1621202102637464\n",
      "  (0, 19)\t0.1621202102637464\n",
      "  (0, 18)\t0.15009852142217217\n",
      "  (0, 17)\t0.15895553830614526\n",
      "  (0, 16)\t0.1839893123695707\n",
      "  (0, 15)\t0.1839893123695707\n",
      "  (0, 14)\t0.1799411923358619\n",
      "  (0, 13)\t0.13470220793211754\n",
      "  (0, 12)\t0.16881727448838887\n",
      "  (0, 11)\t0.1799411923358619\n",
      "  (0, 10)\t0.15009852142217217\n",
      "  (0, 9)\t0.16881727448838887\n",
      "  (0, 8)\t0.155901930675138\n",
      "  (0, 7)\t0.1839893123695707\n",
      "  (0, 6)\t0.155901930675138\n",
      "  (0, 5)\t0.15895553830614526\n",
      "  (0, 4)\t0.13470220793211754\n",
      "  (0, 3)\t0.1799411923358619\n",
      "  (0, 2)\t0.17236955906048276\n",
      "  (0, 1)\t0.17607304938404197\n",
      "headset attention headset longer us shared youtube api key please create key following quick guide make sure running latest version headset simple music player mac window linux integrated youtube search home screen popularity list genre era best radio powered reddit headset take song shared 80 music subreddits categorizes play automatically great pretty unique way find new music chosen human like algorithm question join slack workspace httpstinyurlcomy7m8y5x4 want start contributing check contributing doc installation macos homebrew update homebrew install headset using hombrew cask brew update brew cask install headset window chocolatey install run following command command line powershell c choco install headset upgrade run following command command line powershell c choco upgrade headset detail chocolatey page httpschocolateyorgpackagesheadset linux alternative deb rpm package website also install directly commandline debian wget q httpheadsetappcoheadsetelectrondebianheadsetasc sudo aptkey add echo deb archamd64 httpheadsetappcoheadsetelectrondebian stable nonfree sudo tee etcaptsourceslistdheadsetlist sudo aptget update sudo aptget install headset redhat sudo dnf configmanager addrepo httpheadsetappcoheadsetelectronredhatheadsetrepo sudo dnf install headset sudo yumconfigmanager addrepo httpheadsetappcoheadsetelectronredhatheadsetrepo sudo yum install headset build source would like create build different environment eg manjaro aur etc please follow step install nodejs 8 later clone repo git clone httpsgithubcomheadsetappheadsetelectrongit install dependency cd headsetelectron npm ci create build electronpackager executablename headset ignore binsigghpagesplayertestprocfilemd prune true build overwrite asar platformlinux archx64 optional ubuntu build using electroninstallerdebian fedora build using electroninstallerredhat might installer specific version google contributor app design helene giraud wwwgirographecom\n",
      "  (0, 38)\t0.2898185597965184\n",
      "  (0, 37)\t0.2605436400774207\n",
      "  (0, 36)\t0.25038555006408286\n",
      "  (0, 35)\t0.21218188927127057\n",
      "  (0, 29)\t0.2553705171644441\n",
      "  (0, 27)\t0.22377229626689177\n",
      "  (0, 24)\t0.19480784437694046\n",
      "  (0, 20)\t0.24092859451024093\n",
      "  (0, 18)\t0.23643404470571477\n",
      "  (0, 17)\t0.25038555006408286\n",
      "  (0, 13)\t0.21218188927127057\n",
      "  (0, 11)\t0.28344199203318915\n",
      "  (0, 5)\t0.25038555006408286\n",
      "  (0, 3)\t0.28344199203318915\n",
      "  (0, 1)\t0.27734892279484297\n",
      "  (0, 0)\t0.2553705171644441\n",
      "sqlalchemy python sql toolkit object relational mapper introduction sqlalchemy python sql toolkit object relational mapper give application developer full power flexibility sql sqlalchemy provides full suite well known enterpriselevel persistence pattern designed efficient highperforming database access adapted simple pythonic domain language major sqlalchemy feature include industrial strength orm built core identity map unit work data mapper pattern pattern allow transparent persistence object using declarative configuration system domain model constructed manipulated naturally change synchronized current transaction automatically relationallyoriented query system exposing full range sqls capability explicitly including join subqueries correlation everything else term object model writing query orm us technique relational composition use writing sql drop literal sql time virtually never needed comprehensive flexible system eager loading related collection object collection cached within session loaded individual access using join query per collection across full result set core sql construction system dbapi interaction layer sqlalchemy core separate orm full database abstraction layer right includes extensible pythonbased sql expression language schema metadata connection pooling type coercion custom type primary foreign key constraint assumed composite natural surrogate integer primary key course still norm sqlalchemy never assumes hardcodes model database introspection generation database schema reflected one step python structure representing database metadata structure generate create statement right back within core independent orm sqlalchemys philosophy sql database behave le le like object collection size performance start matter object collection behave le le like table row abstraction start matter sqlalchemy aim accommodate principle orm doesnt need hide r relational database provides rich setbased functionality fully exposed sqlalchemys orm provides openended set pattern allow developer construct custom mediation layer domain model relational schema turning socalled object relational impedance issue distant memory developer case make decision regarding design structure naming convention object model well relational schema sqlalchemy provides mean automate execution decision sqlalchemy thing orm generated bad query retain full control structure query including join organized subqueries correlation used column requested everything sqlalchemy doe ultimately result developer initiated decision dont use orm problem doesnt need one sqlalchemy consists core separate orm component core offer full sql expression language allows pythonic construction sql construct render directly sql string target database returning result set essentially enhanced dbapi cursor transaction norm sqlalchemys orm nothing go permanent storage commit called sqlalchemy encourages application create consistent mean delineating start end series operation never render literal value sql statement bound parameter used greatest degree possible allowing query optimizers cache query plan effectively making sql injection attack nonissue documentation latest documentation httpwwwsqlalchemyorgdocs installation requirement full documentation installation installation getting help development bug reporting please refer sqlalchemy community guide code conduct sqlalchemy place great emphasis polite thoughtful constructive communication user developer please see current code conduct code conduct license sqlalchemy distributed mit license\n",
      "  (0, 39)\t0.23749657976255525\n",
      "  (0, 35)\t0.1934127924769525\n",
      "  (0, 34)\t0.26418191088037907\n",
      "  (0, 33)\t0.247497633986146\n",
      "  (0, 32)\t0.1900806889928397\n",
      "  (0, 31)\t0.25281530781189304\n",
      "  (0, 28)\t0.23749657976255525\n",
      "  (0, 19)\t0.23278105879202543\n",
      "  (0, 18)\t0.21551966089192834\n",
      "  (0, 17)\t0.22823704982595414\n",
      "  (0, 16)\t0.26418191088037907\n",
      "  (0, 14)\t0.25836939888060484\n",
      "  (0, 9)\t0.24239706964270397\n",
      "  (0, 7)\t0.26418191088037907\n",
      "  (0, 6)\t0.22385251309037457\n",
      "  (0, 5)\t0.22823704982595414\n",
      "  (0, 4)\t0.1934127924769525\n",
      "  (0, 2)\t0.247497633986146\n",
      "inconsolata opensource monospace font code listing originally raphlinus ligature inconsolata includes ligature javascript operator available two family inconsolata expose ligature dlig disabled default probably wont show editor enable cs rule fontvariantligatures discretionaryligatures ligconsolata expose ligature liga enabled default family use text editor note ligconsolata variant ha yet upgraded version 3000 prioritizing nonligature variant building family family built using glyph fontmake gftools post processing script tool python based install python tool virtualenv following python3 venv venv source venvbinactivate pip install r requirementstxt build font must load sourcesinconsolatavfglyphs glyph following run decomposetransformedcomponentspy script run geninstancespy script run incofixpy script save file back source directory filename prodglyphs run build script terminal cd source script need run source dir sh buildsh font take approximately 25 minute build changelog v3000 upgrade 2axis variable font family width 50 200 weight 200 900 changelog v2013 removed ligature fi fl operator ligature moved dlig new variant ligconsolata introduced expose operator ligature liga changelog v2011 march 2018 glyph set expansion wa completed appsforartists included glyph set expanded include ligature changelog v2001 august 2016 glyph set expansion wa completed alexei vanyashin cyreal included glyph set expanded gf latin pro additional glyph minor design improvement trademark corner spur reading inconsolata expansion project thread google font discussion supported glyph set gf latin pro license font software licensed sil open font license version 11 license copied also available faq httpscriptssilorgofl inconsolata build instruction inconsolata font built using either export glyph using fontmake font file committed repo done using fontmake source file inconsolata source file available glyph format located source directory adding ligature follow creating ligature section glyph ligature tutorial name new glyph suffix dlig instance bargreaterdlig open font info panel switch feature tab click dlig sidebar click update button bottom panel switch instance tab update rename glyph value ligconsolata regular include new line new glyph instance bargreaterdligbargreaterliga update rename glyph value ligconsolata bold export font explained exporting variable font using fontmake possible export project single variable font bit tricky font us component varying 2x2 component triggering bug present fontmake glyph export thus incofixpy script source directory detects case decomposes component run script exporting script also decomposes corner component make resulting glyph file suitable fontmake export well fontmake currently ha support corner component copy script script folder glyph make available script menu copy macro panel running script following fontmake invocation generate variable font fontmake g sourcesinconsolatavfglyphs variable version font directory slightly smaller version generated glyph check result incofix script version control want preserve editability entirely possible future version fontmake glyph able handle source file without running script exporting instance using fontmake source file contains 15 instance including weight normal 100 width also master reasonable complement working font run geninstancespy script generate total 72 instance combination weight 200 900 width 50 70 80 90 110 120 150 200 two instance ligconsolata fontmake attempt generate rename glyph custom parameter doesnt seem respected fontmake wont ligature enabled use glyph export instead detailed run command generate otf fontmake g sourcesinconsolatavfglyphs otf command generate autohinted ttf fontmake g sourcesinconsolatavfglyphs ttf version font directory font export option glyph preferred way generate ligconsolata instance ttf otf file exported fontsttf fontsotf folder ttfs generated glyph app autohint option checked moment custom build script required produce font file since default ttfautohinting option suffice otfs generated option remove overlap autohint save ttf export destination repopathfontsotf future work addition want export subset including vietnamese script coverage avoid overlarge line spacing older application terminal text editor dont understand use typo metric flag see httpsgithubcomgooglefontsinconsolataissues35 copyright copyright 2006 inconsolata project author link inconsolata google font inconsolata leviencom official upstream git\n",
      "  (0, 39)\t0.19779314605520182\n",
      "  (0, 38)\t0.22001736334959893\n",
      "  (0, 37)\t0.19779314605520182\n",
      "  (0, 36)\t0.19008157581286936\n",
      "  (0, 35)\t0.16107905532612588\n",
      "  (0, 32)\t0.15830399544205054\n",
      "  (0, 30)\t0.19779314605520182\n",
      "  (0, 29)\t0.19386594117089204\n",
      "  (0, 28)\t0.19779314605520182\n",
      "  (0, 27)\t0.16987797693113194\n",
      "  (0, 24)\t0.14788945300717188\n",
      "  (0, 23)\t0.17618648890313035\n",
      "  (0, 22)\t0.22001736334959893\n",
      "  (0, 21)\t0.19386594117089204\n",
      "  (0, 20)\t0.1829022756751159\n",
      "  (0, 19)\t0.19386594117089204\n",
      "  (0, 18)\t0.17949021332089818\n",
      "  (0, 16)\t0.22001736334959893\n",
      "  (0, 13)\t0.16107905532612588\n",
      "  (0, 12)\t0.20187439771606935\n",
      "  (0, 11)\t0.2151765566480103\n",
      "  (0, 10)\t0.17949021332089818\n",
      "  (0, 9)\t0.20187439771606935\n",
      "  (0, 7)\t0.22001736334959893\n",
      "  (0, 4)\t0.16107905532612588\n",
      "  (0, 3)\t0.2151765566480103\n",
      "  (0, 1)\t0.2105509694203714\n",
      "akihabara important note read moving new repository community friendly tidy httpsgithubcomakihabara start playing whats akihabara akihabara set library tool presets create pixelated indiestyle 816bit era game javascript run browser without flash plugin making use small small small subset html5 feature actually available many modern browser note developer maximum compatibility make sure youre using name setting object property reserved name like goto data discovered patching wii also use comma last element array property object still work many browser broken opera wii probably ie supported making sure subscript loaded try add alert end opera wii silently fail syntax error like one explained opera wii want canvas blitted least used fails browser crash builtin gboxcreatecanvas wa already fixed good thing use method spawning canvas akibaka thought flexible simple akihabara resource editor akibaka ha committed partially uncompleted due lack time functional enough hope ill start working better someone pick code give spin experimental feature feature available current stable version use section changelog next one syncrhonous keyboard listener use function called frame instead usual keyupdown listener changing keyboard status order support specific hardware like wiiu wiiu official support synchronous keyboard listener standard button mapping unusable since impossibile cancel default action todo way updating jsdoc automatically darren darius wrapped tutorial doc btw script generating doc form source needed better embeddability keeping playability mobile solve randomly blinking sprite wii akibaka add addimage addtiles used improvement audio compatibility work progress nice networking\n",
      "  (0, 39)\t0.20926766992887216\n",
      "  (0, 38)\t0.23278117513341265\n",
      "  (0, 37)\t0.20926766992887216\n",
      "  (0, 36)\t0.2011087303079039\n",
      "  (0, 35)\t0.17042369391826423\n",
      "  (0, 33)\t0.21807999605287604\n",
      "  (0, 32)\t0.16748764518535486\n",
      "  (0, 31)\t0.22276560968178985\n",
      "  (0, 30)\t0.20926766992887216\n",
      "  (0, 29)\t0.20511263709854632\n",
      "  (0, 28)\t0.20926766992887216\n",
      "  (0, 27)\t0.17973306514214138\n",
      "  (0, 25)\t0.22276560968178985\n",
      "  (0, 21)\t0.20511263709854632\n",
      "  (0, 20)\t0.19351293924278584\n",
      "  (0, 18)\t0.18990293377616627\n",
      "  (0, 17)\t0.2011087303079039\n",
      "  (0, 15)\t0.23278117513341265\n",
      "  (0, 12)\t0.21358568621253413\n",
      "  (0, 9)\t0.21358568621253413\n",
      "  (0, 6)\t0.19724534083387604\n",
      "  (0, 5)\t0.2011087303079039\n",
      "  (0, 4)\t0.17042369391826423\n",
      "  (0, 0)\t0.20511263709854632\n",
      "ipython productive interactive computing overview welcome ipython full documentation available ipythonreadthedocsio contains information install use contribute project ipython interactive python command shell interactive computing multiple programming language originally developed python programming language offer introspection rich medium shell syntax tab completion history ipython version python support starting ipython 710 ipython follows nep 29 ipython 717 requires python version 37 ipython 710 requires python version 36 ipython 70 requires python version 35 ipython 6x requires python version 33 ipython 5x lts compatible release python 27 require python 2 support must use ipython 5x lts please update project configuration requirement necessary notebook qt console number piece part jupyter see jupyter installation doc want use main feature ipython comprehensive object introspection input history persistent across session caching output result session automatically generated reference extensible tab completion support default completion python variable keywords filename function keywords extensible system magic command controlling environment performing many task related ipython operating system rich configuration system easy switching different setup simpler changing pythonstartup environment variable every time session logging reloading extensible syntax processing special purpose situation access system shell userextensible alias system easily embeddable python program gui integrated access pdb debugger python profiler development instant running find latest version development documentation readthedocs run ipython directory without even installing systemwide typing terminal python ipython see development installation doc latest revision read doc documentation installation instruction older version ipython found ipython website ipython requires python version 3 starting version 60 ipython doe support python 27 30 31 32 version compatible python 27 please install 5x lts long term support version encountering error message likely trying install use ipython source need checkout remote 5x branch using git following work git fetch origin git checkout 5x encounter error message regular install ipython likely need update package manager example using pip check version pip pip version need update pip version 901 greater using pip please inquiry maintainer package package manager information see one blog post httpsblogjupyterorgreleaseofipython508ce60b8d2e8e well following pullrequest discussion httpsgithubcomipythonipythonpull9900 error doe also occur invoking setuppy directly using easyinstall case use pip install instead setuppy install pip install e instead setuppy develop depending ipython dependency may also want conditional dependency ipython depending python version installreq ipython sysversioninfo0 3 bdistwheel sysargv installreqremoveipython installreqappendipython6 setup installrequiresinstallreq alternative ipython ipython may taste thats case might similar project might want use classic python repl bpython mypython ptpython ptipython httpspypiorgprojectptpython xonsh httpsxonsh ignoring commits git blameignorerevsfile git 223 possible make formatting change without breaking git blame see git documentation detail use feature must install git 223 configure local git repo running posix toolsconfiguregitblameignorerevssh window toolsconfiguregitblameignorerevsbat\n",
      "  (0, 39)\t0.24082891370117554\n",
      "  (0, 37)\t0.24082891370117554\n",
      "  (0, 36)\t0.23143946254257508\n",
      "  (0, 35)\t0.19612658318997517\n",
      "  (0, 32)\t0.19274772668930018\n",
      "  (0, 31)\t0.256362580076894\n",
      "  (0, 30)\t0.24082891370117554\n",
      "  (0, 29)\t0.23604722887016363\n",
      "  (0, 27)\t0.20683997126300785\n",
      "  (0, 24)\t0.1800671915377604\n",
      "  (0, 23)\t0.2145210871944124\n",
      "  (0, 19)\t0.23604722887016363\n",
      "  (0, 18)\t0.21854363488409334\n",
      "  (0, 13)\t0.19612658318997517\n",
      "  (0, 11)\t0.2619946010517331\n",
      "  (0, 9)\t0.24579816275570818\n",
      "  (0, 8)\t0.22699340601338963\n",
      "  (0, 3)\t0.2619946010517331\n",
      "  (0, 2)\t0.25097029353469535\n",
      "5 super senior swift developer question link offtop ua pull request datajson url laravel framework laravel framework gitter httpsgitterimphpualaravel atlassian user group saintpetersburg atlassian user group atlassian telegram httpstmeaugspb interesting question performance plugin hacking please ask aimlds dev ua data science gitter httpsgitterimdevuaaimlds allthatjs javascript slack httpsallthatjsherokuappcom angular ru angularjs javascript gitter httpsgitterimangularjsruschat angularjs ua dev ua angularjs javascript gitter httpangularim angularjs angularjs angularjs telegram httpstelegrammeangularjs android russpeaking developer chat android gitter httpsgitterimrusspeakingandroid android russpeaking slack team android slack httpsgooglformsymwbvtvseslyhwwh3 android developer android telegram httpstelegrammeandroidru android united android skype httpbitlyandroidchat android developer ua android skype httpsjoinskypecomvg41lckg7ptg android job ua adroid android telegram httpstmejoinchathmerxjoq6lkltufhepkg pet android android declarative android declarative android ui jetpack compose anko anvil litho android ui jetpack compose anko anvil litho telegram httpstmeandroiddeclarative ansible ru ansible slack httpsgooglvqfjzp slack register form httpgooglsbmi3f android dev android dev apptractorruandroiddev telegram httpstmeandroiddevpodcast android architecture telegram httpstmeandroidarchitecture ruembedded embedded softwarehardware ircircforestnetorg6667ruembedded webdev webdevelopment theory practice irc httpwebdevaecname net c azure net aspnet c azure xamarin skype httpbitlydotnetchat atlassian user group moscow atlassian user group atlassian telegram httpstmeaugmoscow php telegram php telegram telegram httpstelegrammeprophp7 clojure ua dev ua clojure clojurescript fp gitter httpsgitterimdevuaclojure cicerone chat ru httpsgithubcomterrakokcicerone telegram httpstmeciceronerus c russia telegram httpstelegrammejoinchatcmhkjwai8vac99lmyofq clojure ru clojure clojurescript telegram httpstmeclojureru clojure pro clojure clojurescript telegram httpstmeclojurepro postgreschat postgres gitter httpsgitterimpostgresmenpostgresqlrussia devops devops telegram httpstmedevopsru dagger 2 dagger 2 telegram httpstmedagger2 dart group dev ua dart gitter httpsgitterimdevuadartskype httpbitlydartchat cocoa chat cocoa skype httpbitlycocoachat read guideline banned cocoa developer club iosos x slack httpcocoadevelopersclubchat delphi developer ua delphi skype httpsjoinskypecombklfxscj6kwy diy glory sad robot hardware microcontrollers robotics skype httpbitlyrobotschat devops devs vagrant docker dokku oh skype httpbitlydevopsfordevs continuous integrationdelivery ru continuous integrationdelivery telegram httpstelegrammecicdru propython prodot python telegram httpstelegrammejoinchata7kpxzxo8hpyxsxtsku7g itcrowd kz developer community kazakhstan slack httpitcrowdkzslackcom gentoo gentoo linux telegram httpstmerussiangentooother httptelegraphinfo0611 go lang dev ua go gitter httpsgitterimdevuagoskype httpisgd0hu7ar programming work metarhia computer science software engeneering programming telegram httpstmeprogrammingip9x graphql graphql telegram httpstelegrammegraphqlru hangopsru russian devops hangout slack httpjoinhangopsruskype skype outdated httptinyurlcomhangopsru frontend kz html5 css3 javascript slack httpfrontendkzgithubio haskell ua dev ua haskell chat gitter httpsgitterimdevuahaskell haskell haskell chat gitter httpsgitterimruhaskellforall haxe haxe telegram httpstmehaxeru hexlet c java ruby php j slack httpslackruhexletio game made gamedev slack httphgaminviteherokuappcom docker docker docker swarm telegram httpstmedockerru itchat web scraping python skype httptinyurlcomitchatnew ember chat dev ua emberjs gitter httpsgitterimdevuaember flask flask telegram httpstmeruflask erlang elixir erlang elixir slack httpotprussianherokuappcomtelegram httpstelegrammeproelixir nice perm perm telegram httpstmeitperm 1 feather j feathersjs telegram httpstmefeatherjs flow type checker community flow j telegram httpstelegrammeflowtyperu fronthub j cs html fun flood slack httpsfronthubslackcom gamedev gamedev skype httpsbitlyrugamedevskypechat django django telegram httpstmepydjango rubywhatever ruby skype httptinyurlcomrubyconf good person openvidu kurento openvidu kurento openvidukurento telegram httpstmeopenvidu nodeua metarhia nodejs software engineering telegram httpstmenodeua javachat java jvm skype httpbitlyjavachatru moxy mvp android httpsgithubcomarellomobilemoxy moxy moxy moxy telegram httpstmemoxyru java talk java jvm software design skype httpbitlyjavatalksby kotlin community kotlin telegram httpstmekotlinlang krasnodar dev day telegram httpstelegrammekrddevdays krasnodar frontend c frontend telegram httpstelegrammekrdfrontend kubernetes kubernetes telegram httpstmekubernetesru slack httpanjlabcomruvladimir8bit nodejs ua dev ua nodejs devops nosql gitter httpsgitterimdevuanode nodejs ru nodejs gitter httpsgitterimnodejsruschat moscowjs html5 css3 javascript gitter httpsgitterimmoscowjschat mobile web ua hybrid apps phonegap crosswalk skype httpbitlymobilewebua lovely clojure clojure clojurescript fp skype httptinyurlcomcljcljs odeskconf undefined slack httpsodeskconfherokuappcom laravel laravel php gitter httpsgitterimlaravelruschat javascriptru javascript nodejs angularjs slack httpslackjavascriptru javascript noobs j telegram httpstelegrammejsnoobsru slackdevby belarussian dev community lot channel different topic slack httpslackdevby true c true c skype httpgoogltajsf2 reactivex telegram httpstmereactivex python community chelyabinsk python telegram httpstmepychel rollup rollupjs telegram httpstmerollupru true big data true big datadata science skype httpgoogln2djvo true net true net skype httpgoogl3lkldj russianspeaking rubyjs dev community ruby j slack httpsrusdevsherokuappcom phalcon ru phalcon php gitter httpsgitterimphalconruschat phalcon framework phalcon framework gitter httpsgitterimphpuaphalcon php ua dev ua php gitter httpsgitterimdevuaphpskype httpbitlyphpua chat migrated gitter php community php community gitter httpsgitterimphpuaphp true android development true android skype httpgooglv8cica pyha pyharu slack httpspyhaslackcom piter united slack httpbitlypiterunited symfony symfony component symfony framework telegram httpstmesymfonyphp symfony framework ru symfony framework gitter httpsgitterimsymfonysibsymfony symfony framework ua symfony framework gitter httpsgitterimphpuasymfony spb frontend j cs html gitter httpsgitterimspbfrontendtalksslack httpslackspbfrontendru scala user group telegram scala telegram httpstmescalaru true asm true assembler skype httpgooglcvxdnr scalachat dev ua scala jvm software design gitter httpsgitterimdevuascalaslack httpsscalaruherokuappcomskype httpbitlyscalachat swiftchat swift io osx skype httpbitlyswiftskypechat python python telegram httpstelegrammerupython python ua python skype httpbitlypythonua qac automation testing qa automation skype httpbitlytestautomationchat qac performance load testing qa skype httpsjoinskypecomivtvbl4t6r9k qt qt qml qtcreator telegram httpstmeqtchat reportportalio community reportportalio community open sourced tool test automation slack httpsreportportalslackautoherokuappcom reactjs dev ua reactjs flux redux gitter httpsgitterimdevuareactjsskype httpbitlyreactjschat scala ua dev ua scala jvm gitter httpsgitterimdevuascalaskype httpbitlyscalaua skype readonly archive rubyror dev ua ruby rail gitter httpsgitterimdevuarubyuaskype httpbitlyrubyuatelegram httpstelegrammerubylang startup startup entrepreneurship skype httpbitlystartupsuachat rustua dev ua rust gitter httpsgitterimdevuarust salesforcedevelopersru skype salesforcedevelopersru skype httpsjoinskypecomh9hvp9pnxioc salesforceru russianspeaking salesforce developer gitter httpsgitterimsalesforcerusalesforceru softwaretesters urkqa slack httpssoftwaretestersherokuappcom xamarin net xamarin android io window 10 telegram httpstmexamarinrussia true cs true cs skype httpgooglnsmtb3 chatbots ai community chatbots ai community chatbots telegram httpstelegrammejoinchatabi4pz6rz2ivzwuzavqpma chatbots ai community true window development true development window phonertwpf skype httpgooglqzot3t true database true database skype httpgoogljhuouj true unix true nix skype httpgooglrqcepd true system administration true russian speaking sysadmins skype httpgooglznsgaf true devops true devops skype httpgoogli3mwjc true htmlcssjs true htmlcssjs skype httpgooglnvj9fk true infosec true info security skype httpgooglnoc6rq true true skype httpgooglfolxzp true startup true russian speaking startup community skype httpgooglunpceb true rust true rust skype httpgooglkwhhov true javascript true javascript skype httpgoogl1atiyi true lamp true linuxapachemysqlphp python perl skype httpgooglfbeagb true ruby true ruby skype httpgooglg5bvgd true python true python skype httpgooglc8ky7e vim vim skype httptinyurlcomruvimchat prolua prodot telegram httpstelegrammeprolua projs prodot javascript nodejs telegram httpstelegrammejoinchatbe4rst5rsgq30dhutjxxga golangruslackcom go slack http4gophersruslack io developer io telegram httpstelegrammeiosru phpgeeks 22 php telegram telegram httpstmephpgeeks typescript typescript russian speaking community telegram httpstelegrammetypescriptru projvm prodot jvm android java scala kotlin groovy clojure telegram httpstelegrammejvmchat procxx telegram httpstmeprocxx ntwrk network engineer community telegram httpstelegrammentwrk zend framework zend framework gitter httpsgitterimphpuazf yii framework yii framework gitter httpsgitterimphpuayii codingteam codingteam gitter httpsgitterimcodingteamtelegram httpstmecodingteam vuejs vuejs javascript gitter httpsgitterimvuejsrudiscussion visual studio code telegram httpstmevscoderu proasm assembler telegram httpstmeproasm unity dev ua unity engine gitter httpsgitterimdevuaunity true java true java jvm software design skype httptinyurlcomtruejava yiijobs yii telegram httpstmeyiijobs pgsql postgresql telegram postgresql telegram httpstmepgsql true io true development io skype httpgooglkjnfsn jquery ru jquery javascript gitter httpsgitterimjqueryruschat supaprocxx telegram httpstmesupapro html cs svg j slack httpslackwebstandardsru russian speaking community berlin germany slack httpsslackfilescomt09s9jdu1f0hheg8pkc9396c730askype httpbitlyberlinruitchattelegram httpstelegrammeberlinru russian speaking community munich germany skype httptinyurlcomskypetraktoristivmunchene rust gitter httpsgitterimrurustgeneral offence flame spam net dotnetru net c f telegram httpstmedotnetruchat f fsharplangru f gitter httpsgitterimfsharplangrulobbytelegram httpstmefsharpchat ua plan work work abroad skype httpbitlyitemigrantua beware troll\n",
      "  (0, 39)\t0.4044803794828662\n",
      "  (0, 34)\t0.4499281617960037\n",
      "  (0, 26)\t0.4215131730145922\n",
      "  (0, 22)\t0.4499281617960037\n",
      "  (0, 6)\t0.38124317214804593\n",
      "  (0, 4)\t0.3294012898043972\n",
      "main repository discussion coordination code live elsewhere follow repository update project check homepage stay date reading post medium join u spectrum\n",
      "  (0, 25)\t0.5480036672955759\n",
      "  (0, 23)\t0.458562799841971\n",
      "  (0, 4)\t0.41924249166949407\n",
      "  (0, 3)\t0.5600427415925022\n",
      "reduxcode companion repo course udemy\n",
      "  (0, 24)\t1.0\n",
      "healthclinicbiz connect 2015 showcased many technology available developer across azure office window visual studio visual studio team service weve also heard love realworld application directly experience whats possible using technology year built full health technology scenario connect 2015 demo delighted share source code healthclinicbiz fictitious regular doctor practice specialized offering healthcare preventive care clinic using different microsoft multichannel apps built visual studio 2015 grow business modernize customer experience also innovate offer multiple apps servicesincluding website mobile apps wearable appsto empower patient wellbeing easy access manage healthcare data stay healthy license project us thirdparty asset license requires attribution roboto font christian robertson roboto google font raleway font matt mcinerney pablo impallari rodrigo fuenzalida igino marini raleway google font extra information license see dependency repository prerequisite window 10 visual studio 2015 update 2 make sure install uwp development tool cross platform mobile development office developer tool xamarin visual studio microsoft azure sdk visual studio 2015 microsoft office 2016 bing map key getting bing map key microsoft azure subscription sign microsoft azure need azure account work demo code open azure account freeazure subscription get credit used try paid azure service even credit used keep account use free azure service feature web apps feature azure app service activate visual studio subscriber benefit visual studio subscription give credit every month use paid azure service visual studio subscriber get 25 monthly azure credit joining visual studio dev essential please see wiki detailed azure deployment instruction demo scenario blog post link blog post related project connectdemos 2015 healthclinicbiz erika ehrli aspnet 5 net core rc1 context plus connect 2015 news scott hanselman license sample template licensed mit license see licensetxt file root code conduct project ha adopted microsoft open source code conduct information see code conduct faq contact opencodemicrosoftcom additional question comment\n",
      "  (0, 39)\t0.25271824588352515\n",
      "  (0, 35)\t0.20580903394515399\n",
      "  (0, 33)\t0.26336028916220633\n",
      "  (0, 32)\t0.20226336878884196\n",
      "  (0, 29)\t0.24770049704145458\n",
      "  (0, 25)\t0.26901878412986907\n",
      "  (0, 23)\t0.225111644725797\n",
      "  (0, 22)\t0.2811138972131564\n",
      "  (0, 19)\t0.24770049704145458\n",
      "  (0, 18)\t0.2293327790592781\n",
      "  (0, 16)\t0.2811138972131564\n",
      "  (0, 13)\t0.20580903394515399\n",
      "  (0, 12)\t0.25793281869008644\n",
      "  (0, 10)\t0.2293327790592781\n",
      "  (0, 9)\t0.25793281869008644\n",
      "  (0, 6)\t0.2381997016604516\n",
      "  (0, 4)\t0.20580903394515399\n",
      "reactnativereduxcasts companion repo complete react native redux course repo organized branch branch line one video course use branch seletor left side select section want see alternatively look completed code available master branch\n",
      "  (0, 37)\t0.5910199723195997\n",
      "  (0, 32)\t0.4730235848421713\n",
      "  (0, 24)\t0.4419041921617725\n",
      "  (0, 4)\t0.48131566092560496\n",
      "hey welcome hacktoberfest 2020 disclaimer pull request wont count toward hacktoberfest repo welcome beginner github opensource community helping learn make first pr contribution open source said highquality contribution pull request add value open source project part core value hacktoberfest repository like one others allow user quickly gain pr toward completing challenge excluded hacktoberfest pull request wont count toward hacktoberfest try contributing meaningful way hacktoberfest issue still want generate music certificate add hacktoberfest2020vercelapp go ahead raise pr open first pull request hacktoberfest 2020 challenge generate personalized music certificate make first pull request step1 star repo step2 show love step3 fork clone repository step4 create new branch git checkout b newuser step5 create new file contributor folder name file yourgithubusernamejson forget include json file extension step6 add detail yourgithubusernamejson file format githubusername yourgithubusername favouriteemoji yourfavouriteemoji favouritemusic yourfavouritemusicurl favouritecolor yourfavouritecolor note githubusername one youre making pull request favouriteemoji emoji supported modern browser pick one httpsemojipediaorg favouritemusic song httpssoundcloudcom favouritecolor color hex format example fff44f pick colour httpswwwgooglecomsearchqcolorpicker step7 add file git add step8 commit change git commit added step9 push fork git push origin newuser submit pull request step10 pat self back wait pull request reviewed merged designer react developer project built using nextjs react based framework open contribution frontend devs designer want make bigger better hacktoberfest monthlong celebration october 1st 31st sponsored digital ocean github get people involved open source create first pull request public repository github contribute open source developer community httpshacktoberfestdigitaloceancom checkout hacktoberfest video faq profile showing website raise pull request wait approved merged master branch upon successful merge detail show automatically within 612 hr website httpshacktoberfest2020vercelapp make pull request welcomed raise pr anytime increasing count hacktoberfest star repo raise pr oct 1st 31st pull request counted towards hacktoberfest 2020 repo welcome beginner github opensource community helping learn make first pr contribution open source said highquality contribution pull request add value open source project part core value hacktoberfest repository like one others allow user quickly gain pr toward completing challenge might excluded hacktoberfest highly recommend contribute meaningful way hacktoberfest issue rely repository alone awesome contributor generated using contributorsimg\n",
      "  (0, 38)\t0.2529659191798704\n",
      "  (0, 37)\t0.22741352881240087\n",
      "  (0, 35)\t0.18520134352511278\n",
      "  (0, 34)\t0.2529659191798704\n",
      "  (0, 29)\t0.22289820793843623\n",
      "  (0, 26)\t0.23698998265061955\n",
      "  (0, 25)\t0.2420818916414586\n",
      "  (0, 24)\t0.17003654096846388\n",
      "  (0, 23)\t0.20257118090100795\n",
      "  (0, 22)\t0.2529659191798704\n",
      "  (0, 21)\t0.22289820793843623\n",
      "  (0, 20)\t0.2102926859128279\n",
      "  (0, 18)\t0.20636965240041266\n",
      "  (0, 17)\t0.21854711743025879\n",
      "  (0, 14)\t0.2474001806481634\n",
      "  (0, 10)\t0.20636965240041266\n",
      "  (0, 8)\t0.21434872866928112\n",
      "  (0, 5)\t0.21854711743025879\n",
      "  (0, 2)\t0.23698998265061955\n",
      "  (0, 0)\t0.22289820793843623\n",
      "weight bias use wb organize analyze machine learning experiment frameworkagnostic lighter tensorboard time run script instrumented wandb save hyperparameters output metric visualize model course training compare version model easily also automatically track state code system metric configuration parameter sign free account feature store hyperparameters used training run search compare visualize training run analyze system usage metric alongside run collaborate team member replicate historic result run parameter sweep keep record experiment available forever documentation question please dont hesitate ask slack community simple integration framework install wandb library login pip install wandb wandb login flexible integration python script import wandb 1 start wb run wandbinitprojectgpt3 2 save model input hyperparameters config wandbconfig configlearningrate 001 model training code 3 log metric time visualize performance range 10 wandblogloss loss try colab question please dont hesitate ask slack community explore wb dashboard academic researcher youd like free academic account research group reach u make easy cite wb published paper learn track model data pipeline hyperparameters set wandbconfig beginning script save hyperparameters input setting like dataset name model type independent variable experiment useful analyzing experiment reproducing work future setting configs also allows visualize relationship feature model architecture data pipeline model performance seen screenshot wandbinit wandbconfigepochs 4 wandbconfigbatchsize 32 wandbconfiglearningrate 0001 wandbconfigarchitecture resnet see set configs colab doc use favorite framework kera kera use callback automatically save metric tracked modelfit get started minimal example import wb import wandb wandbkeras import wandbcallback step1 initialize wb run wandbinitprojectprojectname 2 save model input hyperparameters config wandbconfig configlearningrate 001 model training code step 3 add wandbcallback modelfitxtrain ytrain validationdataxtest ytest callbackswandbcallback try colab learn doc pytorch wb provides first class support pytorch automatically log gradient store network topology call watch pas pytorch model use log anything else want track like import wandb 1 start new run wandbinitprojectgpt3 2 save model input hyperparameters config wandbconfig configdropout 001 3 log gradient model parameter wandbwatchmodel batchidx data target enumeratetrainloader batchidx argsloginterval 0 4 log metric visualize performance wandblogloss loss try colab learn doc tensorflow simplest way log metric tensorflow logging tfsummary tensorflow logger import wandb 1 start wb run wandbinitprojectgpt3 2 save model input hyperparameters config wandbconfig configlearningrate 001 model training 3 log metric time visualize performance tfsession sess wandbtensorflowlogtfsummarymergeall try colab doc fastai visualize compare iterate fastai model using weight bias wandbcallback import wandb fastai2callbackwandb import wandbcallback 1 start new run wandbinitprojectgpt3 2 automatically log model metric learnfit cbswandbcallback try colab doc huggingface run script using huggingfaces trainer environment wandb installed well automatically log loss evaluation metric model topology gradient 1 install wandb library pip install wandb 2 run script ha trainer automatically log metric model topology gradient python rungluepy modelnameorpath bertbaseuncased taskname mrpc datadir gluedirtaskname dotrain evaluateduringtraining maxseqlength 128 pergputrainbatchsize 32 learningrate 2e5 numtrainepochs 3 outputdir tmptaskname overwriteoutputdir loggingsteps 50 try colab doc optimize hyperparameters sweep use weight bias sweep automate hyperparameter optimization explore space possible model get started 5 min try sweep pytorch colab benefit using wb sweep quick setup line code run wb sweep transparent cite algorithm using code open source powerful sweep completely customizable configurable launch sweep across dozen machine easy starting sweep laptop common use case explore efficiently sample space hyperparameter combination discover promising region build intuition model optimize use sweep find set hyperparameters optimal performance kfold cross validation brief code example kfold cross validation wb sweep visualize sweep result hyperparameter importance plot surface hyperparameters best predictor highly correlated desirable value metric parallel coordinate plot map hyperparameter value model metric theyre useful honing combination hyperparameters led best model performance share insight report report let organize visualization describe finding share update collaborator common use case note add graph quick note collaboration share finding colleague work log track youve tried plan next step explore report gallery read doc experiment wb visualize document result report click quick demo video version control datasets model artifact git github make code version control easy theyre optimized tracking part ml pipeline datasets model large binary file wb artifact extra line code start tracking team output directly linked run try artifact colab common use case pipeline management track visualize input output run graph dont repeat prevent duplication compute effort sharing data team collaborate model datasets without headache learn artifact read doc testing run basic test use make test detailed information found contributingmd use circleci ci\n",
      "  (0, 39)\t0.1933076245904229\n",
      "  (0, 38)\t0.21502784462455038\n",
      "  (0, 37)\t0.1933076245904229\n",
      "  (0, 36)\t0.1857709361098653\n",
      "  (0, 35)\t0.15742613016364324\n",
      "  (0, 33)\t0.20144786828275393\n",
      "  (0, 32)\t0.15471400264564994\n",
      "  (0, 31)\t0.20577612806918774\n",
      "  (0, 30)\t0.1933076245904229\n",
      "  (0, 29)\t0.18946948023301446\n",
      "  (0, 28)\t0.1933076245904229\n",
      "  (0, 27)\t0.16602551122584833\n",
      "  (0, 22)\t0.21502784462455038\n",
      "  (0, 21)\t0.18946948023301446\n",
      "  (0, 20)\t0.17875444699722695\n",
      "  (0, 18)\t0.17541976284965716\n",
      "  (0, 17)\t0.1857709361098653\n",
      "  (0, 15)\t0.21502784462455038\n",
      "  (0, 13)\t0.15742613016364324\n",
      "  (0, 12)\t0.19729632227612448\n",
      "  (0, 10)\t0.17541976284965716\n",
      "  (0, 9)\t0.19729632227612448\n",
      "  (0, 8)\t0.18220219258466713\n",
      "  (0, 7)\t0.21502784462455038\n",
      "  (0, 6)\t0.18220219258466713\n",
      "  (0, 4)\t0.15742613016364324\n",
      "  (0, 1)\t0.20577612806918774\n",
      "  (0, 0)\t0.18946948023301446\n",
      "douban conversation corpus data set release douban conversation corpus comprising training data set development set test set retrieval based chatbot statistic douban conversation corpus shown following table train val test sessionresponse pair 1m 50k 10k avg positive response per session 1 1 118 fless kappa na na 041 min turn per session 3 3 3 max ture per session 98 91 45 average turn per session 669 675 595 average word per utterance 1856 1850 2074 test data contains 1000 dialogue context context create 10 response candidate recruited three labelers judge candidate proper response session proper response mean response naturally reply message given context pair received three label majority label wa taken final decision far known first humanlabeled test set retrievalbased chatbots entire corpus link httpswwwdropboxcoms90t0qtji9ow20cadoubanconversaioncorpuszipdl0 data template label conversation utterance splited response source code also release source code help others reproduce result code ha tested ubuntu 1404 python 27 please first run preprocesspy edit code correct path give bin file please run smnlastpy generated bin file training loss printed screen set trainflag false give predicted score model tip 200d word embedding shared https1drvmsusatcxwlquqjw1jf0bjeakheunwita shared file list ha 3 element one word2vec file please download replace input path training data scripy tensorflow resource tensorflow code requires several data set ha uploaded following path resource file https1drvmsusatcxwlquqjw1jgn5kpzsh03lng6u worddict file https1drvmsusatcxwlquqjw1jgrcjg8lik1wen9 requirement tensorflow13 reference please cite paper use data code repos wu yu et al sequential matching network new archtechture multiturn response selection retrievalbased chatbots acl 2017\n",
      "  (0, 32)\t0.2567413005875549\n",
      "  (0, 29)\t0.3144165359620724\n",
      "  (0, 28)\t0.32078577311781176\n",
      "  (0, 27)\t0.2755122674995733\n",
      "  (0, 20)\t0.29663539448972803\n",
      "  (0, 12)\t0.3274048471121875\n",
      "  (0, 11)\t0.34897861456683815\n",
      "  (0, 10)\t0.2911016281178718\n",
      "  (0, 6)\t0.3023567815075649\n",
      "  (0, 5)\t0.3082789594517379\n",
      "  (0, 4)\t0.2612419607373909\n",
      "complexityreport note fork longer maintained use jareds fork instead software complexity analysis javascript project commandline frontend escomplex le attractive elder brother jscomplexityorg software complexity analysis work complexity metric result result installation usage commandline option output format license software complexity analysis complexity quality consisting many interrelated part software consists many interrelated part becomes difficult reason software difficult reason fertile breeding ground bug software simple every problem space contains level inherent complexity shared possible solution however programmer reduce complexity chosen solution limiting interrelatedness constituent component commonly referred favouring cohesion coupling form bedrock axiom single responsibility principle built codebases large andor unfamiliar difficult know whether region complexity exist might defining metric complexity search offending component automated brought existing build process alongside form static analysis unit test work complexityreport nodejsbased commandline wrapper around escomplex library performs actual analysis work code passed escomplex form syntax tree generated esprima popular javascript parser example report complexity metric readme escomplex contains brief overview metric produce result number returned tool interpreted definitive indicator whether piece software complex whatever might mean software development varied field every project subject unique set environmental factor attempt set generic hard limit complexity metric must essentially arbitrary fail consider specific requirement given project complexity amorphous multidimensional continuum attempting pigeonhole chunk code discrete point along single axis intrinsically crude approach result better use tool fuzzy highlevel mechanism identify region interest concern programming domainexpertise take comprehensive analysis although metric perfect help identify area code warrant closer inspection also tracked time indicator direction overall code quality may moving tool configured fail complexity metric pas specified threshold aid usefulness automated environment ci also option controlling metric calculated format report output installation must nodejs installed projectbased install npm install complexityreport globally project sudo npm install g complexityreport usage cr option path tool recursively read file directory encounter automatically commandline option h help output usage information c config path specify configuration json file output path specify output file report f format format specify output format report e ignoreerrors ignore parser error allfiles include hidden file report p filepattern pattern specify file process using regular expression match file name p dirpattern pattern specify directory process using regular expression match directory name x excludepattern pattern specify directory exclude using regular expression match directory name maxfiles number specify maximum number file open point f maxfod firstorder density specify perproject firstorder density threshold maxcost change cost specify perproject change cost threshold maxsize core size specify perproject core size threshold minmi maintainability index specify permodule maintainability index threshold c maxcyc cyclomatic complexity specify perfunction cyclomatic complexity threshold maxcycden cyclomatic density specify perfunction cyclomatic complexity density threshold maxhd halstead difficulty specify perfunction halstead difficulty threshold v maxhv halstead volume specify perfunction halstead volume threshold e maxhe halstead effort specify perfunction halstead effort threshold silent dont write output console l logicalor disregard operator source cyclomatic complexity w switchcase disregard switch statement source cyclomatic complexity forin treat forin statement source cyclomatic complexity trycatch treat catch clause source cyclomatic complexity n newmi use microsoftvariant maintainability index scale 0 100 coffeescript include coffeescript file configuration file default complexityreport attempt read configuration option json file called complexrc current working directory file contain json object property name matching longform option name command line one follow option set file overridden option specified command line see example configuration file also specify alternative path file using c commandline option output format currently five output format supported plain markdown minimal json xml loaded srcformats subdirectory format file found directory second attempt made load module without subdirectory prefix easily enabling use custom format desired adding new format simple one must commonjs module export function named format format function take report object defined escomplex return string representation report see plain formatter example development see contribution guideline license mit\n",
      "  (0, 39)\t0.23431523194494797\n",
      "  (0, 35)\t0.19082196204958776\n",
      "  (0, 32)\t0.1875344932299313\n",
      "  (0, 31)\t0.24942876039900316\n",
      "  (0, 29)\t0.22966287698869706\n",
      "  (0, 28)\t0.23431523194494797\n",
      "  (0, 23)\t0.20871895126932924\n",
      "  (0, 22)\t0.2606431039364185\n",
      "  (0, 21)\t0.22966287698869706\n",
      "  (0, 20)\t0.21667479385818939\n",
      "  (0, 16)\t0.2606431039364185\n",
      "  (0, 15)\t0.2606431039364185\n",
      "  (0, 13)\t0.19082196204958776\n",
      "  (0, 10)\t0.2126327014101729\n",
      "  (0, 8)\t0.2208539322068184\n",
      "  (0, 7)\t0.2606431039364185\n",
      "  (0, 4)\t0.19082196204958776\n",
      "  (0, 2)\t0.2441823186307333\n",
      "  (0, 1)\t0.24942876039900316\n",
      "supporting vuejs vuejs mitlicensed open source project ongoing development made possible entirely support awesome backer youd like join please consider become backer sponsor patreon become backer sponsor open collective onetime donation via paypal cryptocurrencies whats difference patreon opencollective fund donated via patreon go directly support evan yous fulltime work vuejs fund donated via opencollective managed transparent expense used compensating work expense core team member sponsoring community event namelogo receive proper recognition exposure donating either platform special sponsor platinum sponsor platinum sponsor china gold sponsor sponsor via open collective platinum gold introduction vue pronounced vju like view progressive framework building user interface designed ground incrementally adoptable easily scale library framework depending different use case consists approachable core library focus view layer ecosystem supporting library help tackle complexity large singlepage application browser compatibility vuejs support browser es5compliant ie8 supported ecosystem project status description vuerouter singlepage application routing vuex largescale state management vuecli project scaffolding vueloader single file component vue file loader webpack vueserverrenderer serverside rendering support vueclasscomponent typescript decorator classbased api vuerx rxjs integration vuedevtools browser devtools extension documentation check live example doc visit vuejsorg question question support please use official forum community chat issue list repo exclusively bug report feature request issue please make sure read issue reporting checklist opening issue issue conforming guideline may closed immediately changelog detailed change release documented release note stay touch twitter blog job board contribution please make sure read contributing guide making pull request vuerelated projectcomponenttool add pull request curated list thank people already contributed vue license mit copyright c 2013present yuxi evan\n",
      "  (0, 39)\t0.21344288012278811\n",
      "  (0, 34)\t0.2374255157317435\n",
      "  (0, 33)\t0.22243102563579537\n",
      "  (0, 32)\t0.17082927996233954\n",
      "  (0, 30)\t0.21344288012278811\n",
      "  (0, 29)\t0.20920494803031095\n",
      "  (0, 26)\t0.22243102563579537\n",
      "  (0, 24)\t0.15959072100923452\n",
      "  (0, 23)\t0.19012666707728312\n",
      "  (0, 22)\t0.2374255157317435\n",
      "  (0, 21)\t0.20920494803031095\n",
      "  (0, 18)\t0.1936917878558542\n",
      "  (0, 17)\t0.20512115717323123\n",
      "  (0, 16)\t0.2374255157317435\n",
      "  (0, 15)\t0.2374255157317435\n",
      "  (0, 14)\t0.23220169607412805\n",
      "  (0, 10)\t0.1936917878558542\n",
      "  (0, 9)\t0.2178470474378596\n",
      "  (0, 8)\t0.20118068716822352\n",
      "  (0, 3)\t0.23220169607412805\n",
      "  (0, 2)\t0.22243102563579537\n",
      "  (0, 0)\t0.20920494803031095\n",
      "home assistant configuration home assistant configuration installed ha intel nuc skullcanyon 32gb ram 500gb nvme ssd currently running ubuntu 1604 lts nuc used virtual environment approach install ha regularly update configuration file check current ha version like anything sure repo thing run nuc home assistant homebridge plex medium server docker container using command docker create name plex nethost restartalways e tzamericanew york e puid1000 e pgid1000 e plexclaimclaim p 3240032400 v dockercontainersplexconfigconfig v dockercontainersplextranscodetranscode v mntmusicdatamusicshared v mntmediatv showsdatatvshowsshared v mntbollywooddatabollywoodshared v mnthollywooddatamoviesshared plexincpmsdockerplexpass machinebox image tagging service docker container using following command first obtain api key assign mbkey run container using access tagbox interface httpipaddres8081 sudo docker run namemachinebox p 80818080 e mbkeymbkey machineboxtagbox device service use ha aeotec zstick gen5 zwave control use zwave dry contact relay along tilt sensor automating garage door xiaomi aqara zigbee sensor currently using water temperaturehumidity doorwindow human body sensor also using mi magic cube volume brightness automation presence detection cornerstone setup use elaborate approach explained currently combine information following device tracker using pythonscript bayesian binary sensor component use presence unifi wap networkbased device tracking owntracks geofency life360 customcomponent tracking io device io app security abode home security almost entirely automated using presence four hikvision ds2cd2042wdi camera across house integrated using synology camera component three arlo camera indoor monitoring ring doorbell networking ubiquiti unifi cloud key ubiquiti unifi 80211ac pro ap pihole sensor light switch lifx wifi light wemo switch porch driveway wemo plug miscellaneous automation including smart charging prevent overcharging humidifier christmas light etc ge zwave dimmer 12724 kitchen light voice interaction google home google assistant dialogflow component amazon echo dot ha cloud medium sonos speaker component plex medium consumption along plex component plex activity monitor track pm google cast nvidia shield tv notification io pushbullet basic notification telegram io actionable notification tt sonos notification android tv send visual notification shield weather climate related ecobee thermostat main floor kid room wunderground integrate weather station bloomsky weather station darksky weather data forecast pollen sensor allergy related information home assistant dashboard moved entire configuration lovelace screenshots please note may updated image get idea useful link ha cheat sheet miscellaneous tip trick\n",
      "  (0, 36)\t0.26449388476363067\n",
      "  (0, 35)\t0.22413758364043573\n",
      "  (0, 33)\t0.2868141291377616\n",
      "  (0, 32)\t0.22027615537706005\n",
      "  (0, 27)\t0.23638106882350166\n",
      "  (0, 24)\t0.20578457314528945\n",
      "  (0, 21)\t0.26975973702010464\n",
      "  (0, 17)\t0.26449388476363067\n",
      "  (0, 13)\t0.22413758364043573\n",
      "  (0, 12)\t0.2809033093181373\n",
      "  (0, 11)\t0.29941293959980125\n",
      "  (0, 10)\t0.24975626172751314\n",
      "  (0, 6)\t0.2594128378653877\n",
      "  (0, 5)\t0.26449388476363067\n",
      "  (0, 3)\t0.29941293959980125\n",
      "lineprofiler kernprof lineprofiler module linebyline profiling function kernprof convenient script running either lineprofiler python standard library cprofile profile module depending available available bsd license content installation lineprofiler kernprof frequently asked question bug change 21 20 11 10 10b3 10b2 10b1 installation note version 212 pip install lineprofiler doe work please install follows fixed next release git clone httpsgithubcomrkernlineprofilergit find lineprofiler name pyx exec cython cd lineprofiler pip install user release lineprofiler installed using pip pip install lineprofiler source release binary downloaded pypi link httppypipythonorgpypilineprofiler check development source use git git clone httpsgithubcomrkernlineprofilergit may also download source tarballs snapshot url source release require c compiler order build lineprofiler addition git checkout also require cython 010 source release pypi contain pregenerated c source cython required case kernprof singlefile pure python script doe require compiler wish use run cprofile linebyline profiling may copy directory path manually avoid trying build c extension lineprofiler current profiling tool supported python 27 later time function call good first step locating hotspot one program frequently one need optimize program however sometimes cause hotspot actually single line function line may obvious reading source code case particularly frequent scientific computing function tend larger sometimes legitimate algorithmic complexity sometimes programmer still trying write fortran code single statement without function call trigger lot computation using library like numpy cprofile time explicit function call special method called syntax consequently relatively slow numpy operation large array like alargeindexarray someotherlargearray hotspot never get broken cprofile explicit function call statement lineprofiler given function profile time execution individual line inside function typical workflow one care line timing function wading result timing every single line code would overwhelming however lineprofiler doe need explicitly told function profile easiest way get started use kernprof script kernprof l scripttoprofilepy kernprof create instance lineprofiler insert builtins namespace name profile ha written used decorator script decorate function want profile profile profile def slowfunctiona b c default behavior kernprof put result binary file scripttoprofilepylprof tell kernprof immediately view formatted result terminal vview option otherwise view result later like python lineprofiler scripttoprofilepylprof example result profiling single function decorated version pystonepy benchmark first two line output pystonepy kernprof pystone11 time 50000 pass 248 machine benchmark 201613 pystonessecond wrote profile result pystonepylprof timer unit 1e06 file pystonepy function proc2 line 149 total time 0606656 line hit time per hit time line content 149 profile 150 def proc2intpario 151 50000 82003 16 135 intloc intpario 10 152 50000 63162 13 104 1 153 50000 69065 14 114 char1glob 154 50000 66354 13 109 intloc intloc 1 155 50000 67263 13 111 intpario intloc intglob 156 50000 65494 13 108 enumloc ident1 157 50000 68001 14 112 enumloc ident1 158 50000 63739 13 105 break 159 50000 61575 12 101 return intpario source code function printed timing information line six column information line line number file hit number time line wa executed time total amount time spent executing line timer unit header information table see line timer unit giving conversion factor second may different different system per hit average amount time spent executing line timer unit time percentage time spent line relative total amount recorded time spent function line content actual source code note always read disk formatted result viewed code wa executed edited file meantime line match formatter may even able locate function display using ipython implementation lprun magic command let specify function profile statement execute also add lineprofiler instance builtins typically would use like ipython 011 install editing ipython configuration file ipythonprofiledefaultipythonconfigpy add lineprofiler item extension list cterminalipythonappextensions lineprofiler get usage help lprun use standard ipython help mechanism 1 lprun two method expected frequent userlevel way using lineprofiler usually easiest however building tool lineprofiler need use api two way inform lineprofiler function profile pas argument constructor use addfunctionf method instantiation profile lineprofilerf g profileaddfunctionh lineprofiler ha run runctx runcall method cprofileprofile well enable disable noted though enable disable entirely safe nested nesting common using lineprofiler decorator order support nesting use enablebycount disablebycount function increment decrement counter actually enable disable profiler count transition 0 profiling dumpstatsfilename method pickle result given file printstatsstream print formatted result sysstdout whatever stream specify getstats return linestats object hold two attribute dictionary containing result timer unit kernprof kernprof also work cprofile thirdparty incarnation lsprof purepython profile module depending available ha main feature encapsulation profiling concern modify script order initiate profiling save result unless want use advanced builtins feature course robust script execution many script require thing like name file syspath set relative naive approach encapsulation would use execfile many script rely information fail kernprof set variable correctly executing script easy executable location profiling application installed path give name executable kernprof doe find given script current directory search path inserting profiler builtins sometimes want profile small part code bbuiltin argument profiler instantiated inserted builtins name profile like lineprofiler may used decorator enableddisabled enablebycount disablebycount even context manager profile statement preprofiling setup ssetup option provide script executed without profiling executing main script typically useful case import large library like wxpython vtk interfering result modify source code builtins approach may easier result profile scripttoprofilepy written scripttoprofilepyprof default typical marshalled file read pstatsstats may interactively viewed command python pstats scripttoprofilepyprof file may also viewed graphical tool like kcachegrind converter program pyprof2calltree runsnakerun frequently asked question name kernprof didnt manage come meaningful name named use hotshot instead lineprofile hotshot linebyline timing however deprecated may disappear standard library also take long time process result want quick turnaround workflow hotshot pay processing time order make minimally intrusive code profiling code doe network operation example may even go different code path profiling slows execution much use case think many people linebyline profiling affected much concern allow using hotshot kernprofpy dont use hotshot accept contribution vein though linebyline timing dont add one profiled function call another whats let say function f calling function g using lineprofiler total time reported g le time reported line f call g reason im reasonably clever possibly clever recording time basically try prevent recording time spent inside lineprofiler bookkeeping line time python tracing facility issue line event happens line actually get executed lineprofiler find two timestamps one beginning doe anything tbegin one close end possible tend almost overhead lineprofilers data structure happens two time line event come lineprofiler find function belongs first line function record line number tend associated function next time see line event belonging function take tbegin new event subtract old tend find amount time spent old line record new tend active line function way removing lineprofilers overhead result well almost one profiled function f call another profiled function g line f call g basically record total time spent executing line includes time spent inside profiler inside g first time question wa asked questioner g function call part larger expression wanted try estimate much time wa spent function opposed rest expression response wa even could remove effect might still misleading g might called elsewhere relevant line f workaround would modify code split two line one assigns result g temporary variable rest expression open suggestion make robust simple admonition trying clever list comprehension many hit use lineprofiler lineprofiler record line list comprehension iteration list comprehension kernprof distributed lineprofiler work cprofile right partly kernprofpy essential using lineprofiler effectively mostly im lazy dont want maintain overhead two project module small however kernprofpy standalone pure python script used function profiling python standard library may grab install without lineprofiler need c compiler build lineprofiler kernprofpy need c compiler lineprofiler kernprofpy pure python script installed separately though need cython build lineprofiler building released source tarball contain generated c source already running problem may bug let know building git checkout snapshot need cython generate c source probably need version 010 higher bug earlier version handle null pyobject pointer version python need lineprofiler kernprof tested python 27 3234 cprofile us neat rotating tree data structure minimize overhead looking recording entry lineprofiler us python dictionary extension object thanks cython mostly started prototype wanted play quickly possible passed stealing rotating tree usual got working seems acceptable performance much le motivated use different strategy maybe later contribution accepted bug bug pull requested submitted github change 21 enh add support python 35 coroutines enh documentation update enh ci recent python version 35 36 36dev 37dev nightly enh add timer unit argument output time granularity spec 20 bug added support ipython 50 removed support ipython 012 11 bug read source file byte 10 enh kernprofpy installed kernprof enh python 3 support thanks longsuffering mikhail korobov patient dropped 26 wa annoying enh stripzeros addmodule option thanks erik tollerud contributing enh support ipython cell block thanks michael forbes adding feature enh better warning building without cython thanks david cournapeau spotting 10b3 enh profile generator bug update compatibility newer version cython thanks ondrej certik spotting bug bug update ipython compatibility 011 thanks yaroslav halchenko others providing updated import 10b2 bug fixed line timing overflow window doc improved readme 10b1 initial release\n",
      "  (0, 39)\t0.16815310583257626\n",
      "  (0, 38)\t0.18704694132325578\n",
      "  (0, 37)\t0.16815310583257626\n",
      "  (0, 36)\t0.161597143136415\n",
      "  (0, 35)\t0.13694075845330897\n",
      "  (0, 34)\t0.18704694132325578\n",
      "  (0, 33)\t0.1752340849817418\n",
      "  (0, 32)\t0.1345815516370706\n",
      "  (0, 31)\t0.1789991218108951\n",
      "  (0, 30)\t0.16815310583257626\n",
      "  (0, 29)\t0.16481440723908075\n",
      "  (0, 28)\t0.16815310583257626\n",
      "  (0, 27)\t0.14442112885727731\n",
      "  (0, 23)\t0.14978428679490105\n",
      "  (0, 22)\t0.18704694132325578\n",
      "  (0, 21)\t0.16481440723908075\n",
      "  (0, 20)\t0.1554936878855917\n",
      "  (0, 19)\t0.16481440723908075\n",
      "  (0, 18)\t0.15259293579382813\n",
      "  (0, 17)\t0.161597143136415\n",
      "  (0, 16)\t0.18704694132325578\n",
      "  (0, 15)\t0.18704694132325578\n",
      "  (0, 14)\t0.18293154755030827\n",
      "  (0, 13)\t0.13694075845330897\n",
      "  (0, 12)\t0.17162276671894341\n",
      "  (0, 10)\t0.15259293579382813\n",
      "  (0, 9)\t0.17162276671894341\n",
      "  (0, 8)\t0.15849278908440365\n",
      "  (0, 7)\t0.18704694132325578\n",
      "  (0, 6)\t0.15849278908440365\n",
      "  (0, 5)\t0.161597143136415\n",
      "  (0, 4)\t0.13694075845330897\n",
      "  (0, 3)\t0.18293154755030827\n",
      "  (0, 2)\t0.1752340849817418\n",
      "  (0, 1)\t0.1789991218108951\n",
      "  (0, 0)\t0.16481440723908075\n",
      "v012 gita commandline tool manage multiple git repos tool doe two thing display status multiple git repos branch modification commit message side side batch delegate git commandsaliases working directory several repos related help see status together also hate change directory execute git command screenshot gita remote nowhub command translates git remote v nowhub repo see predefined subcommands run gita h take look cmdsyml add subcommands see customization section run arbitrary git command see superman mode section branch color distinguishes 5 situation local remote branch white local ha remote green local remote red local ha diverged remote purple local ahead remote good push yellow local behind remote good merge choice purple ahead yellow behind motivated blueshift redshift using green baseline change color scheme using gita color subcommand see customization section additional status symbol denote staged change unstaged change untracked filesfolders bookkeeping subcommands gita add repopaths add repos gita gita context context subcommand gita context show current context gita context none remove context gita context groupname set context groupname operation apply repos group gita color color subcommand gita color show available color current coloring scheme gita color set situation color use specified color localremote situation gita group group subcommand gita group add reponames n groupname add repos new group existing group gita group display existing group repos gita group l display existing group name gita group rename groupname newname change group name gita group rm groupnames delete group gita info info subcommand gita info display used unused information item gita info add infoitem enable information item gita info rm infoitem disable information item gita display status repos gita groupname display status repos group gita l display name repos gita l reponame display absolute path one repo gita rename reponame newname rename repo gita rm reponames remove repos gita wont remove file disk gita v display gita version git delegating subcommands two format gita subcommand reponames groupnames optional repo group input input mean repos gita subcommand reponames groupsnames required repo name group name input translate git subcommand corresponding repos default fetch pull take optional input word gita fetch gita pull apply repos see predefined subcommands run gita h take look cmdsyml add subcommands see customization section run arbitrary git command see superman mode section one repos specified git command run asynchronously exception log difftool mergetool require nontrivial user input repo path saved xdgconfighomegitarepopath likely configgitarepopath installation install latest version run pip3 install u gita prefer development mode download source code run pip3 install e gitasourcefolder either case calling gita terminal may work put following line bashrc file alias gitapython3 gita window user may need enable ansi escape sequence terminal branch color work see stackoverflow post detail autocompletion download gitacompletionbash gitacompletionzsh source rc file superman mode superman mode delegate git command alias usage gita super reponames groupnames anygitcommandwithorwithoutoptions reponames groupnames optional absence mean repos example gita super checkout master put repos master branch gita super frontendrepo backendrepo commit implement new feature executes git commit implement new feature frontendrepo backendrepo customization userdefined subcommand using yaml file custom delegating subcommands defined xdgconfighomegitacmdsyml likely configgitacmdsyml shadow default one name collision exist default delegating subcommands defined cmdsyml example gita stat reponames registered stat cmd diff stat help show edit statistic executes git diff stat specified repos delegated git command single word cmd tag omitted see push example disable asynchronous execution set disableasync tag true see difftool example want custom command behave like gita fetch ie apply command repos repo specified set allowall option true example following snippet creates new command gita comaster reponames optional repo name input comaster cmd checkout master allowall true help checkout master branch customize information displayed gita command customize information displayed gita used unused information item shown gita info configuration saved xdgconfighomegitainfoyml example default information item setting corresponds branch commitmsg customize localremote relationship coloring displayed gita command see default color scheme available color via gita color change color coding use gita color set situation color configuration saved xdgconfighomegitacoloryml requirement gita requires python 36 higher due use fstring asyncio module hood gita us subprocess run git commandsaliases thus installed git version may matter git 1831 2172 2201 machine result agree contributing contribute reportfix bug requestimplement feature starrecommend project chat room available run test locally simply pytest implementation detail designmd stepbystep guide reproduce project also sponsor github amount appreciated contributor multirepo tool havent tried heard good thing myrepos repo\n",
      "  (0, 39)\t0.21470539889192405\n",
      "  (0, 37)\t0.21470539889192405\n",
      "  (0, 36)\t0.20633445278997473\n",
      "  (0, 35)\t0.1748520791376563\n",
      "  (0, 34)\t0.2388298922549176\n",
      "  (0, 33)\t0.22374670945969147\n",
      "  (0, 32)\t0.17183973846133638\n",
      "  (0, 29)\t0.21044239934905457\n",
      "  (0, 28)\t0.21470539889192405\n",
      "  (0, 27)\t0.18440335030503208\n",
      "  (0, 24)\t0.16053470321439492\n",
      "  (0, 23)\t0.19125126999474862\n",
      "  (0, 20)\t0.19854128841303015\n",
      "  (0, 19)\t0.21044239934905457\n",
      "  (0, 17)\t0.20633445278997473\n",
      "  (0, 13)\t0.1748520791376563\n",
      "  (0, 12)\t0.21913561694194858\n",
      "  (0, 11)\t0.2335751736028708\n",
      "  (0, 10)\t0.19483747853176167\n",
      "  (0, 9)\t0.21913561694194858\n",
      "  (0, 8)\t0.20237067482858226\n",
      "  (0, 4)\t0.1748520791376563\n",
      "  (0, 2)\t0.22374670945969147\n",
      "  (0, 0)\t0.21044239934905457\n",
      "repo deprecated mixed mode found httpsgithubcomfamousengine looking old website support material version famous please visit httpdeprecatedfamousorg repo moved deprecated organization coming month question concern pelase join u famous community slack signup httpslackfamousorgsignup\n",
      "  (0, 36)\t0.6099241009448785\n",
      "  (0, 30)\t0.6346685956536049\n",
      "  (0, 24)\t0.47454016139591654\n",
      "react native storybook content repo wa moved storybook monorepo npm package name ha changed old name package wa kadirareactnativestorybook new name package storybookreactnative location code httpsgithubcomstorybooksstorybooktreemasterappreactnative repo youre looking date longer maintained\n",
      "  (0, 24)\t0.4233641682387964\n",
      "  (0, 20)\t0.523595619806798\n",
      "  (0, 12)\t0.577907245850906\n",
      "  (0, 4)\t0.46112213475784003\n",
      "persona rl sl method envs quantitative trading persona repo implement paper proposed method deep reinforcement learning supervised learning applies financial market persona includes 4 rl 3 sl implement simulate financial market supporting stock future short sale still implementing rl sl method updating warning repo reconstructing start 20180824 20180901 timestamp successfully found job attention feature input naive day frequency clearly enough recommended could replace feature content deep deterministic policy gradient ddpg implement ddpg tensorflow arxiv150902971 continuous control deep reinforcement learning double dqn implement doubledqn tensorflow arxiv150906461 deep reinforcement learning double qlearning duelingdqn implement duelingdqn tensorflow arxiv151106581 dueling network architecture deep reinforcement learning policy gradient implement policy gradient tensorflow nip vol 99 1999 policy gradient method reinforcement learning function approximation darnn dualattnrnn implement arxiv170402971 darnn tensorflow arxiv170402971 dualstage attentionbased recurrent neural network time series prediction trenet hnn implement trenet tensorflow ijcai 2017 hybrid neural network learning trend time series naivelstm lstm implement simple lstm based model tensorflow arxiv150602078 visualizing understanding recurrent network environment basic simulate environment financial market implemented market implement market trader position gym env gym required give env regression sequence data generating rl sl model market support stock data future data also function updating experiment deep deterministic policy gradient ddpg doubledqn duelingdqn policy gradient pg train agent trade stock market using stock data set 20120101 20180101 70 training data 30 testing data total profit baseline profit test set darnn dualattnrnn naivelstm lstm trenet hnn train predictor predict stock price using stock data set 20080101 20180101 70 training data 30 testing data price prediction experiment 4 bank stock test set requirement start testing following requirement needed python35 tensorflow14 numpy scipy panda rqalpha sklearn tushare matplotlib mongoengine cuda option talib option docker option pytorch option best docker user run whole project without installing dependency manually also use ansible run cudaplaybook dockerplaybook install cuda nvidiadocker want run test docker container use use docker base image image repo ceruleanwangpersonae persona inherited ceruleanwangquantbase image ceruleanwangquantbase inherited nvidiacuda80cudnn6runtime please make sure cuda version cudnn version correct instruction first make sure stock data mongodb dont use spider writen repo crawl stock future data start make sure mongodb service running dont mongodb service running also use mongodb container option following code docker run p 2701727017 v datadbdatadb networkyournetwork mongo use spider crawl stock data following code docker run v localprojectdirdockerprojectdir networkyournetwork ceruleanwangpersonae spiderstockspiderpy also crawl future data following code docker run v localprojectdirdockerprojectdir networkyournetwork ceruleanwangpersonae spiderfuturespiderpy remember set stock future code want crawl default stock code stockcodes 600036 601328 601998 601398 default future code futurecodes au88 rb88 cu88 al88 modified default args parser run model docker run v localprojectdirdockerprojectdir networkyuornetwork ceruleanwangpersonae algorithmrl slalgorithmnamepy use conda create env install python35 dependency required run algorithm way one thing noticed hostname mongoengine config training testing model implemented tensorflow support persistence edit many parameter training testing model example following code show parameter could edited env marketcodes startdate20080101 enddate20180101 market market mixindexstate true trainingdataratio trainingdataratio algorithm algorithmtfsessionconfigconfig env envtraderactionspace envdatadim mode mode episode episode enablesaver true enablesummarywriter true savepath ospathjoincheckpointsdir rl modelname market model summarypath ospathjoincheckpointsdir rl modelname market summary todo implementation paper highfrequency stock data\n",
      "  (0, 38)\t0.25360865906050095\n",
      "  (0, 37)\t0.2279913447681491\n",
      "  (0, 36)\t0.2191024054652031\n",
      "  (0, 35)\t0.18567190608079567\n",
      "  (0, 34)\t0.25360865906050095\n",
      "  (0, 32)\t0.18247316210305486\n",
      "  (0, 31)\t0.24269697720966835\n",
      "  (0, 30)\t0.2279913447681491\n",
      "  (0, 28)\t0.2279913447681491\n",
      "  (0, 27)\t0.19581420883113956\n",
      "  (0, 24)\t0.17046857254963188\n",
      "  (0, 23)\t0.2030858770191792\n",
      "  (0, 18)\t0.2068939997361314\n",
      "  (0, 13)\t0.18567190608079567\n",
      "  (0, 11)\t0.2480287790107148\n",
      "  (0, 9)\t0.23269570421161914\n",
      "  (0, 8)\t0.2148933493704604\n",
      "  (0, 7)\t0.25360865906050095\n",
      "  (0, 6)\t0.2148933493704604\n",
      "  (0, 5)\t0.2191024054652031\n",
      "  (0, 4)\t0.18567190608079567\n",
      "diyhue hue bridge emulator project emulates philip hue bridge able control zigbee light using raspbee module original hue bridge ikea tradfri gateway milight bulb using milight hub neopixel strip ws2812b sk6812 cheap esp8266 based bulb replacing firmware custom one written python run small device raspberry pi arduino sketch provided hue dimmer switch hue tap switch hue motion sensor light twoway synchronized change made original philipstradfri sensor switch also applied bridge emulator masterrefactor detail newest version diyhue ha numerous change compare old version understand using version result thing breaking breaking change made listed something doe break listed please make issue debug log look config incompatible master branch migrated comparing old new config manually config stored config please use mounting config directory docker installation method besides docker unsupported docker available platform including raspberry pi getting started documentation instruction found diyhuereadthedocsio requirement python 3 python module ws4py request astral pahomqtt see requirementstxt docker recommendation hue essential phone app remote control entertainment effect ws2812 strip wemos d1 mini board cool entertainment affect raspberrypi 3b connected via ethernet port network bridge emulation avoid using 2 interface time working hue feature control light function control group function scene function routine wake go sleep switch custom esp8266 switch autodiscover light hue entertainment working device application amazon alexa control light logitech harmony tradfri gateway hue bridge original emulator home assistant domoticz openhab philip ambilight tv kodi hue ambilight jeedom hue sync pc deconz zigbee2mqtt see mqtt working smartphone application hue official application hue essential recommended huemanic onswitch hueswitcher lampshade working home away future hue app requires remote api google home requires remote api eneco toon likely us cloud service detection supported light device ws2812b sk6812 smart led strip milight yeelight lyt8266 phillips hue ikea tradfri pwm rgbcct pwm rgbw pwm rgb pwm cct pwm dimming 6 light every esp8266 onoff plugslights 6 light every esp8266 onoff 433mhz device multiple device every esp8266 mqtt light see mqtt hyperionng sonsoff tx t3 u 123c 1 3 button esp8266 alarm horn schematic alarm email notification eps8266 horn support need help diyhue get support user aswell maintainer fast live support board might already fix answer ready look since slack faster providing live support good come save show known issue kindly ask open topic discourse group provide help others future note please provide log make easier u enable debug manually starting diyhue additional debug true argument diyhue opensource maintained volunteer free time welcome contribute become recognised member diyhue community stability light house controlled solution stability important turning back classic illumination switch replaced ikea tradfri remote hole covered however dont use function im unable perform full test every change currently use deconz tradfri device light sensor xiaomi motion sensor native esp8266 bulb esp8266 ws2812b strip xiaomi yeelight color bulb please post slack team deviceapplication find work emulator check doc detail push update fast want notified watch repo contribution welcome hue living color light project 3d printing thingiverse 2773413 qthue also may want see new project qthue provides simple user interface controlling light credit ben cheesemarathon fancy github integration stephan van rooij zigbee2mqtt integration avinashraja98 hue entertainment server federico zivolo fezvrasta internal webgui j3n50m4t yeelight integration martin cerny mcer12 yeelight color bulb probonopd httpsgithubcomprobonopdesp8266hueemulator sidoh httpsgithubcomsidohesp8266milighthub stefanbruens httpsgithubcomstefanbruensesp8266newpwm cedric ticed35 linkbutton implementation cheesemarathon help docker image mevel 433mhz device nikfinn99 pcb design crankyoldgit ir remote library\n",
      "  (0, 39)\t0.20574929758148947\n",
      "  (0, 37)\t0.20574929758148947\n",
      "  (0, 36)\t0.19772753245840777\n",
      "  (0, 35)\t0.16755839698909866\n",
      "  (0, 34)\t0.22886747527782092\n",
      "  (0, 32)\t0.1646717114123612\n",
      "  (0, 31)\t0.21902029937504894\n",
      "  (0, 30)\t0.20574929758148947\n",
      "  (0, 27)\t0.17671125175586255\n",
      "  (0, 26)\t0.21441346396079244\n",
      "  (0, 24)\t0.15383824810311755\n",
      "  (0, 23)\t0.18327352114137932\n",
      "  (0, 22)\t0.22886747527782092\n",
      "  (0, 21)\t0.2016641224249154\n",
      "  (0, 20)\t0.19025944779556908\n",
      "  (0, 19)\t0.2016641224249154\n",
      "  (0, 18)\t0.18671013657480207\n",
      "  (0, 15)\t0.22886747527782092\n",
      "  (0, 14)\t0.22383194903010323\n",
      "  (0, 12)\t0.20999471598563593\n",
      "  (0, 9)\t0.20999471598563593\n",
      "  (0, 7)\t0.22886747527782092\n",
      "  (0, 3)\t0.22383194903010323\n",
      "  (0, 2)\t0.21441346396079244\n",
      "lain lain docker paas devops startup iaa idc latest release 211 release note quick start curl fssl httpsgithubcomlaincloudlainarchivev211targz tar xf cd lain211 vagrant config dns local shell sudo bash c echo 19216877201 consolelainlocal etchosts console httpconsolelainlocal install lain lain app demo lain contributor qiangning hong jia mi flex tachikoma cloudfly baijian pan li meng wenbin chaoyiwang zhuoyun wei xu tao chang cheng xu yunnan zhang kai xu zhuofu luo libin license lain licensed mit license\n",
      "  (0, 21)\t0.5794454298872266\n",
      "  (0, 16)\t0.6576093506614568\n",
      "  (0, 13)\t0.48144878824795534\n",
      "archived content repo merged ipfsjsipfs please open issue submit pr javascript http client library ipfs implementation client library ipfs http api implemented javascript client library implement interfaceipfscore enabling application change embedded jsipfs node remote ipfs node without change code addition client library implement set utility function lead maintainer alan shaw table content lead maintainer table content install running daemon right port importing module usage importing submodule usage web browser cors custom header global timeouts usage api file graph network node management additional option instance utils static type utils glob source globsourcepath option example url source urlsourceurl example development testing contribute historical context license install module us nodejs installed npm npm install save ipfshttpclient support current active lts version nodejs please see nodejsorg currently running daemon right port interact api need local daemon running need open right port 5001 default used example set whatever need show ipfs config api port check correct ipfs config addressesapi ip4127001tcp5001 set doe match output ipfs config addressesapi ip4127001tcp5001 restart daemon changing config run daemon ipfs daemon importing module usage const ipfsclient requireipfshttpclient connect ipfs daemon api server const ipfs ipfsclienthttplocalhost5001 default nodejs connect multiaddr const ipfs ipfsclientip4127001tcp5001 using option const ipfs ipfsclient host localhost port 5001 protocol http specifying specific api path const ipfs ipfsclient host 1111 port 80 apipath ipfsapiv0 importing submodule usage const bitswap requireipfshttpclientsrcbitswapip4127001tcp5001 const list await bitswapwantlistkey web browser browserify nodejs browserify code serving see browserify repo see example example folder get boilerplate webpack see example example folder get idea use jsipfshttpclient webpack cdn instead local installation browserification may request remote copy ipfs api unpkg cdn always request latest version use following script srchttpsunpkgcomipfshttpclientdistindexminjsscript note remove min url get humanreadable minified version maximum security may also decide reference specific version ipfs api prevent unexpected breaking change newer latest version published generate sri hash version use ensure integrity set cors setting attribute make anonymous request cdn example script srchttpsunpkgcomipfshttpclient900distindexjs integritysha3845bxrcw9kyxxnsmboohzraqa7z0pqwiaocgeg327zit1hz5lzcebimxlwkpreub crossoriginanonymousscript cdnbased ipfs api provides ipfshttpclient constructor method global window object example const ipfs windowipfshttpclient host localhost port 5001 omit host port client parse windowhost use information also work useful want write apps run multiple different gateway const ipfs windowipfshttpclient cors web browser ipfs http client either browserified cdnbased might encounter error saying origin allowed would cors cross origin resource sharing failure ipfs server designed reject request unknown domain default whitelist domain calling changing ipfs config like ipfs config json apihttpheadersaccesscontrolalloworigin httpexamplecom ipfs config json apihttpheadersaccesscontrolallowmethods put post get custom header wish send custom header request made library example authorization header use config const ipfs ipfsclient host localhost port 5001 protocol http header authorization bearer token global timeouts set global timeout request pas value timeout option timeout 10 second const ipfs ipfsclient timeout 10000 timeout 2 minute const ipfs ipfsclient timeout 2m see httpswwwnpmjscompackageparseduration valid string value usage api jsipfshttpclient follows spec defined interfaceipfscore concern interface expect ipfs implementation interface currently active endeavor use today consult method available file regular file api ipfsadddata option ipfscatipfspath option ipfsgetipfspath option ipfslsipfspath mf mutable file system specific ipfsfilescpfrom ipfsfilesflushpath ipfsfileslspath option ipfsfilesmkdirpath option ipfsfilesmvfrom ipfsfilesreadpath option ipfsfilesrmpath option ipfsfilesstatpath option ipfsfileswritepath content option explore mutable file system interactive coding challenge protoschool tutorial block ipfsblockgetcid option ipfsblockputblock option ipfsblockstatcid ref ipfsrefsipfspath option ipfsrefslocal graph dag ipfsdaggetcid path option ipfsdagputdagnode option ipfsdagtreecid path option explore dag api interactive coding challenge protoschool tutorial object ipfsobjectdatamultihash option ipfsobjectgetmultihash option ipfsobjectlinksmultihash option ipfsobjectnewtemplate ipfsobjectpatchaddlinkmultihash daglink option ipfsobjectpatchappenddatamultihash data option ipfsobjectpatchrmlinkmultihash daglink option ipfsobjectpatchsetdatamultihash data option ipfsobjectputobj option ipfsobjectstatmultihash option pin ipfspinaddhash option ipfspinlshash option ipfspinrmhash option network bootstrap ipfsbootstrapaddaddr option ipfsbootstraplist ipfsbootstraprmaddr option bitswap ipfsbitswapstat ipfsbitswapwantlistpeerid ipfsbitswapunwantcid dht ipfsdhtfindpeerpeerid ipfsdhtfindprovshash ipfsdhtgetkey ipfsdhtprovidecid ipfsdhtputkey value pubsub ipfspubsublstopic ipfspubsubpeerstopic ipfspubsubpublishtopic data ipfspubsubsubscribetopic handler option ipfspubsubunsubscribetopic handler swarm ipfsswarmaddrs ipfsswarmconnectaddr ipfsswarmdisconnectaddr ipfsswarmpeersoptions name ipfsnamepublishaddr option ipfsnamepubsubcancelarg ipfsnamepubsubstate ipfsnamepubsubsubs ipfsnameresolveaddr option node management miscellaneous operation ipfsdnsdomain ipfsid ipfspingid option ipfsstop alias ipfsshutdown ipfsversion config ipfsconfiggetkey ipfsconfigreplaceconfig ipfsconfigsetkey value ipfsconfigprofileslist ipfsconfigprofilesapplyname option stats ipfsstatsbitswap ipfsstatsbwoptions ipfsstatsrepooptions log ipfsloglevelsubsystem level option ipfslogls ipfslogtail repo ipfsrepogcoptions ipfsrepostatoptions ipfsrepoversion key ipfskeyexportname password ipfskeygenname option ipfskeyimportname pem password ipfskeylistoptions ipfskeyrenameoldname newname ipfskeyrmname additional option core api method take additional option specific http api header object header instance used set custom http header note option also configured globally via constructor option signal abortsignal used abort request demand timeout number string specifying timeout request timeout reached data received timeouterror thrown number specified interpreted millisecond string passed intepreted according parseduration note option also configured globally via constructor option searchparams object urlsearchparams instance used add additional query parameter query string sent request instance utils ipfsgetendpointconfig call client instance return object containing host port protocol apipath static type utils aside default export ipfshttpclient export various type utility included bundle buffer multiaddr multibase multicodec multihash cid globsource available browser urlsource accessed like example const cid requireipfshttpclient esmodule import cid ipfshttpclient glob source utility allow file file system easily added ipfs globsourcepath option path path single file directory glob option optional option optionsrecursive path directory use option recursive true add directory subdirectory optionsignore exclude file glob directory use option ignore ignorethisfolder andthisfile optionshidden hiddendot file file folder starting example git included default add use option hidden true return async iterable yield path content object suitable passing ipfsadd example const ipfshttpclient requireipfshttpclient const globsource ipfshttpclient const ipfs ipfshttpclient await const file ipfsaddglobsourcedocs recursive true consolelogfile path docsassetsanchorjs cid cidqmvhxrocowguchlevfeyduud6qj4phddl2dtlcpuy3dsc2 size 15347 path docsassetsbassaddonscss cid cidqmpilwkd6ysemwdtghegb8t7wvs7zwgygyvfj7dgnt2viq size 232 url source utility allow content internet easily added ipfs urlsourceurl url string url url instance send http get request return async iterable yield path content object suitable passing ipfsadd example const ipfshttpclient requireipfshttpclient const urlsource ipfshttpclient const ipfs ipfshttpclient await const file ipfsaddurlsourcehttpsipfsioimagesipfslogosvg consolelogfile path ipfslogosvg cid cidqmtqzhr6f7jzdhlgpardpnsbzpvvgxzczycxk7ywklxsyu size 3243 development testing run test executing npm test terminal window run nodejs browser test chrome phantomjs ensure module conforms interfaceipfscore spec run batch test provided interface module found contribute jsipfshttpclient work progress thing right help check existing issue perform code review eye help speed project along b ensure quality c reduce possible future bug add test never enough test note interface test exist inside interfaceipfscore contribute faq repository question ipfs relevant technology good example would asking merkledag tree dont know term odds someone else doesnt either eventually good understanding need improve communication teaching together make ipfs ipns better want hack ipfs historical context module started direct mapping goipfs cli javascript implementation although wa useful familiar lot developer coming ipfs first time also created confusion operate core ipfs access full capacity protocol much consideration decided create interfaceipfscore goal standardizing interface core implementation ipfs keep utility function ipfs community learned use love reading file disk storing directly ipfs license mit\n",
      "  (0, 39)\t0.17465627013224294\n",
      "  (0, 37)\t0.17465627013224294\n",
      "  (0, 36)\t0.16784676170259952\n",
      "  (0, 35)\t0.14223681437290359\n",
      "  (0, 33)\t0.18201109953580336\n",
      "  (0, 32)\t0.13978636743673448\n",
      "  (0, 31)\t0.18592174564747957\n",
      "  (0, 30)\t0.17465627013224294\n",
      "  (0, 29)\t0.17118845048925468\n",
      "  (0, 28)\t0.17465627013224294\n",
      "  (0, 27)\t0.15000648111498302\n",
      "  (0, 26)\t0.18201109953580336\n",
      "  (0, 25)\t0.18592174564747957\n",
      "  (0, 24)\t0.1305900672964747\n",
      "  (0, 23)\t0.15557705417622722\n",
      "  (0, 22)\t0.19428080706217568\n",
      "  (0, 21)\t0.17118845048925468\n",
      "  (0, 19)\t0.17118845048925468\n",
      "  (0, 18)\t0.15849432505168567\n",
      "  (0, 17)\t0.16784676170259952\n",
      "  (0, 16)\t0.19428080706217568\n",
      "  (0, 15)\t0.19428080706217568\n",
      "  (0, 14)\t0.19000625427916532\n",
      "  (0, 13)\t0.14223681437290359\n",
      "  (0, 11)\t0.19000625427916532\n",
      "  (0, 10)\t0.15849432505168567\n",
      "  (0, 8)\t0.16462234965734082\n",
      "  (0, 7)\t0.19428080706217568\n",
      "  (0, 6)\t0.16462234965734082\n",
      "  (0, 5)\t0.16784676170259952\n",
      "  (0, 4)\t0.14223681437290359\n",
      "  (0, 3)\t0.19000625427916532\n",
      "  (0, 2)\t0.18201109953580336\n",
      "  (0, 0)\t0.17118845048925468\n",
      "ng6 de facto starter repo building scalable apps angular es6 webpack repo serf minimal starter looking get upandrunning angular es6 using gulp webpack build process seed yeoman generator minimal starter task building boilerplate feature best practice directoryfile organization angular allowing infinite horizontal app scaling readytogo build system working es6 task generating additional boilerplate angular component full testing system place sas support via nodesass check jspm versionan alternative webpack es6 build system youre looking preliminary angular 2 build please use angular2webpackstarter table content walkthrough build system file structure testing setup getting started dependency installing running app gulp task testing generating component starter kit support question walkthrough build system ng6 us npm script gulp webpack together build system yes dont need gulp youre using webpack true build system responsible file manipulation however webpack handle filerelated concern transpiling es6 es5 babel loading html file module transpiling stylesheets appending dom refreshing browser rebuilding file change hot module replacement transpiled stylesheets bundling app loading module specjs file well gulp orchestrator starting calling webpack starting development server yes webpack generating boilerplate angular app check jspm versionan alternative webpack es6 build system file structure use componentized approach ng6 eventual standard particularly helpful using angulars new router well great way ensure tasteful transition angular 2 time ripe everythingor mostly everything well explore belowis component component selfcontained concernmay feature strictlydefined everpresent element ui header sidebar footer also characteristic component harness stylesheets template controller route service spec encapsulation allows u comfort isolation structural locality look client app appjs app entry file apphtml app template common functionality pertinent several component propagate directory component component live componentsjs component entry file home home component homejs home entry file route configuration declaration occur homecomponentjs home directive homecontrollerjs home controller homescss home style homehtml home template homespecjs home spec entry component controller testing setup test also written es6 use webpack take care logistics getting file run various browser like client file testing stack karma webpack babel mocha chai run test type npm test terminal read testing getting started dependency tool needed run app node npm installing fork repo clone fork npm install install dependency running app ng6 us gulp build launch development environment installed dependency may run app running npm start bundle app webpack launch development server watch file port displayed terminal task list available task npm run build run webpack transpile concatenate compress collectively bundle asset module distbundlejs also prepares indexhtml used application entry point link asset created dist version application npm run serve start dev server via webpackdevserver serving client folder npm run watch alias serve npm start default task run typing gulp without providing argument run serve npm run component scaffold new angular component read usage detail testing run test run npm test karma combined webpack run file matching specjs inside app folder allows u keep test file local componentwhich keep u good faith continuing build app modularly file specbundlejs bundle file spec file karma run sure define specjs file within corresponding component directory must name spec file like namespecjs dont want use specjs suffix must change regex specbundlejs look whatever file want mocha testing suite chai assertion library would like change see karmaconfjs example always easier learn something example list repos based starter todomvc example app generating component following consistent directory structure component offer u certainty predictability take advantage certainty creating gulp task automate instantiation component component boilerplate task generates componentname componentnamejs entry file dependency load componentnamecomponentjs componentnamecontrollerjs componentnamehtml componentnamescss scoped affect template componentnamespecjs contains passing demonstration test may course create file manually every time new module needed get quickly tedious generate component run npm run component name componentname parameter following name flag name component created ensure unique overwrite preexisting identicallynamed component component created default inside clientappcomponents change apply parent flag followed path relative clientappcomponents example running npm run component name signup parent auth create signup component clientappcomponentsauthsignup running npm run component name footer parent common creates footer component clientappcommonfooter argument name applies folder name actual component name make sure camelcase component name starter kit support question contact u anytime regarding anything project gitter angularclassng6starter twitter patrickjs enjoy patrickjs\n",
      "  (0, 38)\t0.22364720180416336\n",
      "  (0, 37)\t0.20105633018153665\n",
      "  (0, 36)\t0.19321753473395425\n",
      "  (0, 35)\t0.16373653171956232\n",
      "  (0, 33)\t0.20952287425620097\n",
      "  (0, 32)\t0.16091568899849817\n",
      "  (0, 31)\t0.21402463165235397\n",
      "  (0, 30)\t0.20105633018153665\n",
      "  (0, 27)\t0.17268061761303316\n",
      "  (0, 24)\t0.15032932782149255\n",
      "  (0, 23)\t0.1790932071859919\n",
      "  (0, 20)\t0.18591979076376808\n",
      "  (0, 19)\t0.19706433441394838\n",
      "  (0, 18)\t0.18245143632898836\n",
      "  (0, 17)\t0.19321753473395425\n",
      "  (0, 15)\t0.22364720180416336\n",
      "  (0, 13)\t0.16373653171956232\n",
      "  (0, 11)\t0.2187265316497589\n",
      "  (0, 10)\t0.18245143632898836\n",
      "  (0, 9)\t0.20520491418379685\n",
      "  (0, 8)\t0.18950573868837287\n",
      "  (0, 7)\t0.22364720180416336\n",
      "  (0, 5)\t0.19321753473395425\n",
      "  (0, 3)\t0.2187265316497589\n",
      "  (0, 2)\t0.20952287425620097\n",
      "  (0, 1)\t0.21402463165235397\n",
      "gitrepo git service cli utility get source httpsgithubcomguyzmogitrepo httpsgitlabcomguyzmogitrepo httpsbitbucketorgguyzmogitrepo issue httpsgithubcomguyzmogitrepoissues meet community come chat irc gitrepo freenode matrix gitrepomatrixorg gitter gitservicesgitrepo looking help past month ive really busy coding stuff put food table sadly cannot give project love deserves taken month spend hour merge release pr featured repository im still using project daily im enough time keep putting effort needed make shine ssh key issue support id like share maintenance responsibility someone people youre interested please ping irc mail commits im always happy guide code design usage main command control remote git hosting service git commandline usage simple full usage list source clone new project github issue git hub clone guyzmogitrepo work also project gitlab bitbucket gitlab gogs git lab clone guyzmogitrepo git bb clone guyzmogitrepo git myprecious clone guyzmogitrepo git gg clone guyzmogitrepo want choose default branch clone git lab clone guyzmogitrepo master though sometimes youre starting new project want create new repository push git hub create guyzmogitrepo actually namespace facultative per default want create new repository within account might also want add existing remote ref workspace easily done git lab add guyzmogitrepo add httpsgitlabcomguyzmogitrepo gitlab remote also fork repository using git hub fork neovimneovim course delete using git bb delete guyzmogitrepo also open repository page using open command git lab open guyzmogitrepo successfully fetched branch 2 guyzmogitrepo request2 request merges aka pull request aka merge request youre set repository check request merge aka pull request github using request command git hub request guyzmogitrepo list list open request merge id title url 2 prefer gitrepotargettoken privatekey doc httpsapigithubcomreposguyzmogitrepoissues2 fetch locally check andor amend merging git hub request guyzmogitrepo fetch 2 create request git hub request create guyzmogitrepo myfeature master neat feature much say feature create request also simply calling git hub request create command ha bit automagic lookup namespace project current branch least github remote called hub take source request target request lookup take parent current project ha parent doe take currently loaded branch source default one target call service ask request merge source onto target gist snippet finally another extra feature play gist handling git hub gist list id title httpsgistgithubcom4a0dd9177524b2b125e9166640666737 test gist list file within git hub gist list a7ce4fddba7744ddf335 language size name python 1048 unicodecombinedpy git hub v gist list httpsgistgithubcom4a0dd9177524b2b125e9166640666737 language size name markdown 16 readmemd text 14 license restructuredtext 17 readmerst output locally use fetch command specify file one git hub gist fetch httpsgistgithubcoma7ce4fddba7744ddf335 mygistpy git hub gist fetch 4a0dd9177524b2b125e9166640666737 license licensefromgist thorough modification consulting well clone git hub gist clone 4a0dd9177524b2b125e9166640666737 pulling github successfully cloned 4a0dd9177524b2b125e9166640666737 4a0dd9177524b2b125e9166640666737 youre done get rid git hub gist f delete 4a0dd9177524b2b125e9166640666737 successfully deleted gist nota bene thanks git cli flexibility installing gitrepo directly access tool using gitrepo hub git repo hub git hub call set alias see configure remote traditionally origin used remote name code hosted service nature gitrepo single origin encourages use multiple one also leave control wherever origin point clone service create new repo service using special remote carry name service git hub clone foobar cd bar git status sb head 1 mastergithubmaster git lab create bar git push gitlab master bonus time adding new remote updating remote push code remote repository one command git push master another special remote upstream fork project current special remote service name renamed upstream newly forked project one service name git lab clone foobar cd bar git remote gitlab git lab fork git remote gitlab upstream finally want link existing project add command git bb add foobar name identical current project dont need add name git hub add git gg add foobar gitea alone use alone switch dont want add project special remote course command sugar around regular git command also done git remote add gitbucket httpsgitbucketlocal8080foobar command append url remote alone skip step git remote seturl add httpsgitbucketlocal8080foobar remove remote git remote remove github installation get tool using pypi use pip3 python2 python3 installed pip install gitrepo getting source running python3 setuppy install configuration configure gitrepo simply call following command git repo config wizard run getting authentication token service add command alias name remote though configuring custom service still handled wizard prefer manual configuration youll tweak gitconfig service youve got account make section gitconfig gitrepo gitlab token yourverysecretkey gitrepo github token yourotherverysecretkey gitrepo bitbucket username fordprefect token yoursecretappkey gitrepo gogs fqdn urlofyourgogs token yourverysecretkey setting basic private token notice token needed bitbucket apptoken confused oauthtoken also avaiable butbucket setting also ability set alias gitrepo bitbucket alias bit username fordprefect token yoursecretappkey change command use name youll prefer handle action service use gitrepo bit clone guyzmogitrepo also setup gitlab selfhosted server using configuration gitrepo myprecious type gitlab token yoursuperprivatekey fqdn gitlabexampleorg set use selfsigned certificate experience problem insecure true finally make really cool make alias gitconfig alias hub repo hub lab repo lab bb repo bb perso repo perso run tool git subcommand git hub clone guyzmogitrepo like keep dotfiles git repository itd horrendous store token offer access social account repository im even talking want share dotfiles dont worry configured fire favorite editor move gitrepo section new file like gitconfigrepos run following command automagically python gitrepoextractconfig want use another path change default python gitrepoextractconfig gitconfigrepos gitconfig configuring gerrit please note configuration wizard ask password provide gerrit account password enter http password instead setup setting http password page may also need tweak gitconfig set rosuffix gerrit isnt served server root example set rosuffix r gerrit hosted httpsreviewhostcomr set sshport parameter set custom port ssh connection gerrit default 29418 set authtype basic default digest development development start virtualenv within install devel requirement virtualenv var varbinpip install r requirementstesttxt youll executable bin varbingitrepo help run test varbinpytest covgitrepo covreport termmissing capturesys test nb buildout longer supported development verbose running repeat v argument several time increase level verbosity gitrepo argument give detail youll v set debugging level debug giving execution info vv print git command executed vvv give verbose insight git layer vvvv output http exchange different apis vvvvv printout parsed argument testing run test binpytest use following option pytest help debug test fail v show detail upon error x stop upon first failure pdb launch debugger exception ha launched test use recording exchanged http data dont need real credential real connection testing api minor change recording called cassette thanks betamax framework use test suite running existing test based provided cassette dont need setting also youve got configuration gitconfig test use anyway use environment variable setting environment variable precedence configuration setting use credential setup following environment variable githubnamespace default notconfigured name account use github gitlabnamespace default notconfigured name account use gitlab bitbucketnamespace default notconfigured name account use bitbucket gogsnamespace default notconfigured name account use gogs privatekeygithub private token youve setup github account privatekeygitlab private token youve setup gitlab account privatekeybitbucket private token youve setup bitbucket account privatekeygogs private token youve setup gogs account todo make gitrepo fork action make possible choose method ssh http handle default branch properly make nice way push remote refactor code multiple module add regression test actually find smart way implement add travis build show nice progress bar fetching cf 15 add support handling gist cf 12 cf 13 add support handling pull request cf 10 11 add application token support bitbucket cf 14 add support gogs cf 18 add support gitbucket cf 142 add support managing ssh key cf 22 add support issue cf 104 add support gerrit cf 19 whats needed make nice documentation 146 feature write issue even better pr contributor project original idea ha brought maintained bernard guyzmo pratz commits code contribution coming pyhedgehog commits guyhughes commits buaazp commits peterazmanov commits crazybus commits rnestler commits jayvdb commits kounoike commits amandacameron commits fa7ad commits license copyright 20162017 bernard guyzmo pratz guyzmogitrepopubm0gnet program free software redistribute andor modify term gnu general public license published free software foundation either version 2 license option later version program distributed hope useful without warranty without even implied warranty merchantability fitness particular purpose see gnu general public license detail received copy gnu general public license along program write free software foundation inc 51 franklin street fifth floor boston 021101301 usa see license file full license\n",
      "  (0, 39)\t0.16472573652149006\n",
      "  (0, 38)\t0.18323446968766097\n",
      "  (0, 37)\t0.16472573652149006\n",
      "  (0, 36)\t0.1583034002917458\n",
      "  (0, 35)\t0.1341495727024668\n",
      "  (0, 33)\t0.17166238809188072\n",
      "  (0, 32)\t0.13183845225965846\n",
      "  (0, 31)\t0.17535068431241158\n",
      "  (0, 30)\t0.16472573652149006\n",
      "  (0, 29)\t0.16145508872635272\n",
      "  (0, 28)\t0.16472573652149006\n",
      "  (0, 27)\t0.14147747496241145\n",
      "  (0, 26)\t0.17166238809188072\n",
      "  (0, 25)\t0.17535068431241158\n",
      "  (0, 24)\t0.1231650315303026\n",
      "  (0, 23)\t0.14673131869596556\n",
      "  (0, 22)\t0.18323446968766097\n",
      "  (0, 21)\t0.16145508872635272\n",
      "  (0, 20)\t0.15232434830492814\n",
      "  (0, 19)\t0.16145508872635272\n",
      "  (0, 18)\t0.14948272059656\n",
      "  (0, 17)\t0.1583034002917458\n",
      "  (0, 16)\t0.18323446968766097\n",
      "  (0, 14)\t0.17920295765005578\n",
      "  (0, 13)\t0.1341495727024668\n",
      "  (0, 12)\t0.1681246772794187\n",
      "  (0, 11)\t0.17920295765005578\n",
      "  (0, 10)\t0.14948272059656\n",
      "  (0, 9)\t0.1681246772794187\n",
      "  (0, 8)\t0.15526232052631944\n",
      "  (0, 7)\t0.18323446968766097\n",
      "  (0, 6)\t0.15526232052631944\n",
      "  (0, 5)\t0.1583034002917458\n",
      "  (0, 4)\t0.1341495727024668\n",
      "  (0, 3)\t0.17920295765005578\n",
      "  (0, 2)\t0.17166238809188072\n",
      "  (0, 1)\t0.17535068431241158\n",
      "  (0, 0)\t0.16145508872635272\n",
      "php report reporting framework managing displaying nice looking exportable report data source including sql mongodb major feature include display report data source output tabular data sql mongodb php etc output report html xml csv json custom format add customizable parameter report eg start date end date add graph chart google data visualization api support multiple database environment eg production staging dev fully extendable customizable installation instruction documentation check httpjdorngithubiophpreports question post official forum httpostiojdornphpreports basic introduction report organized grouped directory report file report consists header containing metadata eg name description actual report sql query javascript php code report return row data displayed sortablesearchable html table report exported number format including csv xl json xml php report framework tie together different report type output format metadata consistent interface example report example sql report product cost least x variable name minprice select name price product price minprice set sql comment top report header first row always report name variable header tell report framework prompt user value running report provided passed report body minprice example executed mongodb report list food option mongodatabase mydatabase variable name includeinactive display include inactive type select option yesno var query type food ifincludeinactive querystatus active var result dbproductsfindquery printjsonresult see structure similar mongodb report use javascript style comment header everything else remains populate db variable specifying mongodatabase option php report php list payment charge connects stripe payment api show list charge include stripephp variable name count display number display ifcount 100 count 1 throw new exceptioncount must 1 100 charge stripechargeallarraycount count row array foreachcharges charge row array charge idchargeid amountnumberformatchargeamount1002 datedateymdchargecreated echo jsonencoderows header format similar include header includes another report within running one example content stripephp php stripe php included report header even nested include header header even bubble parent variable header include stripe api client requireoncelibstripestripephp set stripe api key stripesetapikey123456 hopefully begin see power php report full documentation information getting started check httpjdorngithubiophpreports\n",
      "  (0, 34)\t0.31921356523898603\n",
      "  (0, 32)\t0.22967634011838664\n",
      "  (0, 30)\t0.28696942082608384\n",
      "  (0, 29)\t0.2812716111011644\n",
      "  (0, 28)\t0.28696942082608384\n",
      "  (0, 20)\t0.2653649085677221\n",
      "  (0, 10)\t0.2604144965987499\n",
      "  (0, 9)\t0.2928907302785245\n",
      "  (0, 8)\t0.27048316273115575\n",
      "  (0, 6)\t0.27048316273115575\n",
      "  (0, 4)\t0.23370255307658766\n",
      "  (0, 3)\t0.31219025061362377\n",
      "  (0, 0)\t0.2812716111011644\n",
      "celebration 1k star repo starhistory chrome extension 67 099 star history missing star history graph github repos website extension note load extension folder chrome install extension access token starhistory use github api retrieve repository metadata user exceed rate limit unauthenticated request starhistory need personal access token unlimit dont already one create one add starhistory scope personal data needed develop website npm run startwebsite extension npm run buildextension load extension folder unpacked extension chrome view build deploy website deploy starhistoryt9tio npm run deploywebsite extension npm run buildextension zip extension folder publish chrome web store update 2019828 use chartxkcd plot graph 2019306 add personal access token update style mono repo 2016630 alert notie 2016628 add clear btn 2016628 better view many star repos use current star number last point graph 2016626 store repo info url hash 2016626 multiple kind input style eg githubcomtimqianstarhistory 2016626 better view le star repos 28 2016614 toggle search hit enter 26 prevent crash searching existing repo 2016526 update mobile view\n",
      "  (0, 34)\t0.3070818212898892\n",
      "  (0, 32)\t0.22094746749859098\n",
      "  (0, 27)\t0.23710146217034403\n",
      "  (0, 26)\t0.28768822193816906\n",
      "  (0, 25)\t0.2938694209384874\n",
      "  (0, 24)\t0.20641172081880874\n",
      "  (0, 21)\t0.270581854970423\n",
      "  (0, 19)\t0.270581854970423\n",
      "  (0, 13)\t0.2248206638246296\n",
      "  (0, 7)\t0.3070818212898892\n",
      "  (0, 6)\t0.26020342267581203\n",
      "  (0, 5)\t0.26529995453822197\n",
      "  (0, 1)\t0.2938694209384874\n",
      "  (0, 0)\t0.270581854970423\n",
      "dockercasts companion repo course udemycom\n",
      "  (0, 24)\t1.0\n",
      "djangoreportbuilder gui django orm build custom query display result target sys admins capable end user might able program gain direct interactive shell access call sponsorship fan report builder using workplace please consider sponsorship may donate liberapay directly contact sponsoring feature right need better documentation get profile company logo added readme sponsor paid commercial support also available email infoburkesoftwarecom infomation news 64 added django 30 31 support django 111 22 still supported likely last release support 111 632 fixed admin widget thanks predatell angular updated version 8 63 added django 22 support django 111 21 still supported unit test finally run python 37 thanks celery supporting angular updated version 7 view changelog django report builder feature add filter add display field preview create xlsx report us django permission model staff user must change view permission view report unprivileged user still build report see database schema report builder intended generally trusted staff user requires isstaff set export report global admin action scheduled report generate send user cron like schedule optional asynchronous report generation documentation httpdjangoreportbuilderreadthedocsorg google group contributing development quick start package us django docker angular cli development purpose start docker dockercompose migrate create admin user dockercompose run rm web managepy migrate start angular cli server ensure node installed cd j yarn yarn start django run port 8000 default go localhost8000admin log angular run port 4200 logged go localhost4200 detailed instruction\n",
      "  (0, 36)\t0.27083048238024576\n",
      "  (0, 35)\t0.2295073474047628\n",
      "  (0, 34)\t0.3134833473111777\n",
      "  (0, 30)\t0.2818180190718405\n",
      "  (0, 28)\t0.2818180190718405\n",
      "  (0, 27)\t0.2420441552069865\n",
      "  (0, 19)\t0.2762224910009307\n",
      "  (0, 17)\t0.27083048238024576\n",
      "  (0, 9)\t0.28763303481600766\n",
      "  (0, 5)\t0.27083048238024576\n",
      "  (0, 2)\t0.2936854627745678\n",
      "  (0, 1)\t0.29999551702941435\n",
      "  (0, 0)\t0.2762224910009307\n",
      "urwid urwid console user interface library python includes many feature useful text console application developer including application resize quickly smoothly automatic programmable text alignment wrapping simple markup setting text attribute within block text powerful list box programmable content scrolling widget type choice event loop twisted glib tornado selectbased loop prebuilt widget include edit box button check box radio button display module include raw curse experimental lcd web display support utf8 simple 8bit cjk encoding 24bit true color 256 color 88 color mode support compatible python 27 35 pypy home page httpurwidorg installation install using pip pip install urwid alternatively debian ubuntu aptget install pythonurwid testing run test locally install run tox must appropriate python version installed run tox test code python version tox test version specified toxini tox e py36 test python 36 tox e py27py36pypy test python 27 python 36 pypy supported python version 27 35 36 37 38 pypy author creator wardi maintainer and3rson tonycpsu ulidtko contributor 1in7billion abadger agrenott akorb alethiophile aleufroy alobbs amjltc295 andsemakin andrewshadura andyz anttin2020 apteryks arfrever autoawesome belak berney bk2204 bkphcgql3v bwesterb carlosjenkins certseeds chipsterjulien chrisspen cltrudeau codebergasgithubalternativebuhtz cortesi d0cs4vage derdon dholth dimays dlo dnaeon doddo douglaslarocca drestebon dsotr dwf edwardbetts elenril enricobilla extempore fabiand floppym flowblok fmoreau goncalopp gordin gregingelmo grzaks gurupras harveyhunt hoolean hukka hydratim ids1024 imrek isovector itaisod ixxra jeblair johndeaton jonblack jspricke kedder kelketek kennethnielsen kesipyc kkrolczyk kwpolska lahorde laike9m larsks lfam lgbaldoni lighth7015 livibetter lothiraldan madness madebr magniff marloxouda mattymo mdtrooper mgk mimi1vx mobyte0 monaaraj monthlypython mountainstorm mselee mwhudson naquad nchavez324 neumond nolash ntamas nyov ocarneiro okayzed pquentin rbanffy reddykilowatt regebro renegarcia rianhunter roburban rrmoelker rwarren scopatz seanhussey seonon shadedke sithglan sjc1000 sporkexec squrky ssbr techdragon thehunmonkgroup thisch thornycrackers tomastomecek tompickering tony ttanner tu500 uspike vega0 vit1251 waveform80 wesmania xandfury xndcn zhongshangwu zrax\n",
      "  (0, 36)\t0.314272206067799\n",
      "  (0, 35)\t0.2663207617685967\n",
      "  (0, 34)\t0.3637666715324943\n",
      "  (0, 30)\t0.32702216451032856\n",
      "  (0, 27)\t0.2808684973500041\n",
      "  (0, 15)\t0.3637666715324943\n",
      "  (0, 13)\t0.2663207617685967\n",
      "  (0, 9)\t0.33376991982271836\n",
      "  (0, 4)\t0.2663207617685967\n",
      "  (0, 3)\t0.35576310256611665\n",
      "deepgcns gcns go deep cnns work present new way successfully train deep gcns borrow concept cnns mainly residualdense connection dilated convolution adapt gcn architecture extensive experiment show positive effect deep gcn framework project paper slide tensorflow code pytorch code overview extensive experiment show different component layer filter nearest neighbor dilation etc effect deepgcns also provide ablation study different type deep gcns mrgcn edgeconv graphsage gin information detail please contact guohao li matthias muller requirement tensorflow 1120 h5py vtk needed visualization jupyter notebook needed visualization conda environment order setup conda environment neccessary dependency run conda env create f environmentyml getting started find detailed instruction use code semantic segmentation 3d point cloud folder semseg currently provide following conda environment setup s3dis dataset training code evaluation code several pretrained model visualization code citation please cite paper find anything helpful inproceedingsli2019deepgcns titledeepgcns gcns go deep cnns authorguohao li matthias muller ali thabet bernard ghanem booktitlethe ieee international conference computer vision iccv year2019 miscli2019deepgcnsjournal titledeepgcns making gcns go deep cnns authorguohao li matthias muller guocheng qian itzel c delgadillo abdulellah abualshour ali thabet bernard ghanem year2019 eprint191006849 archiveprefixarxiv primaryclasscscv license mit license acknowledgement code heavily borrowed pointnet edgeconv would also like thank 3dsemanticsegmentation visualization code\n",
      "  (0, 39)\t0.31318485954575087\n",
      "  (0, 38)\t0.3483745944312937\n",
      "  (0, 32)\t0.2506578997647017\n",
      "  (0, 27)\t0.26898409477871615\n",
      "  (0, 23)\t0.27897296686704226\n",
      "  (0, 20)\t0.2896067162100883\n",
      "  (0, 17)\t0.300974390723196\n",
      "  (0, 16)\t0.3483745944312937\n",
      "  (0, 11)\t0.34070968087305525\n",
      "  (0, 5)\t0.300974390723196\n",
      "  (0, 4)\t0.25505191824996626\n",
      "deprecated use headless ui instead tailwinduivue project still prealpha state could change dramatically time production set completely unstyled fully accessible ui component vuejs designed integrate beautifully tailwind cs bring style markup handle complex keyboard interaction aria management installation npm npm install tailwinduivue yarn yarn add tailwinduivue usage listbox basic example template listbox vmodelselectedwrestler vslot isopen listboxlabel classsronly select wrestler listboxlabel listboxbutton classrounded p3 border selectedwrestler listboxbutton listboxlist vshowisopen listboxoption vforwrestler wrestler keywrestler valuewrestler vslot isactive isselected div classp3 classisactive bgblue600 textwhite bgwhite textgray900 wrestler img vshowisselected srccheckmarksvg div listboxoption listboxlist listbox template script import listbox listboxlabel listboxbutton listboxlist listboxoption tailwinduivue export default component listbox listboxlabel listboxbutton listboxlist listboxoption data return selectedwrestler ultimate warrior wrestler ultimate warrior randy savage hulk hogan bret hart undertaker mr perfect ted dibiase bam bam bigelow yokozuna script\n",
      "  (0, 32)\t0.28201884098336627\n",
      "  (0, 31)\t0.37509691526133343\n",
      "  (0, 28)\t0.3523688309267045\n",
      "  (0, 23)\t0.31387653393485276\n",
      "  (0, 13)\t0.2869626149543325\n",
      "  (0, 8)\t0.3321254075175379\n",
      "  (0, 6)\t0.3321254075175379\n",
      "  (0, 2)\t0.3672071910762466\n",
      "  (0, 0)\t0.3453725086501597\n",
      "react react javascript library building user interface declarative react make painless create interactive uis design simple view state application react efficiently update render right component data change declarative view make code predictable simpler understand easier debug componentbased build encapsulated component manage state compose make complex uis since component logic written javascript instead template easily pas rich data app keep state dom learn write anywhere dont make assumption rest technology stack develop new feature react without rewriting existing code react also render server using node power mobile apps using react native learn use react project installation react ha designed gradual adoption start use little much react need use online playground get taste react add react website script tag one minute create new react app youre looking powerful javascript toolchain use react script tag cdn react package npm documentation find react documentation website check getting started page quick overview documentation divided several section tutorial main concept advanced guide api reference get support contributing guide improve sending pull request repository example several example website first one get started function hellomessage name return divhello namediv reactdomrender hellomessage nametaylor documentgetelementbyidcontainer example render hello taylor container page youll notice used htmllike syntax call jsx jsx required use react make code readable writing feel like writing html youre using react script tag read section integrating jsx otherwise recommended javascript toolchains handle automatically contributing main purpose repository continue evolving react core making faster easier use development react happens open github grateful community contributing bugfixes improvement read learn take part improving react code conduct facebook ha adopted code conduct expect project participant adhere please read full text understand action tolerated contributing guide read contributing guide learn development process propose bugfixes improvement build test change react good first issue help get foot wet get familiar contribution process list good first issue contain bug relatively limited scope great place get started license react mit licensed\n",
      "  (0, 35)\t0.15630653480922463\n",
      "  (0, 34)\t0.21349859293258514\n",
      "  (0, 33)\t0.20001519571910484\n",
      "  (0, 32)\t0.15361369560992771\n",
      "  (0, 30)\t0.19193284444280595\n",
      "  (0, 26)\t0.20001519571910484\n",
      "  (0, 25)\t0.20431267345211096\n",
      "  (0, 23)\t0.17096635875406432\n",
      "  (0, 22)\t0.21349859293258514\n",
      "  (0, 20)\t0.1774831672660176\n",
      "  (0, 19)\t0.18812199649792877\n",
      "  (0, 18)\t0.1741721989836361\n",
      "  (0, 17)\t0.1844497559675446\n",
      "  (0, 16)\t0.21349859293258514\n",
      "  (0, 15)\t0.21349859293258514\n",
      "  (0, 14)\t0.20880121176360167\n",
      "  (0, 12)\t0.19589317499914696\n",
      "  (0, 9)\t0.19589317499914696\n",
      "  (0, 8)\t0.18090639290915816\n",
      "  (0, 7)\t0.21349859293258514\n",
      "  (0, 6)\t0.18090639290915816\n",
      "  (0, 5)\t0.1844497559675446\n",
      "  (0, 4)\t0.15630653480922463\n",
      "  (0, 3)\t0.20880121176360167\n",
      "  (0, 2)\t0.20001519571910484\n",
      "  (0, 1)\t0.20431267345211096\n",
      "  (0, 0)\t0.18812199649792877\n",
      "createopenapirepo generate organized multifile openapi repository hello need write contribute openapi definition read recommend docslikecode approach openapi definition write using favorite texteditor ide love vscode organize multiple file folder make easy navigate store using source control github continuously validate using free openapicli tool free continuous validation service coming soon bundle smaller footprint use tool tool support multifile format advantage hosting api definition github community engagement pr issue public repo advertisment github community hosting github page perfect uptime cdn jekyll custom domain cname revision history branching ci review approval workflow using pull request fast onboarding time developer tech writer know use github fully compatible redocly api reference also advantage multifile yaml format openapi definition reuse schema object keep thing dry dont repeat smaller diffs compared json especially markdown description easier navigate easier edit confidence feature generator help create github repo following feature split big small openapi definition smaller file organized folder bundle single file deployment continuous integrationdeployment travis redocly workflow code sample separate file automate deployment openapi definition doc openapi definition validated commit live editing editor choice structure structure similar redoclyyaml license readmemd doc faviconpng indexhtml openapi readmemd codesamples c echo postcs php echo postphp readmemd component readmemd path readmemd packagejson however adjust structure prefer openapi folder openapi definition live inside subfolders readmemd file help guide also entrypoint openapiyaml live component folder organize subfolders schema define schema path folder organize path readmemd file suggestion organize specially named file folder use place file cannot character also able use path parameter wrapping curly brace example redoclyyaml file universal configuration various redocly tool including lint tool reference doc engine command generated repository includes installing dependency openapicli tool support command validate bundle scripted shortcut defined repository packagejson example generated repository httpsgithubcomrebillyrebillyapi httpsgithubcomthingfulopenapispec httpsgithubcomtwinehealthtwinedeveloperdocs generate repository assume already nodejs installed install createopenapirepo globally npm install g createopenapirepo use npx well use npx example however remove npx installed globally npx createopenapirepo presented question create new definition use existing definition initialize project please note start new one remember create github repo openapi definition live use prior version generated repository please read following upgrade instruction upgrading prior version migrate repository previous structure openapi repo newer structure migration tool run root folder repo npx createopenapirepo migrate23 note migration tool doe migrate plugins automatically would need manually add transformer folder support thank wanting support u idea support u star u tell friend colleague u tweet u write article let u know open issue let u know link consider commercial product looking automation ease docslike code workflow hosting along convenience like custom domain access control preview api reference documentation full developer portal httpsredocly\n",
      "  (0, 36)\t0.18775900107828566\n",
      "  (0, 35)\t0.15911085750068604\n",
      "  (0, 32)\t0.15636970560556832\n",
      "  (0, 31)\t0.20797828261563192\n",
      "  (0, 30)\t0.19537634494369435\n",
      "  (0, 29)\t0.19149712591389376\n",
      "  (0, 27)\t0.16780226656575245\n",
      "  (0, 26)\t0.20360370308814593\n",
      "  (0, 25)\t0.20797828261563192\n",
      "  (0, 24)\t0.1460824167092194\n",
      "  (0, 23)\t0.1740336958933319\n",
      "  (0, 22)\t0.21732900827309973\n",
      "  (0, 21)\t0.19149712591389376\n",
      "  (0, 20)\t0.18066742359876795\n",
      "  (0, 19)\t0.19149712591389376\n",
      "  (0, 18)\t0.17729705265931694\n",
      "  (0, 17)\t0.18775900107828566\n",
      "  (0, 16)\t0.21732900827309973\n",
      "  (0, 14)\t0.2125473505726283\n",
      "  (0, 13)\t0.15911085750068604\n",
      "  (0, 11)\t0.2125473505726283\n",
      "  (0, 10)\t0.17729705265931694\n",
      "  (0, 9)\t0.1994077284784562\n",
      "  (0, 8)\t0.1841520659277865\n",
      "  (0, 7)\t0.21732900827309973\n",
      "  (0, 5)\t0.18775900107828566\n",
      "  (0, 4)\t0.15911085750068604\n",
      "  (0, 0)\t0.19149712591389376\n",
      "practical tensorflow repository deepctr deepfmwidendeepfnnpnnnfmafmdeep cross networkctr deeprl deepreinforcement learing deepmtl multitask learning deeptxt dssm welcome pull request\n",
      "  (0, 26)\t0.6995516458802439\n",
      "  (0, 25)\t0.7145820419981473\n",
      "rasa core deprecated code part rasa repo httpsgithubcomrasahqrasa please create pull request issue license licensed apache license version 20 copyright 2019 rasa technology gmbh copy license list license dependency project found bottom library summary\n",
      "  (0, 36)\t0.32756911343083356\n",
      "  (0, 26)\t0.3552121822591643\n",
      "  (0, 24)\t0.2548590877372679\n",
      "  (0, 23)\t0.3036235980351251\n",
      "  (0, 16)\t0.3791576976548728\n",
      "  (0, 15)\t0.3791576976548728\n",
      "  (0, 14)\t0.3708154964039188\n",
      "  (0, 5)\t0.32756911343083356\n",
      "  (0, 4)\t0.2775888358448828\n",
      "nature code book project repo longer active follow project visit nocbook2 hello found way found raw source material nature code book book sale pdf print form natureofcodecom youll also find free version book available html may notice book content illustration raw text html well design element cs book licensed creative common attributionnoncommercial 30 unported license free share remix book long provide attribution attempt resell book code example licensed mit license using github host raw material book hope able easily manage correction revision please use github issue bug report typo suggestion etc also welcome fork repo make correction submit pull request repository progress new edition book generating magic book previous version book check nature code archived repo step build nature code install nodejs terminal prompt info npm install magicbook g clone download repo terminal navigate directory cloned repo enter command npm install magicbook build navigate build directory look generated file build note mac osx need install princexml along nodeprince brew cask install prince download via information magic book readme\n",
      "  (0, 38)\t0.25272572900829837\n",
      "  (0, 36)\t0.21833960777914718\n",
      "  (0, 35)\t0.18502549555863224\n",
      "  (0, 32)\t0.18183788790091188\n",
      "  (0, 29)\t0.22268656694354888\n",
      "  (0, 26)\t0.23676496156960497\n",
      "  (0, 25)\t0.24185203581235584\n",
      "  (0, 24)\t0.16987509192393987\n",
      "  (0, 23)\t0.2023788403404538\n",
      "  (0, 21)\t0.22268656694354888\n",
      "  (0, 20)\t0.21009301381283318\n",
      "  (0, 19)\t0.22268656694354888\n",
      "  (0, 18)\t0.2061737052057154\n",
      "  (0, 16)\t0.25272572900829837\n",
      "  (0, 14)\t0.24716527512401423\n",
      "  (0, 13)\t0.18502549555863224\n",
      "  (0, 10)\t0.2061737052057154\n",
      "  (0, 8)\t0.21414520537222106\n",
      "  (0, 4)\t0.18502549555863224\n",
      "  (0, 3)\t0.24716527512401423\n",
      "  (0, 1)\t0.24185203581235584\n",
      "mongocasts example course found within repo either look file completed state check change made particular section clicking one link\n",
      "  (0, 24)\t0.3508950016484679\n",
      "  (0, 10)\t0.4258736334366326\n",
      "  (0, 8)\t0.4423396116585556\n",
      "  (0, 3)\t0.510546064404293\n",
      "  (0, 2)\t0.4890631147823848\n",
      "halloffame halloffame help show love contributor automatically highlight new trending top contributor update every hour put widget anywhere inside readme eg contributing section maintenance required work every hour halloffame look recent commits repo using github api selects three category contributor new made first commit repo last 7 day trending commits last 7 day top commits time selects three new contributor 4 trending contributor total le 7 fill remaining spot top contributor contributor halloffame represented avatar badge newtrendingtop corresponding number commits avatar link contributor profile mean anyone ha chance prominently featured readme time halloffame work sourcerer httpssourcererio required contributor contributor ha sourcerer profile sourcerer avatar halo used avatar link sourcerer profile dont avatar based github used linked github profile live example iterativedvc ironmussaoptimus epicmaxcovuesticadmin getting started halloffame code entirely open source run google cloud already order add halloffame repository sign sourcererio github httpssourcereriostart go settingshalloffame httpssourcereriosettingshof add repository see code insert readmemd look something like httpssourcereriofameuserownerrepoimages0httpssourcereriofameuserownerrepolinks0 httpssourcereriofameuserownerrepoimages7httpssourcereriofameuserownerrepolinks7 paste code readmemd good go halloffame take care rest note halloffame use github token hourly update via github api count towards github api limit large repo shoud expect dozen request every hour small percentage 5000 hourly limit github set faq q show 7 entry 7 lucky number seriously recognition mean stand hard stand crowd limit 7 strongly feel different number better file issue well consider q reason show new trending top order want halloffame change frequently hence emphasis change last week want immediately exciting first time contributor need new contributor right better make excited q commited dont see face halloffame going refreshes hour sometimes take bit longer wait another possibility enough contributor commits week contributor sorted number commits push another commit increase chance show halloffame contributing contribute halloffame mean live halloffame repo\n",
      "  (0, 39)\t0.20143672353827413\n",
      "  (0, 37)\t0.20143672353827413\n",
      "  (0, 35)\t0.1640463169865326\n",
      "  (0, 33)\t0.20991928609451335\n",
      "  (0, 32)\t0.16122013730427692\n",
      "  (0, 31)\t0.21442956069878205\n",
      "  (0, 29)\t0.1974371750183366\n",
      "  (0, 28)\t0.20143672353827413\n",
      "  (0, 27)\t0.17300732485830125\n",
      "  (0, 26)\t0.20991928609451335\n",
      "  (0, 25)\t0.21442956069878205\n",
      "  (0, 24)\t0.150613747006775\n",
      "  (0, 22)\t0.22407033650349076\n",
      "  (0, 21)\t0.1974371750183366\n",
      "  (0, 20)\t0.18627154618091263\n",
      "  (0, 19)\t0.1974371750183366\n",
      "  (0, 18)\t0.18279662970959018\n",
      "  (0, 17)\t0.19358309729322126\n",
      "  (0, 14)\t0.21914035656890804\n",
      "  (0, 12)\t0.20559315655375815\n",
      "  (0, 10)\t0.18279662970959018\n",
      "  (0, 8)\t0.18986427862588987\n",
      "  (0, 7)\t0.22407033650349076\n",
      "  (0, 4)\t0.1640463169865326\n",
      "  (0, 2)\t0.20991928609451335\n",
      "  (0, 0)\t0.1974371750183366\n",
      "spot sdk documentation best viewed via developer site devbostondynamicscom spot sdk develop application payload spot using boston dynamic spot sdk sdk consists conceptual documentation document explain key abstraction used spot api python client library application using python library control spot read sensor health information spot wide variety example program quickstart guide also included payload developer documentation payload add additional sensing communication control capability beyond base platform provides payload icd cover mechanical electrical software interface spot support spot api protocol definition reference guide cover detail protocol application used communicate spot application developer wish use language python implement client speak protocol spot sdk repository github repo spot sdk code hosted version 210 sdk please review release note see ha changed content concept python payload api protocol release note sdk repository\n",
      "  (0, 36)\t0.2802658794811143\n",
      "  (0, 35)\t0.23750309788786605\n",
      "  (0, 33)\t0.3039170989614423\n",
      "  (0, 32)\t0.23341140938151225\n",
      "  (0, 30)\t0.2916362082828675\n",
      "  (0, 25)\t0.31044698765700335\n",
      "  (0, 24)\t0.21805568180811408\n",
      "  (0, 21)\t0.2858457389746417\n",
      "  (0, 15)\t0.324404717167314\n",
      "  (0, 12)\t0.29765381194185064\n",
      "  (0, 8)\t0.27488184544609884\n",
      "  (0, 4)\t0.23750309788786605\n",
      "  (0, 0)\t0.2858457389746417\n",
      "git filterrepo versatile tool rewriting history includes capability found anywhere else roughly fall space tool git filterbranch without capitulationinducing poor performance far capability design scale usabilitywise beyond trivial rewriting case git filterrepo recommended git project instead git filterbranch user probably use filterrepo simple command line tool likely use flag core filterrepo contains library creating history rewriting tool user specialized need leverage quickly create entirely new history rewriting tool table content prerequisite install use filterrepo instead alternative filterbranch bfg repo cleaner simple example comparison solving filterrepo solving bfg repo cleaner solving filterbranch solving fastexportfastimport design rationale behind filterrepo contribute code conduct upstream improvement prerequisite filterrepo requires git 2220 minimum feature require git 2240 later python3 35 install gitfilterrepo singlefile python script wa done make installation basic use trivial copy path see installmd thing beyond basic usage special case involved instruction needed working python3 executable named something python3 want install documentation beyond builtin doc shown h want run contrib example want create python filtering script using filterrepo modulelibrary use see user manual prefer learning example simple example may interest user manual ha extensive example section cheat sheet converting filterbranch command cover every example filterbranch manual cheat sheet converting bfg repo cleaner command cover every example bfg website filterrepo instead alternative wa covered detail git rev news article filterrepo highlight main competitor filterbranch filterbranch extremely unusably slow multiple order magnitude slower nontrivial repository filterbranch riddled gotchas silently corrupt rewrite least thwart cleanup effort giving something problematic messy started filterbranch onerous use rewrite even slightly nontrivial git project ha stated issue filterbranch cannot backward compatibly fixed recommend stop using filterbranch diehard fan filterbranch may interested filterlamely aka filterbranchish reimplementation filterbranch based filterrepo performant though nearly fast safe filterrepo cheat sheet available showing convert example command manual filterbranch filterrepo command bfg repo cleaner great tool time make thing simple limited kind rewrite architecture amenable handling type rewrite architecture present shortcoming bug even intended usecase fan bfg may interested bfgish reimplementation bfg based filterrepo includes several new feature bugfixes relative bfg cheat sheet available showing convert example command manual bfg repo cleaner filterrepo command simple example comparison let say want extract piece repository intent merging piece bigger repo extraction want extract history single directory src mean path src remain repo commits touched path outside directory removed rename file new leading directory mymodule eg srcfooc becomes mymodulesrcfooc rename tag extracted repository mymodule prefix avoid conflict later merge repo something else solving filterrepo filterrepo simple following command git filterrepo path src tosubdirectoryfilter mymodule tagrename mymodule single quote unnecessary make clearer human replacing empty string prefix mymodule solving bfg repo cleaner bfg repo cleaner capable kind rewrite fact three type wanted change outside capability solving filterbranch filterbranch come pile caveat even figure necessary invocation git filterbranch treefilter mkdir p mymodule git lsfiles grep v src xargs git rm f q l grep v mymodule xargs file mv file mymodule tagnamefilter echo mymodulecat &#9; pruneempty git clone filepwd newcopy cd newcopy git foreachref formatdelete refname refstags grep v refstagsmymodule git updateref stdin git gc prunenow might notice filterbranch invocation really slow due using treefilter could alternatively use indexfilter option filterbranch changing command git filterbranch indexfilter git lsfiles grep v src xargs git rm q cached git lsfiles sed sprintf tmymodule git updateindex indexinfo git lsfiles grep v mymodule xargs git rm q cached tagnamefilter echo mymodulecat pruneempty git clone filepwd newcopy cd newcopy git foreachref formatdelete refname refstags grep v refstagsmymodule git updateref stdin git gc prunenow however either filterbranch command pile caveat first may wondering list five command filterbranch despite use tagnamefilter filterbranchs manpage claiming clone enough get rid old object extra step delete tag another gc still required clean old object avoid mixing new old history pushing somewhere caveat commit message rewritten commit message refer prior commits abbreviated sha1 rewrite message refer commits longer part history would better rewrite abbreviated sha1 reference refer new commit id pruneempty flag sometimes miss commits pruned also prune commits started empty rather ended empty due filtering repository intentionally use empty commits versioning publishing related purpose detrimental command osspecific gnu v bsd issue sed xargs command often trip user think failed get folk use indexfilter since example filterbranch manpage us show move everything subdirectory linuxspecific obvious reader ha portability issue since silently misbehaves rather failing loudly indexfilter version filterbranch command may two three time faster treefilter version filterbranch command going multiple order magnitude slower filterrepo command assume filename composed entirely ascii character even special ascii character tab double quote wreak havoc likely result missing file misnamed file solving fastexportfastimport one kind hack together something like git fastexport nodata reencodeyes marktags fakemissingtagger signedtagsstrip tagoffilteredobjectrewrite grep vp 09 09af src grep vp src perl pe sm 09 09af 1mymodule2 perl pe sd 1mymodule2 perl pe srefstagsrefstagsmymodule git c coreignorecasefalse fastimport dateformatrawpermissive force quiet git foreachref formatdelete refname refstags grep v refstagsmymodule git updateref stdin git reset hard git reflog expire expirenow git gc prunenow come nasty caveat limitation various greps regex replacement operate entire fastexport stream thus might accidentally corrupt unintended portion commit message needed edit file content thus dropped nodata flag could also end corrupting file content command assumes filename repository composed entirely ascii character also exclude special character tab double quote special filename exists within old src directory pruned even though wa intended kept slightly different repository rewrite type editing also risk corrupting filename special character adding extra double quote near end filename leading directory name command leave behind huge number useless empty commits ha realistic way pruning tried combine technique another tool prune empty commits way distinguish commits made empty filtering want remove commits empty filtering process thus may want keep commit message reference commits hash reference old commits longer exist attempting edit commit message update extraordinarily difficult add kind direct rewrite design rationale behind filterrepo none existing repository filtering tool wanted came short need tool provided first eight trait wanted failed provide least one last four trait well starting report provide user analysis repo help get started prune rename instead expecting guess find tool figure triggered eg running first time special flag analyze keep v remove instead providing way user easily remove selected path also provide flag user keep certain path sure user could workaround specifying remove path one want keep need specify path ever existed version repository could sometimes quite painful filterbranch using pipeline like git lsfiles grep v xargs r git rm might reasonable workaround get unwieldy isnt straightforward user plus command often operatingsystem specific spot gnuism snippet provided renaming easy rename path example addition allowing one treat subdirectory root repository also provide option user make root repository become subdirectory generally allow file directory easily renamed provide sanity check renaming cause multiple file exist path add special handling commit merely copied oldnamenewname without modification filtering oldnamenewname doesnt trigger sanity check die commit intelligent safety writing copy original ref special namespace within repo doe provide userfriendly recovery mechanism many would struggle recover using almost everyone ive ever seen repository filtering operation ha done fresh clone wiping clone case error vastly easier recovery mechanism strongly encourage workflow detecting bailing fresh clone unless user override force auto shrink automatically remove old cruft repack repository user filtering unless overridden simplifies thing user help avoid mixing old new history together avoids problem multistep process shrinking repo documented manpage doesnt actually work case im looking filterbranch clean separation avoid confusing user prevent accidental repushing old stuff due mixing old repo rewritten repo together particularly problem filterbranch using tagnamefilter option sometimes also issue filtering subset branch versatility provide user ability extend tool even write new tool leverage existing capability provide extensibility way avoids need fork separate process would destroy performance b avoids making user specify osdependent shell command would prevent user sharing command c take advantage rich data structure hash dicts list array prohibitively difficult shell provides reasonable string manipulation capability sorely lacking shell old commit reference provide way user use old commit id new repository particular via mapping old new hash refsreplace reference commit message consistency commit message refer commits id eg reverts commit 01234567890abcdef commit 0013deadbeef9a commit message rewritten refer new commit id becomeempty pruning commits become empty due filtering pruned parent commit pruned first nonpruned ancestor need become new parent nonpruned ancestor exists commit wa merge becomes new root commit nonpruned ancestor exists commit wa merge merge one le parent thus make likely become nonmerge commit would pruned file change one special thing note prune commits become empty commits start empty project intentionally create empty commits versioning publishing reason removed special case commits started empty whose parent wa pruned away also considered become empty becomedegenerate pruning pruning commits become empty potentially cause topology change lot special case normally merge commits removed since needed preserve graph topology pruning parent ancestor ultimately result loss one parent simple case wa already noted merge commit loses enough parent become nonmerge commit ha file change pruned merge commits also topology becomes degenerate could end mergebase serving parent intervening commits original repo pruned could end one parent ancestor parent case merge ha file change merge commit also pruned however much empty pruning prune merge commits started degenerate indicates may intentional noff merges merge commits become degenerate file change speed filtering reasonably fast contribute see contributing guideline code conduct participant filterrepo community expected adhere standard git project git code conduct applies upstream improvement work filterrepo predecessor ha also driven numerous improvement fastexport fastimport occasionally command core git based thing filterrepo need work git2280 fastimport add new dateformatrawpermissive format git2240 fastexport handle nested tag t9350 add test tag thing commit fastexport allow user request tag marked marktags fastexport add support importmarksifexists fastimport add support new alias command fastimport allow tag identified mark label fastimport fix handling deleted tag fastexport fix exporting tag nothing else gitfastimporttxt clarify multiple merge commits allowed git2230 t9350 fix encoding test actually test reencoding fastimport support encoding commit header fastexport avoid stripping encoding header cannot reencode fastexport differentiate explicitly utf8 implicitly utf8 fastexport automatic reencoding commit message requested git2220 logdifftree add combinedallpaths option t9300 demonstrate bug getmark empty orphan commits gitfastimporttxt fix wording l command appear fastimport check prominent command first fastimport allow catblob request make sense fastimport fix erroneous handling getmark empty orphan commits honor coreprecomposeunicode place git2210 fastexport convert sha1 oid gitfastimporttxt fix documentation quiet option gitfastexporttxt clarify misleading documentation revlist args fastexport use value correct enum fastexport avoid dying filtering path old tag exist fastexport move commit rewriting logic function reuse fastexport using path avoid corrupt stream nonexistent mark fastexport ensure export requested ref fastexport add referenceexcludedparents option fastimport remove unmaintained duplicate documentation fastexport add showoriginalids option show original name gitshowreftxt fix order flag git2200 updateref fix type updateflags variable match usage updateref allow noderef stdin git173 fastexport fix dropping file importmarks path limiting fastexport add fulltree option fastexport fix output order df change fastimport improve robustness df change provided wrong order git164 fastexport set revstopoorder calling setuprevisions fastexport omit tag tag tree fastexport make sure show actual ref name instead null fastexport parent rewriting avoid dropping relevant commits fastexport add tagoffilteredobject option newly dangling tag add new fastexport testcases fastexport document fact gitrevlist argument accepted git163 gitfilterbranch avoid collision variable evaled command correct missing sp character grammar comment top fastimportc fastexport avoid dropping file commits git1614 fastexport ensure traverse commits topological order\n",
      "  (0, 39)\t0.1755841046116725\n",
      "  (0, 38)\t0.19531289386528444\n",
      "  (0, 37)\t0.1755841046116725\n",
      "  (0, 36)\t0.16873842171944492\n",
      "  (0, 35)\t0.14299242549708183\n",
      "  (0, 34)\t0.19531289386528444\n",
      "  (0, 32)\t0.14052896093975506\n",
      "  (0, 31)\t0.18690942622692197\n",
      "  (0, 30)\t0.1755841046116725\n",
      "  (0, 28)\t0.1755841046116725\n",
      "  (0, 27)\t0.15080336739459382\n",
      "  (0, 26)\t0.18297800541132866\n",
      "  (0, 25)\t0.18690942622692197\n",
      "  (0, 24)\t0.13128380687431496\n",
      "  (0, 23)\t0.15640353326548917\n",
      "  (0, 21)\t0.17209786271203825\n",
      "  (0, 20)\t0.16236524341894867\n",
      "  (0, 19)\t0.17209786271203825\n",
      "  (0, 18)\t0.15933630169223528\n",
      "  (0, 17)\t0.16873842171944492\n",
      "  (0, 15)\t0.19531289386528444\n",
      "  (0, 14)\t0.19101563318032924\n",
      "  (0, 13)\t0.14299242549708183\n",
      "  (0, 12)\t0.17920709627169865\n",
      "  (0, 11)\t0.19101563318032924\n",
      "  (0, 10)\t0.15933630169223528\n",
      "  (0, 9)\t0.17920709627169865\n",
      "  (0, 8)\t0.16549688048283676\n",
      "  (0, 6)\t0.16549688048283676\n",
      "  (0, 5)\t0.16873842171944492\n",
      "  (0, 4)\t0.14299242549708183\n",
      "  (0, 3)\t0.19101563318032924\n",
      "  (0, 2)\t0.18297800541132866\n",
      "  (0, 0)\t0.17209786271203825\n",
      "knowledge repo knowledge repo project focused facilitating sharing knowledge data scientist technical role using data format tool make sense profession provides various data store utility manage knowledge post particular focus notebook r markdown jupyter ipython notebook better promote reproducible research information motivation inspiration behind project encourage read medium post documentation httpknowledgereporeadthedocsio source httpsgithubcomairbnbknowledgerepo bug report httpsgithubcomairbnbknowledgerepoissues screenshots\n",
      "  (0, 35)\t0.3761145035091333\n",
      "  (0, 29)\t0.45267084577317157\n",
      "  (0, 24)\t0.3453171989332373\n",
      "  (0, 23)\t0.41138988346221306\n",
      "  (0, 18)\t0.4191039755681295\n",
      "  (0, 6)\t0.4353082117372912\n",
      "taxitracker repo nyc taxi day life data visualization show movement earnings single nyc taxi 24 hour made 2013 nyc taxi trip data obtained foil request taxi limousine commission\n",
      "  (0, 26)\t0.6547232845063128\n",
      "  (0, 24)\t0.4697535370222276\n",
      "  (0, 6)\t0.5921731462844061\n",
      "script analyze git repos produce cool looking graph like running git installing run pip install gitoftheseus running first need run gitoftheseusanalyze path repo see gitoftheseusanalyze help bunch config analyze repository might take quite time generate plot way run gitoftheseusstackplot cohortsjson write stackplotpng run gitoftheseussurvivalplot survivaljson write survivalplotpng run help option want plot multiple repository run gitoftheseusanalyze separately project store data separate directory using outdir flag run gitoftheseussurvivalplot foosurvivaljson barsurvivaljson optionally expfit flag fit exponential decay help attributeerror unknown property label upgrade matplotlib seeing pip install matplotlib upgrade pic survival line code set interesting repos curve produced gitoftheseussurvivalplot script show percentage line commit still present x year aggregate commits matter point time made x0 includes commits whereas x0 commits counted would look future survival curve estimated using kaplanmeier also add exponential fit linux stack plot curve produced gitoftheseusstackplot script show total number line repo broken cohort year code wa added node stack plot rail stack plot plotting stuff gitoftheseusanalyze write extsjson cohortsjson authorsjson run gitoftheseusstackplot authorsjson plot author statistic well gitoftheseusstackplot extsjson plot file extension statistic author statistic might want create mailmap file deduplicate author instance author statistic kubernetes also normalize 100 author statistic git stuff markovtsev vadim implemented similar analysis claim 206x faster git theseus named hercules great blog post complexity going analysis git history\n",
      "  (0, 38)\t0.28660120334583133\n",
      "  (0, 37)\t0.25765127265389504\n",
      "  (0, 35)\t0.20982639909615827\n",
      "  (0, 31)\t0.27426999525317136\n",
      "  (0, 28)\t0.25765127265389504\n",
      "  (0, 27)\t0.2212881377596353\n",
      "  (0, 25)\t0.27426999525317136\n",
      "  (0, 24)\t0.19264522830711167\n",
      "  (0, 23)\t0.2295057942889677\n",
      "  (0, 19)\t0.2525355780173751\n",
      "  (0, 17)\t0.24760595042345562\n",
      "  (0, 13)\t0.20982639909615827\n",
      "  (0, 10)\t0.2338093246069397\n",
      "  (0, 6)\t0.24284932836578532\n",
      "  (0, 5)\t0.24760595042345562\n",
      "  (0, 4)\t0.20982639909615827\n",
      "  (0, 0)\t0.2525355780173751\n",
      "mexican government report text analysis repository document process extracting text pdf cleaning passing nlp pipeline presenting result graph pdf government report 2019 wa released september 1st pdf data folder requirement project us following python library pypdf2 extracting text pdf file spacy passing extracted text nlp pipeline numpy fast matrix operation panda analysing getting insight datasets matplotlib creating graph plot seaborn enhancing style matplotlib plot geopandas plotting map window strongly recommend use anaconda install geopandas using command conda install c condaforge geopandas conda install c condaforge descartes pdf extraction government report process downloaded following url httpswwwgobmxprimerinforme convenience added pdf file data folder extracting text pdf file bit unreliable lose original formatting time dont get text fortunately pdf file simple enough extracting text wasnt complex encountered challenge go detail section task use pypdf2 wellknown pdf library reader pypdf2pdffilereaderinformepdf fulltext page number pdf reported number page use variable keep track pdfpagenumber 3 retrieve first 3 section government report page 14 326 reason 3 first section contain substantial amount text range14 327 block used remove page number start page first remove page number one digit second remove page number 2 digit else statement remove page number 3 digit pdfpagenumber 9 pagetext readergetpageiextracttextstrip1 elif pdfpagenumber 10 pdfpagenumber 99 pagetext readergetpageiextracttextstrip2 else pagetext readergetpageiextracttextstrip3 fulltext pagetextreplacen pdfpagenumber 1 previous code block ensures get cleanest possible output remove page number build u full transcript single string small issue decoding pdf file manually fix weird character correct equivalent item replacement charactersitems fulltext fulltextreplaceitem replacement actually took hour complete manually map weird character correct equivalent example character c e e e remove extra white space finally save cleaned text txt file look weird thats practical way remove double quad white space fulltext fulltextreplace replace replace opentranscriptcleantxt w encodingutf8 tempfile tempfilewritefulltext transcript cleaned well encoded ready run nlp pipeline nlp pipeline step make use spacy library well built easy use installing pip must install spanish model running following command cmd terminal python spacy download escorenewsmd point made decision save pipeline result csv file way csv file loaded statistical toolkit start preparing corpus loading spanish model corpus opentranscriptcleantxt r encodingutf8read nlp spacyloadescorenewsmd corpus bigger default limit set new limit equal length nlpmaxlength lencorpus doc nlpcorpus note script take minute complete also need gigabyte ram properly run feel free skip use csv file data folder everything loaded save result csv file text token code pretty straight forward initialize list header row iterate doc object add token text lemma partofspeech property data list save csv using csvwriter datalist text textlower lemma lemmalower partofspeech isalphabet isstopword token doc datalistappendtokentext tokenlower tokenlemma tokenlemmalower tokenpos tokenisalpha tokenisstop csvwriteropentokenscsv w encodingutf8 newlinewriterowsdatalist important note token always word punctuation mark number thats also save isalpha property later filter nonalphabetic token also saved lowercase form token lemma dont every time want process panda text entity almost previous code block main difference iterate docent object datalist text textlower label ent docent datalistappendenttext entlower entlabel csvwriteropenentitiescsv w encodingutf8 newlinewriterowsdatalist entity refer real world person organization location since model wa trained wikipedia get broad amount text sentence function bit different previous one part counted number positive negative word per sentence used following dataset positive negative word httpswwwkagglecomrtatmansentimentlexiconsfor81languages download require register kaggle free zip file require 2 txt file negativewordsestxt positivewordsestxt required file workspace load memory turn content list openpositivewordsestxt r encodingutf8 tempfile positivewords tempfilereadsplitlines opennegativewordsestxt r encodingutf8 tempfile negativewords tempfilereadsplitlines iterate docsents object keep score sentence save result csv datalist text score sent docsents take account real sentence lensenttext 10 score 0 start scoring sentence word sent wordlower positivewords score 1 wordlower negativewords score 1 datalistappendsenttext score csvwriteropensentencescsv w encodingutf8 newlinewriterowsdatalist running 3 function 3 csv file ready analyzed panda plotted matplotlib plotting data creating plot use seaborn matplotlib reason seaborn applies subtle yet nice looking effect plot project going use bar plot 1 horizontal 1 vertical helpful comparing different value category plot map use geopandas shape file mexico first thing set custom color apply globally plot snssetstyleticks rc figurefigsize 12 7 textcolor white axeslabelcolor white axesedgecolor white xtickcolor white ytickcolor white axesfacecolor 5c0e10 figurefacecolor 5c0e10 style declared ready plot data used word start loading token csv file dataframe df pdreadcsvdatatokenscsv small issue lemma programas program fix grouping together programa programar dflocdflemmalower programa lemmalower programar take account top 20 alphabet token longer 1 character stop word word dfdfisalphabet true dfisstopword false dflemmalowerstrlen 1lemmalowervaluecounts20 use seaborn barplot allows u apply gradient color value without effort snsbarplotxwordsvalues ywordsindex palettebluesd linewidth0 add final customizations pltxlabelocurrences count plttitlemost frequent word pltshow table added lemma count closest english equivalent lemma spanish lemma english total count nacional national 806 junio june 783 mexico mexico 646 programar program 584 millon million 564 peso mexican peso 460 diciembre december 407 publico public population 386 servicio service 357 accionar action 349 desarrollar develop 338 personar people 298 federal federal government 283 educacion education 279 salud health 278 realizar perform 274 pais country 274 social social program 266 atencion aid 256 apoyar support 248 mention per state window require use anaconda python distribution come bundled hundred data science oriented library install anaconda require install 2 package running command cmd terminal conda install c condaforge geopandas conda install c condaforge descartes dont try use pip install geopandas window wont work work well linux macos though geopandas installed require shape file mexico download following link httpswwwarcgiscomhomeitemhtmlidac9041c51b5c49c683fbfec61dc03ba8 require unzip file rename folder mexicostates folder contains various file metadata others coordinate start loading entity csv file loading shape file df pdreadcsvdataentitiescsv mexicodf geopandasreadfilemexicostates shape file loaded folder instead specific file iterate state detail shape file contains state name without accent mark us old name ciudad de mexico wa named distrito federal modifying shape file dataframe clean state name matched state state remove accent mark rename ciudad de mexico former name cleanname cleanwordstate cleanname ciudad de mexico cleanname distrito federal elif cleanname estado de mexico cleanname mexico insert count value row matching adminname state name mexicodflocmexicodfadminname cleanname count lendfdftextlower statelower shape file dataframe ha new column count state use plot method dataframe specify column name color map enable legend mexicodfplotcolumncount cmapplasma legendtrue add final customizations plttitlementions state pltaxisoff plttightlayout pltshow sentiment analysis sentiment analysis used lexiconbased method consists counting positive negative word per sentence method ha consideration important doesnt know context sentence sentence like reduced crime level 10 considered negative way around train model use machine learning evaluate sentence unfortunately timeconsuming task use method first thing load sentence csv file take account score 10 10 case score go beyond boundary df pdreadcsvdatasentencescsv df dfdfscore 10 dfscore 10 make bar score zero yellow bar score zero blue first create array length dataframe element array tuple 3 decimal value representing rgb color color nparray0811 0913 0145lendfscore use boolean mask set different rgb value score equal higher zero colorsdfscore 0 0529 0870 0972 use bar plot pas x previously calculated color pltbardfindex dfscore colorcolors linewidth0 set yticks step 2 10 10 ytickslabels formatinti nparange12 12 2 pltyticksnparange12 12 2 ytickslabels add final customizations pltxlabelsentence number pltylabelscore plttitlesentiment analysis pltshow conclusion previous project used nlp workflow tokenizing word sentence time wanted something bit complex learned several new thing best practice new knowledge come handy future project next step build machine learning model sentiment analysis evaluate next year report\n",
      "  (0, 39)\t0.18641813268441554\n",
      "  (0, 38)\t0.20736424315903199\n",
      "  (0, 37)\t0.18641813268441554\n",
      "  (0, 35)\t0.15181545623469458\n",
      "  (0, 33)\t0.19426825774769577\n",
      "  (0, 32)\t0.1491999890560069\n",
      "  (0, 31)\t0.19844225817250888\n",
      "  (0, 30)\t0.18641813268441554\n",
      "  (0, 28)\t0.18641813268441554\n",
      "  (0, 27)\t0.1601083549925919\n",
      "  (0, 25)\t0.19844225817250888\n",
      "  (0, 23)\t0.1660540666883299\n",
      "  (0, 21)\t0.18271677995403415\n",
      "  (0, 20)\t0.1723836309553892\n",
      "  (0, 19)\t0.18271677995403415\n",
      "  (0, 18)\t0.16916779509170088\n",
      "  (0, 17)\t0.17915005209966609\n",
      "  (0, 15)\t0.20736424315903199\n",
      "  (0, 14)\t0.20280182952643572\n",
      "  (0, 13)\t0.15181545623469458\n",
      "  (0, 12)\t0.19026467301611014\n",
      "  (0, 11)\t0.20280182952643572\n",
      "  (0, 10)\t0.16916779509170088\n",
      "  (0, 8)\t0.17570849874445504\n",
      "  (0, 7)\t0.20736424315903199\n",
      "  (0, 6)\t0.17570849874445504\n",
      "  (0, 5)\t0.17915005209966609\n",
      "  (0, 4)\t0.15181545623469458\n",
      "  (0, 1)\t0.19844225817250888\n",
      "  (0, 0)\t0.18271677995403415\n",
      "home heroimage herotext actiontext actionlink meta true dortanialogoclearpng dortanias opencore install guide getting started prerequisitesmd name content description current supported version 063 opencore guide opencore refer boot loader complex piece software use prepare system macos specifically injecting new data macos smbios acpi table kexts tool differs others like clover ha designed security quality mind allowing u use many security feature found real mac sip filevault indepth look found opencore clover others guide specifically focus two main thing installing macos x86based pc teaching make hack work expected read learn even use google simple oneclick install setup please remember opencore still new currently beta quite stable arguably much stable clover pretty much every way still frequently updated chunk configuration change quite often ie new quirk replacing old one lastly issue visit rhackintosh subreddit rhackintosh discord help\n",
      "  (0, 39)\t0.28503932883927113\n",
      "  (0, 38)\t0.31706660636589035\n",
      "  (0, 36)\t0.27392619954227376\n",
      "  (0, 32)\t0.22813158854748103\n",
      "  (0, 20)\t0.2635801236866938\n",
      "  (0, 18)\t0.25866300707875767\n",
      "  (0, 17)\t0.27392619954227376\n",
      "  (0, 14)\t0.3100905289800927\n",
      "  (0, 13)\t0.23213072209998978\n",
      "  (0, 12)\t0.29092081289187416\n",
      "  (0, 9)\t0.29092081289187416\n",
      "  (0, 6)\t0.2686639536201211\n",
      "  (0, 2)\t0.2970424228898361\n",
      "nano minimalistic couchdb driver nodejs nano feature minimalistic minimum abstraction couchdb pipe proxy request couchdb directly end user error error proxied directly couchdb know couchdb already know nano installation install npm npm install nano table content getting started tutorial screencasts configuration database function nanodbcreatename callback nanodbgetname callback nanodbdestroyname callback nanodblistcallback nanodbcompactname designname callback nanodbreplicatesource target opts callback nanodbchangesname params callback nanodbfollowname params callback nanodbinfocallback nanousename nanorequestopts callback nanoconfig nanoupdatesparams callback nanofollowupdatesparams callback document function dbinsertdoc params callback dbdestroydocname rev callback dbgetdocname params callback dbheaddocname callback dbcopysrcdoc destdoc opts callback dbbulkdocs params callback dblistparams callback dbfetchdocnames params callback dbfetchrevsdocnames params callback multipart function dbmultipartinsertdoc attachment params callback dbmultipartgetdocname params callback attachment function dbattachmentinsertdocname attname att contenttype params callback dbattachmentgetdocname attname params callback dbattachmentdestroydocname attname params callback view design function dbviewdesignname viewname params callback dbshowdesignname showname docid params callback dbatomicdesignname updatename docname body callback dbsearchdesignname viewname params callback using cookie authentication advanced feature extending nano pipe test getting started use nano need connect couchdb install var nano requirenanohttplocalhost5984 create new database nanodbcreatealice use var alice nanodbusealice example didnt specify callback function absence callback mean ignore happens nano callback function receives always three argument err error body http response body couchdb error json parsed body binary non json response header http response header couchdb error simple complete example using callback var nano requirenanohttplocalhost5984 clean database created previously nanodbdestroyalice function create new database nanodbcreatealice function specify database going use var alice nanousealice insert document aliceinsert crazy true rabbit functionerr body header err consolelogaliceinsert errmessage return consolelogyou inserted rabbit consolelogbody run exampleafter starting couchdb see inserted rabbit ok true id rabbit rev 16e4cb465d49c0368ac3946506d26335d also see document futon configuration configuring nano use database server simple var nano requirenanohttplocalhost5984 db nanousefoo however dont need instrument database object simply nano par url know database var db requirenanohttplocalhost5984foo also pas option require nano par url know database var db requirenanohttplocalhost5984foo specify configuration option pas object literal instead nano par url know database var db requirenano url httplocalhost5984foo requestdefaults proxy httpsomeproxy log function id args consolelogid args please check request information default support feature like cookie jar proxy ssl etc tell nano parse url maybe server behind proxy accessed rewrite rule nano doe parse url return server api httplocalhost5984prefix couchdb server root var couch requirenano url httplocalhost5984prefix parseurl false var db couchusefoo pool size open socket important configuration parameter high traffic website using nano setting poolsize default nodejs http global agent client ha certain size active connection run simultaneously others kept queue pooling disabled setting agent property requestdefaults false adjust global pool size using httpglobalagentmaxsockets 20 also increase size calling context using requestdefaults problematic refer request documentation example clarification example explicitly using keep alive agent installed using npm install agentkeepalive especially useful limit open socket highvolume access couchdb localhost var agentkeepalive requireagentkeepalive var myagent new agentkeepalive maxsockets 50 maxkeepaliverequests 0 maxkeepalivetime 30000 var db requirenano url httplocalhost5984foo requestdefaults agent myagent database function nanodbcreatename callback creates couchdb database given name nanodbcreatealice functionerr body err consolelogdatabase alice created nanodbgetname callback get information name nanodbgetalice functionerr body err consolelogbody nanodbdestroyname callback destroys name nanodbdestroyalice even though example look sync async function nanodblistcallback list database couchdb nanodblistfunctionerr body body array bodyforeachfunctiondb consolelogdb nanodbcompactname designname callback compact name designname specified also compact view nanodbreplicatesource target opts callback replicates source target option opts target ha exist add createtargettrue opts create prior replication nanodbreplicatealice httpadminpasswordotherhostcom5984alice createtargettrue functionerr body err consolelogbody nanodbchangesname params callback asks change feed name params contains addition query string nanodbchangesalice functionerr body err consolelogbody nanodbfollowname params callback us follow create solid change feed please consult follow documentation information complete api var feed dbfollowsince feedonchange function change consolelogchange change feedfollow processnexttickfunction dbinsertbar baz bar nanodbinfocallback get database information nanodbinfofunctionerr body err consoleloggot database info body nanousename creates scope operate inside name var alice nanousealice aliceinsert crazy true rabbit functionerr body something nanodbusename alias nanouse nanodbscopename alias nanouse nanoscopename alias nanouse nanorequestopts callback make request couchdb available opts optsdb database name optsmethod http method default get optspath full path request override optsdoc optsatt optsdoc document name optsatt attachment name optsqs query string parameter appended existing optspath optsdoc optsatt optscontenttype content type request default json optsheaders additional http header override existing one optsbody document attachment body optsencoding encoding attachment optsmultipart array object multipart request nanorelaxopts callback alias nanorequest nanodinosauropts callback alias nanorequest wat u say l nanoconfig object containing nano configuration possible key url couchdb url db database name nanoupdatesparams callback listen db update available params paramsfeed type feed one longpoll close connection first event continuous send line json per event keep socket open timeout eventsource like continuous sends event eventsource format paramstimeout number second couchdb close connection default 60 paramsheartbeat whether couchdb send newline character n timeout default true nanofollowupdatesparams callback changed version 6 use follow create solid dbupdates feed please consult follow documentation information complete api var feed nanofollowupdatessince feedonchange function change consolelogchange change feedfollow processnexttickfunction nanodbcreatealice document function dbinsertdoc params callback insert doc database optional params params string assumed intended document name params object passed query string parameter docname checked defining document name var alice nanousealice aliceinsert crazy true rabbit functionerr body err consolelogbody insert function also used method signature dbinsertdoccallback doc contains id field eg var alice nanousealice aliceinsert id myid crazy true functionerr body err consolelogbody also used update existing document including rev token document saved var alice nanousealice aliceinsert id myid rev 123202479633c2b380f79507a776743d5 crazy false functionerr body err consolelogbody dbdestroydocname rev callback remove revision rev docname couchdb alicedestroyrabbit 366c01cdf99e84c83a9b3fe65b88db8c0 functionerr body err consolelogbody dbgetdocname params callback get docname database optional query string addition params alicegetrabbit revsinfo true functionerr body err consolelogbody dbheaddocname callback get lightweight version return header aliceheadrabbit functionerr header err consolelogheaders dbcopysrcdoc destdoc opts callback copy content attachment document new document overwrite existing target document alicecopyrabbit rabbit2 overwrite true functionerr header err consolelogheaders dbbulkdocs params callback bulk operationsupdatedeleteinsert database refer couchdb doc dblistparams callback list doc database optional query string addition params useful searching aliceliststartkeycat limit3 functionerr body err bodyrowsforeachfunctiondoc consolelogdoc full list params see couchdb doc dbfetchdocnames params callback bulk fetch database document docnames specified per couchdb doc additional query string params specified includedocs always set true dbfetchrevsdocnames params callback changed version 6 bulk fetch revision database document docnames specified per couchdb doc additional query string params specified method fetch includedocs automatically set true multipart function dbmultipartinsertdoc attachment params callback insert doc together attachment params params string assumed intended document name params object passed query string parameter docname checked defining document name refer doc detail attachment must array object name data contenttype property var f requirefs fsreadfilerabbitpng functionerr data err alicemultipartinsert foo bar name rabbitpng data data contenttype imagepng mydoc functionerr body err consolelogbody dbmultipartgetdocname params callback get docname together attachment via multipartrelated request optional query string addition params refer doc detail multipart response body buffer alicemultipartgetrabbit functionerr buffer err consolelogbuffertostring attachment function dbattachmentinsertdocname attname att contenttype params callback insert attachment attname docname case paramsrev required refer doc detail var f requirefs fsreadfilerabbitpng functionerr data err aliceattachmentinsertrabbit rabbitpng data imagepng rev 12150985a725ec88be471921a54ce91452 functionerr body err consolelogbody using pipe var f requirefs fscreatereadstreamrabbitpngpipe aliceattachmentinsertnew rabpng null imagepng dbattachmentgetdocname attname params callback get docnames attachment attname optional query string addition params var f requirefs aliceattachmentgetrabbit rabbitpng functionerr body err fswritefilerabbitpng body using pipe var f requirefs aliceattachmentgetrabbit rabbitpngpipefscreatewritestreamrabbitpng dbattachmentdestroydocname attname params callback changed version 6 destroy attachment attname docnames revision rev aliceattachmentdestroyrabbit rabbitpng rev 14701d73a08ce5c2f2983bf7c9ffd3320 functionerr body err consolelogbody view design function dbviewdesignname viewname params callback call view specified design optional query string addition params youre looking filter view result key pas array key eg key key1 key2 keyn params aliceviewcharacters crazyones functionerr body err bodyrowsforeachfunctiondoc consolelogdocvalue dbviewwithlistdesignname viewname listname params callback call list function feeded given view specified design document aliceviewwithlistcharacters crazyones mylist functionerr body err consolelogbody dbshowdesignname showname docid params callback call show function specified design document specified docid optional query string addition params aliceshowcharacters formatdoc 3621898430 functionerr doc err consolelogdoc take look couchdb wiki possible query paramaters information show function dbatomicdesignname updatename docname body callback call design update function specified doc input dbatomicupdate inplace foobar field foo value bar function error response assertequalerror undefined failed update assertequalresponsefoo bar update worked note data sent body request example update handler follows update inplace functiondoc req var field reqbodyfield var value reqbodyvalue var message set field value docfield value return doc message dbsearchdesignname searchname params callback call view specified design optional query string addition params alicesearchcharacters crazyones q cat functionerr doc err consolelogdoc check test fully functioning example using cookie authentication nano support making request using couchdbs cookie authentication functionality example coffeescript essentially var nano requirenanohttplocalhost5984 username user userpass pas callback consolelog would normally callback cooky store cooky normally redis something nanoauthusername userpass function err body header err return callbackerr header headerssetcookie cookiesuser headerssetcookie callbacknull worked reusing cookie var auth stored cookie callback consolelog would normally callback alice requirenano url httplocalhost5984alice cookie authsession auth aliceinsertdoc function err body header err return callbackerr change cookie couchdb tell u header headerssetcookie auth headerssetcookie callbacknull worked getting current session var nano requirenanourl httplocalhost5984 cookie authsession auth nanosessionfunctionerr session err return consolelogoh consoleloguser ha role j sessionuserctxname sessionuserctxroles advanced feature extending nano nano minimalistic add feature nanorequestopts callback example create function retrieve specific revision rabbit document function getrabbitrevrev callback nanorequest db alice doc rabbit method get params rev rev callback getrabbitrev42e6cdc4c7e26b745c2881a24e0eeece2 functionerr body err consolelogbody pipe pipe nano like stream example rabbit document ha attachment name picturepng picture white rabbit course pipe writable stream var f requirefs nano requirenanohttp1270015984 var alice nanousealice aliceattachmentgetrabbit picturepngpipefscreatewritestreamtmprabbitpng open tmprabbitpng see rabbit picture tutorial example wild screencasts article nano minimalistic couchdb client nodejs article getting started nodejs couchdb article document update handler support article nano 3 article securing site couchdb cookie authentication using nodejs nano article adding copy nano article update document nano article thought development using couchdb nodejs example wild nanoblog roadmap check issue test run configure test suite simply cd nano npm install npm test adding new test run individually verbose output using nanoenvtesting node testsdoclistjs listdocparams listdocparams test name meta roar im vegan cannes est superb code git clone gitgithubcomdscapenanogit home httpgithubcomdscapenano bug httpgithubcomdscapenanoissues build deps chat httpsgitterimdscapenano oo caos license copyright 2011 nuno job nunojobcom oo licensed apache license version 20 license may use file except compliance license may obtain copy license httpwwwapacheorglicenseslicense20html unless required applicable law agreed writing software distributed license distributed basis without warranty condition kind either express implied see license specific language governing permission limitation license\n",
      "  (0, 36)\t0.17530693716447676\n",
      "  (0, 35)\t0.14855872122172595\n",
      "  (0, 34)\t0.20291587928434354\n",
      "  (0, 33)\t0.19010082807612622\n",
      "  (0, 32)\t0.14599936087001994\n",
      "  (0, 30)\t0.1824191033706478\n",
      "  (0, 29)\t0.17879715181147354\n",
      "  (0, 28)\t0.1824191033706478\n",
      "  (0, 27)\t0.15667372127013945\n",
      "  (0, 26)\t0.19010082807612622\n",
      "  (0, 22)\t0.20291587928434354\n",
      "  (0, 21)\t0.17879715181147354\n",
      "  (0, 20)\t0.16868566883401476\n",
      "  (0, 19)\t0.17879715181147354\n",
      "  (0, 18)\t0.16553881886618307\n",
      "  (0, 17)\t0.17530693716447676\n",
      "  (0, 16)\t0.20291587928434354\n",
      "  (0, 14)\t0.19845133824383665\n",
      "  (0, 13)\t0.14855872122172595\n",
      "  (0, 12)\t0.18618312797642278\n",
      "  (0, 10)\t0.16553881886618307\n",
      "  (0, 9)\t0.18618312797642278\n",
      "  (0, 8)\t0.1719392117816534\n",
      "  (0, 7)\t0.20291587928434354\n",
      "  (0, 6)\t0.1719392117816534\n",
      "  (0, 5)\t0.17530693716447676\n",
      "  (0, 4)\t0.14855872122172595\n",
      "  (0, 3)\t0.19845133824383665\n",
      "  (0, 2)\t0.19010082807612622\n",
      "  (0, 1)\t0.19418528812300428\n",
      "  (0, 0)\t0.17879715181147354\n",
      "deepgcns gcns go deep cnns work present new way successfully train deep gcns borrow concept cnns mainly residualdense connection dilated convolution adapt gcn architecture extensive experiment show positive effect deep gcn framework project paper slide tensorflow code pytorch code overview extensive experiment show different component layer filter nearest neighbor dilation etc effect deepgcns also provide ablation study different type deep gcns mrgcn edgeconv graphsage gin requirement pytorch140 pytorchgeometric130 tensorflow graphic used tensorboard visualization install enviroment runing source deepgcnenvinstallsh code architecture misc misc image utils common useful module gcnlib gcn library dense gcn library dense data b x c x n x 1 sparse gcn library sparse data n x c example modelnetcls code point cloud classification modelnet40 semsegdense code point cloud semantic segmentation s3dis data type dense semsegsparse code point cloud semantic segmentation s3dis data type sparse partsemseg code part segmentation partnet ppi code node classification ppi dataset ogb code nodegraph property prediction ogb datasets train test evaluate model please look detail readmemd task inside example folder information code data pretrained model found citation please cite paper find anything helpful inproceedingsli2019deepgcns titledeepgcns gcns go deep cnns authorguohao li matthias muller ali thabet bernard ghanem booktitlethe ieee international conference computer vision iccv year2019 miscli2019deepgcnsjournal titledeepgcns making gcns go deep cnns authorguohao li matthias muller guocheng qian itzel c delgadillo abdulellah abualshour ali thabet bernard ghanem year2019 eprint191006849 archiveprefixarxiv primaryclasscscv miscli2020deepergcn titledeepergcn need train deeper gcns authorguohao li chenxin xiong ali thabet bernard ghanem year2020 eprint200607739 archiveprefixarxiv primaryclasscslg license mit license contact information please contact guohao li matthias muller guocheng qian\n",
      "  (0, 39)\t0.28316919552337444\n",
      "  (0, 38)\t0.3149863431743589\n",
      "  (0, 33)\t0.29509353768321184\n",
      "  (0, 29)\t0.27754683969394084\n",
      "  (0, 23)\t0.2522361735975596\n",
      "  (0, 20)\t0.26185078348398577\n",
      "  (0, 19)\t0.27754683969394084\n",
      "  (0, 16)\t0.3149863431743589\n",
      "  (0, 15)\t0.3149863431743589\n",
      "  (0, 13)\t0.23060772034858185\n",
      "  (0, 8)\t0.2669012585825922\n",
      "  (0, 6)\t0.2669012585825922\n",
      "  (0, 4)\t0.23060772034858185\n",
      "analytics reporter lightweight system publishing analytics data google analytics profile us google analytics core reporting api v3 google analytics real time api v3 used combination 18fanalyticsusagov power government analytics hub analyticsusagov available report named described reportsjson theyre hardcoded repository installation docker build docker image computer run export nodeenvdevelopment needed developing image export nodeenvproduction build image production docker build buildarg nodeenvnodeenv analyticsreporter create alias order analytics command available alias analyticsdocker run v homehome e analyticsreportemail e analyticsreportids e analyticskey analyticsreporter make command working expected export env var follows export analyticsreportemail yourreportemail export analyticsreportidsyourreportids export analyticskeyyourkey npm run utility computer install npm npm install g analyticsreporter youre developing locally inside repo npm install sufficient setup create api service account google developer dashboard visit apis section google developer dashboard project enable analytics api go credential section generate service account credential using new service account download json private key file give grab generated client email address end gserviceaccountcom content json file grant email address read analyze collaborate permission google analytics profile whose data wish publish set environment variable apps generated email address profile authorized export analyticsreportemailyyyyyyydevelopergserviceaccountcom export analyticsreportidsgaxxxxxx may wish manage using autoenv exampleenv file copy env get started find google analytics view id sign analytics account select admin tab select account dropdown account column select property dropdown property column select view dropdown view column click view setting copy view id youll need enter ga prefix specify private key environment variable either file path content key helpful heroku herokulike system specify file path useful development linux server environment export analyticskeypathpathtosecretkeyjson alternatively specify key directly useful paas environment paste content json file privatekey field directly exactly quote rendering actual line break n example ha sanitized export analyticskeybegin private key content key end private key multiple account profile set analyticscredentials variable json encoded array credential theyll used authorize api request roundrobin style export analyticscredentials key begin private keyncontents keynend private key email email1examplecom key begin private keyncontents keynend private key email email2examplecom make sure computer server syncing time world ntp computer time need match google server authentication work test configuration printing report stdout binanalytics user see nicely formatted json file set optional authorize s3 publishing plan use project lightweight s3 publishing system youll need add 6 environment variable export awsregionuseast1 export awsaccesskeyidyourkey export awssecretaccesskeyyoursecretkey export awsbucketyourbucket export awsbucketpathyourpath export awscachetime0 case want use custom object storage server compatible amazon s3 apis like minio specific case set extra env variable export awss3endpointhttpyourstorageserverport configuration use single domain analytics data profile likely set return relative path eg faq absolute path accessing realtime report set default domain returned data realtime data point export analyticshostnamehttpskonklonecom produce point similar following page postwhygoogleishurryingthewebtokillsha1 pagetitle google hurrying web kill sha1 activevisitors 1 domain httpskonklonecom use report created published using analytics command analytics run every report sequence print resulting json stdout two newlines report report might look something like name device query dimension gadate gadevicecategory metric gasessions startdate 90daysago enddate yesterday sort gadate meta name device description weekly desktopmobiletablet visit day site data date 20141014 device desktop visit 11495462 date 20141014 device mobile visit 2499586 date 20141014 device tablet visit 976396 total device mobile 213920363 desktop 755511646 tablet 81874189 startdate 20141014 enddate 20150111 option output output directory analytics output pathtodata note using docker image use absolute path example homeyouruserpathtodata publish publish s3 bucket requires aws environment variable set described analytics publish writetodatabase write data database requires postgres configuration set environment variable described run one specific report multiple report comma separated analytics device analytics devicestoday slim supported use total omit data array applies json report slim true analytics device slim csv give csv instead json analytics csv frequency limit report frequency value analytics frequencyrealtime debug print debug detail stdout analytics publish debug saving data postgres analytics reporter write data pull google analytics postgres database postgres configuration set using environment variable export postgreshost mydbhostcom export postgresuser postgres export postgrespassword 123abc export postgresdatabase analytics database expects particular schema described api server consumes data write report database use writetodatabase option starting reporter deploying govcloud analytics reporter run gov please refer manifestyml file root repository application information ensure youre targeting proper org space cf target deploy application following command cf push f manifestyml set environmental variable based local env file cf setenv analyticsreporter awsaccesskeyid 123abc cf setenv analyticsreporter awssecretaccesskey 456def restage application use environment variable cf restage analyticsreporter developing docker repo contains docker compose configuration reporter configured run container running govcloud helpful seeing reporter behave deployed without pushing cloudgov start reporter first run dockerupdate script install necessary dependency bindockerupdate note script need run new dependency added update docker volume dependency stored dependency installed reporter started using docker compose dockercompose public domain project worldwide public domain stated contributing project public domain within united state copyright related right work worldwide waived cc0 10 universal public domain dedication contribution project released cc0 dedication submitting pull request agreeing comply waiver copyright interest\n",
      "  (0, 39)\t0.19960441210198912\n",
      "  (0, 37)\t0.19960441210198912\n",
      "  (0, 35)\t0.16255411666965372\n",
      "  (0, 34)\t0.22203214489226963\n",
      "  (0, 33)\t0.20800981545851643\n",
      "  (0, 32)\t0.15975364452106833\n",
      "  (0, 31)\t0.21247906364221483\n",
      "  (0, 28)\t0.19960441210198912\n",
      "  (0, 27)\t0.17143361330099077\n",
      "  (0, 26)\t0.20800981545851643\n",
      "  (0, 25)\t0.21247906364221483\n",
      "  (0, 24)\t0.14924373221376822\n",
      "  (0, 23)\t0.17779989468395474\n",
      "  (0, 21)\t0.1956412443291385\n",
      "  (0, 20)\t0.18457718043505136\n",
      "  (0, 19)\t0.1956412443291385\n",
      "  (0, 18)\t0.18113387254571287\n",
      "  (0, 17)\t0.1918222241177079\n",
      "  (0, 13)\t0.16255411666965372\n",
      "  (0, 12)\t0.20372303731552596\n",
      "  (0, 11)\t0.2171470091075327\n",
      "  (0, 10)\t0.18113387254571287\n",
      "  (0, 8)\t0.1881372326187991\n",
      "  (0, 6)\t0.1881372326187991\n",
      "  (0, 5)\t0.1918222241177079\n",
      "  (0, 1)\t0.21247906364221483\n",
      "  (0, 0)\t0.1956412443291385\n",
      "dash user contributed docsets report bug request docset open issue install docset install docsets dash preference downloads user contributed contribute new docset contribute docset follow step get stuck point question open issue ill help generate docset following instruction httpkapelicomdocsets note ignore instruction regarding docset feed wont need plan contribute repo make sure docset fulfils required criterion docset contribution checklist many optional one possible check versioning guideline understand docset versioning work dash fork clone repo set directory structure copy sampledocset folder docsets folder rename use name docset replace whitespaces underscore note dont add docset end name use docset name eg extjs nothing else archive docset using tar excludedsstore cvzf docset nametgz docset namedocset copy docset archive note dont worry repos size getting huge soon docset get distributed cdn get removed repo automatically docset exceeds githubs file limit 100 mb open issue well figure different way submit docset include iconpng icon2xpng size 16x16 32x32 simply delete sample icon dont want icon edit docsetjson file make sure follow naming rule sample ie docset name archive name replace whitespaces underscore edit readmemd submit pull request\n",
      "  (0, 39)\t0.22088430853198115\n",
      "  (0, 38)\t0.2457030697865666\n",
      "  (0, 37)\t0.22088430853198115\n",
      "  (0, 35)\t0.17988406809994378\n",
      "  (0, 34)\t0.2457030697865666\n",
      "  (0, 32)\t0.17678503663270703\n",
      "  (0, 28)\t0.22088430853198115\n",
      "  (0, 26)\t0.23018581489041917\n",
      "  (0, 24)\t0.16515465888562814\n",
      "  (0, 22)\t0.2457030697865666\n",
      "  (0, 21)\t0.21649862605190123\n",
      "  (0, 20)\t0.2042550184228756\n",
      "  (0, 19)\t0.21649862605190123\n",
      "  (0, 18)\t0.20044461827094595\n",
      "  (0, 14)\t0.24029712796126715\n",
      "  (0, 13)\t0.17988406809994378\n",
      "  (0, 11)\t0.24029712796126715\n",
      "  (0, 10)\t0.20044461827094595\n",
      "  (0, 7)\t0.2457030697865666\n",
      "  (0, 3)\t0.24029712796126715\n",
      "  (0, 0)\t0.21649862605190123\n",
      "simple demonstration get basic understanding kubernetes work working step step learnt kubernetes like made repo solve problem faced learning experience might help beginner wont going depth docker see sufficient content get basic understanding learn work kubernetes hope enjoy learning like please give important seeing size readme might second thought honest work start finish wont experience problem learn along way content requirement docker docker creating web server building docker image getting docker image running container image accessing application listing running container running shell inside existing container exploring container within stopping removing container pushing image image registry pushing image docker hub kubernetes kubernetes splitting apps microservice scaling microservices deploying microservices working kubernetes setting kubernetes cluster running local single node kubernetes cluster minikube starting kubernetes cluster minikube checking status cluster deploying node app listing pod accessing web application creating service object listing service horizontally scaling application increasing desired replica count seeing result scale displaying pod ip pod node listing pod accessing dashboard using minikube pod examining yaml descriptor existing pod introducing main part pod definition creating simple yaml descriptor pod using kubectl create create pod retrieving pod log kubectl log forwarding local network port pod introducing label specifying label creating pod modifying label existing pod listing subset pod label selector listing pod using label selector using multiple condition label selector using label selector constrain pod scheduling using label categorizing worker node scheduling pod specific node scheduling one specific node annotating pod looking object annotation adding modifying annotation using namespace group resource discovering namespaces pod creating namespace managing object namespaces understanding isolation provided namespaces stopping removing pod deleting pod name deleting pod using label selector deleting pod deleting whole namespace deleting pod namespace keeping namespace delete almost resource namespace replication controller deploying managed pod keeping pod healthy introducing liveness probe creating http based liveness probe seeing liveness probe action configuring additional property liveness probe creating effective liveness probe introducing replicationcontrollers operation replicationcontroller introducing controller reconciliation loop creating replicationcontroller seeing replicationcontroller action understanding exactly caused controller create new pod moving pod scope replicationcontroller changing pod template horizontally scaling pod deleting replicationcontroller using replicasets instead replicationcontrollers defining replicaset using replicasets expressive label selector running exactly one pod node daemonsets using daemonset run pod every node explaning daemon set example creating daemonset running pod perform single completable task introducing job resource defining job resource seeing job run pod todo requirement need docker installed minikube installed running locally kubectl installed simple concept start docker docker platform packaging distribution running application allows package application together whole environment either library app requires even file usually available filesystem installed operating system docker make possible transfer package central repository transferred computer running docker executed three main concept docker comprise scenario image docker based container image something package application environment contains filesystem available application metadata path executable executed image run registry docker registry repository store docker image facilitates easy sharing image different user computer build image either run computer youve built push upload image registry pull download another computer run certain registry public allowing anyone pull image others private accessible certain people machine container dockerbased container regular linux container created dockerbased container image running container process running host running docker completely isolated host process running process also resourceconstrained meaning access use number resource cpu ram allocated learning working creating web server first need create container image use docker creating simple web server see kubernetes work create file appjs copy code const http requirehttp const requireos consolelogkubia server starting var handler function request response consolelogreceived request requestconnectionremoteaddress responsewritehead200 responseendyouve hit oshostname n var www httpcreateserverhandler wwwlisten8080 create docker file run cluster create docker image create file named dockerfile copy code node8 run npm add appjs appjs entrypoint node appjs building docker image make sure docker server running create docker image local machine open terminal current project folder run docker build kubia youre telling docker build image called kubia based content current directory note dot end build command docker look dockerfile directory build image based instruction file check docker image created running docker image getting docker image docker image command list image running container image docker run name kubiacontainer p 80808080 kubia tell docker run new container called kubiacontainer kubia image container detached console flag mean run background port 8080 local machine mapped port 8080 inside container p 80808080 option access app localhost accessing application run terminal curl localhost8080 youve hit 44d76963e8e1 listing running container list running container command docker p docker p command show basic information container get additional information container run command docker inspect kubiacontainer see container running docker p running shell inside existing container nodejs image youve based image contains bash shell run shell inside container like docker exec kubiacontainer bash run bash inside existing kubiacontainer container bash process linux namespaces main container process allows explore container within see nodejs app see system running inside container option shorthand two option make sure stdin kept open need entering command shell allocates pseudo terminal tty exploring container within let see use shell following listing see process running container rootc61b9b509f9a p aux user pid cpu mem vsz r tty stat start time command root 1 04 13 872872 27832 ssl 0601 000 node appjs root 11 01 01 20244 3016 pts0 0602 000 bash root 16 00 00 17504 2036 pts0 r 0602 000 p aux see three process dont see process host like isolated process tree container also ha isolated filesystem listing content root directory inside container show file container include file image plus file created container running log file similar shown following listing rootc61b9b509f9a l appjs bin boot dev etc home lib lib64 medium mnt opt packagelockjson proc root run sbin srv sys tmp usr var contains appjs file system directory part node8 base image youre using exit container exit shell running exit command youll returned host machine like logging ssh session example stopping removing container docker stop kubiacontainer stop main process running container consequently stop container process running inside container container still exists see docker p option print container running stopped truly remove container need remove docker rm command docker rm kubiacontainer deletes container content removed cant started pushing image image registry image youve built ha far available local machine allow run machine need push image external image registry sake simplicity wont set private image registry instead push image docker hub need retag image according docker hub rule docker hub allow push image image repository name start docker hub id create docker hub id registering hubdocker ill use id knrt10 following example please change every occurrence id know id youre ready rename image currently tagged kubia knrt10kubia replace knrt10 docker hub id docker tag kubia knrt10kubia doesnt rename tag creates additional tag image confirm listing image stored system docker image command shown following listing docker image head see kubia knrt10kubia point image id theyre fact one single image two tag pushing image docker hub push image docker hub need log user id docker login command youre logged finally push youridkubia image docker hub like docker push knrt10kubia kubernetes year ago software application big monolith running either single process small number process spread across handful server today big monolithic legacy application slowly broken smaller independently running component called microservices microservices decoupled developed deployed updated scaled individually enables change component quickly often necessary keep today rapidly changing business requirement bigger number deployable component increasingly larger datacenters becomes increasingly difficult configure manage keep whole system running smoothly much harder figure put component achieve high resource utilization thereby keep hardware cost manually hard work need automation including automatic scheduling component server automatic configuration supervision failurehandling kubernetes come kubernetes enables developer deploy application often want without requiring assistance operation ops team kubernetes doesnt solely benefit developer also help ops team automatically monitoring rescheduling apps event hardware failure focus system administrator sysadmins shift supervising individual apps mostly supervising managing kubernetes rest infrastructure kubernetes take care apps splitting apps microservice microservice run independent process communicates microservices simple welldefined interface apis refer image image taken source microservices communicate synchronous protocol http usually expose restful representational state transfer apis asynchronous protocol amqp advanced message queueing protocol protocol simple well understood developer tied specific programming language microservice written language thats appropriate implementing specific microservice microservice standalone process relatively static external api possible develop deploy microservice separately change one doesnt require change redeployment service provided api doesnt change change backwardcompatible way scaling microservices scaling microservices unlike monolithic system need scale system whole done perservice basis mean option scaling service require resource leaving others original scale refer image image taken source monolithic application cant scaled one part unscalable splitting app microservices allows horizontally scale part allow scaling part dont scale horizontally scaled vertically instead deploying microservices always microservices also drawback system consists small number deployable component managing component easy trivial decide deploy component arent many choice number component increase deploymentrelated decision become increasingly difficult doe number deployment combination increase number interdependency component increase even greater factor microservices also bring problem making hard debug trace execution call span multiple process machine luckily problem addressed distributed tracing system zipkin multiple application running host may conflicting dependency working kubernetes app packaged inside container image made available docker hub deploy kubernetes cluster instead running docker directly first need set cluster setting kubernetes cluster setting fullfledged multinode kubernetes cluster isnt simple task especially youre wellversed linux networking administration proper kubernetes install span multiple physical virtual machine requires networking set properly container running inside kubernetes cluster connect flat networking space running local single node kubernetes cluster minikube simplest quickest path fully functioning kubernetes cluster using minikube minikube tool set singlenode cluster thats great testing kubernetes developing apps locally starting kubernetes cluster minikube minikube installed locally immediately start kubernetes cluster following command minikube start starting local kubernetes cluster starting vm sshing file vm kubectl configured use cluster starting cluster take minute dont interrupt command completes checking see cluster kubernetes talk interact kubernetes also need kubectl cli client installing easy verify cluster working use kubectl clusterinfo command shown following listing kubectl clusterinfo kubernetes master running https192168991008443 kubernetesdashboard running https192168991008443apiv1 kubedns running https192168991008443apiv1namespaceskubesystemserviceskubednsdnsproxy show cluster show url various kubernetes component including api server web console deploying node app simplest way deploy app use kubectl run command create necessary component without deal json yaml kubectl run kubia imageknrt10kubia port8080 generatorrunv1 imageknrt10kubia part obviously specifies container image want run port8080 option tell kubernetes app listening port 8080 last flag generator doe require explanation though usually wont use youre using kubernetes creates replicationcontroller instead deployment listing pod cant list individual container since theyre standalone kubernetes object list pod instead yes let see tell kubectl list pod following listing kubectl get pod kubectl get pod name ready status restarts age kubia5k788 11 running 1 7d accessing web application pod running access pod get ip address address internal cluster isnt accessible outside make pod accessible outside youll expose service object youll create special service type loadbalancer create regular service clusterip service pod would also accessible inside cluster creating loadbalancertype service external load balancer created connect pod load balancer public ip creating service object create service youll tell kubernetes expose replicationcontroller created earlier kubectl expose rc kubia typeloadbalancer name kubiahttp service kubiahttp exposed important using abbreviation rc instead replicationcontroller resource type abbreviation like dont type full name example po pod svc service listing service expose command output mention service called kubiahttp service object like pod node see newly created service object running kubectl get service svc command shown following listing kubectl get svc name type clusterip externalip port age kubernetes clusterip 109601 none 443tcp 7d kubiahttp loadbalancer 10969992 pending 808030126tcp 7d important minikube doesnt support loadbalancer service service never get external ip access service anyway external port external ip always pending case using minikube get ip port access service running minikube service kubiahttp horizontally scaling application running application monitored kept running replicationcontroller exposed world service let make additional magic happen one main benefit using kubernetes simplicity scale deployment let see easy scale number pod youll increase number running instance three pod managed replicationcontroller let see kubectl get command kubectl get rc name desired current ready age kubia 1 1 1 7d increasing desired replica count scale number replica pod need change desired replica count replicationcontroller like kubectl scale rc kubia replicas3 replicationcontroller kubia scaled youve told kubernetes make sure three instance pod always running notice didnt instruct kubernetes action take didnt tell add two pod set new desired number instance let kubernetes determine action need take achieve requested state seeing result scale back replica count increase let list replicationcontrollers see updated replica count kubectl get rc name desired current ready age kubia 3 3 3 7d actual number pod ha already increased three evident current column listing pod show three pod instead one kubectl get pod name ready status restarts age kubia5k788 11 running 1 7d kubia7zxwj 11 running 1 3d kubiabsksp 11 running 1 3d see three pod exist instead one currently running pending would ready moment soon container image downloaded container started see scaling application incredibly simple app running production need scale app arises add additional instance single command without install run additional copy manually keep mind app need support scaled horizontally kubernetes doesnt magically make app scalable make trivial scale app displaying pod ip pod node listing pod youve paying close attention probably noticed kubectl get pod command doesnt even show information node pod scheduled usually important piece information request additional column display using wide option listing pod option show pod ip node pod running kubectl get pod wide name ready status restarts age ip node kubia5k788 11 running 1 7d 1721704 minikube kubia7zxwj 11 running 1 3d 1721705 minikube kubiabsksp 11 running 1 3d 1721706 minikube accessing dashboard using minikube open dashboard browser using minikube run kubernetes cluster run following command minikube dashboard pod pod kubernetes resource usually created posting json yaml manifest kubernetes rest api endpoint also use simpler way creating resource kubectl run command usually allow configure limited set property additionally defining kubernetes object yaml file make possible store version control system benefit brings examining yaml descriptor existing pod youll use kubectl get command yaml option get whole yaml definition pod use json get whole json definition shown following listing kubectl get po kubiabsksp yaml introducing main part pod definition pod definition consists part first kubernetes api version used yaml type resource yaml describing three important section found almost kubernetes resource metadata includes name namespace label information pod spec contains actual description pod content pod container volume data status contains current information running pod condition pod description status container pod internal ip basic info status part contains readonly runtime data show state resource given moment creating new pod never need provide status part three part described previously show typical structure kubernetes api object object anatomy make understanding new object relatively easy going individual property previous yaml doesnt make much sense instead let see basic yaml creating pod look like creating simple yaml descriptor pod youre going create file called kubiamanualyaml create directory want copy repo youll find file filename kubiamanualyaml following listing show entire content file apiversion v1 kind pod metadata name kubiamanual spec container image knrt10kubia name kubia port containerport 8080 protocol tcp let examine descriptor detail conforms v1 version kubernetes api type resource youre describing pod name kubiamanual pod consists single container based knrt10kubia image youve also given name container indicated listening port 8080 using kubectl create create pod create pod yaml file use kubectl create command kubectl create f kubiamanualyaml podkubiamanual created kubectl create f command used creating resource pod yaml json file retrieving pod log kubectl log little nodejs application log process standard output containerized application usually log standard output standard error stream instead writing log file allow user view log different application simple standard way see pod log precisely container log run following command local machine need ssh anywhere kubectl log kubiamanual kubia server starting havent sent web request nodejs app log show single log statement server starting see retrieving log application running kubernetes incredibly simple pod contains single container specifying container name getting log multiple container pod pod includes multiple container explicitly specify container name including c container name option running kubectl log kubiamanual pod set container name kubia additional container exist pod youd get log like kubectl log kubiamanual c kubia note retrieve container log pod still existence pod deleted log also deleted forwarding local network port pod want talk specific pod without going service debugging reason kubernetes allows configure port forwarding pod done kubectl portforward command following command forward machine local port 8888 port 8080 kubiamanual pod kubectl portforward kubiamanual 88888080 different terminal use curl send http request pod kubectl portforward proxy running localhost8888 curl localhost8888 youve hit kubiamanual using port forwarding like effective way test individual pod introducing label organizing pod kubernetes object done label label simple yet incredibly powerful kubernetes feature organizing pod kubernetes resource label arbitrary keyvalue pair attach resource utilized selecting resource using label selector resource filtered based whether include label specified selector specifying label creating pod youll see label action creating new pod two label create new file called kubiamanualwithlabelsyaml content following listing also copy kubiamanualwithlabelsyaml apiversion v1 kind pod metadata name kubiamanualv2 label creationmethod manual env prod spec container image knrt10kubia name kubia port containerport 8080 protocol tcp youve included label creationmethodmanual envdatalabels section youll create pod kubectl create f kubiamanualwithlabelsyaml podkubiamanualv2 created kubectl get po command doesnt list label default see using showlabels switch kubectl get po showlabels name ready status restarts age label kubia5k788 11 running 1 8d runkubia kubia7zxwj 11 running 1 5d runkubia kubiabsksp 11 running 1 5d runkubia kubiamanual 11 running 0 7h none kubiamanualv2 11 running 0 3m creationmethodmanualenvprod instead listing label youre interested certain label specify l switch displayed column list pod show column two label youve attached kubiamanualv2 pod kubectl get po l creationmethodenv modifying label existing pod label also added modified existing pod kubiamanual pod wa also created manually let add creationmethodmanual label kubectl label po kubiamanual creationmethodmanual let also change envprod label envdebug kubiamanualv2 pod see existing label changed need use overwrite option changing existing label kubectl label po kubiamanualv2 envdebug overwrite listing subset pod label selector attaching label resource see label next resource listing isnt interesting label go hand hand label selector label selector allow select subset pod tagged certain label perform operation pod label selector select resource based whether resource contains doesnt contain label certain key contains label certain key value contains label certain key value equal one specify listing pod using label selector let use label selector pod youve created far see pod created manually labeled creationmethodmanual following kubectl get po l creationmethodmanual name ready status restarts age kubiamanual 11 running 0 22h kubiamanualv2 11 running 0 14h dont env label kubectl get po l env name ready status restarts age kubia5k788 11 running 1 9d kubia7zxwj 11 running 1 5d kubiabsksp 11 running 1 5d kubiamanual 11 running 0 22h make sure use single quote around env bash shell doesnt evaluate exclamation mark using multiple condition label selector selector also include multiple commaseparated criterion resource need match match selector execute command given kubectl get po l env creationmethod showlabels using label selector constrain pod scheduling pod youve created far scheduled pretty much randomly across worker node certain case exist however youll want least little say pod scheduled good example hardware infrastructure isnt homogenous never want say specifically node pod scheduled would couple application infrastructure whereas whole idea kubernetes hiding actual infrastructure apps run using label categorizing worker node pod arent kubernetes resource type attach label label attached kubernetes resource including node let imagine one node cluster contains gpu meant used generalpurpose gpu computing want add label node showing feature youre going add label gputrue one node pick one list returned kubectl get node kubectl label node minikube gputrue nodeminikube labeled use label selector listing node like pod list node include label gputrue kubectl get node l gputrue name status role age version minikube ready master 9d v1100 expected one node ha label also try listing node tell kubectl display additional column showing value node gpu label kubectl get node l gpu name status role age version gpu minikube ready master 9d v1100 true scheduling pod specific node imagine want deploy new pod need gpu perform work ask scheduler choose among node provide gpu youll add node selector pod yaml create file called kubiagpuyaml following listing content use kubectl create f kubiagpuyaml create pod content file apiversion v1 kind pod metadata name kubiagpu spec nodeselector gpu true container image luksakubia name kubia youve added nodeselector field spec section create pod scheduler choose among node contain gputrue label single node case scheduling one specific node similarly could also schedule pod exact node node also ha unique label key kubernetesiohostname value set actual hostname node example shown kubectl get node showlabels name status role age version label minikube ready master 9d v1100 betakubernetesioarchamd64betakubernetesiooslinuxgputruekubernetesiohostnameminikubenoderolekubernetesiomaster setting nodeselector specific node hostname label may lead pod unschedulable node offline annotating pod addition label pod object also contain annotation also key value pair essence similar label arent meant hold identifying information cant used group object way label object selected label selector thing annotation selector hand annotation hold much larger piece information primarily meant used tool certain annotation automatically added object kubernetes others added user manually great use annotating pod add desciption pod api object everyone using cluster quickly look information individual object looking object annotation let see example annotation kubernetes added automatically pod created previous section see annotation youll need request full yaml pod use kubectl describe command youll use first option following listing kubectl get po kubiazb95q yaml apiversion v1 kind pod metadata annotation kubernetesiocreatedby kindserializedreference apiversionv1 referencekindreplicationcontroller namespacedefault without going many detail see kubernetesiocreatedby annotation hold json data object created pod thats something youd want put label label short whereas annotation contain relatively large blob data 256 kb total important kubernetesiocreatedby annotation wa deprecated version 18 removed 19 longer see yaml adding modifying annotation annotation obviously added pod creation time way label also add using following command let try adding kubiamanual pod kubectl annotate pod kubiamanual knrt10githubiosomeannotationmessi ronaldo added annotation knrt10githubiosomeannotation value messi ronaldo good idea use format annotation key prevent key collision different tool library add annotation object may accidentally override others annotation dont use unique prefix like check pod using following command kubectl describe po kubiamanual using namespace group resource previously saw label organize pod object group object multiple label group object overlap plus working cluster kubectl example dont explicitly specify label selector youll always see object discovering namespaces pod let u first list namespaces cluster type following command kubectl get n name status age default active 9h kubepublic active 9h kubesystem active 9h point youve operated default namespace listing resource kubectl get command youve never specified namespace explicitly kubectl always defaulted default namespace showing object namespace see list kubepublic kubesystem namespaces also exist let look pod belong kubesystem namespace telling kubectl list pod namespace kubectl get po n kubesystem name ready status restarts age etcdminikube 11 running 0 4h kubeaddonmanagerminikube 11 running 1 9h kubeapiserverminikube 11 running 0 4h kubecontrollermanagerminikube 11 running 0 4h kubedns86f4d74b45w8mqv 33 running 4 9h kubeproxy25t92 11 running 0 4h kubeschedulerminikube 11 running 0 4h kubernetesdashboard5498ccf6772zcw5 11 running 2 9h storageprovisioner 11 running 2 9h explain pod later dont worry pod shown dont match one system exactly clear name namespace resource related kubernetes system separate namespace keep everything nicely organized default namespace mixed resource create youd hard time seeing belongs might inadvertently delete system resource namespaces enable separate resource dont belong together nonoverlapping group several user group user using kubernetes cluster manage distinct set resource use namespace way dont need take special care inadvertently modify delete user resource dont need concern name conflict namespaces provide scope resource name ha already mentioned creating namespace namespace kubernetes resource like create posting yaml file kubernetes api server let see youre going create file called customnamespaceyaml create directory want copy repo youll find file filename customnamespaceyaml following listing show entire content file apiversion v1 kind namespace metadata name customnamespace type following command kubectl create f customnamespaceyaml namespacecustomnamespace created managing object namespaces create resource namespace youve created either add namespace customnamespace entry metadata section specify namespace creating resource kubectl create command kubectl create f kubiamanualyaml n customnamespace podkubiamanual created two pod name kubiamanual one default namespace customnamespace listing describing modifying deleting object namespaces need pas namespace n flag kubectl dont specify namespace kubectl performs action default namespace configured current kubectl context current context namespace current context changed kubectl config command understanding isolation provided namespaces wrap section namespaces let explain namespaces dont provide least box although namespaces allow isolate object distinct group allows operate belonging specified namespace dont provide kind isolation running object example may think different user deploy pod across different namespaces pod isolated cant communicate thats necessarily case whether namespaces provide network isolation depends networking solution deployed kubernetes solution doesnt provide internamespace network isolation pod namespace foo know ip address pod namespace bar nothing preventing sending traffic http request pod stopping removing pod created number pod running followed start 5 pod default namespace one customnamespace going stop dont need anymore deleting pod name let first delele kubiagpu pod name kubectl delete po kubiagpu deleting pod using label selector instead specifying pod delete name youll use youve learned label selector stop kubiamanual kubiamanualv2 pod pod include creationmethodmanual label delete using label selector kubectl delete po l creationmethodmanual pod kubiamanual deleted pod kubiamanualv2 deleted earlier microservices example ten possibly hundred pod could instance delete canary pod specifying relcanary label selector kubectl delete po l relcanary deleting pod deleting whole namespace okay back real pod pod customnamespace longer need either pod namespace namespace delete whole namespace using following command pod inside workspace automatically deleted kubectl delete n customnamespace namespace customnamespace deleted deleting pod namespace keeping namespace suppose want keep namespace delete pod approach follow cleaned almost everything pod running ran kubectl run command time instead deleting specific pod tell kubernetes delete pod current namespace using option kubeclt delete po pod kubiapjxrs deleted pod kubiaxvfxp deleted pod kubiazb95q deleted double check pod left running kubectl get po kubia5gknm 11 running 0 48s kubiah62k7 11 running 0 48s kubiax4nsb 11 running 0 48s wait pod terminating new pod werent ha appeared matter many time delete pod new pod called kubiasomething emerge may remember created first pod kubectl run command mentioned doesnt create pod directly instead creates replicationcontroller creates pod soon delete pod created replicationcontroller immediately creates new one delete pod also need delete replicationcontroller delete almost resource namespace delete replicationcontroller pod well service youve created deleting resource current namespace single command kubectl delete pod kubia5gknm deleted pod kubiah62k7 deleted pod kubiax4nsb deleted replicationcontroller kubia deleted service kubernetes deleted service kubiahttp deleted first command specifies youre deleting resource type option specifies youre deleting resource instance instead specifying name already used option ran previous delete command deletes resource kubectl print name every resource deletes list see kubia replicationcontroller kubiahttp service created note kubectl delete command also deletes kubernetes service recreated automatically moment replication controller deploying managed pod far might understood pod represent basic deployment unit kubernetes know create supervise manage manually realworld use case want deployment stay running automatically remain healthy without manual intervention never almost create pod directly instead create type resource like replicationcontrollers deployment create manage actual pod create unmanaged pod one created previously cluster node selected run pod container run node well learn kubernetes monitor container automatically restarts fail whole node fails pod node lost replaced new one unless pod managed previously mentioned replicationcontrollers similar well learn kubernetes check container still alive restarts isnt well also learn run managed podsboth run indefinitely perform single task stop keeping pod healthy one main benefit using kubernetes ability give list container let keep container running somewhere cluster creating pod resource letting kubernetes pick worker node run pod container node one container dy container pod die soon pod scheduled node kubelet node run container keep running long pod exists container main process crash kubelet restart container application ha bug cause crash every kubernetes restart automatically even without anything special app running app kubernetes automatically give ability heal sometimes apps stop working without process crashing example java app memory leak start throwing outofmemoryerrors jvm process keep running would great way app signal kubernetes longer functioning properly kubernetes restart weve said container crash restarted automatically maybe youre thinking could catch type error app exit process occur certainly still doesnt solve problem example situation app stop responding fall infinite loop deadlock make sure application restarted case must check application health outside depend app internally introducing liveness probe kubernetes check container still alive liveness probe specify liveness probe container pod specification kubernetes probe container using one three mechanism http get probe performs http get request container ip address port path specify probe receives response response code doesnt represent error word http response code 2xx 3xx probe considered successful server return error response code doesnt respond probe considered failure container restarted result tcp socket probe try open tcp connection specified port container connection established successfully probe successful otherwise container restarted exec probe executes arbitrary command inside container check command exit status code status code 0 probe successful probe considered failure creating http based liveness probe let see add liveness probe nodejs app web app make sense add liveness probe check whether web server serving request particular nodejs app simple ever fail youll need make app fail artificially properly demo liveness probe youll modify app slightly make return 500 internal server error http status code request fifth oneyour app handle first five client request properly return error every subsequent request thanks liveness probe restarted happens allowing properly handle client request ive pushed container image docker hub dont need build want see folder kubiaunhealthy information youll create new pod includes http get liveness probe following listing show yaml pod youre going create file called kubialivenessprobeyaml create directory want copy repo youll find file filename kubialivenessprobeyaml following listing show entire content file apiversion v1 kind pod metadata name kubialiveness spec container image knrt10kubiaunhealthy name kubia livenessprobe httpget path port 8080 pod descriptor defines httpget liveness probe tell kubernetes periodically perform http get request path port 8080 determine container still healthy request start soon container run five request actual client request app start returning http status code 500 kubernetes treat probe failure thus restart container seeing liveness probe action see liveness probe doe try creating pod minute half container restarted see running kubectl get kubectl get po kubialiveness name ready status restarts age kubialiveness 11 running 1 2m restarts column show pod container ha restarted wait another minute half get restarted cycle continues indefinitely see container restarted looking kubectl describe print see container currently running previously terminated error exit code wa 137 ha special meaning denotes process wa terminated external signal number 137 sum two number 128x x signal number sent process caused terminate example x equal 9 number sigkill signal meaning process wa killed forcibly container killed completely new container created container restarted configuring additional property liveness probe may noticed kubectl describe also display additional information liveness probe liveness httpget http8080 delay0s timeout1s period10s success1 failure3 beside liveness probe option specified explicitly also see additional property delay timeout period delay0s part show probing begin immediately container started timeout set 1 second container must return response 1 second probe counted failed container probed every 10 second period10s container restarted probe fails three consecutive time failure3 dont set initial delay prober start probing container soon start usually lead probe failing app isnt ready start receiving request number failure exceeds failure threshold container restarted even able start responding request properly tip always remember set initial delay account apps startup time ive seen many occasion user confused container wa restarted theyd used kubectl describe theyd seen container terminated exit code 137 143 telling pod wa terminated externally additionally listing pod event would show container wa killed failed liveness probe see happening pod startup failed set initialdelayseconds appropriately creating effective liveness probe pod running production always define liveness probe without one kubernetes ha way knowing whether app still alive long process still running kubernetes consider container healthy liveness probe check simplistic liveness probe simply check server responding may seem overly simple even liveness probe like doe wonder cause container restarted web server running within container stop responding http request compared liveness probe major improvement may sufficient case better liveness check youd configure probe perform request specific url path health example app perform internal status check vital component running inside app ensure none ha died unresponsive tip make sure health http endpoint doesnt require authentication otherwise probe always fail causing container restarted indefinitely sure check internals app nothing influenced external factor example frontend web server liveness probe shouldnt return failure server cant connect backend database underlying cause database restarting web server container fix problem liveness probe fail youll end container restarting repeatedly database becomes accessible keeping probe light liveness probe shouldnt use many computational resource shouldnt take long complete default probe executed relatively often allowed one second complete probe doe heavy lifting slow container considerably later book youll also learn limit cpu time available container probe cpu time counted container cpu time quota heavyweight liveness probe reduce cpu time available main application process dont bother implementing retry loop probe youve already seen failure threshold probe configurable usually probe must fail multiple time container killed even set failure threshold 1 kubernetes retry probe several time considering single failed attempt therefore implementing retry loop probe wasted effort liveness probe wrapup understand kubernetes keep container running restarting crash liveness probe fail job performed kubelet node hosting pod kubernetes control plane component running master part process node crash control plane must create replacement pod went node doesnt pod create directly pod arent managed anything except kubelet kubelet run node cant anything node fails make sure app restarted another node need pod managed replicationcontroller similar mechanism later readme introducing replicationcontrollers replication controllerrc kubernetes resource ensures pod always kept running pod disappers reason like case node disappearing cluster pod wa evicted node rc note pod missing creates replacement pod please refer image node fails pod backed replicationcontroller recreated rc figure manage single pod general meant create manage mutiple copy replica pod thats rc got name operation replicationcontroller rc contantly monitor list running pod make sure actual number pod type always match desire number pod running creates new replica pod template much pod running remove excess replica might wondering desired number replica happen reason someone creates pod type manually someone change existing pod type someone decrease desired number pod ive used term pod type time thing exists replication controller dont operate pod type set pod match certain label selector told previously introducing controller reconciliation loop replicationcontrollers job make sure exact number pod always match label selector doesnt replicationcontroller take appropriate action reconcile actual desired number replicationcontroller ha three essential part label selector determines pod replicationcontrollers scope replica count specifies desired number pod running pod template used creating new pod replica three key part replicationcontroller pod selector replica count pod template replicationcontrollers replica count label selector even pod template modified time change replica count affect existing pod change label selector pod template effect existing pod changing label selector make existing pod fall scope replicationcontroller controller stop caring replicationcontrollers also dont care actual content pod container image environment variable thing create pod template therefore affect new pod created replicationcontroller think cookie cutter cutting new pod benefit make sure pod multiple pod replica always running starting new pod existing one go missing cluster node fails creates replacement replica pod running failed node replication controller control enables easy horizontal scaling podsboth manual automatic note pod instance never relocated another node instead replicationcontroller creates completely new pod instance ha relation instance replacing creating replicationcontroller youre going create file called kubiarcyaml create directory want copy repo youll find file filename kubiarcyaml following listing show entire content file apiversion v1 kind replicationcontroller metadata name kubia spec replica 3 selector app kubia template metadata label app kubia spec container name kubia image knrt10kubia port containerport 8080 post file api server kubernetes creates new replicationcontroller named kubia make sure three pod instance always match label selector appkubia arent enough pod new pod created provided pod template content template almost identical pod defination created pod label template must obviously match label selector replicationcontroller otherwise controller would create new pod indefinitely spinning new pod wouldnt bring actual replica count closer desired number replica prevent scenario api server verifies replicationcontroller definition accept misconfigured specifying selector also option case configured automatically label pod template create replicationcontroller use kubectl create command already know kubectl create f kubiarcyaml replicationcontroller kubia created seeing replicationcontroller action pod exist appkubia label replicationcontroller spin three new pod pod template list pod see replicationcontroller ha done supposed kubectl get po name ready status restarts age kubia53thy 01 containercreating 0 6 kubiak0xz6 01 containercreating 0 6 kubiaq3vkg 01 containercreating 0 6 indeed ha wanted three pod created three pod managing three pod next well mess little see replicationcontroller responds try deleting pod rc spawn another pod automatically replicationcontroller ha done job nice little helper isnt understanding exactly caused controller create new pod controller responding deletion pod creating new replacement pod well technically isnt responding deletion resulting statethe inadequate number pod replicationcontroller immediately notified pod deleted api server allows client watch change resource resource list thats cause create replacement pod notification trigger controller check actual number pod take appropriate action pod disappears replicationcontroller see pod creates new replacement pod seeing replicationcontroller respond manual deletion pod isnt interesting let look better example youre using google kubernetes engine run example threenode kubernetes cluster youre going disconnect one node network simulate node failure note youre using minikube cant exercise one node act master worker node node fails nonkubernetes world ops team would need migrate application running node machine manually kubernetes hand doe automatically soon replicationcontroller detects pod spin new pod replace let see action need ssh one node gcloud compute ssh command shut network interface sudo ifconfig eth0 shown following gcloud compute ssh gkekubiadefaultpoolb46381f1zwko enter passphrase key homeknrt10sshgooglecomputeengine welcome kubernetes v1162 knrt10gkekubiadefaultpoolb46381f1zwko sudo ifconfig eth0 shut network interface ssh session stop responding need open another terminal hardexit ssh session new terminal list node see kubernetes ha detected node take minute node status shown notready list pod youll still see three pod kubernetes wait rescheduling pod case node unreachable temporary network glitch kubelet restarting node stay unreachable several minute status pod scheduled node change unknown point replicationcontroller immediately spin new pod see listing pod looking age pod see kubiadmdck pod new three pod instance running mean replicationcontroller ha done job bringing actual state system desired state thing happens node fails either break becomes unreachable immediate human intervention necessary system heals automatically bring node back need reset following command gcloud compute instance reset gkekubiadefaultpoolb46381f1zwko node boot status return ready pod whose status wa unknown deleted moving pod scope replicationcontroller pod created replicationcontroller arent tied replicationcontroller way moment replicationcontroller manages pod match label selector changing pod label removed added scope replicationcontroller even moved one replicationcontroller another tip although pod isnt tied replicationcontroller pod doe reference metadataownerreferences field use easily find replicationcontroller pod belongs change pod label longer match replicationcontrollers label selector pod becomes like manually created pod longer managed anything node running pod fails pod obviously rescheduled keep mind changed pod label replication controller noticed one pod wa missing spun new pod replace kubectl label po kubiadmdck appkubia2 overwrite overwrite argument necessary otherwise kubectl print warning wont change label prevent inadvertently changing existing label value intent add new one four pod altogether one isnt managed replicationcontroller three among newly created pod removing pod scope replicationcontroller changing label replicationcontroller spin pod kubia2qneh bring number back three pod kubiadmdck completely independent keep running delete manually dont need anymore removing pod controller practice removing pod scope replicationcontroller come handy want perform action specific pod example might bug cause pod start behaving badly specific amount time specific event know pod malfunctioning take replicationcontrollers scope let controller replace new one debug play pod way want youre done delete pod changing pod template replicationcontrollers pod template modified time changing pod template like replacing cookie cutter another one affect cooky cut afterward effect one youve already cut see figure modify old pod youd need delete let replication controller replace new one based new template changing replicationcontrollers pod template affect pod created afterward ha effect existing pod exercise try editing replicationcontroller adding label pod template edit replicationcontroller following command kubectl edit rc kubia open replicationcontrollers yaml definition default text editor find pod template section add additional label metadata save change exit editor kubectl update replicationcontroller print following message replicationcontroller kubia edited list pod label confirm havent changed delete pod wait replacement created youll see new label editing replicationcontroller like change container image pod template deleting existing pod letting replaced new one new template could used upgrading pod youll learn better way later horizontally scaling pod scaling number pod easy changing value replica field replicationcontroller resource change replicationcontroller either see many pod exist scaling delete part see scaling create additional pod already know command kubectl scale rc kubia replicas10 instead using kubectl scale command youre going scale declarative way editing replicationcontrollers definition kubectl edit rc kubia text editor open find specreplicas field change value 10 check listing kubectl get rc name desired current ready age kubia 10 10 4 21m scale back 3 use kubectl scale command kubectl scale rc kubia replicas3 horizontally scaling pod kubernetes matter stating desire want x number instance running youre telling kubernetes youre specifying desired state declarative approach make interacting kubernetes cluster easy imagine manually determine current number running instance explicitly tell kubernetes many additional instance run thats work much errorprone changing simple number much easier later youll learn even done kubernetes enable horizontal pod autoscaling deleting replicationcontroller delete replicationcontroller kubectl delete pod also deleted pod created replicationcontroller arent integral part replicationcontroller managed delete replicationcontroller leave pod running shown may useful initially set pod managed replicationcontroller decide replace replicationcontroller replicaset without affecting pod keep running without interruption replace replicationcontroller manages deleting replicationcontroller kubectl delete keep pod running passing cascadefalse option command try kubectl delete rc kubia cascadefalse youve deleted replicationcontroller pod longer managed always create new replicationcontroller proper label selector make managed using replicasets instead replicationcontrollers initially replicationcontrollers kubernetes component replicating pod rescheduling node failed later similar resource called replicaset wa introduced new generation replicationcontroller replaces completely replicationcontrollers eventually deprecated could started section creating replicaset instead replicationcontroller felt would good idea start wa initially available kubernetes please dont report plus well still see replicationcontrollers used wild good know said always create replicasets instead replicationcontrollers theyre almost identical shouldnt trouble using instead replicaset behaves exactly like replicationcontroller ha expressive pod selector whereas replicationcontrollers label selector allows matching pod include certain label replicasets selector also allows matching pod lack certain label pod include certain label key regardless value also example single replicationcontroller cant match pod label envproduction label envdevel time match either pod envproduction label pod envdevel label single replicaset match set pod treat single group similarly replicationcontroller cant match pod based merely presence label key regardless value whereas replicaset example replicaset match pod include label key env whatever actual value isyou think env defining replicaset youre going create replicaset see orphaned pod created replicationcontroller abandoned earlier adopted replicaset youre going create file called kubiareplicasetyaml create directory want copy repo youll find file filename kubiareplicasetyaml following listing show entire content file apiversion appsv1 kind replicaset metadata name kubia spec replica 3 selector matchlabels app kubia template metadata label app kubia spec container name kubia image knrt10kubia port containerport 8080 first thing note replicasets arent part v1 api need ensure specify proper apiversion creating resource youre creating resource type replicaset ha much content replicationcontroller created earlier difference selector instead listing label pod need directly selector property youre specifying selector matchlabels simpler le expressive way defining label selector replicaset still three pod matching appkubia selector running earlier creating replicaset cause new pod created replicaset take existing three pod wing create replicaset using kubectl create command examine using kubectl describe command see replicaset isnt different replicationcontroller showing ha three replica matching selector list pod youll see theyre still three pod replicaset didnt create new one using replicasets expressive label selector main improvement replicasets replicationcontrollers expressive label selector intentionally used simpler matchlabels selector first replicaset example see replicasets different replicationcontrollers add additional expression selector example expression must contain key operator possibly depending operator list value youll see four valid operator inlabels value must match one specified value notinlabels value must match specified value existspod must include label specified key value isnt important using operator shouldnt specify value field doesnotexistpod must include label specified key value property must specified specify multiple expression expression must evaluate true selector match pod specify matchlabels matchexpressions label must match expression must evaluate true pod match selector wa quick introduction replicasets alternative replicationcontrollers remember always use instead replicationcontrollers may still find replicationcontrollers people deployment delete replicaset clean cluster little delete replicaset way youd delete replicationcontroller kubectl delete r kubia replicaset kubia deleted deleting replicaset delete pod list pod confirm thats case running exactly one pod node daemonsets rc r used running specific number pod deployed anywhere kubernetes cluster certain case exist want pod run every node cluster node need run exactly one instance pod case include infrastructure related pod perform systemlevel operation example youll want run log collector resource monitor every node another good example kubernetes kubeproxy process need run node make service work daemonsets run single pod replica node whereas replicasets scatter around whole cluster randomly using daemonset run pod every node run pod cluster node create daemonset object much like replicationcontroller replicaset except pod created daemonset already target node specified skip kubernetes scheduler arent scattered around cluster randomly daemonset make sure creates many pod node deploys one node shown whereas replicaset replicationcontroller make sure desired number pod replica exist cluster daemonset doesnt notion desired replica count doesnt need job ensure pod matching pod selector running node node go daemonset doesnt cause pod created elsewhere new node added cluster daemonset immediately deploys new pod instance also doe someone inadvertently deletes one pod leaving node without daemonsets pod like replicaset daemonset creates pod pod template configured explaning daemon set example let imagine daemon called ssdmonitor need run node contain solidstate drive ssd youll create daemonset run daemon node marked ssd cluster administrator added diskssd label node youll create daemonset node selector selects node label youll create daemonset run mock ssdmonitor process print ssd ok standard output every five second ive already prepared mock container image pushed docker hub use instead building youre going create file called ssdmonitordaemonsetyaml create directory want copy repo youll find file filename ssdmonitordaemonsetyaml following listing show entire content file apiversion appsv1 kind daemonset metadata name ssdmonitor spec selector matchlabels app ssdmonitor template metadata label app ssdmonitor spec nodeselector disk ssd container name main image knrt10ssdmonitor youre defining daemonset run pod single container based knrt10ssdmonitor container image instance pod created node ha diskssd label creating daemonset use kubectl create command know kubectl create f ssdmonitordaemonsetyaml let see created daemonset kubectl get name desired current ready uptodate available node selector age ssdmonitor 0 0 0 0 0 diskssd 18 zero look strange didnt daemonset deploy pod list pod kubectl get po resource found pod know whats going yes forgot label node diskssd label problemyou daemonset detect node label changed deploy pod node matching label let see thats true daemonset created one pod let see kubectl label node minikube diskssd name ready status restarts age ssdmonitorzs6sr 11 running 0 6 okay far good multiple node add label node youll see daemonset spin pod imagine youve made mistake mislabeled one node ha spinning disk drive ssd happens change node label pod terminated knew wa going happen right wrap exploration daemonsets may want delete ssdmonitor daemonset still daemon pod running youll see deleting daemonset deletes pod well running pod perform single completable task far told pod run continuously well case need terminate task completed replicationcontollers relicasets daemonsets run continuously task never considered completed process task restarted exit want want stop process completed introducing job resource kubernetes includes support job resource similar resource discussed far allows run pod whose container isnt restarted process running inside finish successfully doe pod considered complete event node failure pod node managed job reschduled node way replicasets event failure process process return error exit code job configured either restart container shown tell pod created job rescheduled new node node wa initially scheduled fails also show managed pod isnt rescheduled pod backed replicaset example job useful ad hoc task crucial task finish properly could run task unmanaged pod wait finish event node failing pod evicted node performing task youd need manually recreate manually doesnt make sense especially job take hour complete example job would data stored somewhere needed transform export somewhere youre going emulate running container image built top busybox image invokes sleep command two minute ive already built image pushed docker hub peek dockerfile book code archive pod managed job rescheduled finish successfully defining job resource create job manifest following listing youre going create file called exporteryaml create directory want copy repo youll find file filename exporteryaml following listing show entire content file apiversion batchv1 kind job metadata name batchjob spec template metadata label app batchjob spec restartpolicy onfailure container name main image knrt10batchjob job part batch api group v1 api version yaml defines resource type job run knrt10batchjob image invokes process run exactly 120 second exit image already pushed dockerhub pod specification specify kubernetes process running container finish done restartpolicy pod spec property default always job pod cant use default policy theyre meant run indefinitely therefore need explicitly set restart policy either onfailure never setting prevents container restarted finish fact pod managed job resource seeing job run pod create job kubectl create command see start pod immediately kubectl get job name desired successful age batchjob 1 0 2 todo write pod write yaml file write ingres routing write volume write config map secret write updating running pod write statefulsets securing pod container implement write gcp\n",
      "  (0, 39)\t0.16460552202357764\n",
      "  (0, 38)\t0.18310074777972538\n",
      "  (0, 37)\t0.16460552202357764\n",
      "  (0, 36)\t0.1581878727234024\n",
      "  (0, 35)\t0.13405167225370793\n",
      "  (0, 34)\t0.18310074777972538\n",
      "  (0, 33)\t0.17153711132438412\n",
      "  (0, 32)\t0.13174223843370372\n",
      "  (0, 31)\t0.17522271587883007\n",
      "  (0, 30)\t0.16460552202357764\n",
      "  (0, 29)\t0.1613372611006489\n",
      "  (0, 28)\t0.16460552202357764\n",
      "  (0, 27)\t0.14137422671488392\n",
      "  (0, 26)\t0.17153711132438412\n",
      "  (0, 25)\t0.17522271587883007\n",
      "  (0, 24)\t0.1230751474433442\n",
      "  (0, 23)\t0.14662423626806115\n",
      "  (0, 22)\t0.18310074777972538\n",
      "  (0, 21)\t0.1613372611006489\n",
      "  (0, 20)\t0.1522131841636227\n",
      "  (0, 19)\t0.1613372611006489\n",
      "  (0, 18)\t0.14937363023471023\n",
      "  (0, 17)\t0.1581878727234024\n",
      "  (0, 15)\t0.18310074777972538\n",
      "  (0, 13)\t0.13405167225370793\n",
      "  (0, 12)\t0.16800198228291952\n",
      "  (0, 11)\t0.17907217788222324\n",
      "  (0, 10)\t0.14937363023471023\n",
      "  (0, 9)\t0.16800198228291952\n",
      "  (0, 8)\t0.15514901229470407\n",
      "  (0, 7)\t0.18310074777972538\n",
      "  (0, 6)\t0.15514901229470407\n",
      "  (0, 5)\t0.1581878727234024\n",
      "  (0, 4)\t0.13405167225370793\n",
      "  (0, 3)\t0.17907217788222324\n",
      "  (0, 2)\t0.17153711132438412\n",
      "  (0, 1)\t0.17522271587883007\n",
      "  (0, 0)\t0.1613372611006489\n",
      "note repo going updated anymore tensorflow version used repo wa old july 19th 2018 mytensorflowtutorials repo contains tensorflow deep learning project deep learning well traditional machine learning data mining tensorflow kera youtube httpswwwyoutubecomckevinxu fun\n",
      "  (0, 36)\t0.42098129914911453\n",
      "  (0, 33)\t0.45650728298176385\n",
      "  (0, 24)\t0.3275367104421698\n",
      "  (0, 23)\t0.390207292178494\n",
      "  (0, 21)\t0.42936268507808906\n",
      "  (0, 6)\t0.41289405839429905\n",
      "topstarreddevsandrepostofollow topstarred python github devs orgs repos follow alltime trending follow topstarred python github devs following influencers usually good practice ha helped multiple way whenever run inspiration look influencers see achieved brings back energy back project follow influencers see event attending reading working quickly become wealth knowledge extent also provides human touch influencers looking profile might come across one world start following regularly tend relate influencers inspired following reddit post reading post wa curious see similar list python github devs orgs repos topstarred definitive way determine top devs orgs repos language every metric ha flaw list look total number star python repository seems decent metric readily availableeasy mine dev stats individual contributor org stats also provided viewing org link show devs part org sure youd measure stats dev part org similarly devs contributing project github perfect classifying repos python list try manually filter misclassified repos found interesting track time trending stats list included source provided list topstarred python github devs follow alltime format dev top repo total dev star kennethreitz request 44472 jkbrzt httpie 26428 nvbn thefuck 23493 donnemartin datascienceipythonnotebooks 20648 rg3 youtubedl 19759 valloric youcompleteme 11875 apenwarr sshuttle 9628 faif pythonpatterns 9033 fchollet kera 8742 tomchristie djangorestframework 8575 jonathanslenders pythonprompttoolkit 7826 binux pyspider 7796 soimort youget 7402 pew maybe 7133 miguelgrinberg flasky 6771 alexjc neuraldoodle 6505 toastdriven restless 6481 coleifer peewee 6437 nvie rq 6229 nicolargo glance 5775 source githubawards last updated 20160821 topstarred python github devs follow trending format dev top repo total dev star donnemartin gitsome 8495 alexjc neuraldoodle 6392 pew maybe 5985 eliangcs httpprompt 5513 0x5e wechatdeletedfriends 4497 a1studmuffin spaceshipgenerator 4284 samshadwell trumpscript 3923 jayfk statuspage 3261 reinderien mimic 3079 pavelgonchar colornet 2825 juanpotato legofy 2783 diafygi acmetiny 2636 cyrusand gdbdashboard 2625 awentzonline imageanalogies 2560 programthink zhao 2361 nlintz tensorflowtutorials 2321 gongjianhui appledns 2009 ujjwalkarn datasciencepython 1986 mchristopher pokemongodesktopmap 1979 yenchenlin deeplearningflappybird 1759 source github search aggregating repos dev last updated 20160821 trending 20150821 20160821 topstarred python github orgs alltime format org top repo total org star pallet flask 33572 openstack nova 24591 django django 24490 google yapf 23552 ansible ansible 21169 scrapy scrapy 17881 docker compose 17070 certbot certbot 16023 shadowsocks shadowsocks 14934 facebook chisel 14082 getsentry sentry 13703 scikitlearn scikitlearn 12993 tornadoweb tornado 11958 reddit reddit 11752 ipython ipython 10567 pydata panda 10079 yelp mrjob 9879 airbnb caravel 9842 kivy kivy 9674 xxnet xxnet 9267 source githubawards last updated 20160821 topstarred python github orgs trending format org top repo total org star rochesternrt rocalphago 7224 tensorflow magenta 5663 cmusatyalab openface 4973 zulip zulip 4005 pokemongof pokemongobot 3990 awslabs awsshell 3742 reverseshell routersploit 3680 tflearn tflearn 3471 magicstack uvloop 3469 openai gym 3399 lektor lektor 1960 pokemongomap pokemongomap 1930 eastlakeside interpyzh 1552 zerodb zerodb 1477 digitalocean netbox 1426 commaai research 1412 nerevu riko 1129 ascribe imagematch 1039 cachebrowser cachebrowser 1024 ansible ansiblecontainer 1003 source github search aggregating repos org last updated 20160821 trending 20150821 20160821 topstarred python github repos alltime jkbrzthttpie 25585cli http client userfriendly curl replacement intuitive ui json support syntax highlighting wgetlike downloads extension etc palletsflask 22167a microframework based werkzeug jinja2 good intention nvbnthefuck 21504magnificent app corrects previous console command djangodjango 20841the web framework perfectionist deadline kennethreitzrequests 20420python http request human rg3youtubedl 19722commandline program download video youtubecom video site ansibleansible 18399ansible radically simple automation platform make application system easier deploy avoid writing script custom code deploy update application automate language approach plain english using ssh agent install remote system certbotcertbot 16024certbot previously let encrypt client effs tool obtain cert let encrypt optionally autoenable http server also act client ca us acme protocol scrapyscrapy 15535scrapy fast highlevel web crawling scraping framework python scikitlearnscikitlearn 12923scikitlearn machine learning python tornadowebtornado 11958tornado python web framework asynchronous networking library originally developed friendfeed valloricyoucompleteme 11558a codecompletion engine vim redditreddit 11269the code power redditcom getsentrysentry 10107sentry crossplatform crash reporting built love ipythonipython 9911official repository ipython repos ipython organization contain thing like website documentation build etc xxnetxxnet 9131a web proxy tool faifpythonpatterns 9028a collection design patternsidioms python dockercompose 8074define run multicontainer application docker fcholletkeras 7706deep learning library python convnets recurrent neural network run theano tensorflow fabricfabric 7517simple pythonic remote execution deployment source github search last updated 20160821 topstarred python github repos trending rochesternrtrocalphago 7224an independent studentled replication deepminds 2016 nature publication mastering game go deep neural network tree search nature 529 484489 28 jan 2016 detail found website httpsdeepmindcompublicationshtml alexjcneuraldoodle 6392turn twobit doodle fine artwork deep neural network generate seamless texture photo transfer style one image another perform examplebased upscaling wait implementation semantic style transfer pewmaybe 5985 see program doe deciding whether really want happen eliangcshttpprompt 5513httpie prompttoolkit interactive commandline http client featuring autocomplete syntax highlighting cmusatyalabopenface 4973face recognition deep neural network 0x5ewechatdeletedfriends 4497 a1studmuffinspaceshipgenerator 4284a blender script procedurally generate 3d spaceship zulipzulip 4005zulip server powerful open source group chat samshadwelltrumpscript 3923make python great reverseshellroutersploit 3680the router exploitation framework pokemongofpokemongobot 3564the pokemon go bot baking community tflearntflearn 3471deep learning library featuring higherlevel api tensorflow jayfkstatuspage 3261a statuspage generator let host statuspage free github donnemartingitsome 3249a supercharged gitgithub command line interface cli openaigym 3131a toolkit developing comparing reinforcement learning algorithm reinderienmimic 3079abusing unicode create tragedy tensorflowmagenta 3008magenta music art generation machine intelligence donnemartinsaws 2955a supercharged aws command line interface cli pavelgoncharcolornet 2825neural network colorize grayscale image juanpotatolegofy 2783make image look made 1x1 lego block source github search last updated 20160821 trending 20150821 20160821 contribution sure license\n",
      "  (0, 38)\t0.2406201249065597\n",
      "  (0, 37)\t0.21631479800001352\n",
      "  (0, 35)\t0.17616274380498206\n",
      "  (0, 31)\t0.23026728340810904\n",
      "  (0, 30)\t0.21631479800001352\n",
      "  (0, 29)\t0.21201984365909288\n",
      "  (0, 27)\t0.18578560985249232\n",
      "  (0, 26)\t0.22542388086060086\n",
      "  (0, 25)\t0.23026728340810904\n",
      "  (0, 24)\t0.16173804700315875\n",
      "  (0, 23)\t0.19268486050965442\n",
      "  (0, 22)\t0.2406201249065597\n",
      "  (0, 18)\t0.1962979507219801\n",
      "  (0, 17)\t0.2078811045556132\n",
      "  (0, 16)\t0.2406201249065597\n",
      "  (0, 15)\t0.2406201249065597\n",
      "  (0, 13)\t0.17616274380498206\n",
      "  (0, 12)\t0.22077822429265861\n",
      "  (0, 11)\t0.2353260176804225\n",
      "  (0, 5)\t0.2078811045556132\n",
      "  (0, 4)\t0.17616274380498206\n",
      "  (0, 1)\t0.23026728340810904\n"
     ]
    }
   ],
   "source": [
    "# Show sentences and vector space representation.\n",
    "# \n",
    "# (A, B) C\n",
    "# A : Document Index\n",
    "# B : Specific word-vector index\n",
    "# C : TF-IDF score\n",
    "for i, v in zip(train.text_filtered, vector_spaces):\n",
    "    print(i)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21x9546 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11180 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate\n",
    "tfidf_v = TfidfVectorizer(stop_words='english', #min_df=20, \n",
    "                             ngram_range=(1,2), \n",
    "                             binary=True)\n",
    "\n",
    "tfidf_sparse_matrix_v = tfidf_v.fit_transform(validate.text_filtered)\n",
    "tfidf_sparse_matrix_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>00 uploading</th>\n",
       "      <th>000</th>\n",
       "      <th>000 gb</th>\n",
       "      <th>0000</th>\n",
       "      <th>0000 0100</th>\n",
       "      <th>0000 gb</th>\n",
       "      <th>0004</th>\n",
       "      <th>0004 10000</th>\n",
       "      <th>0005</th>\n",
       "      <th>...</th>\n",
       "      <th>zeroday</th>\n",
       "      <th>zeroday cve20184878</th>\n",
       "      <th>zip</th>\n",
       "      <th>zip button</th>\n",
       "      <th>zip computer</th>\n",
       "      <th>zip file</th>\n",
       "      <th>zjd55qmsy6ld53crtqncrg</th>\n",
       "      <th>zjd55qmsy6ld53crtqncrg gm5ybhjwros7zjtiyujtbu</th>\n",
       "      <th>zoopark</th>\n",
       "      <th>zoopark aptc38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030856</td>\n",
       "      <td>0.035037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035411</td>\n",
       "      <td>0.035411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035411</td>\n",
       "      <td>0.035411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.026778</td>\n",
       "      <td>0.026778</td>\n",
       "      <td>0.026778</td>\n",
       "      <td>0.026778</td>\n",
       "      <td>0.023583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026778</td>\n",
       "      <td>0.026778</td>\n",
       "      <td>0.026778</td>\n",
       "      <td>0.026778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows Ã— 9546 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          00  00 uploading       000    000 gb      0000  0000 0100   0000 gb  \\\n",
       "0   0.000000      0.000000  0.000000  0.000000  0.030856   0.035037  0.000000   \n",
       "1   0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "2   0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "3   0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "4   0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "5   0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "6   0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "7   0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "8   0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "9   0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "10  0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "11  0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "12  0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "13  0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "14  0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "15  0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "16  0.026778      0.026778  0.026778  0.026778  0.023583   0.000000  0.026778   \n",
       "17  0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "18  0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "19  0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "20  0.000000      0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "\n",
       "        0004  0004 10000      0005  ...   zeroday  zeroday cve20184878  \\\n",
       "0   0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "1   0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "2   0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "3   0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "4   0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "5   0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "6   0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "7   0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "8   0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "9   0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "10  0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "11  0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "12  0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "13  0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "14  0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "15  0.000000    0.000000  0.000000  ...  0.035411             0.035411   \n",
       "16  0.026778    0.026778  0.026778  ...  0.000000             0.000000   \n",
       "17  0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "18  0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "19  0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "20  0.000000    0.000000  0.000000  ...  0.000000             0.000000   \n",
       "\n",
       "         zip  zip button  zip computer  zip file  zjd55qmsy6ld53crtqncrg  \\\n",
       "0   0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "1   0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "2   0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "3   0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "4   0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "5   0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "6   0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "7   0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "8   0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "9   0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "10  0.081152    0.081152      0.081152  0.081152                0.000000   \n",
       "11  0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "12  0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "13  0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "14  0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "15  0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "16  0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "17  0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "18  0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "19  0.000000    0.000000      0.000000  0.000000                0.000000   \n",
       "20  0.000000    0.000000      0.000000  0.000000                0.039993   \n",
       "\n",
       "    zjd55qmsy6ld53crtqncrg gm5ybhjwros7zjtiyujtbu   zoopark  zoopark aptc38  \n",
       "0                                        0.000000  0.000000        0.000000  \n",
       "1                                        0.000000  0.000000        0.000000  \n",
       "2                                        0.000000  0.000000        0.000000  \n",
       "3                                        0.000000  0.000000        0.000000  \n",
       "4                                        0.000000  0.000000        0.000000  \n",
       "5                                        0.000000  0.000000        0.000000  \n",
       "6                                        0.000000  0.000000        0.000000  \n",
       "7                                        0.000000  0.000000        0.000000  \n",
       "8                                        0.000000  0.000000        0.000000  \n",
       "9                                        0.000000  0.000000        0.000000  \n",
       "10                                       0.000000  0.000000        0.000000  \n",
       "11                                       0.000000  0.000000        0.000000  \n",
       "12                                       0.000000  0.000000        0.000000  \n",
       "13                                       0.000000  0.000000        0.000000  \n",
       "14                                       0.000000  0.000000        0.000000  \n",
       "15                                       0.000000  0.035411        0.035411  \n",
       "16                                       0.000000  0.000000        0.000000  \n",
       "17                                       0.000000  0.000000        0.000000  \n",
       "18                                       0.000000  0.000000        0.000000  \n",
       "19                                       0.000000  0.000000        0.000000  \n",
       "20                                       0.039993  0.000000        0.000000  \n",
       "\n",
       "[21 rows x 9546 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_sparse_matrix_v.todense(), columns=tfidf_v.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'viz': 9233,\n",
       " 'index': 4371,\n",
       " 'gallery': 3445,\n",
       " 'interactive': 4524,\n",
       " 'website': 9329,\n",
       " 'faq': 2951,\n",
       " 'interact': 4519,\n",
       " 'following': 3287,\n",
       " 'visualization': 9221,\n",
       " 'table': 8364,\n",
       " 'httpwwwdonnemartincomviz': 4180,\n",
       " 'community': 1585,\n",
       " 'd3d3fc': 2017,\n",
       " 'colineberhardt': 1493,\n",
       " 'contribute': 1786,\n",
       " 'viewing': 9207,\n",
       " 'raw': 6557,\n",
       " 'stats': 8097,\n",
       " 'tell': 8431,\n",
       " 'story': 8185,\n",
       " 'help': 3928,\n",
       " 'rest': 7093,\n",
       " 'continually': 1773,\n",
       " 'updated': 8883,\n",
       " 'stay': 8117,\n",
       " 'uptodate': 8927,\n",
       " 'evolution': 2772,\n",
       " 'getting': 3486,\n",
       " 'started': 8049,\n",
       " 'spread': 7990,\n",
       " 'word': 9393,\n",
       " 'contribution': 1812,\n",
       " 'feedback': 2985,\n",
       " 'welcome': 9341,\n",
       " 'feel': 2989,\n",
       " 'free': 3380,\n",
       " 'follow': 3282,\n",
       " 'star': 8026,\n",
       " 'fork': 3324,\n",
       " 'check': 1325,\n",
       " 'update': 8860,\n",
       " 'iframe': 4251,\n",
       " 'srchttpsghbtnscomgithubbtnhtmluserdonnemartintypefollowcounttrue': 7997,\n",
       " 'frameborder0': 3373,\n",
       " 'scrolling0': 7595,\n",
       " 'width145': 9354,\n",
       " 'height20iframe': 3925,\n",
       " 'idghstar': 4247,\n",
       " 'srchttpsghbtnscomgithubbtnhtmluserdonnemartinrepoviztypestarcountfalse': 7995,\n",
       " 'allowtransparencytrue': 612,\n",
       " 'width50': 9356,\n",
       " 'idghfork': 4245,\n",
       " 'srchttpsghbtnscomgithubbtnhtmluserdonnemartinrepoviztypefork': 7993,\n",
       " 'width53': 9358,\n",
       " 'navigate': 5454,\n",
       " 'dashboard': 2027,\n",
       " 'offer': 5683,\n",
       " 'different': 2271,\n",
       " 'level': 4853,\n",
       " 'interactivity': 4528,\n",
       " 'try': 8728,\n",
       " 'interacting': 4522,\n",
       " 'filter': 3140,\n",
       " 'hovering': 4019,\n",
       " 'element': 2630,\n",
       " 'view': 9199,\n",
       " 'tooltip': 8622,\n",
       " 'info': 4389,\n",
       " 'clicking': 1421,\n",
       " 'highlight': 3956,\n",
       " 'change': 1288,\n",
       " 'activate': 465,\n",
       " 'control': 1827,\n",
       " 'offline': 5689,\n",
       " 'yes': 9482,\n",
       " 'youll': 9488,\n",
       " 'need': 5461,\n",
       " 'reader': 6582,\n",
       " 'download': 2523,\n",
       " 'run': 7240,\n",
       " 'latest': 4809,\n",
       " 'workbook': 9418,\n",
       " 'allows': 602,\n",
       " 'local': 4993,\n",
       " 'copyyoull': 1845,\n",
       " 'pushed': 6476,\n",
       " 'depending': 2183,\n",
       " 'setup': 7749,\n",
       " 'likely': 4923,\n",
       " 'improved': 4334,\n",
       " 'performance': 6046,\n",
       " 'running': 7286,\n",
       " 'locally': 5014,\n",
       " 'doe': 2479,\n",
       " 'online': 5700,\n",
       " 'reset': 7079,\n",
       " 'minute': 5310,\n",
       " 'inactivity': 4336,\n",
       " 'session': 7706,\n",
       " 'timeout': 8580,\n",
       " 'post': 6177,\n",
       " 'tableau': 8372,\n",
       " 'forum': 3356,\n",
       " 'isnt': 4567,\n",
       " 'loading': 4990,\n",
       " 'hosting': 4015,\n",
       " 'service': 7693,\n",
       " 'issue': 4570,\n",
       " 'status': 8110,\n",
       " 'javascript': 4623,\n",
       " 'python': 6486,\n",
       " 'ticket': 8557,\n",
       " 'data': 2033,\n",
       " 'tracked': 8640,\n",
       " 'github': 3631,\n",
       " 'trending': 8702,\n",
       " 'great': 3825,\n",
       " 'tool': 8608,\n",
       " 'discover': 2382,\n",
       " 'upandcoming': 8858,\n",
       " 'project': 6343,\n",
       " 'review': 7143,\n",
       " 'month': 5394,\n",
       " 'thirdparty': 8535,\n",
       " 'site': 7832,\n",
       " 'alltime': 618,\n",
       " 'relatively': 6725,\n",
       " 'static': 8091,\n",
       " 'dominated': 2497,\n",
       " 'wellestablished': 9344,\n",
       " 'repos': 6949,\n",
       " 'meant': 5221,\n",
       " 'supplement': 8305,\n",
       " 'existing': 2834,\n",
       " 'solution': 7878,\n",
       " 'filtering': 3165,\n",
       " 'newest': 5538,\n",
       " 'popular': 6156,\n",
       " 'created': 1911,\n",
       " 'specific': 7948,\n",
       " 'timeframe': 8578,\n",
       " 'example': 2780,\n",
       " '2016': 205,\n",
       " 'track': 8636,\n",
       " 'year': 9480,\n",
       " 'time': 8567,\n",
       " 'range': 6540,\n",
       " 'currently': 1969,\n",
       " 'provides': 6433,\n",
       " '2015': 203,\n",
       " 'rolling': 7222,\n",
       " '6months': 323,\n",
       " 'older': 5696,\n",
       " 'future': 3438,\n",
       " 'extended': 2887,\n",
       " 'regardless': 6703,\n",
       " 'creation': 1930,\n",
       " 'date': 2081,\n",
       " 'mining': 5306,\n",
       " 'directly': 2322,\n",
       " 'powered': 6189,\n",
       " 'api': 696,\n",
       " 'leverage': 4858,\n",
       " 'github3py': 3665,\n",
       " 'access': 361,\n",
       " 'panda': 5911,\n",
       " 'ipython': 4565,\n",
       " 'notebook': 5606,\n",
       " 'wrangling': 9441,\n",
       " 'google': 3792,\n",
       " 'map': 5169,\n",
       " 'geocoder': 3484,\n",
       " 'location': 5031,\n",
       " 'public': 6442,\n",
       " 'bigquery': 1019,\n",
       " 'archive': 779,\n",
       " 'interested': 4532,\n",
       " 'mined': 5291,\n",
       " 'january': 4610,\n",
       " '0000': 4,\n",
       " '0100': 34,\n",
       " 'pdt': 6025,\n",
       " 'include': 4342,\n",
       " 'preserved': 6267,\n",
       " 'manual': 5164,\n",
       " 'search': 7599,\n",
       " 'result': 7106,\n",
       " 'manually': 5166,\n",
       " 'query': 6524,\n",
       " 'similar': 7802,\n",
       " 'moststarred': 5401,\n",
       " 'created2016010120161231': 1922,\n",
       " 'stars100': 8032,\n",
       " 'languagejavascript': 4787,\n",
       " 'user': 9011,\n",
       " 'orgs': 5825,\n",
       " 'userusername': 9042,\n",
       " 'count': 1860,\n",
       " 'performed': 6049,\n",
       " 'restrict': 7099,\n",
       " 'stars500': 8038,\n",
       " 'githubs': 3685,\n",
       " 'rapidly': 6547,\n",
       " 'growing': 3854,\n",
       " '49': 313,\n",
       " 'million': 5289,\n",
       " 'repository': 6978,\n",
       " 'rate': 6551,\n",
       " 'limit': 4926,\n",
       " 'additional': 533,\n",
       " 'pull': 6459,\n",
       " 'request': 7024,\n",
       " 'contributor': 1823,\n",
       " 'commits': 1570,\n",
       " '1month': 172,\n",
       " 'loosen': 5077,\n",
       " 'restriction': 7101,\n",
       " 'le': 4831,\n",
       " 'analyze': 657,\n",
       " 'case': 1255,\n",
       " 'perfect': 6041,\n",
       " 'metric': 5268,\n",
       " 'simple': 7807,\n",
       " 'fairly': 2934,\n",
       " 'effective': 2620,\n",
       " 'measure': 5225,\n",
       " 'detailed': 2232,\n",
       " 'discussion': 2390,\n",
       " 'measuring': 5228,\n",
       " 'repo': 6791,\n",
       " 'popularity': 6159,\n",
       " 'application': 726,\n",
       " 'preliminary': 6243,\n",
       " 'note': 5589,\n",
       " 'concludes': 1626,\n",
       " 'number': 5623,\n",
       " 'tends': 8448,\n",
       " 'correlate': 1849,\n",
       " 'usage': 8947,\n",
       " 'client': 1425,\n",
       " 'reinforces': 6713,\n",
       " 'importance': 4326,\n",
       " 'real': 6599,\n",
       " 'new': 5503,\n",
       " 'support': 8310,\n",
       " 'includes': 4352,\n",
       " 'calculated': 1216,\n",
       " 'provide': 6419,\n",
       " 'group': 3838,\n",
       " 'org': 5815,\n",
       " 'applies': 740,\n",
       " 'language': 4773,\n",
       " 'plus': 6134,\n",
       " 'unknown': 8837,\n",
       " 'option': 5746,\n",
       " 'identified': 4236,\n",
       " 'githublinguist': 3677,\n",
       " 'missing': 5314,\n",
       " 'file': 3010,\n",
       " 'java': 4620,\n",
       " 'objectivec': 5654,\n",
       " 'swift': 8348,\n",
       " 'php': 6086,\n",
       " 'cs': 1949,\n",
       " 'html': 4027,\n",
       " 'ruby': 7236,\n",
       " 'shell': 7766,\n",
       " 'scala': 7500,\n",
       " 'clojure': 1428,\n",
       " 'coffeescript': 1483,\n",
       " 'lua': 5092,\n",
       " 'haskell': 3912,\n",
       " 'viml': 9212,\n",
       " 'perl': 6054,\n",
       " 'julia': 4682,\n",
       " 'overall': 5866,\n",
       " 'affiliated': 563,\n",
       " 'contributing': 1796,\n",
       " 'guideline': 3872,\n",
       " 'submit': 8250,\n",
       " 'tracker': 8645,\n",
       " 'contact': 1741,\n",
       " 'discus': 2388,\n",
       " 'question': 6528,\n",
       " 'comment': 1542,\n",
       " 'email': 2635,\n",
       " 'donnemartingmailcom': 2509,\n",
       " 'twitter': 8752,\n",
       " 'donnemartin': 2503,\n",
       " 'linkedin': 4948,\n",
       " 'donnemartincom': 2507,\n",
       " 'license': 4870,\n",
       " 'providing': 6436,\n",
       " 'code': 1451,\n",
       " 'resource': 7081,\n",
       " 'open': 5712,\n",
       " 'source': 7916,\n",
       " 'personal': 6073,\n",
       " 'receive': 6609,\n",
       " 'employer': 2640,\n",
       " 'facebook': 2917,\n",
       " 'copyright': 1841,\n",
       " 'donne': 2501,\n",
       " 'martin': 5181,\n",
       " 'licensed': 4897,\n",
       " 'apache': 694,\n",
       " 'version': 9163,\n",
       " '20': 176,\n",
       " 'use': 8961,\n",
       " 'compliance': 1605,\n",
       " 'obtain': 5658,\n",
       " 'copy': 1832,\n",
       " 'httpwwwapacheorglicenseslicense20': 4178,\n",
       " 'unless': 8840,\n",
       " 'required': 7046,\n",
       " 'applicable': 723,\n",
       " 'law': 4821,\n",
       " 'agreed': 577,\n",
       " 'writing': 9450,\n",
       " 'software': 7870,\n",
       " 'distributed': 2424,\n",
       " 'basis': 979,\n",
       " 'warranty': 9295,\n",
       " 'condition': 1634,\n",
       " 'kind': 4734,\n",
       " 'express': 2874,\n",
       " 'implied': 4315,\n",
       " 'governing': 3805,\n",
       " 'permission': 6056,\n",
       " 'limitation': 4928,\n",
       " 'viz index': 9246,\n",
       " 'index viz': 4375,\n",
       " 'viz gallery': 9241,\n",
       " 'gallery viz': 3447,\n",
       " 'viz interactive': 9247,\n",
       " 'interactive website': 4527,\n",
       " 'website faq': 9333,\n",
       " 'faq viz': 2952,\n",
       " 'gallery interact': 3446,\n",
       " 'interact following': 4520,\n",
       " 'following visualization': 3305,\n",
       " 'visualization table': 9229,\n",
       " 'table viz': 8371,\n",
       " 'viz website': 9260,\n",
       " 'website httpwwwdonnemartincomviz': 9335,\n",
       " 'httpwwwdonnemartincomviz viz': 4182,\n",
       " 'httpwwwdonnemartincomviz community': 4181,\n",
       " 'community visualization': 1590,\n",
       " 'visualization d3d3fc': 9224,\n",
       " 'd3d3fc colineberhardt': 2018,\n",
       " 'colineberhardt contribute': 1494,\n",
       " 'contribute faq': 1789,\n",
       " 'viz viewing': 9258,\n",
       " 'viewing raw': 9208,\n",
       " 'raw stats': 6558,\n",
       " 'stats table': 8107,\n",
       " 'table tell': 8370,\n",
       " 'tell story': 8433,\n",
       " 'story viz': 8187,\n",
       " 'viz help': 9244,\n",
       " 'help tell': 3944,\n",
       " 'tell rest': 8432,\n",
       " 'rest story': 7095,\n",
       " 'story interactive': 8186,\n",
       " 'interactive visualization': 4525,\n",
       " 'visualization continually': 9223,\n",
       " 'continually updated': 1775,\n",
       " 'updated help': 8887,\n",
       " 'help stay': 3943,\n",
       " 'stay uptodate': 8118,\n",
       " 'uptodate evolution': 8928,\n",
       " 'evolution viz': 2773,\n",
       " 'viz viz': 9259,\n",
       " 'viz getting': 9242,\n",
       " 'getting started': 3488,\n",
       " 'started help': 8052,\n",
       " 'help spread': 3941,\n",
       " 'spread word': 7992,\n",
       " 'word contribution': 9394,\n",
       " 'contribution feedback': 1815,\n",
       " 'feedback welcome': 2988,\n",
       " 'welcome feel': 9343,\n",
       " 'feel free': 2990,\n",
       " 'free follow': 3388,\n",
       " 'follow star': 3285,\n",
       " 'star fork': 8029,\n",
       " 'fork check': 3326,\n",
       " 'check update': 1351,\n",
       " 'update iframe': 8871,\n",
       " 'iframe srchttpsghbtnscomgithubbtnhtmluserdonnemartintypefollowcounttrue': 4254,\n",
       " 'srchttpsghbtnscomgithubbtnhtmluserdonnemartintypefollowcounttrue frameborder0': 7998,\n",
       " 'frameborder0 scrolling0': 3374,\n",
       " 'scrolling0 width145': 7596,\n",
       " 'width145 height20iframe': 9355,\n",
       " 'height20iframe iframe': 3926,\n",
       " 'iframe idghstar': 4253,\n",
       " 'idghstar srchttpsghbtnscomgithubbtnhtmluserdonnemartinrepoviztypestarcountfalse': 4248,\n",
       " 'srchttpsghbtnscomgithubbtnhtmluserdonnemartinrepoviztypestarcountfalse allowtransparencytrue': 7996,\n",
       " 'allowtransparencytrue frameborder0': 613,\n",
       " 'scrolling0 width50': 7597,\n",
       " 'width50 height20iframe': 9357,\n",
       " 'iframe idghfork': 4252,\n",
       " 'idghfork srchttpsghbtnscomgithubbtnhtmluserdonnemartinrepoviztypefork': 4246,\n",
       " 'srchttpsghbtnscomgithubbtnhtmluserdonnemartinrepoviztypefork allowtransparencytrue': 7994,\n",
       " 'scrolling0 width53': 7598,\n",
       " 'width53 height20iframe': 9359,\n",
       " 'height20iframe navigate': 3927,\n",
       " 'navigate viz': 5457,\n",
       " 'viz dashboard': 9239,\n",
       " 'dashboard viz': 2032,\n",
       " 'viz offer': 9251,\n",
       " 'offer different': 5684,\n",
       " 'different level': 2277,\n",
       " 'level interactivity': 4854,\n",
       " 'interactivity try': 4529,\n",
       " 'try interacting': 8731,\n",
       " 'interacting filter': 4523,\n",
       " 'filter hovering': 3150,\n",
       " 'hovering element': 4020,\n",
       " 'element view': 2632,\n",
       " 'view tooltip': 9206,\n",
       " 'tooltip info': 8623,\n",
       " 'info clicking': 4390,\n",
       " 'clicking element': 1422,\n",
       " 'element highlight': 2631,\n",
       " 'highlight filter': 3959,\n",
       " 'filter change': 3141,\n",
       " 'change activate': 1289,\n",
       " 'activate dashboard': 466,\n",
       " 'dashboard following': 2029,\n",
       " 'following control': 3290,\n",
       " 'control viz': 1831,\n",
       " 'viz offline': 9252,\n",
       " 'offline yes': 5692,\n",
       " 'yes youll': 9485,\n",
       " 'youll need': 9492,\n",
       " 'need free': 5474,\n",
       " 'free reader': 3391,\n",
       " 'reader download': 6583,\n",
       " 'download run': 2531,\n",
       " 'run latest': 7255,\n",
       " 'latest viz': 4815,\n",
       " 'viz workbook': 9261,\n",
       " 'workbook allows': 9420,\n",
       " 'allows interact': 605,\n",
       " 'interact local': 4521,\n",
       " 'local copyyoull': 4997,\n",
       " 'copyyoull need': 1846,\n",
       " 'need download': 5468,\n",
       " 'download latest': 2530,\n",
       " 'latest workbook': 4816,\n",
       " 'workbook update': 9421,\n",
       " 'update continually': 8866,\n",
       " 'continually pushed': 1774,\n",
       " 'pushed depending': 6477,\n",
       " 'depending setup': 2185,\n",
       " 'setup youll': 7751,\n",
       " 'youll likely': 9491,\n",
       " 'likely improved': 4925,\n",
       " 'improved performance': 4335,\n",
       " 'performance running': 6048,\n",
       " 'running viz': 7293,\n",
       " 'viz locally': 9249,\n",
       " 'locally doe': 5016,\n",
       " 'doe online': 2483,\n",
       " 'online viz': 5706,\n",
       " 'viz reset': 9256,\n",
       " 'reset minute': 7080,\n",
       " 'minute inactivity': 5311,\n",
       " 'inactivity session': 4337,\n",
       " 'session timeout': 7707,\n",
       " 'timeout inactivity': 8581,\n",
       " 'inactivity view': 4338,\n",
       " 'view post': 9204,\n",
       " 'post tableau': 6180,\n",
       " 'tableau forum': 8373,\n",
       " 'forum isnt': 3357,\n",
       " 'isnt online': 4568,\n",
       " 'online interactive': 5702,\n",
       " 'interactive viz': 4526,\n",
       " 'viz loading': 9248,\n",
       " 'loading visualization': 4992,\n",
       " 'visualization hosting': 9226,\n",
       " 'hosting service': 4016,\n",
       " 'service issue': 7698,\n",
       " 'issue check': 4574,\n",
       " 'check status': 1348,\n",
       " 'status run': 8115,\n",
       " 'run viz': 7273,\n",
       " 'offline visualization': 5691,\n",
       " 'visualization javascript': 9227,\n",
       " 'javascript python': 4629,\n",
       " 'python check': 6491,\n",
       " 'check following': 1332,\n",
       " 'following ticket': 3304,\n",
       " 'ticket community': 8558,\n",
       " 'contribute data': 1787,\n",
       " 'data tracked': 2062,\n",
       " 'tracked github': 8642,\n",
       " 'github trending': 3660,\n",
       " 'trending great': 8703,\n",
       " 'great tool': 3827,\n",
       " 'tool discover': 8614,\n",
       " 'discover upandcoming': 2383,\n",
       " 'upandcoming project': 8859,\n",
       " 'project allows': 6344,\n",
       " 'allows review': 607,\n",
       " 'review month': 7146,\n",
       " 'month data': 5397,\n",
       " 'data thirdparty': 2060,\n",
       " 'thirdparty site': 8536,\n",
       " 'site alltime': 7833,\n",
       " 'alltime stats': 619,\n",
       " 'stats relatively': 8103,\n",
       " 'relatively static': 6726,\n",
       " 'static dominated': 8093,\n",
       " 'dominated wellestablished': 2498,\n",
       " 'wellestablished repos': 9345,\n",
       " 'repos viz': 6964,\n",
       " 'viz meant': 9250,\n",
       " 'meant supplement': 5224,\n",
       " 'supplement existing': 8306,\n",
       " 'existing solution': 2837,\n",
       " 'solution filtering': 7879,\n",
       " 'filtering newest': 3166,\n",
       " 'newest popular': 5539,\n",
       " 'popular repos': 6158,\n",
       " 'repos created': 6952,\n",
       " 'created specific': 1918,\n",
       " 'specific timeframe': 7956,\n",
       " 'timeframe example': 8579,\n",
       " 'example viz': 2797,\n",
       " 'viz 2016': 9235,\n",
       " '2016 track': 215,\n",
       " 'track repos': 8638,\n",
       " 'created year': 1921,\n",
       " 'year 2016': 9481,\n",
       " '2016 stats': 214,\n",
       " 'stats time': 8108,\n",
       " 'time range': 8572,\n",
       " 'range 2016': 6541,\n",
       " '2016 viz': 216,\n",
       " 'viz currently': 9238,\n",
       " 'currently provides': 1971,\n",
       " 'provides stats': 6435,\n",
       " 'stats 2016': 8098,\n",
       " '2016 2015': 207,\n",
       " '2015 rolling': 204,\n",
       " 'rolling 6months': 7223,\n",
       " '6months stats': 324,\n",
       " 'stats older': 8102,\n",
       " 'older repos': 5697,\n",
       " 'repos future': 6954,\n",
       " 'future viz': 3442,\n",
       " 'viz extended': 9240,\n",
       " 'extended track': 2888,\n",
       " 'repos regardless': 6957,\n",
       " 'regardless creation': 6704,\n",
       " 'creation date': 1931,\n",
       " 'date feedback': 2082,\n",
       " 'feedback ticket': 2987,\n",
       " 'ticket welcome': 8561,\n",
       " 'welcome data': 9342,\n",
       " 'data mining': 2047,\n",
       " 'mining data': 5307,\n",
       " 'data directly': 2038,\n",
       " 'directly github': 2325,\n",
       " 'github viz': 3662,\n",
       " 'viz powered': 9253,\n",
       " 'powered github': 6190,\n",
       " 'github api': 3634,\n",
       " 'api leverage': 702,\n",
       " 'leverage following': 4859,\n",
       " 'following github3py': 3292,\n",
       " 'github3py access': 3666,\n",
       " 'access github': 365,\n",
       " 'api python': 705,\n",
       " 'python panda': 6496,\n",
       " 'panda following': 5912,\n",
       " 'following ipython': 3293,\n",
       " 'ipython notebook': 4566,\n",
       " 'notebook data': 5607,\n",
       " 'data wrangling': 2067,\n",
       " 'wrangling google': 9442,\n",
       " 'google map': 3802,\n",
       " 'map api': 5170,\n",
       " 'api geocoder': 697,\n",
       " 'geocoder location': 3485,\n",
       " 'location data': 5034,\n",
       " 'data tableau': 2058,\n",
       " 'tableau public': 8374,\n",
       " 'public visualization': 6451,\n",
       " 'visualization future': 9225,\n",
       " 'future google': 3439,\n",
       " 'google bigquery': 3795,\n",
       " 'bigquery github': 1020,\n",
       " 'github archive': 3636,\n",
       " 'archive supplement': 780,\n",
       " 'supplement github': 8307,\n",
       " 'api interested': 700,\n",
       " 'interested visualization': 4534,\n",
       " 'ticket data': 8559,\n",
       " 'data data': 2037,\n",
       " 'data table': 2057,\n",
       " 'table tableau': 8369,\n",
       " 'tableau workbook': 8375,\n",
       " 'workbook 2016': 9419,\n",
       " '2016 data': 208,\n",
       " 'data viz': 2066,\n",
       " 'stats mined': 8101,\n",
       " 'mined january': 5292,\n",
       " 'january 2016': 4611,\n",
       " '2016 0000': 206,\n",
       " '0000 0100': 5,\n",
       " '0100 pdt': 35,\n",
       " 'pdt include': 6026,\n",
       " 'include repos': 4348,\n",
       " 'data preserved': 2049,\n",
       " 'preserved 2016': 6268,\n",
       " '2016 manual': 211,\n",
       " 'manual search': 5165,\n",
       " 'search result': 7604,\n",
       " 'result different': 7108,\n",
       " 'different viz': 2281,\n",
       " '2016 github': 210,\n",
       " 'github search': 3659,\n",
       " 'search manually': 7602,\n",
       " 'manually run': 5168,\n",
       " 'run query': 7264,\n",
       " 'query similar': 6527,\n",
       " 'similar github': 7803,\n",
       " 'api view': 710,\n",
       " 'view moststarred': 9203,\n",
       " 'moststarred javascript': 5402,\n",
       " 'javascript repos': 4630,\n",
       " 'created 2016': 1912,\n",
       " '2016 run': 213,\n",
       " 'run following': 7250,\n",
       " 'following query': 3301,\n",
       " 'query created2016010120161231': 6525,\n",
       " 'created2016010120161231 stars100': 1923,\n",
       " 'stars100 languagejavascript': 8033,\n",
       " 'languagejavascript check': 4788,\n",
       " 'check stats': 1347,\n",
       " 'stats user': 8109,\n",
       " 'user orgs': 9024,\n",
       " 'orgs repos': 5827,\n",
       " 'run created2016010120161231': 7244,\n",
       " 'stars100 userusername': 8037,\n",
       " 'userusername star': 9043,\n",
       " 'star count': 8028,\n",
       " 'count search': 1861,\n",
       " 'search data': 7600,\n",
       " 'data time': 2061,\n",
       " 'time performed': 8570,\n",
       " 'performed search': 6051,\n",
       " 'search restrict': 7603,\n",
       " 'restrict search': 7100,\n",
       " 'result stars100': 7111,\n",
       " 'stars100 stars500': 8035,\n",
       " 'stars500 viz': 8039,\n",
       " '2016 repos': 212,\n",
       " 'repos stars100': 6959,\n",
       " 'stars100 tracked': 8036,\n",
       " 'tracked help': 8643,\n",
       " 'help filter': 3932,\n",
       " 'filter githubs': 3149,\n",
       " 'githubs rapidly': 3687,\n",
       " 'rapidly growing': 6548,\n",
       " 'growing 49': 3855,\n",
       " '49 million': 314,\n",
       " 'million repository': 5290,\n",
       " 'repository github': 6994,\n",
       " 'api rate': 706,\n",
       " 'rate limit': 6552,\n",
       " 'limit visualization': 4927,\n",
       " 'visualization additional': 9222,\n",
       " 'additional data': 535,\n",
       " 'data pull': 2050,\n",
       " 'pull request': 6462,\n",
       " 'request issue': 7034,\n",
       " 'issue contributor': 4575,\n",
       " 'contributor commits': 1824,\n",
       " 'commits filter': 1571,\n",
       " 'filter repos': 3155,\n",
       " 'repos stars500': 6960,\n",
       " 'viz 1month': 9234,\n",
       " '1month loosen': 173,\n",
       " 'loosen restriction': 5078,\n",
       " 'restriction le': 7103,\n",
       " 'le repos': 4832,\n",
       " 'repos analyze': 6950,\n",
       " 'analyze google': 658,\n",
       " 'api star': 707,\n",
       " 'fork viz': 3334,\n",
       " 'viz provides': 9254,\n",
       " 'stats repos': 8105,\n",
       " 'repos user': 6962,\n",
       " 'orgs star': 5828,\n",
       " 'star case': 8027,\n",
       " 'case fork': 1260,\n",
       " 'fork star': 3332,\n",
       " 'fork perfect': 3328,\n",
       " 'perfect metric': 6042,\n",
       " 'metric simple': 5272,\n",
       " 'simple fairly': 7810,\n",
       " 'fairly effective': 2935,\n",
       " 'effective measure': 2621,\n",
       " 'measure detailed': 5226,\n",
       " 'detailed discussion': 2233,\n",
       " 'discussion measuring': 2391,\n",
       " 'measuring repo': 5229,\n",
       " 'repo popularity': 6812,\n",
       " 'popularity check': 6160,\n",
       " 'check popularity': 1341,\n",
       " 'popularity github': 6161,\n",
       " 'github application': 3635,\n",
       " 'application preliminary': 730,\n",
       " 'preliminary note': 6244,\n",
       " 'note concludes': 5590,\n",
       " 'concludes number': 1627,\n",
       " 'number star': 5631,\n",
       " 'star tends': 8031,\n",
       " 'tends correlate': 8449,\n",
       " 'correlate number': 1850,\n",
       " 'number fork': 5628,\n",
       " 'fork effective': 3327,\n",
       " 'effective usage': 2622,\n",
       " 'usage client': 8949,\n",
       " 'client application': 1426,\n",
       " 'application reinforces': 732,\n",
       " 'reinforces importance': 6714,\n",
       " 'importance star': 4327,\n",
       " 'star real': 8030,\n",
       " 'real measure': 6601,\n",
       " 'measure popularity': 5227,\n",
       " 'popularity new': 6162,\n",
       " 'new support': 5526,\n",
       " 'support additional': 8312,\n",
       " 'additional metric': 537,\n",
       " 'metric update': 5274,\n",
       " 'update viz': 8880,\n",
       " 'viz includes': 9245,\n",
       " 'includes additional': 4353,\n",
       " 'commits stats': 1576,\n",
       " 'orgs calculated': 5826,\n",
       " 'calculated provide': 1217,\n",
       " 'provide stats': 6422,\n",
       " 'orgs viz': 5829,\n",
       " 'viz group': 9243,\n",
       " 'group star': 3845,\n",
       " 'fork user': 3333,\n",
       " 'user org': 9023,\n",
       " 'org note': 5816,\n",
       " 'note stars100': 5600,\n",
       " 'stars100 restriction': 8034,\n",
       " 'restriction applies': 7102,\n",
       " 'applies language': 741,\n",
       " 'language tracked': 4786,\n",
       " 'tracked viz': 8644,\n",
       " 'viz track': 9257,\n",
       " 'track popular': 8637,\n",
       " 'popular language': 6157,\n",
       " 'language github': 4776,\n",
       " 'github plus': 3652,\n",
       " 'plus unknown': 6140,\n",
       " 'unknown language': 8838,\n",
       " 'language option': 4782,\n",
       " 'option repo': 5778,\n",
       " 'repo language': 6807,\n",
       " 'language identified': 4778,\n",
       " 'identified githublinguist': 4237,\n",
       " 'githublinguist missing': 3678,\n",
       " 'missing popular': 5316,\n",
       " 'language feel': 4775,\n",
       " 'free file': 3387,\n",
       " 'file request': 3083,\n",
       " 'request language': 7035,\n",
       " 'language javascript': 4779,\n",
       " 'javascript java': 4627,\n",
       " 'java objectivec': 4622,\n",
       " 'objectivec python': 5655,\n",
       " 'python swift': 6502,\n",
       " 'swift php': 8349,\n",
       " 'php cs': 6087,\n",
       " 'cs html': 1951,\n",
       " 'html ruby': 4034,\n",
       " 'ruby shell': 7237,\n",
       " 'shell scala': 7767,\n",
       " 'scala clojure': 7501,\n",
       " 'clojure coffeescript': 1429,\n",
       " 'coffeescript lua': 1485,\n",
       " 'lua haskell': 5093,\n",
       " 'haskell viml': 3913,\n",
       " 'viml perl': 9213,\n",
       " 'perl julia': 6055,\n",
       " 'julia unknown': 4683,\n",
       " 'unknown overall': 8839,\n",
       " 'overall viz': 5867,\n",
       " 'viz affiliated': 9236,\n",
       " 'affiliated github': 564,\n",
       " 'viz community': 9237,\n",
       " 'community project': 1588,\n",
       " 'project github': 6356,\n",
       " 'github community': 3640,\n",
       " 'community github': 1587,\n",
       " 'community contribute': 1586,\n",
       " 'contribute review': 1792,\n",
       " 'review contributing': 7144,\n",
       " 'contributing guideline': 1799,\n",
       " 'guideline submit': 3873,\n",
       " 'submit issue': 8254,\n",
       " 'issue submit': 4591,\n",
       " 'submit pull': 8258,\n",
       " 'request check': 7028,\n",
       " 'check issue': 1338,\n",
       " 'issue tracker': 4594,\n",
       " 'tracker contact': 8646,\n",
       " 'contact feel': 1743,\n",
       " 'free contact': 3384,\n",
       " 'contact discus': 1742,\n",
       " 'discus issue': 2389,\n",
       " 'issue question': 4585,\n",
       " 'question comment': 6529,\n",
       " 'comment email': 1543,\n",
       " 'email donnemartingmailcom': 2637,\n",
       " 'donnemartingmailcom twitter': 2510,\n",
       " 'twitter donnemartin': 8754,\n",
       " 'donnemartin github': 2504,\n",
       " 'github donnemartin': 3645,\n",
       " 'donnemartin linkedin': 2505,\n",
       " 'linkedin donnemartin': 4949,\n",
       " 'donnemartin website': 2506,\n",
       " 'website donnemartincom': 9332,\n",
       " 'donnemartincom file': 2508,\n",
       " 'file ticket': 3107,\n",
       " 'ticket issue': 8560,\n",
       " 'tracker license': 8648,\n",
       " 'license viz': 4896,\n",
       " 'viz providing': 9255,\n",
       " 'providing code': 6437,\n",
       " 'code resource': 1467,\n",
       " 'resource repository': 7084,\n",
       " 'repository open': 7003,\n",
       " 'open source': 5717,\n",
       " 'source license': 7923,\n",
       " 'license personal': 4886,\n",
       " 'personal repository': 6075,\n",
       " 'repository license': 7000,\n",
       " 'license receive': 4889,\n",
       " 'receive code': 6610,\n",
       " 'resource employer': 7082,\n",
       " 'employer facebook': 2641,\n",
       " 'facebook copyright': 2918,\n",
       " 'copyright 2016': 1843,\n",
       " '2016 donne': 209,\n",
       " 'donne martin': 2502,\n",
       " 'martin licensed': 5182,\n",
       " 'licensed apache': 4898,\n",
       " 'apache license': 695,\n",
       " 'license version': 4895,\n",
       " 'version 20': 9167,\n",
       " '20 license': 179,\n",
       " 'license use': 4892,\n",
       " 'use file': 8971,\n",
       " 'file compliance': 3020,\n",
       " 'compliance license': 1606,\n",
       " 'license obtain': 4884,\n",
       " 'obtain copy': 5659,\n",
       " 'copy license': 1835,\n",
       " 'license httpwwwapacheorglicenseslicense20': 4879,\n",
       " 'httpwwwapacheorglicenseslicense20 unless': 4179,\n",
       " 'unless required': 8841,\n",
       " 'required applicable': 7048,\n",
       " 'applicable law': 724,\n",
       " 'law agreed': 4822,\n",
       " 'agreed writing': 578,\n",
       " 'writing software': 9453,\n",
       " 'software distributed': 7872,\n",
       " 'distributed license': 2427,\n",
       " 'license distributed': 4874,\n",
       " 'distributed basis': 2425,\n",
       " 'basis warranty': 980,\n",
       " 'warranty condition': 9296,\n",
       " 'condition kind': 1635,\n",
       " 'kind express': 4735,\n",
       " 'express implied': 2880,\n",
       " 'implied license': 4316,\n",
       " 'license specific': 4890,\n",
       " 'specific language': 7952,\n",
       " 'language governing': 4777,\n",
       " 'governing permission': 3806,\n",
       " 'permission limitation': 6062,\n",
       " 'limitation license': 4929,\n",
       " 'gitguardian': 3565,\n",
       " 'shield': 7769,\n",
       " 'protect': 6411,\n",
       " 'secret': 7609,\n",
       " 'ggshield': 3489,\n",
       " 'cli': 1405,\n",
       " 'environment': 2708,\n",
       " 'ci': 1377,\n",
       " 'detect': 2234,\n",
       " '200': 180,\n",
       " 'type': 8760,\n",
       " 'potential': 6181,\n",
       " 'security': 7642,\n",
       " 'vulnerability': 9266,\n",
       " 'policy': 6145,\n",
       " 'break': 1090,\n",
       " 'pygitguardian': 6484,\n",
       " 'scan': 7504,\n",
       " 'v1scan': 9100,\n",
       " 'endpoint': 2664,\n",
       " 'stateless': 8084,\n",
       " 'store': 8157,\n",
       " 'sending': 7660,\n",
       " 'detected': 2238,\n",
       " 'precommit': 6216,\n",
       " 'framework': 3375,\n",
       " 'standalone': 8022,\n",
       " 'globally': 3761,\n",
       " 'key': 4698,\n",
       " 'add': 489,\n",
       " 'variable': 9129,\n",
       " 'gitguardianapikeygitguardian': 3582,\n",
       " 'supported': 8324,\n",
       " 'integration': 4507,\n",
       " 'hook': 3984,\n",
       " 'prereceive': 6254,\n",
       " 'gitlab': 3689,\n",
       " 'action': 432,\n",
       " 'bitbucket': 1025,\n",
       " 'pipeline': 6099,\n",
       " 'circle': 1393,\n",
       " 'orb': 5804,\n",
       " 'travis': 8693,\n",
       " 'jenkins': 4638,\n",
       " 'content': 1754,\n",
       " 'introduction': 4551,\n",
       " 'installation': 4476,\n",
       " 'configuration': 1674,\n",
       " 'onpremises': 5707,\n",
       " 'command': 1517,\n",
       " 'install': 4436,\n",
       " 'global': 3746,\n",
       " 'output': 5840,\n",
       " 'using': 9044,\n",
       " 'pip': 6093,\n",
       " '36': 298,\n",
       " 'newer': 5535,\n",
       " 'package': 5886,\n",
       " 'macos': 5109,\n",
       " 'linux': 4953,\n",
       " 'window': 9364,\n",
       " 'args': 781,\n",
       " 'configpath': 1666,\n",
       " 'set': 7708,\n",
       " 'custom': 1978,\n",
       " 'config': 1640,\n",
       " 'ignores': 4263,\n",
       " 'verbose': 9152,\n",
       " 'display': 2406,\n",
       " 'mode': 5333,\n",
       " 'message': 5248,\n",
       " 'exit': 2844,\n",
       " 'various': 9148,\n",
       " 'main': 5116,\n",
       " 'ha': 3880,\n",
       " 'used': 8992,\n",
       " 'override': 5873,\n",
       " 'behaviour': 1001,\n",
       " 'showsecrets': 7784,\n",
       " 'plaintext': 6114,\n",
       " 'instead': 4497,\n",
       " 'hiding': 3949,\n",
       " 'exitzero': 2850,\n",
       " 'return': 7122,\n",
       " 'nonerror': 5577,\n",
       " 'incident': 4339,\n",
       " 'foundthe': 3362,\n",
       " 'env': 2703,\n",
       " 'var': 9125,\n",
       " 'gitguardianexitzero': 3596,\n",
       " 'json': 4667,\n",
       " 'default': 2112,\n",
       " 'false': 2938,\n",
       " 'allpolicies': 614,\n",
       " 'present': 6265,\n",
       " 'fails': 2924,\n",
       " 'filename': 3129,\n",
       " 'fileextensions': 3123,\n",
       " 'detection': 2243,\n",
       " 'shown': 7781,\n",
       " 'path': 5970,\n",
       " 'route': 7230,\n",
       " 'commitrange': 1563,\n",
       " 'defined': 2134,\n",
       " 'git': 3542,\n",
       " 'directory': 2328,\n",
       " ...}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get vocabularies.\n",
    "tfidf_v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.03999307, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform to document-term matrix\n",
    "vector_spaces_v = tfidf_v.transform(validate.text_filtered)\n",
    "vector_spaces_v.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viz index viz gallery viz interactive website faq viz gallery interact following visualization table viz website httpwwwdonnemartincomviz viz interactive website httpwwwdonnemartincomviz community visualization d3d3fc colineberhardt contribute faq viz viewing raw stats table tell part story viz help tell rest story interactive visualization continually updated help stay uptodate evolution viz viz getting started help spread word contribution feedback welcome feel free follow star fork check back update iframe srchttpsghbtnscomgithubbtnhtmluserdonnemartintypefollowcounttrue frameborder0 scrolling0 width145 height20iframe iframe idghstar srchttpsghbtnscomgithubbtnhtmluserdonnemartinrepoviztypestarcountfalse allowtransparencytrue frameborder0 scrolling0 width50 height20iframe iframe idghfork srchttpsghbtnscomgithubbtnhtmluserdonnemartinrepoviztypefork allowtransparencytrue frameborder0 scrolling0 width53 height20iframe navigate viz dashboard within viz offer different level interactivity try interacting filter hovering element view tooltip info clicking element highlight filter change activate dashboard following control viz offline yes youll need free reader download run latest viz workbook allows interact local copyyoull need download latest workbook update continually pushed depending setup youll likely see improved performance running viz locally doe online viz reset several minute inactivity session timeout inactivity detail view post tableau forum isnt online interactive viz loading visualization hosting service might issue check status also run viz offline see visualization javascript python r please check following ticket community visualization d3d3fc colineberhardt contribute data tracked although github trending great tool discover upandcoming project allows review one month data thirdparty site often show alltime stats relatively static dominated wellestablished repos viz meant supplement existing solution filtering newest popular repos created within specific timeframe example viz 2016 track repos created within year 2016 see stats time range 2016 viz currently provides stats 2016 2015 rolling 1 3 6months see stats older repos future viz extended track repos regardless creation date feedback ticket welcome mine data mining data directly github viz powered github api leverage following github3py access github api python panda following ipython notebook data wrangling google map api geocoder location data tableau public visualization future google bigquery along github archive could also supplement github api interested visualization javascript python r check following ticket find data data data table tableau workbook mine 2016 data viz 2016 stats mined january 1 2016 0000 0100 pdt include repos created year 2016 data preserved 2016 manual search result different viz 2016 github search manually run query similar would get github api view moststarred javascript repos created 2016 run following query created2016010120161231 stars100 languagejavascript check stats user orgs repos created 2016 run created2016010120161231 stars100 userusername star count search show data time performed search restrict search result stars100 stars500 viz 2016 repos stars100 tracked help filter githubs rapidly growing 49 million repository keep within github api rate limit visualization additional data pull request issue contributor commits filter repos stars500 viz 6 3 1month might loosen restriction le repos analyze google bigquery along github archive could also supplement github api star fork viz provides stats repos user orgs star many case fork star fork perfect metric yet simple fairly effective measure interest detailed discussion measuring repo popularity check popularity github application preliminary note concludes number star system tends correlate number fork also effective usage client application reinforces importance star real measure system popularity new support additional metric update viz includes additional data pull request issue contributor commits stats user orgs calculated provide stats user orgs viz group star fork user org note stars100 restriction still applies language tracked viz track popular language github plus unknown language option repo language identified githublinguist missing popular language feel free file request language javascript java objectivec python swift go php c c cs html ruby c shell scala clojure coffeescript lua haskell viml r perl julia unknown overall viz affiliated github viz affiliated github viz community project github community github community contribute please review contributing guideline detail submit issue submit pull request check issue tracker contact feel free contact discus issue question comment email donnemartingmailcom twitter donnemartin github donnemartin linkedin donnemartin website donnemartincom also file ticket issue tracker license viz providing code resource repository open source license personal repository license receive code resource employer facebook copyright 2016 donne martin licensed apache license version 20 license may use file except compliance license may obtain copy license httpwwwapacheorglicenseslicense20 unless required applicable law agreed writing software distributed license distributed basis without warranty condition kind either express implied see license specific language governing permission limitation license\n",
      "  (0, 37)\t0.3109133380966274\n",
      "  (0, 29)\t0.30474011923479\n",
      "  (0, 27)\t0.2670331602997981\n",
      "  (0, 24)\t0.23246914476455824\n",
      "  (0, 13)\t0.25320203347652864\n",
      "  (0, 11)\t0.3382385226275715\n",
      "  (0, 10)\t0.2821427460570418\n",
      "  (0, 7)\t0.3458478427718165\n",
      "  (0, 2)\t0.32400599465720087\n",
      "  (0, 1)\t0.33096750846815787\n",
      "  (0, 0)\t0.30474011923479\n",
      "gitguardian shield protect secret gitguardian gitguardian shield ggshield cli application run local environment ci environment help detect 200 type secret well potential security vulnerability policy break gitguardian shield us public api pygitguardian scan file detect potential secret code v1scan endpoint public api stateless store file sending secret detected also use ggshield via precommit framework repository standalone precommit either globally locally youll need api key gitguardian use ggshield add api key environment variable gitguardianapikeygitguardian api key currently supported integration precommit hook prereceive hook gitlab github action bitbucket pipeline circle ci orb travis ci jenkins table content introduction installation configuration environment variable onpremises command scan install precommit precommit framework global local precommit hook prereceive hook gitlab github action circle ci travis ci jenkins output contributing license installation install update using pip pip install ggshield ggshield support python 36 newer package run macos linux window youll need api key gitguardian dashboard use ggshield add api key environment variable gitguardianapikeygitguardian api key command usage ggshield option command args option c configpath file set custom config file ignores local global config file v verbose verbose display mode h help show message exit command install command install precommit hook local global scan command scan various content scan command ggshield scan main command ggshield ha config option used override output behaviour usage ggshield scan option command args command scan various content option showsecrets show secret plaintext instead hiding exitzero always return 0 nonerror status code even incident foundthe env var gitguardianexitzero also used set option json json output result default false allpolicies present fails policy filename fileextensions secret detection default secret detection shown v verbose verbose display mode output path route ggshield output file h help show message exit command ci scan ci environment commitrange scan defined commitrange git path scan file directory precommit scan precommit git hook repo clone scan repository ggshield scan ha different subcommands type scan ci scan commit since last build ci ggshield scan ci option argument commit range scan commit given commit range usage ggshield scan commitrange option commitrange scan defined commitrange git git revlist commitrange list several commits scan example ggshield scan commitrange head1 path scan file directory recursive option usage ggshield scan path option path scan file directory option r recursive scan directory recursively yes confirm recursive scan h help show message exit precommit scan every change staged git repository ggshield scan precommit option argument repo scan commits git repository usage ggshield scan repo option repository scan repository given url path repository clone uri path repository scan example ggshield scan repo gitgithubcomgitguardianggshieldgit ggshield scan repo repositoriesggshield install command install command allows use ggshield precommit hook machine either locally globally repository find detail precommit part documentation usage ggshield install option command install precommit hook local global option mode localglobal hook installation mode required f force force override h help show message exit configuration configuration ggshield follows globallocalcli configuration scheme meaning option local overwrite extend global option cli overwrite extend local ggshield search global config file user home directory example gitguardianyml linux userprofilegitguardian window ggshield recognize well local config file user working directory example gitguardianyml also use option configpath main command set another config file case neither local global config file evaluated example ggshield configpathdesktoponlyconfigyaml scan path r sample config file found gitguardianexample exclude file path globbing pathsignore readmemd doc license ignore policy break sha256 policy break obtained output secret matchesignore 530e5a4a7ea00814db8845dd0cae5efaa4b974a3ce1c76d0384ba715248a5dc1 mytestcredential showsecrets false default false set true desired exit code cli always 0 otherwise exit code 1 incident found environment variable gitguardianexitzerotrue also used toggle behaviour exitzero false default false default secret detected use allpolicies toggle behaviour allpolicies false default false apiurl httpsapigitguardiancom gitguardianapiurl environment variable override setting verbose false default false environment variable configuration ggshield done environment variable environment variable override setting set config file overridden command line option startup ggshield attempt load environment variable different environment file following order path pointed environment variable gitguardiandotenvpath env current work directory env root current git directory one file loaded three reference current environment variable affect ggshield gitguardianapikey required api key gitguardian api gitguardianapiurl custom url scanning api gitguardiandontloadenv set value environment variable wont loaded file gitguardiandotenvpath set path ggshield attempt load environment specified file onpremises configuration gitguardian shield configured run onpremises dashboard request api key dashboard administrator modify environment variable include gitguardianapikeygitguardian api key gitguardianapiurlgitguardian onpremises api url alternatively setting gitguardianapiurl environment variable set apiurl gitguardianyaml precommit precommit framework order use ggshield precommit framework need following step make sure precommit installed pip install precommit create precommitconfigyaml file root repository repos repo httpsgithubcomgitguardianggshield rev main hook id ggshield languageversion python3 stage commit install hook command precommit install precommit installed githooksprecommit youre good go want skip precommit check add n parameter git commit commit message n another way add skiphookid command skipggshield git commit commit message global local precommit hook install precommit globally current future repos need execute following command ggshield install mode global following check global hook folder defined global git configuration create githooks folder needed create precommit file executed every commit give executable access file also install hook locally desired repository need go repository execute ggshield install mode local precommit executable file already exists overridden force override force option ggshield install mode local force already precommit executable file want use ggshield need add line file ggshield scan precommit want try precommit scanning docker image docker run e gitguardianapikey v pwddata rm gitguardianggshield ggshield scan precommit forget add gitguardian api key gitguardianapikey environment variable project development environment git prereceive hook prereceive hook allows reject commits pushed git repository validate every check find ggshields prereceive hook sample docprereceivesample docprereceivepythonsample python git prereceive hook prereceive hook requires host machine python36 pip installed prereceivepythonsample install ggshield pip pip install ggshield move prereceivepythonsample githooksprereceive forget chmod x githooksprereceive either set environment variable machine wide gitguardianapikey set githooksprereceive instructed sample file add ignored match use custom config prereceive hook create gitguardianyaml somewhere system example config file available replace prereceive hook ggshield scan commitrange span continue ggshield c insert path gitguardianyaml scan commitrange span continue docker git prereceive hook prereceive hook requires host machine docker installed prereceivesample move prereceivesample githooksprereceive forget chmod x githooksprereceive either set environment variable machine wide gitguardianapikey set githooksprereceive instructed sample file add ignored match use custom config prereceive hook create gitguardianyaml somewhere system example config file available replace prereceive hook docker run rm v pwddata e gitguardianapikey gitguardianggshieldlatest ggshield scan commitrange span continue docker run rm v pwddata v insert path gitguardianyaml directoryconfig e gitguardianapikey gitguardianggshieldlatest ggshield c configgitguardianyaml scan commitrange span continue gitlab may interested using gitguardians gitlab integration ensure full coverage gitlab project well full git history scan reporting configuring gitlab pipeline use ggshield simple adding step project pipeline stage scanning gitguardian scan image gitguardianggshieldlatest stage scanning script ggshield scan ci forget add gitguardian api key gitguardianapikey environment variable project setting github may interested using gitguardians github integration ensure full coverage github project well full git history scan reporting ggshields support github come form github action action repository hosted ggshieldaction configuring github workflow use ggshield simple adding step project workflow name gitguardian scan push pullrequest job scanning name gitguardian scan runson ubuntulatest step name checkout us actionscheckoutv2 fetchdepth 0 fetch history multiple commits scanned name gitguardian scan us gitguardianggshieldactionmaster env githubpushbeforesha githubeventbefore githubpushbasesha githubeventbase githubpullbasesha githubeventpullrequestbasesha githubdefaultbranch githubeventrepositorydefaultbranch gitguardianapikey secretsgitguardianapikey forget add gitguardian api key gitguardianapikey secret project setting bitbucket bitbucket pipeline support commit range therefore latest commit pushed group new branch scanned configuring bitbucket pipeline use ggshield simple adding step project workflow pipeline default step image gitguardianggshieldlatest service docker script ggshield scan ci forget add gitguardian api key gitguardianapikey environment variable project setting circle ci circle ci supported ggshield ggshieldorb add ggshield pipeline configure circleciconfigyml add ggshield orb orb ggshield gitguardianggshield workflow main job ggshieldscan name ggshieldscan best practice name orb job baserevision pipelinegitbaserevision revision pipelinegitrevision forget add gitguardian api key gitguardianapikey environment variable project setting travis ci add ggshield pipeline configure travisyml add ggshield scanning job job include name gitguardian scan language python python 38 install pip install ggshield script ggshield scan ci forget add gitguardian api key gitguardianapikey environment variable project setting defining encrypted variable travisyml jenkins add ggshield pipeline configure jenkinsfile add ggshield stage pipeline agent none stage stagegitguardian scan agent docker image gitguardianggshieldlatest environment gitguardianapikey credentialsgitguardianapikey step sh ggshield scan ci forget add gitguardian api key gitguardianapikey credential project setting output secret policy break found exit code 0 ggshield scan precommit secret issue found staged code ci alert giving type policy break filename policy break ha found patch giving position policy break file ggshield scan precommit 2 policy break found file productionrb 11 configpaperclipdefaults 12 s3credentials 13 bucket xxx 14 accesskeyid xxxxxxxxxxxxxxxxxxxx aws key 15 secretaccesskey xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx aws key 16 17 contributing question would like ask developer feedback would like provide feel free create issue issue tracker would love hear additionally feature would like suggest feel free create issue issue tracker related open source project trufflehog gitleaks gitrob githound aws gitsecrets detectsecrets license gitguardian shield mit licensed\n",
      "  (0, 32)\t0.22423354774123355\n",
      "  (0, 29)\t0.2746061314090817\n",
      "  (0, 27)\t0.2406277955524843\n",
      "  (0, 24)\t0.20948161560109163\n",
      "  (0, 23)\t0.24956364089548502\n",
      "  (0, 22)\t0.311648949925667\n",
      "  (0, 16)\t0.311648949925667\n",
      "  (0, 14)\t0.30479207143946285\n",
      "  (0, 13)\t0.2281643488638646\n",
      "  (0, 11)\t0.30479207143946285\n",
      "  (0, 10)\t0.2542432817654882\n",
      "  (0, 5)\t0.26924567497960966\n",
      "  (0, 4)\t0.2281643488638646\n",
      "  (0, 1)\t0.29824004581595487\n",
      "make8bitart make8bitartcom webbased pixel art application thats super fun free open source install run web make8bitartcom locally machine downloading compressed export gliltch unzipping directing browser indexhtml project root directory contribute remix project glitch send link changed app review merge downloaded project work locally run npm install grunt build grunt used concatenate minify j cs file build folder dependency make8bitartcom us jquery jquery plugin wrote draggybits local dev dependency express grunt along various grunt plugins misc note yes know isnt technically 8bit youll get project ha v chill development cycle im poppin feature come folk request expect change often shocked find gross code suggestion im totally open hear learn youre nerf dart made jenn schiffer designed built created graphic passion project dinosaur art source wa found variety geocities website feature request email jenndotbizinfo tweetdm jennschiffer huge shout everyone ha contributed wild project tessa thornton tim branyen vlad filippov mike taylor brian brennan zach leatherman tyler benziger samir zahran phillip calvin monica dinculescu greg smith dominick guzzo andrew lawson noelle leigh xoxo j jennmoneybiz\n",
      "  (0, 29)\t0.32469686111878604\n",
      "  (0, 27)\t0.28452055863760917\n",
      "  (0, 26)\t0.3452244151936163\n",
      "  (0, 24)\t0.24769302381832067\n",
      "  (0, 16)\t0.36849663659215454\n",
      "  (0, 14)\t0.3603889992640326\n",
      "  (0, 13)\t0.26978366256849867\n",
      "  (0, 8)\t0.31224279471524846\n",
      "  (0, 4)\t0.26978366256849867\n",
      "  (0, 1)\t0.35264182281532586\n",
      "tecogan repository contains source code material tecogan project ie code temporally coherent gan video superresolution author mengyu chu xie laura lealtaixe nil thuerey technical university munich repository far contains code tecogan inference training data generation ie download follow soon pretrained model also available find link downloading instruction video preprint paper found video httpswwwyoutubecomwatchvpzxfxtfdak preprint httpsarxivorgpdf181109393pdf additional generated output method generates fine detail persist course long generated video sequence eg mesh structure armor scale pattern lizard dot back spider highlight capability method spatiotemporal discriminator play key role guide generator network towards producing coherent detail running tecogan model find quick start guide running trained tecogan model explanation parameter take look runganpy file note evaluation test case 2 currently requires nvidia gpu cuda tkinter also required may installed via python3tk package install tensorflow18 pip3 install ignoreinstalled upgrade tensorflowgpu tensorflow install pytorch necessary metric evaluation thing pip3 install r requirementstxt download tecogan model vid4 tos scene shown paper video python3 runganpy 0 run inference mode calendar scene take look parameter explanation runganpy feel free try scene python3 runganpy 1 evaluate result 4 metric psnr lpips1 temporal metric tof tlp pytorch take look paper detail python3 runganpy 2 train tecogan model 1 prepare training data training validation dataset downloaded following command chosen directory trainingdatapath note online video downloading requires youtubedl install youtubedl online video downloading pip install user upgrade youtubedl take look parameter first python3 datapreparepy help safe side want see happen following line wont download anything save information log file trainingdatapath still important directory log saved trainingdatapathloglogfilemmddhhmmtxt python3 datapreparepy startid 2000 duration 120 diskpath trainingdatapath test create 308 subfolders trainingdatapath 120 frame 28 online video take long time python3 datapreparepy startid 2000 duration 120 remove diskpath trainingdatapath ready please update parameter trainingdatapath runganpy case 3 case 4 start training downloaded data note data 272 308 sequence one used published model 36 308 online anymore hence script downloads suitable replacement 2 train model section give command train new tecogan model detail additional parameter found runganpy file note tensorboard gif summary requires ffmpeg install ffmpeg gif summary sudo aptget install ffmpeg conda install ffmpeg train tecogan model based frvsr model please check update following parameter vggpath us model default vgg model ca 500mb trainingdatapath see mainpy also adjust output directory testwhiletrain function like write train sub directory default python3 runganpy 3 train without dst ie frvsr model python3 runganpy 4 view log via tensorboard tensorboard logdirextecoganmmddhhlog port8008 tensorboard gif summary example acknowledgement work wa funded erc starting grant realflow erc stg2015637014 part code based lpips1 photorealistic sisr2 gifsummary3 reference 1 unreasonable effectiveness deep feature perceptual metric lpips 2 photorealistic single image superresolution using generative adversarial network 3 gifsummary tum i15 httpsgeintumde tum httpswwwtumde\n",
      "  (0, 33)\t0.31952304679152677\n",
      "  (0, 27)\t0.2633384887326973\n",
      "  (0, 26)\t0.31952304679152677\n",
      "  (0, 24)\t0.22925270101492962\n",
      "  (0, 15)\t0.34106269103336717\n",
      "  (0, 14)\t0.3335586534643287\n",
      "  (0, 13)\t0.24969872941958096\n",
      "  (0, 10)\t0.2782390182183331\n",
      "  (0, 9)\t0.3129381440062983\n",
      "  (0, 2)\t0.31952304679152677\n",
      "  (0, 1)\t0.3263882410775512\n",
      "howtonodeorg community supported blog program nodejs powered new static blog engine written node called wheat run local version blog simply install wheat dependency nodejs v01101 later spark installed type spark directory append listen3000 right closing semicolon run node appjs get working wheat environment box ivy contributing best way contribute fork repository add article first article please add entry author directory well article format every article markdown file metadata top file title control flow node part ii author tim caswell date thu feb 04 2010 022435 gmt0600 cst node v0191 much fun writing last article control flow decided first section display javascript file display content external javascript file path relative markdown file testcodetestfilejs display content external javascript file evaluate content testcodeevaluatefilejs content go author format every author ha markdown file located author folder name file name surname name surnamemarkdown github yourgithubaccount email youremaildomaincom homepage httpyourhomepagecom twitter yourtwitteraccount location city state country word starting project local machine please check project still working add contribution run project three easy step install npmpackages npm install start server node serverserverjs enjoy local blog clone httplocalhost8080 doc come soon licensing article copyright individual author author put note license copyright individual bio page wish\n",
      "  (0, 12)\t1.0\n",
      "ethereumcasts companion repo ethereumsolidity course udemy\n",
      "  (0, 36)\t0.25171860336910157\n",
      "  (0, 35)\t0.21331154618911505\n",
      "  (0, 34)\t0.2913615545455909\n",
      "  (0, 33)\t0.2729607608039863\n",
      "  (0, 32)\t0.2096366282214065\n",
      "  (0, 31)\t0.27882552916482084\n",
      "  (0, 30)\t0.26193077507949225\n",
      "  (0, 28)\t0.26193077507949225\n",
      "  (0, 24)\t0.19584500183560288\n",
      "  (0, 20)\t0.24221129895985152\n",
      "  (0, 18)\t0.23769282016074095\n",
      "  (0, 15)\t0.2913615545455909\n",
      "  (0, 12)\t0.2673354386492155\n",
      "  (0, 10)\t0.23769282016074095\n",
      "  (0, 6)\t0.2468829753922143\n",
      "  (0, 4)\t0.21331154618911505\n",
      "angularui companion suite angularjs usage requirement angularjs v100 currently required jquery plugins depends directive check specific directive dependency information installation repository come module prebuilt compressed build directory angularmodulemyapp ui module found directive filter folder check readme file associated module specific module usage information development need build project use see working need know requirement install nodejs npm come install local dependency npm install install global dependency grunt coffeescript testacular npm install g testacular coffeescript grunt build file run test commit always run grunt build test everything grunt test develop module come unit test run change certainly commiting change project unit test also provide insight usage module first start testacular server grunt server open browser httplocalhost8080 run watch command rerun test every save grunt watch publishing core team wish publish new version follow step bump version number inside packagejson build test commit updated packagejson build folder commit tag commit git tag vmajminpatch push tag git push angularui master tag\n",
      "  (0, 39)\t0.2944923345090841\n",
      "  (0, 37)\t0.2944923345090841\n",
      "  (0, 35)\t0.23982907390668493\n",
      "  (0, 28)\t0.2944923345090841\n",
      "  (0, 25)\t0.31348733641382537\n",
      "  (0, 24)\t0.2201912004230853\n",
      "  (0, 21)\t0.28864515649739964\n",
      "  (0, 20)\t0.27232145918522527\n",
      "  (0, 19)\t0.28864515649739964\n",
      "  (0, 17)\t0.28301065089826033\n",
      "  (0, 13)\t0.23982907390668493\n",
      "  (0, 8)\t0.27757388856554555\n",
      "  (0, 5)\t0.28301065089826033\n",
      "letsbuildexpress series chapter teach create express library scratch help u understand express actually work behind scene use code variable name forth express people read tutorial feel free contribute express directly find people often get confused next work route order work express building express library gain solid understanding also fun chapter build express step step running example toc chapter 01 building express abstraction chapter 02 handling route box chapter 03 implement next function chapter 04 extending response object chapter 05 implementing sendjson response chapter 06 error handling wip come note work progress minimal working library corresponding tutorial done contribution welcome feel free improve repo grammar mistake technical glitch maybe translation happy accept pr license mit\n",
      "  (0, 27)\t0.3771122931836908\n",
      "  (0, 25)\t0.4674023104381242\n",
      "  (0, 24)\t0.32829994663655343\n",
      "  (0, 13)\t0.35757955819384263\n",
      "  (0, 1)\t0.4674023104381242\n",
      "  (0, 0)\t0.43036319931457556\n",
      "chrome extension display repository size github automatically add repository size githubs repository summary screenshot private repository enable viewing size private repository install extension chrome webstore havent go httpsgithubcomsettingstokens generate personal access token check repo scope enable extension private repo click github repo size extension extension icon aside address bar paste access token prompt box temporarily override token set xgithubtoken localstorage access token extension use value even youve previously set token localstoragesetitemxgithubtoken yourpersonalaccesstoken remove use previously set token localstorageremoveitemxgithubtoken development clone repo go chrome extension chromeextensions enable developer mode click load unpacked extension select cloned repo license mit\n",
      "  (0, 39)\t0.16540433164034182\n",
      "  (0, 38)\t0.1839893123695707\n",
      "  (0, 37)\t0.16540433164034182\n",
      "  (0, 36)\t0.15895553830614526\n",
      "  (0, 35)\t0.13470220793211754\n",
      "  (0, 34)\t0.1839893123695707\n",
      "  (0, 33)\t0.17236955906048276\n",
      "  (0, 32)\t0.1323815667241593\n",
      "  (0, 31)\t0.17607304938404197\n",
      "  (0, 30)\t0.16540433164034182\n",
      "  (0, 28)\t0.16540433164034182\n",
      "  (0, 27)\t0.14206029781671653\n",
      "  (0, 26)\t0.17236955906048276\n",
      "  (0, 25)\t0.17607304938404197\n",
      "  (0, 24)\t0.12367241544598345\n",
      "  (0, 23)\t0.14733578499705735\n",
      "  (0, 22)\t0.1839893123695707\n",
      "  (0, 21)\t0.1621202102637464\n",
      "  (0, 19)\t0.1621202102637464\n",
      "  (0, 18)\t0.15009852142217217\n",
      "  (0, 17)\t0.15895553830614526\n",
      "  (0, 16)\t0.1839893123695707\n",
      "  (0, 15)\t0.1839893123695707\n",
      "  (0, 14)\t0.1799411923358619\n",
      "  (0, 13)\t0.13470220793211754\n",
      "  (0, 12)\t0.16881727448838887\n",
      "  (0, 11)\t0.1799411923358619\n",
      "  (0, 10)\t0.15009852142217217\n",
      "  (0, 9)\t0.16881727448838887\n",
      "  (0, 8)\t0.155901930675138\n",
      "  (0, 7)\t0.1839893123695707\n",
      "  (0, 6)\t0.155901930675138\n",
      "  (0, 5)\t0.15895553830614526\n",
      "  (0, 4)\t0.13470220793211754\n",
      "  (0, 3)\t0.1799411923358619\n",
      "  (0, 2)\t0.17236955906048276\n",
      "  (0, 1)\t0.17607304938404197\n",
      "gitup gitrepoupdater gitup tool updating multiple git repository smart enough handle several remote dirty working directory diverged local branch detached head wa originally created manage large collection project deal sporadic internet access gitup work macos linux window latest version git either python 27 python 3 installed installation pip pip install gitup homebrew brew install gitup source first git clone gitgithubcomearwiggitrepoupdatergit cd gitrepoupdater install everyone sudo python setuppy install make sure localbin path python setuppy install user finally simply delete gitrepoupdater directory youre done note using window may wish add macro invoke gitup directory note cpython27 refers directory python installed doskey gitupcpython27pythonexe cpython27scriptsgitup usage two way update repos pas command argument save bookmark example gitup reposfoo reposbar reposbaz automatically pull foo bar baz git repository additionally type gitup repos automatically update git repository directory add bookmark either work gitup add reposfoo reposbar reposbaz gitup add repos update bookmark run gitup without args gitup delete bookmark gitup delete repos view current bookmark gitup list mix match bookmark command argument gitup add reposfoo reposbar gitup reposbaz update baz gitup update foo bar gitup reposbaz update update three update git repository current directory gitup control deep gitup look repository given directory directory git repo depth option depth 0 disable recursion entirely meaning provided path must repos depth 1 descend one level old behavior pre05 gitup depth 1 recurse indefinitely recommended default depth 3 default gitup fetch remote repository pas currentonly c make fetch remote tracked current branch also default gitup try fastforward branch upstreams configured always skip branch possible eg dirty working directory mergerebase required pas fetchonly f skip step fetch remote fetching gitup keep remotetracking branch longer exist upstream pas prune p delete set fetchprune remotenameprune git config default full list command argument abbreviation gitup help\n",
      "  (0, 38)\t0.2898185597965184\n",
      "  (0, 37)\t0.2605436400774207\n",
      "  (0, 36)\t0.25038555006408286\n",
      "  (0, 35)\t0.21218188927127057\n",
      "  (0, 29)\t0.2553705171644441\n",
      "  (0, 27)\t0.22377229626689177\n",
      "  (0, 24)\t0.19480784437694046\n",
      "  (0, 20)\t0.24092859451024093\n",
      "  (0, 18)\t0.23643404470571477\n",
      "  (0, 17)\t0.25038555006408286\n",
      "  (0, 13)\t0.21218188927127057\n",
      "  (0, 11)\t0.28344199203318915\n",
      "  (0, 5)\t0.25038555006408286\n",
      "  (0, 3)\t0.28344199203318915\n",
      "  (0, 1)\t0.27734892279484297\n",
      "  (0, 0)\t0.2553705171644441\n",
      "generate personal youtube report getting started 1 install python 3 dont already python 3 installed computer download httpswwwpythonorgdownloads 2 get youtube data find download google data httpssupportgooglecomaccountsanswer3024190hlen download data google ha stored httpstakeoutgooglecom use script need select download youtube google provide zip file default 3 clone repository httpsgithubcoma3m4personalyoutubereportgenerator click green clone download button top right page click download zip button extract zip somewhere computer note make sure set google account language english downloading 4 extract takeout file extract takeout filefrom step 2 move repository folderfrom step 3 file repository folder look like 5 install dependency open command prompt terminal window repository folder type following press enter pip install r requirementstxt 6 run script command prompt terminal window type following press enter python reportpy 7 result script generate file named youtubereportpdf file automatically open browser script completes besides find image make report image folder\n",
      "  (0, 39)\t0.23749657976255525\n",
      "  (0, 35)\t0.1934127924769525\n",
      "  (0, 34)\t0.26418191088037907\n",
      "  (0, 33)\t0.247497633986146\n",
      "  (0, 32)\t0.1900806889928397\n",
      "  (0, 31)\t0.25281530781189304\n",
      "  (0, 28)\t0.23749657976255525\n",
      "  (0, 19)\t0.23278105879202543\n",
      "  (0, 18)\t0.21551966089192834\n",
      "  (0, 17)\t0.22823704982595414\n",
      "  (0, 16)\t0.26418191088037907\n",
      "  (0, 14)\t0.25836939888060484\n",
      "  (0, 9)\t0.24239706964270397\n",
      "  (0, 7)\t0.26418191088037907\n",
      "  (0, 6)\t0.22385251309037457\n",
      "  (0, 5)\t0.22823704982595414\n",
      "  (0, 4)\t0.1934127924769525\n",
      "  (0, 2)\t0.247497633986146\n",
      "github doc repository contains documentation website code markdown source file docsgithubcom githubs doc team work preproduction content private repo regularly syncs public repo article contributing readmes license contributing start contributing right accept lot different contribution including dont require write single line code click make contribution doc youre using github doc may find something article youd like add update change click make contribution navigate directly article codebase begin making contribution open issue youve found problem open issue using template solve issue solution one open issue need fork repository submit pr using template visible automatically pull request body detail process please check getting started contributing join u discussion use github discussion talk sort topic related documentation site example youd like help troubleshooting pr great new idea want share something amazing youve learned doc join u discussion thats thats get started easily member github documentation community want know youre making complex contribution check getting started contributing thing know youre getting started repo youre trouble github account contact support accept pull request translated content see contributingmd information readmes addition readme youre reading right repo includes readmes describe purpose subdirectory detail contentreadmemd contributingreadmemd datareadmemd datareusablesreadmemd datavariablesreadmemd includesliquidtagsreadmemd includesreadmemd javascriptsreadmemd layoutsreadmemd libliquidtagsreadmemd middlewarereadmemd scriptreadmemd stylesheetsreadmemd testsreadmemd license github product documentation asset content data folder licensed ccby license code repository licensed mit license using github logo sure follow github logo guideline\n",
      "  (0, 39)\t0.19779314605520182\n",
      "  (0, 38)\t0.22001736334959893\n",
      "  (0, 37)\t0.19779314605520182\n",
      "  (0, 36)\t0.19008157581286936\n",
      "  (0, 35)\t0.16107905532612588\n",
      "  (0, 32)\t0.15830399544205054\n",
      "  (0, 30)\t0.19779314605520182\n",
      "  (0, 29)\t0.19386594117089204\n",
      "  (0, 28)\t0.19779314605520182\n",
      "  (0, 27)\t0.16987797693113194\n",
      "  (0, 24)\t0.14788945300717188\n",
      "  (0, 23)\t0.17618648890313035\n",
      "  (0, 22)\t0.22001736334959893\n",
      "  (0, 21)\t0.19386594117089204\n",
      "  (0, 20)\t0.1829022756751159\n",
      "  (0, 19)\t0.19386594117089204\n",
      "  (0, 18)\t0.17949021332089818\n",
      "  (0, 16)\t0.22001736334959893\n",
      "  (0, 13)\t0.16107905532612588\n",
      "  (0, 12)\t0.20187439771606935\n",
      "  (0, 11)\t0.2151765566480103\n",
      "  (0, 10)\t0.17949021332089818\n",
      "  (0, 9)\t0.20187439771606935\n",
      "  (0, 7)\t0.22001736334959893\n",
      "  (0, 4)\t0.16107905532612588\n",
      "  (0, 3)\t0.2151765566480103\n",
      "  (0, 1)\t0.2105509694203714\n",
      "opencv2pythonguide repo contains tutorial opencvpython library using new cv2 interface imp tutorial meant opencv 3x version opencv 2x imp tutorial meant opencv 3x version opencv 2x imp tutorial meant opencv 3x version opencv 2x please try example opencv 3x sending bug report data file input data used tutorial given data folder online official tutorial please visit httpdocsopencvorgtrunkdocpytutorialspytutorialshtml httpsopencvpythontutroalsreadthedocsorgenlatestindexhtml checking may contain lot error please stick official tutorial offline build doc source install sphinx downloadclone repo navigate base folder run command make html html doc available buildhtml folder\n",
      "  (0, 39)\t0.20926766992887216\n",
      "  (0, 38)\t0.23278117513341265\n",
      "  (0, 37)\t0.20926766992887216\n",
      "  (0, 36)\t0.2011087303079039\n",
      "  (0, 35)\t0.17042369391826423\n",
      "  (0, 33)\t0.21807999605287604\n",
      "  (0, 32)\t0.16748764518535486\n",
      "  (0, 31)\t0.22276560968178985\n",
      "  (0, 30)\t0.20926766992887216\n",
      "  (0, 29)\t0.20511263709854632\n",
      "  (0, 28)\t0.20926766992887216\n",
      "  (0, 27)\t0.17973306514214138\n",
      "  (0, 25)\t0.22276560968178985\n",
      "  (0, 21)\t0.20511263709854632\n",
      "  (0, 20)\t0.19351293924278584\n",
      "  (0, 18)\t0.18990293377616627\n",
      "  (0, 17)\t0.2011087303079039\n",
      "  (0, 15)\t0.23278117513341265\n",
      "  (0, 12)\t0.21358568621253413\n",
      "  (0, 9)\t0.21358568621253413\n",
      "  (0, 6)\t0.19724534083387604\n",
      "  (0, 5)\t0.2011087303079039\n",
      "  (0, 4)\t0.17042369391826423\n",
      "  (0, 0)\t0.20511263709854632\n",
      "repokid repokid us access advisor provided aardvark remove permission granting access unused service inline policy iam role aws account getting started install mkvirtualenv repokid git clone gitgithubcomnetflixrepokidgit cd repokid pip install e repokid config configjson dynamodb need dynamodb table called repokidroles specify account endpoint dynamodb config file table following property roleid string primary partition key primary sort key global secondary index named account primary partition key account roleid account projected attribute global secondary index named rolename primary partition key rolename roleid rolename projected attribute development run dynamo locally run locally java djavalibrarypathdynamodblocallib jar dynamodblocaljar shareddb inmemory port 8010 run development version table index created automatically iam permission repokid need iam role account queried additionally repokid need launched role user stsassumerole different account role repokidinstanceprofile create one need ability call stsassumerole repokidroles dynamodb permission repokidroles table index specified assumerole subsection dynamodb config ability run dynamodblisttables repokidrole must exist every account managed repokid must trust policy allowing repokidinstanceprofile name must specified connectioniam config file ha permission version 20121017 statement action iamdeleteinstanceprofile iamdeleterole iamdeleterolepolicy iamgetaccountauthorizationdetails iamgetinstanceprofile iamgetrole iamgetrolepolicy iamlistinstanceprofiles iamlistinstanceprofilesforrole iamlistrolepolicies iamputrolepolicy iamupdateroledescription effect allow resource monitoring n account always need n1 role n repokidroles 1 repokidinstanceprofile editing configjson running repokid config configjson creates file need edit find update field dynamodb using dynamo locally set endpoint httplocalhost8010 using aws hosted dynamo set region assumerole accountnumber aardvarkapilocation location aardvark rest api something like httpsaardvarkyourcompanynetapi1advisors connectioniam set assumerole repokidrole whatever called optional config repokid us filter decide role candidate repoed filter may configured suit environment described blocklist filter role may excluded adding blocklist filter one common reason exclude role corresponding workload performs occasional action may observed known required two way exclude role exclude role name account add list config filterconfigblocklistfilterall exclude role name specific account add list config filterconfigblocklistfilteraccountnumber blocklists also maintained s3 blocklist file following form arns arn1 arn2 name rolename1 accountnumber1 rolename2 accountnumber2 accountnumber3 exclusive filter prefer repo certain role use exclusive filter maybe want consider role used production certain team select role repoing may list name configuration file shell style glob pattern also supported role selection specified per individual account globally activate filter put repokidfiltersexclusiveexclusivefilterin section activefilters config file configure start autogenerated config file ha example config filterconfig section exclusivefilter globpattern accountnumber globpattern age filter default age filter excludes role younger 90 day change edit config setting filterconfigagefilterminimumage active filter new filter created support internal logic netflix several specific use case make active make sure python path add config list section activefilters hook repokid extensible via hook called various operation listed hook name context afterrepo role error afterreporoles role error beforereporoles accountnumber role afterschedulerepo role duringrepoablecalculation accountnumber rolename potentiallyrepoablepermissions minimumage duringrepoablecalculationbatch rolebatch potentiallyrepoablepermissions minimumage example hook implementation found repokidhooksloggers use repokid configured use follows standard flow update role cache repokid updaterolecache accountnumber display role cache repokid displayrolecache accountnumber display information specific role repokid displayrole accountnumber rolename repo specific role repokid reporole accountnumber rolename repo role account repokid repoallroles accountnumber c scheduling rather running repo right schedule one schedulerepo command duration scheduling eligibility configurable default role repoed 7 day scheduling run command reposcheduledroles repo role already scheduled targeting specific permission say find given permission especially dangerous environment ill use s3putobjectacl example use repokid find role permission even hidden wildcard remove single permission find remove ensure role cache updated beginning find role given permission repokid findroleswithpermissions permission outputrolefile remove permission role repokid removepermissionsfromroles rolefilerolefile permission c example repokid findroleswithpermissions s3putobjectacl stsassumerole outputmyrolesjson repokid removepermissionsfromroles rolefilemyrolesjson s3putobjectacl stsassumerole c rolling back repokid store copy version inline policy know added different version policy found updaterolecache time repo action occurs restore previous version run see version role repokid rollbackrole accountnumber rolename restore specific version repokid rollbackrole accountnumber rolename selectionnumber c stats repokid keep count total permission role stats added time updaterolecache reporole action occur output stats csv file run repokid repostats outputfilename optional account number specified output stats specific account library new v0142 repokid called library using repokidlib module repokidlib import displayrole reporole updaterolecache accountnumber 123456789012 displayroleaccountnumber supercoolrolename updaterolecacheaccountnumber reporoleaccountnumber supercoolrolename committrue dispatcher repokid dispatcher designed listen message queue perform action far action list repoable service role set remove optout list perform rollback role repokid respond configurable sn topic information success failure dispatcher component exists help operationalization repo lifecycle across organization may choose expose queue directly developer likely guarded rolling back destructive action done carefully\n",
      "  (0, 39)\t0.24082891370117554\n",
      "  (0, 37)\t0.24082891370117554\n",
      "  (0, 36)\t0.23143946254257508\n",
      "  (0, 35)\t0.19612658318997517\n",
      "  (0, 32)\t0.19274772668930018\n",
      "  (0, 31)\t0.256362580076894\n",
      "  (0, 30)\t0.24082891370117554\n",
      "  (0, 29)\t0.23604722887016363\n",
      "  (0, 27)\t0.20683997126300785\n",
      "  (0, 24)\t0.1800671915377604\n",
      "  (0, 23)\t0.2145210871944124\n",
      "  (0, 19)\t0.23604722887016363\n",
      "  (0, 18)\t0.21854363488409334\n",
      "  (0, 13)\t0.19612658318997517\n",
      "  (0, 11)\t0.2619946010517331\n",
      "  (0, 9)\t0.24579816275570818\n",
      "  (0, 8)\t0.22699340601338963\n",
      "  (0, 3)\t0.2619946010517331\n",
      "  (0, 2)\t0.25097029353469535\n",
      "typescripthandbook repo deprecated handbook ha moved new typescript website repo find revised updated handbook page packagesdocumentation repo typescripthandbook typescript handbook comprehensive guide typescript language meant read online typescript website directly repository formal description language see latest typescript language specification contribute typescripthandbook accepting contribution youve submitted pr existing issue please post comment issue avoid duplication effort see contributing file information also contains guideline submit pr\n",
      "  (0, 39)\t0.4044803794828662\n",
      "  (0, 34)\t0.4499281617960037\n",
      "  (0, 26)\t0.4215131730145922\n",
      "  (0, 22)\t0.4499281617960037\n",
      "  (0, 6)\t0.38124317214804593\n",
      "  (0, 4)\t0.3294012898043972\n",
      "aptreport collected blackorbird httpstwittercomblackorbird interesting apt report sample malware technology intellegence collection apt group country group123 scarcruft continues evolve introduces bluetooth harvester httpssecurelistcomscarcruftcontinuestoevolveintroducesbluetoothharvester90729 may 13 2019 group123 attempt attack printing paper apt disguised guide organization conference httpsblogalyaccokr2287 may 2 2019 group123 apt attack impersonating unification ministry spread malicious code google drive httpsblogalyaccokr2268 april 22 2019 group123 apt organization operation high expert httpsblogalyaccokr2226 april 2 2019 rocketman apt campaign returned operation holiday wiper httpsblogalyaccokr2089 jan 23 2019 operation blackbird mobile invasion httpsblogalyaccokr2035 dec 13 2018 group123 operation korean sword underway httpsblogalyaccokr1985 nov 16 2018 group123 group latest apt campaign operation rocket man httpsblogalyaccokr1853 aug 22 2018 group123 flash player zeroday cve20184878 attack attention httpsblogalyaccokr1521 feb 02 2018 group123 group survey total number discovery separated family north south httpsblogalyaccokr1767 july 28 2014 rocketman apt campaign operation golden bird httpsblogalyaccokr2205 march 20 2013 korea crosshairs httpsblogtalosintelligencecom201801koreaincrosshairshtml jan 16 2018 freemilk highly targeted spear phishing campaign httpsunit42paloaltonetworkscomunit42freemilkhighlytargetedspearphishingcampaign oct 5 2017 baby related kimsuky babyshark malware part two attack continue using kimjongrat pcrat april 26 2019 httpsunit42paloaltonetworkscombabysharkmalwareparttwoattackscontinueusingkimjongratandpcrat operation giant baby giant threat march 28 2019 httpsblogalyaccokr2223 malicious code installed coin purse programalibaba march 15 2019 httpsasecahnlabcom1209 new babyshark malware target u national security think tank feb 22 2019 httpsunit42paloaltonetworkscomnewbabysharkmalwaretargetsusnationalsecuritythinktanks korea latest apt attack operation mystery baby attention feb 11 2018 httpsblogalyaccokr1963 returned korea operation baby coin apt attacker overseas target 2010 apr 19 2014 httpsblogalyaccokr1640 kimsuky kimsuky blue house green support sangchunjae estimate httpsblogalyaccokr2645 kimsuky cyber security bureau cryptographic case may 28 2019 httpsblogalyaccokr2338 kimsuky korea cryptographic exchange event impersonation apt attack may 28 2019 httpsblogalyaccokr2336 kimsuky fake striker apt campaign aimed korea may 20 2019 httpsblogalyaccokr2315 analysis smoke screen apt campaign aimed korea america april 17 2019 httpsblogalyaccokr2243 encrypted apt attack kimsuky organization smoke screen part 2 may 13 2019 httpsblogalyaccokr2299 kimsuky organization operation stealth power silence operation april 3 2019 httpsblogalyaccokr2234 kimsuky organization watering hole started operation low kickmarch 21 2019 httpsblogalyaccokr2209 jaku silivaccine inside north korea antivirus may 1 2018 httpsresearchcheckpointcomsilivaccinealookinsidenorthkoreasantivirus lazarus lazarus group go filelessan implant w remote download inmemory execution httpsobjectiveseecomblogblog0x51html lazarus apt target mac user poisoned word document httpswwwsentinelonecombloglazarusapttargetsmacuserspoisonedworddocument konni konnis apt group conduct attack russiannorth korean trade economic investment document httpsblogalyaccokr2535 apt campaign konni kimsuky find commonality organization june 10 2019 httpsblogalyaccokr2347 korean kusa konni organization blue sky utilizing amadey russia botnet may 16 2019 httpsblogalyaccokr2308 konni apt campaign operation hunter adonis jan 1 2019 httpsblogalyaccokr2061 oceanlotus threat spotlight ratsnif new network vermin oceanlotus july 1 2019 httpsthreatvectorcylancecomenushomethreatspotlightratsnifnewnetworkverminfromoceanlotushtml analysis report attack mobile device oceanlotus may 24 2019 httpsmpweixinqqcomsltcvlpoomhp0ndgdqhknq oceanlotus first quarter 2019 attack technology chinaapril 24 2019 httpsmpweixinqqcomsxpsexp2j5ie7wnsmevc24a deobfuscating apt32 flow graph cutter radare2 april 24 2019 httpsresearchcheckpointcomdeobfuscatingapt32flowgraphswithcutterandradare2 oceanlotus steganography malware analysis white paper april 2 2019 httpsthreatvectorcylancecomenushomereportoceanlotusaptgroupleveragingsteganographyhtml oceanlotus macos malware updateapril 9 2019 httpswwwwelivesecuritycom20190409oceanlotusmacosmalwareupdate apt28 cb tau threat intelligence notification hunting apt28 downloaders april 5 2019 httpswwwcarbonblackcom20190405cbthreatintelligencenotificationhuntingapt28downloaders turla dive turla powershell usage may 29 2019 httpswwwwelivesecuritycom20190529turlapowershellusage tick tick group new campaign attack north korean japan httpswwwahnlabcomkrsitesecurityinfosecunewssecunewsviewdocurpage1menudist2seq28186 april 1 2019 winnti bayersayshasdetectedcontainedcyberattack april 5 2019 httpswwwreuterscomarticleusbayercyberbayersayshasdetectedcontainedcyberattackiduskcn1rg0nn httpswwwtagesschaudeinlandhackerangriffbayer101html middle east asia muddywater recent muddywaterassociated blackwater campaign show sign new antidetection techniquesmay 202019 httpsblogtalosintelligencecom201905recentmuddywaterassociatedblackwaterhtml zoopark aptc38 attack activity revealed may 272019 httpblogs360cnpostanalysisofaptc38html apt group finance carbanak carbanak week part one rare occurrence april 22 2019 httpswwwfireeyecomblogthreatresearch201904carbanakweekpartonearareoccurrencehtml londonblue nigeria evolving tactic london blue start spoofing target domain april 4 2019 pdf folder httpswwwagaricomemailsecuritybloglondonblueevolvingtactics fin6 picksix intercepting fin6 intrusion actor recently tied ryuk lockergoga ransomwareapril 5 2019 httpswwwfireeyecomblogthreatresearch201904picksixinterceptingafin6intrusionhtml fin7 hunt fin7 pursuing enigmatic evasive global criminal operation august 01 2018 httpswwwfireeyecomblogthreatresearch201808fin7pursuinganenigmaticandevasiveglobalcriminaloperationhtml\n",
      "  (0, 25)\t0.5480036672955759\n",
      "  (0, 23)\t0.458562799841971\n",
      "  (0, 4)\t0.41924249166949407\n",
      "  (0, 3)\t0.5600427415925022\n",
      "s3cmd tool amazon simple storage service s3 author michal ludvig michallogixcz project homepage c tgrmn software contributor s3tools s3cmd mailing list announcement new release s3toolsannouncelistssourceforgenet general question discussion s3toolsgenerallistssourceforgenet bug report s3toolsbugslistssourceforgenet s3cmd requires python 26 newer python 3 also supported starting s3cmd version 2 s3cmd s3cmd s3cmd free command line tool client uploading retrieving managing data amazon s3 cloud storage service provider use s3 protocol google cloud storage dreamhost dreamobjects best suited power user familiar command line program also ideal batch script automated backup s3 triggered cron etc s3cmd written python open source project available gnu public license v2 gplv2 free commercial private use pay amazon using storage lot feature option added s3cmd since first release 2008 recently counted 60 command line option including multipart uploads encryption incremental backup s3 sync acl metadata management s3 bucket size bucket policy amazon s3 amazon s3 provides managed internetaccessible storage service anyone store amount data retrieve later s3 paid service operated amazon storing anything s3 must sign aws account aws amazon web service obtain pair identifier access key secret key need give key s3cmd think username password s3 account amazon s3 pricing explained time writing cost using s3 usd 0026 per gb per month storage space used plus 000 per gb data uploaded plus 0000 per gb first 1gb month data downloaded 0090 per gb 10 tb month data downloaded 0085 per gb next 40 tb month data downloaded 0070 per gb next 100 tb month data downloaded 0050 per gb data downloaded month 150 tb plus 0005 per 1000 put copy list request 0004 per 10000 get request instance 1st january upload 2gb photo jpeg holiday new zealand end january charged 006 using 2gb storage space month 00 uploading 2gb data cent request come slightly 006 complete backup precious holiday picture february dont touch data still s3 server pay 006 two gigabyte single cent charged transfer come 006 ongoing cost backup bad march allow anonymous read access picture friend download say 1500mb file owned responsible cost incurred mean end march youll charged 006 storage plus 0045 download traffic generated friend minimum monthly contract setup fee use pay beginning bill used like us003 even nil thats pricing model amazon s3 nutshell check amazon s3 homepage detail needle say money charged amazon obviously payment using s3cmd amazon s3 basic file stored s3 called object name officially called key since sometimes confusing user often refer object file remote file object belongs exactly one bucket describe object s3 storage invented urilike schema following form s3bucket s3bucketobject bucket bucket sort like directory folder restriction user 100 bucket bucket name must unique amongst user s3 bucket nested deeper hierarchy name bucket consist basic alphanumeric character plus dot dash space accented utf8 letter etc good idea use dnscompatible bucket name instance mean use upper case character dns compliance strictly required feature described available dnsincompatible named bucket one step using fully qualified domain name fqdn bucket ha even benefit example s3mybucket dns compatible hand s3mybucket dns compatible fqdn finally s3mybuckets3toolsorg dns compatible fqdn provided s3toolsorg domain create domain record mybuckets3toolsorg look virtual host later text detail regarding fqdn named bucket object file stored amazon s3 unlike bucket almost restriction object name utf8 string 1024 byte long interestingly enough object name contain forward slash character thus myfunnypicturejpg valid object name note directory bucket called funny really single object name called myfunnypicturejpg s3 doe care look like directory structure full uri image could example s3mybucketmyfunnypicturejpg public v private file file stored s3 either private public private one readable user uploaded public one read anyone additionally public file accessed using http protocol using s3cmd similar tool acl access control list file set time upload using aclpublic aclprivate option s3cmd put s3cmd sync command see alternatively acl altered existing remote file s3cmd setacl aclpublic aclprivate command simple s3cmd howto register amazon aws s3 go httpawsamazoncoms3 click sign web service button right column work registration supply credit card detail order allow amazon charge s3 usage end access secret key set separate iam user user access key must least following permission anything s3listallmybuckets s3getbucketlocation s3listbucket example policy found httpsdocsawsamazoncomamazons3latestdevexamplepoliciess3html run s3cmd configure asked two key copy paste confirmation email amazon account page careful copying case sensitive must entered accurately youll keep getting error invalid signature similar remember add s3listallmybuckets permission key get accessdenied error testing access run s3cmd l list bucket started using s3 bucket owned output empty make bucket s3cmd mb s3mynewbucketname mentioned bucket name must unique amongst user s3 mean simple name like test asdf already taken must make something original demonstrate many feature possible let create fqdnnamed bucket s3publics3toolsorg s3cmd mb s3publics3toolsorg bucket s3publics3toolsorg created list bucket s3cmd l see freshly created bucket s3cmd l 20090128 1234 s3publics3toolsorg list content bucket s3cmd l s3publics3toolsorg empty indeed upload single file bucket s3cmd put somefilexml s3publics3toolsorgsomefilexml somefilexml s3publics3toolsorgsomefilexml 1 1 123456 123456 100 2 5175 kb done upload twodirectory tree bucket virtual directory s3cmd put recursive dir1 dir2 s3publics3toolsorgsomewhere file dir1file11txt stored s3publics3toolsorgsomewheredir1file11txt 1 5 file dir1file12txt stored s3publics3toolsorgsomewheredir1file12txt 2 5 file dir1file13log stored s3publics3toolsorgsomewheredir1file13log 3 5 file dir2file21bin stored s3publics3toolsorgsomewheredir2file21bin 4 5 file dir2file22txt stored s3publics3toolsorgsomewheredir2file22txt 5 5 see didnt create somewhere directory fact filename prefix real directory doesnt created way beforehand instead using put recursive option could also use sync command s3cmd sync dir1 dir2 s3publics3toolsorgsomewhere list bucket content s3cmd l s3publics3toolsorg dir s3publics3toolsorgsomewhere 20090210 0510 123456 s3publics3toolsorgsomefilexml use recursive r list remote file s3cmd l recursive s3publics3toolsorg 20090210 0510 123456 s3publics3toolsorgsomefilexml 20090210 0513 18 s3publics3toolsorgsomewheredir1file11txt 20090210 0513 8 s3publics3toolsorgsomewheredir1file12txt 20090210 0513 16 s3publics3toolsorgsomewheredir1file13log 20090210 0513 11 s3publics3toolsorgsomewheredir2file21bin 20090210 0513 8 s3publics3toolsorgsomewheredir2file22txt retrieve one file back verify hasnt corrupted s3cmd get s3publics3toolsorgsomefilexml somefile2xml s3publics3toolsorgsomefilexml somefile2xml 1 1 123456 123456 100 3 3575 kb done md5sum somefilexml somefile2xml 39bcb6992e461b269b95b3bda303addf somefilexml 39bcb6992e461b269b95b3bda303addf somefile2xml checksum original file match one retrieved one look like worked retrieve whole directory tree s3 use recursive get s3cmd get recursive s3publics3toolsorgsomewhere file s3publics3toolsorgsomewheredir1file11txt saved somewheredir1file11txt file s3publics3toolsorgsomewheredir1file12txt saved somewheredir1file12txt file s3publics3toolsorgsomewheredir1file13log saved somewheredir1file13log file s3publics3toolsorgsomewheredir2file21bin saved somewheredir2file21bin file s3publics3toolsorgsomewheredir2file22txt saved somewheredir2file22txt since destination directory wasnt specified s3cmd saved directory structure current working directory important difference get s3publics3toolsorgsomewhere get s3publics3toolsorgsomewhere note trailing slash s3cmd always us last path part ie word last slash naming file case s3somewhere last path part somewhere therefore recursive get name local file somewheredir1 somewheredir2 etc hand s3somewhere last path part empty s3cmd create dir1 dir2 without somewhere prefix s3cmd get recursive s3publics3toolsorgsomewhere file s3publics3toolsorgsomewheredir1file11txt saved dir1file11txt file s3publics3toolsorgsomewheredir1file12txt saved dir1file12txt file s3publics3toolsorgsomewheredir1file13log saved dir1file13log file s3publics3toolsorgsomewheredir2file21bin saved dir2file21bin see dir1 somewheredir1 wa previous example clean delete remote file remove bucket remove everything s3publics3toolsorgsomewhere s3cmd del recursive s3publics3toolsorgsomewhere file s3publics3toolsorgsomewheredir1file11txt deleted file s3publics3toolsorgsomewheredir1file12txt deleted try remove bucket s3cmd rb s3publics3toolsorg error s3 error 409 bucketnotempty bucket tried delete empty ouch forgot s3publics3toolsorgsomefilexml force bucket removal anyway s3cmd rb force s3publics3toolsorg warning bucket empty removing object first may take time file s3publics3toolsorgsomefilexml deleted bucket s3publics3toolsorg removed hint basic usage simple described previous section increase level verbosity v option youre really keen know program doe bonnet run see debugging output configuring configure available option spitted s3cfg file text file ready modified favourite text editor transfer command put get cp mv sync continue transferring even object fails failure occurs failure output stderr exit status expartial 2 option stoponerror specified config option stoponerror true transfer stop appropriate error code returned information refer s3cmd s3tools homepage license copyright c 20072020 tgrmn software httpwwwtgrmncom contributor program free software redistribute andor modify term gnu general public license published free software foundation either version 2 license option later version program distributed hope useful without warranty without even implied warranty merchantability fitness particular purpose see gnu general public license detail\n",
      "  (0, 24)\t1.0\n",
      "flowcoveragereport flowcoveragereport node command line tool help project using flow type javascript code keep track visualize coverage flow type check generate flow coverage report project install command line tool globally dev dependency project npm install g flowcoveragereport npm install savedev flowcoveragereport run flow reporter configures include glob x exclude pattern threshold configure minimum coverage build fail default 80 report type enabled flowcoveragereport srcjs srcjsx x srctest html json text threshold 90 flow executable path specified using f option flowcoveragereport f pathtoflow customize output dir default flowcoverage use option though default output type text meaning ouputs console use conjunction save desired format flowcoveragereport mycustomflowcoveragedir customize type use option flowcoveragereport html load default option json config file config flag allows specifying path config file config file json file following structure concurrentfiles 1 globexcludepatterns nodemodules flowcommandpath pathtoflowbin globincludepatterns srcjs outputdir pathtooutput projectdir pathtoproject threshold 90 reporttypes text type one text html json default text load default option packagejson npm package default option also configured including flowcoveragereport packagejson property property name mynpmpackage version 101 script flowcoverage flowcoveragereport flowcoveragereport globincludepatterns srclibjs srclibjsx reporttypes text html json background gradual typing system javascript flow help statically check part javascript code supporting syntax annotate code type supporting syntax declare export import new type implicitly explicitly inferencing type identifier used code much possible unfortunately even good amount powerful inferencing strategy sometimes flow able inference type chunk code thats usually source meh moment blame flow able catch issue thought would catch statically fortunately flow ha coverage command give u quantitative info flow type coverage optionally colorbased visualization part source file covered single file generate quantitative info useful visualization uncoverage part source entire project found changelog 080 fix upgraded production dependency 197 c13aca8 unpinned dependency fix 122 updated babel v7 updated parsejson v5 updated react reactdom v16 updated stripjsoncomments v3 updated yargs v16 070 breaking change dropped support nodejs 10 fix npm audit updated mkdirp dependency version 104 remove minimist dependency fix npm audit failure due cve20207598 062 npm audit updated mkdirp dependency version 055 061 fix npm audit changed badgeup npm dependency rplbadgeup forked original currently unmantained package update svgo dependency detected npm audit source moderate security vulnerability 178 see 177 rationale 060 bug fix added support new flow annotation strict strictlocal 150 155 added warning deprecated config name improve cliconfig type check feature added percentdecimals cli option 148 157 161 added excludenonflow cli option 144 154 new release fix issue new flow annotation eg strict strictlocal introduces two new command line option excludenonflow automatically ignore file match pattern flow annotation percentdecimals n include n decimal digit coverage percent value thanks ville saukkonen ben style contributing new excludenonflow percentdeciments option xandor schiefer adding support new flow annotation 050 feature added new badge reporter 140 added new strictcoverage option enforce strict coverage reporting mode 141 new badge reporter implicitly executed html report enabled generates two badge flowbadgesvg badge related flow validation check flowcoveragebadgesvg badge related flow coverage level reached project new strictcoverage option enables strict coverage reporting flow annotated file considered covered non annotated file flow weak annotated one considered fully uncovered thanks runar berg baugsson sigriarson contributing new badge reporter desmond brand matt sprague contributing new strictcoverage option 041 bug fix fixed wrong annotation multiple pragmas line 135 thanks ryan albrecht karolis grinkevicius help bugfix release 040 feature collect report flow preamble annotation type along coverage information thanks ryan albrecht bug fix fixed bug related ignored custom threshold rendered html report thanks boris egorov fixed coverage percent 0 rendered nan report text upgraded flow v0573 fixed new flow error julien wajsberg fix flow coverage escaped special char filename thanks ryan albrecht boris egorov julien wajsberg help new release 030 introduces new command line option submit 1 concurrent file flow using c nummanconcurentfilessubmitted default 1 load option specific config file using config filepath disable config loading using noconfig flowcoveragereport v030 load configuration automatically flowcoveragereport section target project packagejson flowcoveragereportjson file project dir going help reduce number command line option explicitly passed command line version flowcoveragereport npm package also switching mit license feature enhancement html report template thanks jason laster added optional cconcurrentfiles option submit multiple file flow optionally load config packagejson json config file bug fix fixed missing error exit code text reporter fixed link github cli help saved collected coverage data temp json file support larger project thanks ryan albrecht jason laster guillaume claret steven luscher help new release 020 introduces new command line option excluded file pattern using x pattern customize output dir using reportdirpath flowcoveragereport v020 also introduces fix needed able generate flow coverage report larger project project flow issue new command line option fix fixed nan percent react falsepositive mutation warning thanks ilium saulenko feat new cli option customize output dir thanks ryan albrecht fix cleanup old dirs new babel build thanks ryan albrecht fix fixed issue larger project project flow issue thanks ilium saulenko ryan albrecht help hunting issue feat new x cli option exclude file coverage report fix fixed reporttext rendering issue larger number file feat highlight file error coverage data report feat included url generated html report console output thanks jason laster thanks ilium saulenko ryan albrecht jason laster help new release 010 initial prototype release collect report coverage data json text html navigable sourcefile coverage html view based codemirror run unit test travis thanks kumar mcmillan andy mackay advice support project github repo wouldnt exist without\n",
      "  (0, 39)\t0.25271824588352515\n",
      "  (0, 35)\t0.20580903394515399\n",
      "  (0, 33)\t0.26336028916220633\n",
      "  (0, 32)\t0.20226336878884196\n",
      "  (0, 29)\t0.24770049704145458\n",
      "  (0, 25)\t0.26901878412986907\n",
      "  (0, 23)\t0.225111644725797\n",
      "  (0, 22)\t0.2811138972131564\n",
      "  (0, 19)\t0.24770049704145458\n",
      "  (0, 18)\t0.2293327790592781\n",
      "  (0, 16)\t0.2811138972131564\n",
      "  (0, 13)\t0.20580903394515399\n",
      "  (0, 12)\t0.25793281869008644\n",
      "  (0, 10)\t0.2293327790592781\n",
      "  (0, 9)\t0.25793281869008644\n",
      "  (0, 6)\t0.2381997016604516\n",
      "  (0, 4)\t0.20580903394515399\n",
      "activeforks find active github fork project project allows find active fork repository find active fork bookmarklet would like use tool bookmarklet saving following javascript code bookmarklet since github doesnt allow javascript markdown add manually hit ctrld create new bookmark paste javascript url location entry may click see url field time youre github repo click bookmarklet itll bring active fork repo javascriptthingdocumenturlmatchgithubcomazwazwif thingvar newpage httpstechgaungithubioactiveforksindexhtmlthing1opennewpage20targetname2020else20windowalertnot20a20valid20github20page\n",
      "  (0, 37)\t0.5910199723195997\n",
      "  (0, 32)\t0.4730235848421713\n",
      "  (0, 24)\t0.4419041921617725\n",
      "  (0, 4)\t0.48131566092560496\n",
      "redux bug reporter author drew schuster greg mathews demo demo prototype demo video feature easy bug filing user able easily file bug right application redux logging bug filed automatically pass along everything needed recreate bug initial redux state action performed final redux state redaction customizable hook allow redaction sensitive information redux state action payload bug submission easy playback bug global function windowbugreporterplayback available replay bug automatic logging browser error call consoleerror windowonerror filed bug automatically automatic browser info logging bug filed automatically include window dimension window location user agent extensible extra property passed meta redux bug reporter component filed alongside bug submit property either url custom function return promise allow redux bug reporter work development environment integration bug tracker ship integration jira github issue asana taiga google sheet via sheetsu easy write custom integration bug tracker integration documentation installation easiest way use redux bug reporter install npm include build process webpack browserify etc npm install save reduxbugreporter umd build also available link relstylesheet hrefreduxbugreporterdistreduxbugreportermincss script srcreduxbugreporterdistreduxbugreporterminjsscript performance production use redux bug reporter put minimal overhead redux action however doe keep copy initial state final state bug submission full copy action dispatched application heavy action network request large payload frequent action redux bug reporter gradually take memory probably good idea disable production default example demonstrate expected common behavior enabling redux bug reporter nonproduction environment serverside rendering redux bug reporter disables default window undefined negatively impact server side render run production redux bug reporter run production assumed application usually wouldnt want bug reporter displayed page allow public user file bug desired behavior redux bug reporter doe work production usage 1 use redux update configure store function configurestoreinitialstate const store createstorereducer initialstate compose applymiddlewaremiddleware return store becomes es6 import storeenhancer reduxbugreporter es5 var storeenhancer requirereduxbugreporterstoreenhancer function configurestoreinitialstate const store createstorereducer initialstate compose processenvnodeenv production storeenhancer f f applymiddlewaremiddleware return store dont store enhancer middlewares es6 import storeenhancer reduxbugreporter es5 var storeenhancer requirereduxbugreporterstoreenhancer function configurestoreinitialstate const store createstorereducer initialstate processenvnodeenv production storeenhancer f f return store 2 render ui component es6 import reduxbugreporter reduxbugreporter import reduxbugreporterdistreduxbugreportercss es5 var reduxbugreporter requirereduxbugreporterdefault requirereduxbugreporterdistreduxbugreportercss const parentcontainer return div app already wrapped provider reactredux processenvnodeenv production reduxbugreporter submithttplocalhostpathtopostbugto projectnametest div 3 integrate backend service redux bug reporter need able submit bug sort backend redux bug reporter ship integration many common bug tracker see integration doc set one backend service doesnt exist temporary solution try redux bug reporter log bug console instead submitting import submitfn reduxbugreporterlibintegrationsconsole later render reduxbugreporter submitsubmitfn projectnameexample 4 replay filed bug replay filed bug call global bugreporterplayback function appropriate parameter windowbugreporterplaybackactions initialstate state delay delay parameter amount time action playback default value 100 note setting delay value 1 skip playback set redux store state equal final state bug useful situation application maintains critical state outside redux playback doe work prop type property type default description submit function string required string url post bug function function called submit bug note function must return promise projectname string required name project bug filed used scope bug different initiative redactstorestate function optional function receives state return redacted state bug submission warning alter passed state see redacting sensitive data name string optional application know name user used prepopulate submission form meta optional meta exists passed along bug submission customencode function optional function receives state return new encoded state bug submission useful serializing immutable object customdecode function optional function receives state return new decoded state bug playback useful deserializing immutable object redacting sensitive data since redux bug reporter log redux state action could easily sensitive information submitted bug two way redact information submission redacting information store state pas redaction function redactstorestate prop reduxbugreporter component applied initial store state final store state bug submission let redactstorestate function state deep clone state prevent altering actual state let newstate clonedeepstate newstate newstateidentity newstateidentityname newstateidentityname redacted return newstate later render reduxbugreporter submithttplocalhostpathtopostbugto projectnametest redactstorestateredactstorestate redacting information action payload order redact information payload action set actionmetaredactfrombugreporter true boolean exists custom redaction function specified logged action type custom redaction function specified creating actionmetaredactfrombugreporterfn redactfrombugreporterfn exists action deep cloned passed redaction function return sanitized action payload let action type simpleaction sensitivefield secret meta redactfrombugreporter true unrelatedmeta true redacted action type simpleaction meta unrelatedmeta true let action type customredactionaction sensitivefield secret nonsensitivefield foo bar meta redactfrombugreporter true redactfrombugreporterfn function action delete actionsensitivefield return action unrelatedmeta true redacted action type customredactionaction nonsensitivefield foo bar meta unrelatedmeta true working immutablejs similar library file replay bug reduxbugreporter need submit redux state json object receive redux state json object part redux store using library immutable need pas customencode customdecode property reduxbugreporter assume redux state form immutablestate immutableobject normalmutablestate foo true import fromjs immutable const customencode state return immutablestate stateimmutablestatetojson mutablestate statemutablestate const customdecode state return immutablestate fromjsstateimmutablestate mutablestate statemutablestate later rendering redux bug reporter reduxbugreporter submithttplocalhostpathtopostbugto projectnametest customencodecustomencode customdecodecustomdecode contribution fork project make change double check change work adding example confirm test still pas write new test applicable update readme appropriate doc commit create pr license mit\n",
      "  (0, 38)\t0.2529659191798704\n",
      "  (0, 37)\t0.22741352881240087\n",
      "  (0, 35)\t0.18520134352511278\n",
      "  (0, 34)\t0.2529659191798704\n",
      "  (0, 29)\t0.22289820793843623\n",
      "  (0, 26)\t0.23698998265061955\n",
      "  (0, 25)\t0.2420818916414586\n",
      "  (0, 24)\t0.17003654096846388\n",
      "  (0, 23)\t0.20257118090100795\n",
      "  (0, 22)\t0.2529659191798704\n",
      "  (0, 21)\t0.22289820793843623\n",
      "  (0, 20)\t0.2102926859128279\n",
      "  (0, 18)\t0.20636965240041266\n",
      "  (0, 17)\t0.21854711743025879\n",
      "  (0, 14)\t0.2474001806481634\n",
      "  (0, 10)\t0.20636965240041266\n",
      "  (0, 8)\t0.21434872866928112\n",
      "  (0, 5)\t0.21854711743025879\n",
      "  (0, 2)\t0.23698998265061955\n",
      "  (0, 0)\t0.22289820793843623\n",
      "reposupervisor reposupervisor tool help detect secret password code easy install adding new webhook github repository work two separate mode first one allows u scan github pull request second one work command line scan local directory reposupervisor usage prerequisite command line mode github pull request mode supported file security check frequently asked question doe work doesnt find secret add support new file type auth0 create free account auth0 issue reporting author license usage prerequisite start using tool download latest release github release page two bundle available aws lambda deployment well cli mode using cli mode doesnt require additional configuration whereas use pr mode necessary deploy bundle aws lambda first aws lambda deployment using docker image command line mode cli mode allows scanning local directory source code detect secret password file simplest deployment option could become part ci pipeline finding might either returned plaintext json format npm ci npm run build node distclijs testfixturesintegrationdirwithsecrets testfixturesintegrationdirwithsecretsfoobarjs zjd55qmsy6ld53crtqncrg gm5ybhjwros7zjtiyujtbu gxc56b6x67anequgynpswtl mltkbugs8s6tx9ik5zal8aw 2g877batsewopowrjhah9ta testfixturesintegrationdirwithsecretsfoofoojson d7kyociu24p9hjsyvkqzoke q28wt3namlt3ngpqi2qzjq7 jsonoutput1 node distclijs testfixturesintegrationdirwithsecrets resultfilepathtestfixturesintegrationdirwithsecretsfoobarjssecretszjd55qmsy6ld53crtqncrggm5ybhjwros7zjtiyujtbugxc56b6x67anequgynpswtlmltkbugs8s6tx9ik5zal8aw2g877batsewopowrjhah9tafilepathtestfixturesintegrationdirwithsecretsfoofoojsonsecretsd7kyociu24p9hjsyvkqzokeq28wt3namlt3ngpqi2qzjq7 github pull request mode running tool pull request mode requires add new webhook github repository webhook triggered pull request event whenever someone open update close pr therefore scan triggered update pr status either success failure depending finding webhook configuration detail setting value payload url aws lambda url content type applicationjson event type pull request whenever tool find security issue set pr status error add link view report link report url aws lambda deployment additional query parameter idjwt allows generate html report check sample report depending success failure scan set proper pr status error issue detected success issue found false positive wa reported supported file reposupervisor aim decrease number false positive much possible mean doesnt scan file type extension file parsed according format extract string contextaware process requires use language tokenizer currently supported file type json json javascript j yaml yaml plan add new file type future read documentation add new file type learn security check list currently implemented check tool module detail entropy meter find string high entropy detect secret password supported file type frequently asked question doe work cli mode scan directory provided argument get list file return matching supported extension like json j process every supported file tokenizer different one file type iterate extracted string run security check entropy meter calculate entropy value see go defined threshold maxallowedentropy print detected issue either plaintext json format pull request mode receive webhook payload process payload extract modified file iterate file use appropriate tokenizer based file type extract string file run security check string tool detects issue set ci status error link report issue found set ci status success read ci status definition doesnt find secret verify secret want find inside supported file type read supported file section add support new file type support new file type need create new parser file type might require use external tokenizers complex structure like javascript file hand simple file type pretty straightforward wa json file read add new file type auth0 auth0 help add authentication multiple authentication source either social like google facebook microsoft account linkedin github twitter box salesforce amont others enterprise identity system like window azure ad google apps active directory adfs saml identity provider add authentication traditional usernamepassword database add support linking different user account user support generating signed json web token call apis flow user identity securely analytics user logging pull data source add user profile javascript rule create free account auth0 go auth0 click sign use google github microsoft account login issue reporting found bug feature request please report repository issue section please report security vulnerability public github issue tracker responsible disclosure program detail procedure disclosing security issue author auth0 license project licensed mit license see license file info\n",
      "  (0, 39)\t0.1933076245904229\n",
      "  (0, 38)\t0.21502784462455038\n",
      "  (0, 37)\t0.1933076245904229\n",
      "  (0, 36)\t0.1857709361098653\n",
      "  (0, 35)\t0.15742613016364324\n",
      "  (0, 33)\t0.20144786828275393\n",
      "  (0, 32)\t0.15471400264564994\n",
      "  (0, 31)\t0.20577612806918774\n",
      "  (0, 30)\t0.1933076245904229\n",
      "  (0, 29)\t0.18946948023301446\n",
      "  (0, 28)\t0.1933076245904229\n",
      "  (0, 27)\t0.16602551122584833\n",
      "  (0, 22)\t0.21502784462455038\n",
      "  (0, 21)\t0.18946948023301446\n",
      "  (0, 20)\t0.17875444699722695\n",
      "  (0, 18)\t0.17541976284965716\n",
      "  (0, 17)\t0.1857709361098653\n",
      "  (0, 15)\t0.21502784462455038\n",
      "  (0, 13)\t0.15742613016364324\n",
      "  (0, 12)\t0.19729632227612448\n",
      "  (0, 10)\t0.17541976284965716\n",
      "  (0, 9)\t0.19729632227612448\n",
      "  (0, 8)\t0.18220219258466713\n",
      "  (0, 7)\t0.21502784462455038\n",
      "  (0, 6)\t0.18220219258466713\n",
      "  (0, 4)\t0.15742613016364324\n",
      "  (0, 1)\t0.20577612806918774\n",
      "  (0, 0)\t0.18946948023301446\n"
     ]
    }
   ],
   "source": [
    "# Show sentences and vector space representation.\n",
    "# \n",
    "# (A, B) C\n",
    "# A : Document Index\n",
    "# B : Specific word-vector index\n",
    "# C : TF-IDF score\n",
    "for i, v in zip(validate.text_filtered, vector_spaces):\n",
    "    print(i)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_v = tfidf_sparse_matrix_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advancedreactnative companion repo course hosted udemycom\n",
      "  (0, 13862)\t0.30310425529978924\n",
      "  (0, 11202)\t0.30310425529978924\n",
      "  (0, 11197)\t0.1400837492055098\n",
      "  (0, 6468)\t0.34417395212791785\n",
      "  (0, 6467)\t0.34417395212791785\n",
      "  (0, 3211)\t0.34417395212791785\n",
      "  (0, 3208)\t0.23289514483972237\n",
      "  (0, 2629)\t0.273964841667851\n",
      "  (0, 2628)\t0.273964841667851\n",
      "  (0, 622)\t0.34417395212791785\n",
      "  (0, 621)\t0.34417395212791785\n",
      "emotion recognition conversation update date announcement 06102020 new paper sota emotion recognition conversation refer directory cosmic code read paper cosmic commonsense knowledge emotion identification conversation 30092020 new paper baseline utterancelevel dialogue understanding released read paper utterancelevel dialogue understanding empirical study fork code 26072020 new dialoguegcn code ha released please visit httpsgithubcomdeclarelabconvemotiontreemasterdialoguegcnmianzhang credit go mian zhang httpsgithubcommianzhang 11072020 interested reading paper erc related task sarcasm detection conversation compiled comprehensive reading list paper please visit httpsgithubcomdeclarelabawesomeemotionrecognitioninconversations 07062020 new stateoftheart result erc task released soon 07062020 convemotion repo maintained httpsgithubcomdeclarelab 22122019 code dialoguegcn ha released 11102019 new paper conversational transfer learning emotion recognition 09082019 new paper emotion recognition conversation erc 06032019 feature code train dialoguernn meld dataset released 20112018 endtoend version icon dialoguernn released repository contains implementation three conversational emotion detection method namely emotion recognition conversation data format tlerc pytorch dialoguegcn pytorch dialoguernn pytorch dialoguegcnmianzhang pytorch icon tensorflow cmn tensorflow bclstmpytorch pytorch bclstm kera unlike emotion detection model technique consider partystates interparty dependency modeling conversational context relevant emotion recognition primary purpose technique pretrain emotion detection model empathetic dialogue generation fig 1 interaction among different controlling variable dyadic conversation person b grey white circle represent hidden observed variable respectively p represents personality u represents utterance represents interlocutor state represents interlocutor intent e represents emotion topic represents topic conversation easily extended multiparty conversation emotion recognition useful empathetic affective dialogue generation data format network expect emotionsentiment label speaker info utterance present dialogue like party 1 hate girlfriend angry party 2 got girlfriend surprise party 1 yes angry however code adpated perform task preceding utterance available without corresponding label context goal label presenttarget utterance example context party 1 hate girlfriend party 2 got girlfriend target party 1 yes angry target emotion angry moreover code also molded train network endtoend manner soon push useful change present sota result method iemocap dailydialog meld emorynlp wavg f1 macro f1 micro f1 wavg f1 3cls wavg f1 7cls wavg f1 3cls wavg f1 7cls roberta 5455 4820 5516 7212 6202 5528 3729 roberta dialoguernn 6476 4965 5732 7214 6361 5536 3744 roberta cosmic 6528 5105 5848 7320 6521 5651 3811 cosmic commonsense knowledge emotion identification conversation cosmic address task utterance level emotion recognition conversation using commonsense knowledge new framework incorporates different element commonsense mental state event causal relation build upon learn interaction interlocutor participating conversation current stateoftheart method often encounter difficulty context propagation emotion shift detection differentiating related emotion class learning distinct commonsense representation cosmic address challenge achieves new stateoftheart result emotion recognition four different benchmark conversational datasets execution first download roberta comet feature keep appropriate directory cosmicerctraining training evaluation four datasets done follows iemocap python trainiemocappy activelistener dailydialog python traindailydialogpy activelistener classweight residual meld emotion python trainmeldpy activelistener classweight residual meld sentiment python trainmeldpy activelistener classweight residual classify sentiment emorynlp emotion python trainemorynlppy activelistener classweight residual emorynlp sentiment python trainemorynlppy activelistener classweight residual classify sentiment citation please cite following paper find code useful work cosmic commonsense knowledge emotion identification conversation ghosal n majumder gelbukh r mihalcea poria finding emnlp 2020 tlerc emotion recognition conversation transfer learning generative conversation modeling tlerc transfer learningbased framework erc pretrains generative dialogue model transfer contextlevel weight include affective knowledge target discriminative model erc setting setup environment conda conda env create f environmentyml conda activate tlerc cd tlerc python setuppy download dataset file iemocap dailydialog store datasets download pretrained weight hred cornell ubuntu datasets store generativeweights optional train new generative weight dialogue model refer httpsgithubcomctr4siahierarchicallatentstructureforvariationalconversationmodeling run erc classifier pretrained weight cd bertmodel python trainpy loadcheckpointgenerativeweightscornellweightspkl dataiemocap change cornell ubuntu iemocap dailydialog dataset combination drop loadcheckpoint avoid initializing contextual weight modify hyperparameters check configspy optional create erc dataset split set glove path preprocessing file python iemocappreprocesspy similarly dailydialog citation please cite following paper find code useful work conversational transfer learning emotion recognition hazarika poria zimmermann r mihalcea r 2020 information fusion dialoguegcn graph convolutional neural network emotion recognition conversation dialoguegcn dialogue graph convolutional network graph neural network based approach erc leverage self interspeaker dependency interlocutor model conversational context emotion recognition graph network dialoguegcn address context propagation issue present current rnnbased method dialoguegcn naturally suited multiparty dialogue requirement python 3 pytorch 10 pytorch geometric 13 panda 023 scikitlearn 020 tensorflow optional required tensorboard tensorboardx optional required tensorboard execution note pytorch geometric make heavy usage cuda atomic operation source nondeterminism reproduce result reported paper recommend use following execution command note script execute cpu obatined weighted average f1 score 6467 machine 6444 google colaboratory iemocap dataset following command iemocap dataset python trainiemocappy basemodel lstm graphmodel nodalattention dropout 04 lr 00003 batchsize 32 classweight l2 00 nocuda citation please cite following paper find code useful work dialoguegcn graph convolutional neural network emotion recognition conversation ghosal n majumder poria n chhaya gelbukh emnlpijcnlp 2019 hong kong china dialoguegcnmianzhang dialoguegcn implementation mian zhang pytorch implementation paper dialoguegcn graph convolutional neural network emotion recognition conversation running run whole process easily take iemocap corpus example step 1 preprocess scriptsiemocapsh preprocess step 2 train scriptsiemocapsh train requirement python 3 pytorch 10 pytorch geometric 143 panda 023 scikitlearn 020 performance comparision dataset weighted f1 original iemocap 6418 implementation iemocap 6410 credit mian zhang github mianzhang citation please cite following paper find code useful work dialoguegcn graph convolutional neural network emotion recognition conversation ghosal n majumder poria n chhaya gelbukh emnlpijcnlp 2019 hong kong china dialoguernn attentive rnn emotion detection conversation dialoguernn basically customized recurrent neural network rnn profile speaker conversationdialogue fly model context conversation time model easily extended multiparty scenario also used pretraining model empathetic dialogue generation note default setting hyperparameters commandline argument code meant bidialoguernnatt user need optimize setting variant change requirement python 3 pytorch 10 panda 023 scikitlearn 020 tensorflow optional required tensorboard tensorboardx optional required tensorboard dataset feature please extract content dialoguernnfeatureszip execution iemocap dataset python trainiemocappy commandline argument avec dataset python trainavecpy commandline argument commandline argument nocuda doe use gpu lr learning rate l2 l2 regularization weight recdropout recurrent dropout dropout dropout batchsize batch size epoch number epoch classweight class weight applicable avec activelistener explicit lisnener mode attention attention type tensorboard enables tensorboard log attribute attribute 1 4 avec 1 valence 2 activationarousal 3 anticipationexpectation 4 power citation please cite following paper find code useful work dialoguernn attentive rnn emotion detection conversation n majumder poria hazarika r mihalcea e cambria g alexander aaai 2019 honolulu hawaii usa icon interactive conversational memory network icon multimodal emotion detection framework extract multimodal feature conversational video hierarchically model textitself textitinterspeaker emotional influence global memory memory generate contextual summary aid predicting emotional orientation utterancevideos requirement python 365 pandas0233 tensorflow190 numpy1150 scikitlearn0200 execution cd icon unzip data follows download feature iemocap using link unzip folder place location iconiemocapdata sample command achieve unzip pathtozipfile iemocap train icon model python trainiemocappy iemocap citation icon interactive conversational memory networkfor multimodal emotion detection hazarika poria r mihalcea e cambria r zimmermann emnlp 2018 brussels belgium cmn cmn neural framework emotion detection dyadic conversation leverage mutlimodal signal text audio visual modality specifically incorporates speakerspecific dependency architecture context modeling summary generated context using multihop memory network requirement python 365 pandas0233 tensorflow190 numpy1150 scikitlearn0200 execution cd cmn unzip data follows download feature iemocap using link unzip folder place location cmniemocapdata sample command achieve unzip pathtozipfile iemocap train icon model python trainiemocappy iemocap citation please cite following paper find code useful work hazarika poria zadeh cambria e morency lp zimmermann r 2018 conversational memory network emotion recognition dyadic dialogue video proceeding 2018 conference north american chapter association computational linguistics human language technology volume 1 long paper vol 1 pp 21222132 bclstmpytorch bclstmpytorch network using context detection emotion utterance dialogue model simple efficient us lstm model temporal relation among utterance repo gave data semeval 2019 task 3 used provided data released semeval 2019 task 3 emotion recognition context organizer task 3 utterance provided utterance1 user1 utterance2 user2 utterance3 user1 consecutively task predict emotion label utterance3 emotion label utterance provided however data contains emotion label utterance still use code adapt accordingly hence code still aplicable datasets like mosi mosei iemocap avec dailydialogue etc bclstm doe make use speaker information like cmn icon dialoguernn requirement python 365 pandas0233 pytorch 10 numpy1150 scikitlearn0200 execution cd bclstmpytorch train bclstm model python trainiemocappy iemocap citation please cite following paper find code useful work poria cambria e hazarika majumder n zadeh morency lp 2017 contextdependent sentiment analysis usergenerated video proceeding 55th annual meeting association computational linguistics volume 1 long paper vol 1 pp 873883 bclstm kera implementation bclstm requirement python 365 pandas0233 tensorflow190 numpy1150 scikitlearn0200 keras21 execution cd bclstm train bclstm model python baselinepy config testbaselineconfig iemocap citation please cite following paper find code useful work poria cambria e hazarika majumder n zadeh morency lp 2017 contextdependent sentiment analysis usergenerated video proceeding 55th annual meeting association computational linguistics volume 1 long paper vol 1 pp 873883\n",
      "  (0, 15542)\t0.02623295365927626\n",
      "  (0, 15541)\t0.02623295365927626\n",
      "  (0, 15540)\t0.02623295365927626\n",
      "  (0, 15539)\t0.02623295365927626\n",
      "  (0, 15536)\t0.02623295365927626\n",
      "  (0, 15535)\t0.02623295365927626\n",
      "  (0, 15534)\t0.02623295365927626\n",
      "  (0, 15532)\t0.023102619573760114\n",
      "  (0, 15528)\t0.02623295365927626\n",
      "  (0, 15527)\t0.02623295365927626\n",
      "  (0, 15526)\t0.02623295365927626\n",
      "  (0, 15298)\t0.02623295365927626\n",
      "  (0, 15297)\t0.02088161219438408\n",
      "  (0, 15141)\t0.02623295365927626\n",
      "  (0, 15127)\t0.02623295365927626\n",
      "  (0, 15121)\t0.02623295365927626\n",
      "  (0, 15120)\t0.02623295365927626\n",
      "  (0, 15117)\t0.02623295365927626\n",
      "  (0, 15115)\t0.02623295365927626\n",
      "  (0, 15109)\t0.012399936643975758\n",
      "  (0, 15044)\t0.02623295365927626\n",
      "  (0, 15043)\t0.023102619573760114\n",
      "  (0, 15023)\t0.02623295365927626\n",
      "  (0, 15022)\t0.02623295365927626\n",
      "  (0, 15021)\t0.02623295365927626\n",
      "  :\t:\n",
      "  (0, 66)\t0.02623295365927626\n",
      "  (0, 36)\t0.02623295365927626\n",
      "  (0, 35)\t0.02623295365927626\n",
      "  (0, 34)\t0.02623295365927626\n",
      "  (0, 29)\t0.019158865031499595\n",
      "  (0, 28)\t0.02623295365927626\n",
      "  (0, 27)\t0.02623295365927626\n",
      "  (0, 26)\t0.02623295365927626\n",
      "  (0, 25)\t0.02623295365927626\n",
      "  (0, 24)\t0.02623295365927626\n",
      "  (0, 23)\t0.02623295365927626\n",
      "  (0, 22)\t0.02623295365927626\n",
      "  (0, 21)\t0.02623295365927626\n",
      "  (0, 20)\t0.02623295365927626\n",
      "  (0, 19)\t0.02623295365927626\n",
      "  (0, 18)\t0.02623295365927626\n",
      "  (0, 14)\t0.02623295365927626\n",
      "  (0, 13)\t0.02623295365927626\n",
      "  (0, 12)\t0.02623295365927626\n",
      "  (0, 11)\t0.02623295365927626\n",
      "  (0, 10)\t0.02623295365927626\n",
      "  (0, 3)\t0.02623295365927626\n",
      "  (0, 2)\t0.02623295365927626\n",
      "  (0, 1)\t0.02623295365927626\n",
      "  (0, 0)\t0.02623295365927626\n",
      "openworm openworm aim build first comprehensive computational model caenorhabditis elegans c elegans microscopic roundworm thousand cell solves basic problem feeding matefinding predator avoidance despite extremely wellstudied biology deep principled understanding biology organism remains elusive using bottomup approach aimed observing worm behaviour emerge simulation data derived scientific experiment carried past decade incorporating data available scientific community software model also forging new collaboration university research institute collect data fill gap earn badge u simply trying package click image get started quickstart put together docker container pull together major component simulation run machine get running doe following run nervous system model known c302 computer parallel run 3d worm body model known sibernetic computer using output nervous system model produce graph nervous system body model demonstrate behavior computer inspect produce movie showing output body model example output note running simulation full amount time would produce content like however order run reasonable amount time default run time simulation limited see partial output equivalent 5 run time compared example extend run time use argument described installation prerequisite least 60 gb free space machine least 2gb ram able clone git repository machine install git gui may useful install install docker system system doe enough free space use external hard disk macos x location image storage specified advanced tab preference see thread addition linux instruction running ensure docker daemon running background macoswindows icon docker whale logo showing menu barsystem tray open terminal run git clone httpgithubcomopenwormopenworm cd openworm optional run buildsh buildcmd window skip step download latest released docker image openworm docker hub run runsh runcmd window 510 minute output display screen step run simulation end run stopsh stopcmd window system clean running container inspect output output directory local machine advanced argument num use modify duration simulation millisecond default 15 use 5000 run time make full movie ie 5 second thing try open terminal run runshellonlysh runshellonlycmd window let log container ha run masteropenwormpy inspect internals various checked code base installed system modify thing afterwards youll still need run stopsh clean wish modify get installed modify dockerfile want modify run modify masteropenwormpy either way need run buildsh order rebuild image locally afterwards run normally faq docker container docker container selfcontained environment run openworm simulation fully set get started following step moment run simulation produce visualization visualization must viewed outside docker container need know much docker use openworm planning working extensively platform may benefit understanding basic docker curriculum excellent tutorial beginner straightforward work section 1 25 plenty sufficient possible modify simulation without run buildsh yes marginally complex easiest way modify anything docker container inside work like bash shell want modify code container youll need use editor run terminal like nano youve modified something container dont need rebuild however run stopsh exit change gone access data already output simulation default output figure movie home system outside docker container want access entire output simulation need copy docker container example say want extract worm motion data contained file wormmotionlogtxt found homeowsiberneticsimulationsspecifictimestampeddirectorywormmotionlogtxt directory specifictimestampeddirectory name like c2fw20180212183632 name found checking output directory actually main output directory simulation contains output including cell modelling worm movement simulation end exit container exit run stopsh run following command openwormdockermaster folder docker cp openwormhomeowsiberneticsimulationsspecifictimestampeddirectorywormmotionlogtxt wormmotionlogtxt copy file docker container whose default name openworm crucial run stopsh trying get data see difference exit stopsh docker container openworm done interacting type exit return system shell stop execution anything container container status exited try restart process using runshellonlysh get error saying container already exists choose point run stopsh remove container file associated allowing run new simulation however dont want remove container instead want reenter enter container exited run stopsh youll delete data reset container new run however dont want reenter docker container like docker start openworm restarts container docker exec openworm binbash run bash inside container tell docker start container execute command exec interactive tty bash bash shell container openworm youll able interact container documentation find openworm documentation available httpdocsopenwormorg join u slack repository reference projectwide tracking via highlevel issue milestone\n",
      "  (0, 15511)\t0.03628971319288141\n",
      "  (0, 15503)\t0.026503676487393567\n",
      "  (0, 15310)\t0.028886862203227785\n",
      "  (0, 15309)\t0.03628971319288141\n",
      "  (0, 15308)\t0.028886862203227785\n",
      "  (0, 15307)\t0.024556471975853908\n",
      "  (0, 15300)\t0.03628971319288141\n",
      "  (0, 15297)\t0.028886862203227785\n",
      "  (0, 15179)\t0.03628971319288141\n",
      "  (0, 15178)\t0.03628971319288141\n",
      "  (0, 15177)\t0.03628971319288141\n",
      "  (0, 15176)\t0.03628971319288141\n",
      "  (0, 15175)\t0.03628971319288141\n",
      "  (0, 15174)\t0.03628971319288141\n",
      "  (0, 15173)\t0.03628971319288141\n",
      "  (0, 15172)\t0.03628971319288141\n",
      "  (0, 15164)\t0.03628971319288141\n",
      "  (0, 15160)\t0.024556471975853908\n",
      "  (0, 15145)\t0.03628971319288141\n",
      "  (0, 15132)\t0.03628971319288141\n",
      "  (0, 15109)\t0.017153620986200283\n",
      "  (0, 15095)\t0.03628971319288141\n",
      "  (0, 15094)\t0.026503676487393567\n",
      "  (0, 15084)\t0.03628971319288141\n",
      "  (0, 15079)\t0.03628971319288141\n",
      "  :\t:\n",
      "  (0, 617)\t0.03195932296550754\n",
      "  (0, 564)\t0.03628971319288141\n",
      "  (0, 563)\t0.03628971319288141\n",
      "  (0, 513)\t0.03628971319288141\n",
      "  (0, 511)\t0.028886862203227785\n",
      "  (0, 449)\t0.03628971319288141\n",
      "  (0, 447)\t0.03628971319288141\n",
      "  (0, 444)\t0.026503676487393567\n",
      "  (0, 406)\t0.03628971319288141\n",
      "  (0, 403)\t0.03628971319288141\n",
      "  (0, 400)\t0.026503676487393567\n",
      "  (0, 319)\t0.03628971319288141\n",
      "  (0, 318)\t0.03628971319288141\n",
      "  (0, 284)\t0.03628971319288141\n",
      "  (0, 283)\t0.03628971319288141\n",
      "  (0, 277)\t0.03628971319288141\n",
      "  (0, 276)\t0.03628971319288141\n",
      "  (0, 238)\t0.03628971319288141\n",
      "  (0, 237)\t0.03628971319288141\n",
      "  (0, 206)\t0.03628971319288141\n",
      "  (0, 205)\t0.03628971319288141\n",
      "  (0, 192)\t0.03628971319288141\n",
      "  (0, 190)\t0.03195932296550754\n",
      "  (0, 97)\t0.03628971319288141\n",
      "  (0, 96)\t0.03628971319288141\n",
      "fullstackreactcode companion repo course udemycom see httpswwwudemycomnodewithreactfullstackwebdevelopment\n",
      "  (0, 13863)\t0.34417395212791785\n",
      "  (0, 13862)\t0.30310425529978924\n",
      "  (0, 11202)\t0.30310425529978924\n",
      "  (0, 11197)\t0.1400837492055098\n",
      "  (0, 6594)\t0.34417395212791785\n",
      "  (0, 5876)\t0.34417395212791785\n",
      "  (0, 5875)\t0.34417395212791785\n",
      "  (0, 3216)\t0.34417395212791785\n",
      "  (0, 3208)\t0.23289514483972237\n",
      "  (0, 2629)\t0.273964841667851\n",
      "  (0, 2628)\t0.273964841667851\n",
      "meilix beautiful customizable linux build box feature internet kiosk use meilix generator web app make linux brandevent also add apps feature need preinstalled create iso image linux use live boot install pc meilix heavy development alpha stage yet recommended productive use index introduction feature architecture ecosystem usage pre requisite development file structure build metapackages testing contribution community guideline branch best practice resource gallery license introduction project serf solution wish preconfigured custom linux needed appsfeatures already installed example use case event every event organizer need system configured equally need specific apps run event configuring system one one time taking difficult task using meilix create custom linux iso runlive boot many system want save countless hour also make process costefficient feature meilix light weight beautiful fast linux feature ubuntudebian distro custom meilix build commissioned meilixgenerator web app architecture meilix based ubuntudebian architecture meilix us lxqt standard desktop environment ecosystem following projectsdependency part meilix ecosystem name meilix repo standalone build backend webapp meilixgenerator webapp generates iso image meilix linux meilixsystemlock program freeze system meilixartwork boot screen splash theme meilix usage create linux event kiosk trying use meilixgenerator web app ha option customize generate iso pre requisite prerequisite develop meilix exposure terminal basic command basic comprehension shell script experience working debian system lpic1 huge plus development meilix fetch ubuntu source customizes add feature build distro us shell script perform task build made local machine via travis ci file structure basic understanding file structure required development level 2 file structure project buildsh licensemd sourcesxeniallist sourcesbioniclist readmemd systemlock011alldeb imageamd64tarlzma imagei386tarlzma ubiquityslideshow slide polkit1 action conf distribution pool main systemlock01 debian etc makefile usr meilixdefaultsettings debian etc makefile usr script aptrepoupdatersh archsh browserurish chrootsh debuildsh legacyinitrdextsh mailfailpy mailpy meilixchecksh mewsh package releasesmaintainersh chroot bin boot dev etc home lib lib64 medium mnt opt proc root run sbin srv sys tmp usr var build building locally make build script executable chmod x buildsh execute script buildsh testing isos local installation qemukvm run live cd virtualbox oracle build using travis update travisyml according api key explained push change repo start build process contribution code contribution always appreciated keep experience good suggest read guideline thoroughly also take time understand workflow project contribution expected follow best practice community guideline following thing contribute meilix report bug think encountered bug know feel free report community take care request feature also request feature community feel viable picked development create pull request cant get better pull request really appreciated community get started picking open issue make pull request community meilix ha contributor around world constantly improving meilix helping others well get touch community use following communication channel gitter httpsgitterimfossasiameilix mailing list httpsgroupsgooglecomforumforummeilix scrum mail meilixgooglegroupscom twitter httpstwittercommeilix guideline fossasia open source guideline found branch meilix us agile continuous integration methodology version frequently updated development really fast master development branch always built generator legacy branch keep reference time chrooted master branch iso release made change requested meilixgenerator app repackaged customized iso branch created main repository step create pull request make pr master branch comply best practice guideline eg pr concern visual element image showing effect must pas continuous integration check get positive review change merged best practice commits commit proper documentation comment code make easy others understand make sure commit message crisp clear read refering issue pull request use special word automatically close related issue like fix 234 keep pr limited scope make easy review correct squash commits resource lubuntu linux operating system lxdelxqt meilix blog andre talk tarun talk license project currently licensed gnu lesser general public license v30 lgpl30 copy licensemd present along source code obtain software different license please contact fossasia\n",
      "  (0, 15169)\t0.036485240081208986\n",
      "  (0, 15168)\t0.03213151796025132\n",
      "  (0, 15163)\t0.036485240081208986\n",
      "  (0, 15160)\t0.024688780835067592\n",
      "  (0, 15159)\t0.036485240081208986\n",
      "  (0, 15158)\t0.036485240081208986\n",
      "  (0, 15108)\t0.036485240081208986\n",
      "  (0, 15107)\t0.036485240081208986\n",
      "  (0, 15096)\t0.036485240081208986\n",
      "  (0, 15094)\t0.026646476772567415\n",
      "  (0, 15014)\t0.036485240081208986\n",
      "  (0, 15012)\t0.03213151796025132\n",
      "  (0, 14956)\t0.036485240081208986\n",
      "  (0, 14955)\t0.036485240081208986\n",
      "  (0, 14954)\t0.036485240081208986\n",
      "  (0, 14944)\t0.03213151796025132\n",
      "  (0, 14943)\t0.02159976583084153\n",
      "  (0, 14891)\t0.036485240081208986\n",
      "  (0, 14862)\t0.01724604370988387\n",
      "  (0, 14804)\t0.036485240081208986\n",
      "  (0, 14799)\t0.024688780835067592\n",
      "  (0, 14786)\t0.036485240081208986\n",
      "  (0, 14785)\t0.036485240081208986\n",
      "  (0, 14620)\t0.036485240081208986\n",
      "  (0, 14619)\t0.036485240081208986\n",
      "  :\t:\n",
      "  (0, 884)\t0.036485240081208986\n",
      "  (0, 883)\t0.036485240081208986\n",
      "  (0, 882)\t0.036485240081208986\n",
      "  (0, 821)\t0.036485240081208986\n",
      "  (0, 817)\t0.036485240081208986\n",
      "  (0, 815)\t0.036485240081208986\n",
      "  (0, 812)\t0.036485240081208986\n",
      "  (0, 811)\t0.02159976583084153\n",
      "  (0, 801)\t0.036485240081208986\n",
      "  (0, 797)\t0.026646476772567415\n",
      "  (0, 761)\t0.036485240081208986\n",
      "  (0, 760)\t0.036485240081208986\n",
      "  (0, 725)\t0.036485240081208986\n",
      "  (0, 724)\t0.036485240081208986\n",
      "  (0, 654)\t0.036485240081208986\n",
      "  (0, 653)\t0.03213151796025132\n",
      "  (0, 535)\t0.036485240081208986\n",
      "  (0, 524)\t0.036485240081208986\n",
      "  (0, 522)\t0.020335058714109934\n",
      "  (0, 489)\t0.036485240081208986\n",
      "  (0, 488)\t0.026646476772567415\n",
      "  (0, 457)\t0.036485240081208986\n",
      "  (0, 456)\t0.029042502956025257\n",
      "  (0, 187)\t0.036485240081208986\n",
      "  (0, 186)\t0.036485240081208986\n",
      "introduction reposado set tool written python replicate key functionality mac x server software update service license reposado licensed new bsd license discussion group discussion user developer reposado feature capability reposado together python curl binary tool web server apache 2 enables host local apple software update server hardware choice reposado contains tool reposync download software update catalog optionally update package apple server enabling host local web server additionally reposado provides commandline tool repoutil enables create arbitrary number branch apple catalog branch contain subset available update example one could create testing release branch set client use testing branch catalog test newlyreleased update would set client use release branch catalog would contain update testing process configure reposado also download actual update well catalog continue offer update superseded recent update example currently offering 1067 update client apple release 1068 update continue offer deprecated 1067 update ready release newer update client even offer 1067 update release client offering 1068 update testing client offering deprecated apple software update feature difficult apple tool limitation dependency apple software update service doe thing primarily replicates software update apple server downloading local machine secondly function web server actually serve update client machine reposado doe duplicate web server portion apple software update service instead may use existing web server wish reposado also currently relies commandline curl binary download update apple server curl available x redhat linux many os including win32 win64 version see httpcurlhaxxse information info information basic documentation available httpsgithubcomwdasreposadotreemasterdocs\n",
      "  (0, 15237)\t0.06258806888345411\n",
      "  (0, 15234)\t0.04982053486598289\n",
      "  (0, 15097)\t0.06258806888345411\n",
      "  (0, 15094)\t0.04571030696332879\n",
      "  (0, 15067)\t0.06258806888345411\n",
      "  (0, 15066)\t0.06258806888345411\n",
      "  (0, 15065)\t0.06258806888345411\n",
      "  (0, 15064)\t0.06258806888345411\n",
      "  (0, 14950)\t0.06258806888345411\n",
      "  (0, 14943)\t0.037053000848511666\n",
      "  (0, 14592)\t0.06258806888345411\n",
      "  (0, 14566)\t0.031187192028858106\n",
      "  (0, 14327)\t0.05511954025655171\n",
      "  (0, 14321)\t0.0395126034344396\n",
      "  (0, 14253)\t0.06258806888345411\n",
      "  (0, 14237)\t0.06258806888345411\n",
      "  (0, 14185)\t0.06258806888345411\n",
      "  (0, 14149)\t0.025474244318955164\n",
      "  (0, 14028)\t0.06258806888345411\n",
      "  (0, 14027)\t0.06258806888345411\n",
      "  (0, 14025)\t0.06258806888345411\n",
      "  (0, 14024)\t0.06258806888345411\n",
      "  (0, 14023)\t0.06258806888345411\n",
      "  (0, 14022)\t0.06258806888345411\n",
      "  (0, 14021)\t0.06258806888345411\n",
      "  :\t:\n",
      "  (0, 1360)\t0.034883477612178096\n",
      "  (0, 1173)\t0.06258806888345411\n",
      "  (0, 1162)\t0.06258806888345411\n",
      "  (0, 1148)\t0.06258806888345411\n",
      "  (0, 1132)\t0.03294277294585756\n",
      "  (0, 912)\t0.06258806888345411\n",
      "  (0, 909)\t0.04982053486598289\n",
      "  (0, 849)\t0.06258806888345411\n",
      "  (0, 848)\t0.06258806888345411\n",
      "  (0, 847)\t0.06258806888345411\n",
      "  (0, 846)\t0.06258806888345411\n",
      "  (0, 845)\t0.06258806888345411\n",
      "  (0, 844)\t0.05511954025655171\n",
      "  (0, 794)\t0.06258806888345411\n",
      "  (0, 792)\t0.05511954025655171\n",
      "  (0, 574)\t0.06258806888345411\n",
      "  (0, 573)\t0.06258806888345411\n",
      "  (0, 516)\t0.06258806888345411\n",
      "  (0, 511)\t0.04982053486598289\n",
      "  (0, 509)\t0.06258806888345411\n",
      "  (0, 505)\t0.05511954025655171\n",
      "  (0, 56)\t0.06258806888345411\n",
      "  (0, 55)\t0.06258806888345411\n",
      "  (0, 54)\t0.06258806888345411\n",
      "  (0, 53)\t0.06258806888345411\n",
      "toolingreport quick way determine best build tool next web project tooling migration worth adopt tool best practice existing configuration code base get set npm install dev npm run dev start build watch mode start http server build production npm run build project shape lib various script plugins build staticbuild script run end build process generates html client clientside j go doesnt need go keep separate static generation j test markdown test result see test structure test directory contains indexmd describes test test category must include title frontmatter result tool folder rollup webpack parcel browserify optional folder contains indexmd describing particular build tool performs result present directory considered category result file requires result frontmatter must pas fail partial folder also contains minimal project respective tool showing pas current test build artifact placed folder called build folder globally ignored test ha subtests folder must named subtests contain structure special import client bundle import bundleurl import clientbundleclienthomeindexts clientbundle followed path script bundle minify script entry point two entry point share module itll codesplit bundleurl url bundled script import url script imported script eg preloading style import used staticbuild cs module import tabbutton promo feature stylescss import ending cs assumed cs module export derived classnames cs cs contains tabbutton tabbutton one export cs bundle import cssurl inline cssbundlestylescss cs support cs module sassstyle nesting import inlined output minified cssurl url cs resource inline text cs markdown import html meta mdwhatevermd md followed path markdown give following html markdown html meta metadata markdown front matter asset import asseturl asseturlfoopng asseturl followed path file add file build asseturl url asset constant import isproduction constsisproduction want add constant value add object passed constsplugin rollupconfigjs youll also need add entry missingtypesdts test data import test testdata return object representation everything test directory see staticbuildmissingtypesdts structure object\n",
      "  (0, 15310)\t0.0414957413652868\n",
      "  (0, 15307)\t0.03527517121053344\n",
      "  (0, 15192)\t0.05212987628348154\n",
      "  (0, 15191)\t0.05212987628348154\n",
      "  (0, 14973)\t0.05212987628348154\n",
      "  (0, 14970)\t0.0414957413652868\n",
      "  (0, 14949)\t0.05212987628348154\n",
      "  (0, 14943)\t0.03086160644709206\n",
      "  (0, 14930)\t0.05212987628348154\n",
      "  (0, 14925)\t0.03086160644709206\n",
      "  (0, 14916)\t0.05212987628348154\n",
      "  (0, 14915)\t0.05212987628348154\n",
      "  (0, 14864)\t0.04590930612872818\n",
      "  (0, 14862)\t0.0246410362923387\n",
      "  (0, 14540)\t0.05212987628348154\n",
      "  (0, 14536)\t0.038072314570297194\n",
      "  (0, 14503)\t0.05212987628348154\n",
      "  (0, 14502)\t0.04590930612872818\n",
      "  (0, 14301)\t0.05212987628348154\n",
      "  (0, 14278)\t0.03086160644709206\n",
      "  (0, 14117)\t0.05212987628348154\n",
      "  (0, 14088)\t0.05212987628348154\n",
      "  (0, 14084)\t0.05212987628348154\n",
      "  (0, 14082)\t0.05212987628348154\n",
      "  (0, 14081)\t0.03086160644709206\n",
      "  :\t:\n",
      "  (0, 1485)\t0.04590930612872818\n",
      "  (0, 1475)\t0.05212987628348154\n",
      "  (0, 1470)\t0.038072314570297194\n",
      "  (0, 1334)\t0.05212987628348154\n",
      "  (0, 1332)\t0.04590930612872818\n",
      "  (0, 1026)\t0.05212987628348154\n",
      "  (0, 1025)\t0.05212987628348154\n",
      "  (0, 1013)\t0.05212987628348154\n",
      "  (0, 1012)\t0.05212987628348154\n",
      "  (0, 1011)\t0.05212987628348154\n",
      "  (0, 1010)\t0.05212987628348154\n",
      "  (0, 1009)\t0.05212987628348154\n",
      "  (0, 1008)\t0.05212987628348154\n",
      "  (0, 1007)\t0.05212987628348154\n",
      "  (0, 1006)\t0.05212987628348154\n",
      "  (0, 1005)\t0.05212987628348154\n",
      "  (0, 981)\t0.05212987628348154\n",
      "  (0, 979)\t0.04590930612872818\n",
      "  (0, 607)\t0.05212987628348154\n",
      "  (0, 606)\t0.05212987628348154\n",
      "  (0, 543)\t0.05212987628348154\n",
      "  (0, 536)\t0.04590930612872818\n",
      "  (0, 534)\t0.05212987628348154\n",
      "  (0, 530)\t0.05212987628348154\n",
      "  (0, 522)\t0.029054601055780078\n",
      "visual studio documentation welcome repo contains source file visual studio technical documentation topic published docsmicrosoftcom repo wa moved june 23 2017 httpsgithubcommicrosoftvsdocs documentation visual basic visual c located dotnet doc repo visual c documentation located c doc repo contribute documentation welcome contribution help u improve visual studio doc article repository use githubflavored markdown several feature area visual studio folder repo debugger topic debugging ide topic visual studio interactive development environment ide forth medium subfolder folder contains art file topic information contributing see contributing guide microsoft open source code conduct project ha adopted microsoft open source code conduct information see code conduct faq contact opencodemicrosoftcom question comment\n",
      "  (0, 15030)\t0.0908741517484741\n",
      "  (0, 15028)\t0.08003029259310124\n",
      "  (0, 15026)\t0.07233645208053935\n",
      "  (0, 14848)\t0.0908741517484741\n",
      "  (0, 14843)\t0.06636864574284702\n",
      "  (0, 14807)\t0.0908741517484741\n",
      "  (0, 14805)\t0.0908741517484741\n",
      "  (0, 14803)\t0.0908741517484741\n",
      "  (0, 14801)\t0.0908741517484741\n",
      "  (0, 14799)\t0.06149259292516647\n",
      "  (0, 14197)\t0.0908741517484741\n",
      "  (0, 14149)\t0.03698708691953939\n",
      "  (0, 13634)\t0.0908741517484741\n",
      "  (0, 13632)\t0.0908741517484741\n",
      "  (0, 13631)\t0.0908741517484741\n",
      "  (0, 13630)\t0.0908741517484741\n",
      "  (0, 13628)\t0.08003029259310124\n",
      "  (0, 13239)\t0.08003029259310124\n",
      "  (0, 13238)\t0.08003029259310124\n",
      "  (0, 12904)\t0.0908741517484741\n",
      "  (0, 12903)\t0.0908741517484741\n",
      "  (0, 12880)\t0.0908741517484741\n",
      "  (0, 12879)\t0.0908741517484741\n",
      "  (0, 12878)\t0.0908741517484741\n",
      "  (0, 12877)\t0.0908741517484741\n",
      "  :\t:\n",
      "  (0, 2922)\t0.0908741517484741\n",
      "  (0, 2920)\t0.05379875241260458\n",
      "  (0, 2860)\t0.0908741517484741\n",
      "  (0, 2858)\t0.06636864574284702\n",
      "  (0, 2729)\t0.0908741517484741\n",
      "  (0, 2728)\t0.0908741517484741\n",
      "  (0, 2727)\t0.0908741517484741\n",
      "  (0, 2726)\t0.0908741517484741\n",
      "  (0, 2575)\t0.06636864574284702\n",
      "  (0, 2423)\t0.0908741517484741\n",
      "  (0, 2413)\t0.03698708691953939\n",
      "  (0, 1375)\t0.0908741517484741\n",
      "  (0, 1360)\t0.05064873376979361\n",
      "  (0, 978)\t0.0908741517484741\n",
      "  (0, 975)\t0.08003029259310124\n",
      "  (0, 974)\t0.0908741517484741\n",
      "  (0, 972)\t0.08003029259310124\n",
      "  (0, 938)\t0.0908741517484741\n",
      "  (0, 936)\t0.08003029259310124\n",
      "  (0, 609)\t0.0908741517484741\n",
      "  (0, 608)\t0.0908741517484741\n",
      "  (0, 185)\t0.0908741517484741\n",
      "  (0, 184)\t0.0908741517484741\n",
      "  (0, 154)\t0.0908741517484741\n",
      "  (0, 152)\t0.08003029259310124\n",
      "repo maintains list repository defining ro distribution implementation rep 143 also home rosdep rule guide contributing please see contributingmd review guideline please see review guideline look criterion get pull request merged repository\n",
      "  (0, 11685)\t0.1620189287072458\n",
      "  (0, 11683)\t0.14268548339191967\n",
      "  (0, 11652)\t0.1620189287072458\n",
      "  (0, 11651)\t0.1620189287072458\n",
      "  (0, 11622)\t0.1620189287072458\n",
      "  (0, 11621)\t0.1620189287072458\n",
      "  (0, 11584)\t0.1620189287072458\n",
      "  (0, 11581)\t0.12896818563996992\n",
      "  (0, 11382)\t0.1620189287072458\n",
      "  (0, 11366)\t0.09591744257269404\n",
      "  (0, 11307)\t0.1620189287072458\n",
      "  (0, 11296)\t0.06923376247966763\n",
      "  (0, 11210)\t0.1620189287072458\n",
      "  (0, 11197)\t0.06594403450710812\n",
      "  (0, 11171)\t0.1620189287072458\n",
      "  (0, 11170)\t0.1620189287072458\n",
      "  (0, 10726)\t0.10963474032464379\n",
      "  (0, 10720)\t0.08527747982243422\n",
      "  (0, 8426)\t0.1620189287072458\n",
      "  (0, 8423)\t0.12896818563996992\n",
      "  (0, 8143)\t0.1620189287072458\n",
      "  (0, 8142)\t0.1620189287072458\n",
      "  (0, 8018)\t0.1620189287072458\n",
      "  (0, 8016)\t0.1022845055469435\n",
      "  (0, 7851)\t0.1620189287072458\n",
      "  (0, 7833)\t0.08527747982243422\n",
      "  (0, 6759)\t0.1620189287072458\n",
      "  (0, 6751)\t0.1183282228897101\n",
      "  (0, 6430)\t0.1620189287072458\n",
      "  (0, 6424)\t0.1183282228897101\n",
      "  (0, 6244)\t0.1620189287072458\n",
      "  (0, 6242)\t0.1620189287072458\n",
      "  (0, 6238)\t0.14268548339191967\n",
      "  (0, 6230)\t0.1620189287072458\n",
      "  (0, 6228)\t0.10963474032464379\n",
      "  (0, 4036)\t0.1620189287072458\n",
      "  (0, 4034)\t0.12896818563996992\n",
      "  (0, 3635)\t0.1620189287072458\n",
      "  (0, 3634)\t0.1620189287072458\n",
      "  (0, 3286)\t0.1620189287072458\n",
      "  (0, 3284)\t0.14268548339191967\n",
      "  (0, 3001)\t0.1620189287072458\n",
      "  (0, 3000)\t0.1620189287072458\n",
      "  (0, 2994)\t0.1620189287072458\n",
      "  (0, 2990)\t0.10963474032464379\n",
      "  (0, 94)\t0.1620189287072458\n",
      "  (0, 93)\t0.14268548339191967\n",
      "freecodecamporgs opensource codebase curriculum freecodecamporg friendly community learn code free run donorsupported 501c3 nonprofit help million busy adult transition tech community ha already helped 10000 people get first developer job fullstack web development machine learning curriculum completely free selfpaced thousand interactive coding challenge help expand skill table content certification learning platform reporting bug issue reporting security issue responsible disclosure contributing platform build deployment status license certification freecodecamporg offer several free developer certification certification involves building 5 required web app project along hundred optional coding challenge help prepare project estimate certification take beginner programmer around 300 hour earn 50 project freecodecamporg curriculum ha agile user story automated test help build project incrementally ensure youve fulfilled user story submit pull test suite freecodecamps cdn mean build project website like codepen glitch even local computer development environment youve earned certification always always able link linkedin resume prospective employer freelance client click link theyll see verified certification specific one exception discover violation academic honesty policy catch people unambiguously plagiarizing submitting people code project without citation rigorous institution learning revoke certification ban people ten core certification 1 responsive web design certification basic html html5 basic cs applied visual design applied accessibility responsive web design principle cs flexbox cs grid project tribute page survey form product landing page technical documentation page personal portfolio webpage 2 javascript algorithm data structure certification basic javascript es6 regular expression debugging basic data structure algorithm scripting objectoriented programming functional programming intermediate algorithm scripting project palindrome checker roman numeral converter caesar cipher telephone number validator cash register 3 front end library certification bootstrap jquery sas react redux react redux project random quote machine markdown previewer drum machine javascript calculator 25 5 clock 4 data visualization certification data visualization d3 json apis ajax project bar chart scatterplot graph heat map choropleth map treemap diagram 5 apis microservices certification managing package npm basic node express mongodb mongoose project timestamp microservice request header parser url shortener exercise tracker file metadata microservice 6 quality assurance certification quality assurance testing chai advanced node express project metricimperial converter issue tracker personal library sudoku solver american british translator 7 scientific computing python certification introduction python everybody project arithmetic formatter time calculator budget app polygon area calculator probability calculator 8 data analysis python certification data analysis python course numpy project meanvariancestandard deviation calculator demographic data analyzer medical data visualizer page view time series visualizer sea level predictor 9 information security certification information security helmetjs python penetration testing project stock price checker anonymous message board port scanner sha1 password cracker secure real time multiplayer game 10 machine learning python certification tensorflow neural network work project rock paper scissors cat dog image classifier book recommendation engine using knn linear regression health cost calculator neural network sm text classifier legacy full stack development certification earned responsive web design algorithm data structure front end library data visualization apis microservices legacy information security quality assurance certification youll able claim freecodecamporg full stack development certification distinction signifies youve completed around 1800 hour coding wide range web development tool legacy certification also 4 legacy certification dating back 2015 curriculum still available required project legacy certification remain available freecodecamporg legacy front end development certification legacy data visualization certification legacy back end development certification legacy information security quality assurance certification learning platform code running live freecodecamporg community also ha forum usually get programming help project feedback within hour youtube channel free course python sql android wide variety technology technical publication thousand programming tutorial article math computer science discord chat room hang talk developer people learning code join community reporting bug issue think youve found bug first read report bug article follow instruction youre confident new bug confirmed someone else facing issue go ahead create new github issue sure include much information possible reproduce bug reporting security issue responsible disclosure think found vulnerability please report responsibly dont create github issue security issue instead please send email securityfreecodecamporg well look immediately appreciate responsible disclosure vulnerability might impact integrity platform user offer bounty swag moment well happy list name hall fame security researcher contributing freecodecamporg community possible thanks thousand kind volunteer like welcome contribution community excited welcome aboard please follow step contribute platform build deployment status general platform status application available statusfreecodecamporg build deployment status code available devops guide license copyright 2020 freecodecamporg content repository bound following license computer software licensed bsd3clause license learning resource curriculum directory including subdirectory thereon licensed ccbysa40 license\n",
      "  (0, 15509)\t0.03318806429197916\n",
      "  (0, 15506)\t0.03318806429197916\n",
      "  (0, 15505)\t0.03318806429197916\n",
      "  (0, 15504)\t0.03318806429197916\n",
      "  (0, 15503)\t0.024238431275614973\n",
      "  (0, 15335)\t0.03318806429197916\n",
      "  (0, 15331)\t0.02922778859314465\n",
      "  (0, 15313)\t0.03318806429197916\n",
      "  (0, 15312)\t0.026417928267956796\n",
      "  (0, 15308)\t0.026417928267956796\n",
      "  (0, 15307)\t0.022457652569122286\n",
      "  (0, 15142)\t0.03318806429197916\n",
      "  (0, 15109)\t0.01568751654509992\n",
      "  (0, 15055)\t0.03318806429197916\n",
      "  (0, 15054)\t0.03318806429197916\n",
      "  (0, 15052)\t0.02922778859314465\n",
      "  (0, 15028)\t0.02922778859314465\n",
      "  (0, 15027)\t0.03318806429197916\n",
      "  (0, 15026)\t0.026417928267956796\n",
      "  (0, 14994)\t0.03318806429197916\n",
      "  (0, 14989)\t0.026417928267956796\n",
      "  (0, 14979)\t0.03318806429197916\n",
      "  (0, 14974)\t0.026417928267956796\n",
      "  (0, 14947)\t0.03318806429197916\n",
      "  (0, 14946)\t0.03318806429197916\n",
      "  :\t:\n",
      "  (0, 435)\t0.03318806429197916\n",
      "  (0, 434)\t0.03318806429197916\n",
      "  (0, 414)\t0.03318806429197916\n",
      "  (0, 413)\t0.03318806429197916\n",
      "  (0, 407)\t0.03318806429197916\n",
      "  (0, 402)\t0.03318806429197916\n",
      "  (0, 400)\t0.024238431275614973\n",
      "  (0, 279)\t0.03318806429197916\n",
      "  (0, 278)\t0.03318806429197916\n",
      "  (0, 272)\t0.03318806429197916\n",
      "  (0, 267)\t0.026417928267956796\n",
      "  (0, 212)\t0.03318806429197916\n",
      "  (0, 211)\t0.03318806429197916\n",
      "  (0, 191)\t0.03318806429197916\n",
      "  (0, 190)\t0.02922778859314465\n",
      "  (0, 167)\t0.03318806429197916\n",
      "  (0, 163)\t0.026417928267956796\n",
      "  (0, 142)\t0.03318806429197916\n",
      "  (0, 141)\t0.02922778859314465\n",
      "  (0, 107)\t0.03318806429197916\n",
      "  (0, 106)\t0.03318806429197916\n",
      "  (0, 41)\t0.03318806429197916\n",
      "  (0, 40)\t0.03318806429197916\n",
      "  (0, 32)\t0.03318806429197916\n",
      "  (0, 29)\t0.024238431275614973\n",
      "babelstandalone part babel go check babelstandalone babelstandalone standalone build babel use nonnodejs environment including browser bundled standard babel plugins presets build babili babelminify optionally available true using babel webpack browserify gulp sufficient use case however valid use case babelstandalone site like jsfiddle j bin repl babel site etc site compile userprovided javascript realtime apps embed javascript engine v8 directly want use babel compilation apps want use javascript scripting language extending app including goody es2015 provides integration babel nonnodejs environment reactjsnet rubybabeltranspiler phpbabeltranspiler etc installation several way get copy babelstandalone pick whichever one like use via unpkg httpsunpkgcombabelstandalone6babelminjs simple way embed webpage without setup install via bower bower install babelstandalone install via npm npm install save babelstandalone manually grab babeljs andor babelminjs github release page every release includes file install via git use repo httpsgithubcomdaniel15babelstandalonebower pull prebuilt version git note generally advised system must pull artifact git bower usage load babeljs babelminjs environment expose babel api babel object var input const getmessage hello world var output babeltransforminput presets es2015 code loaded browser babelstandalone automatically compile execute script tag type textbabel textjsx div idoutputdiv load babel script srchttpsunpkgcombabelstandalone6babelminjsscript custom script script typetextbabel const getmessage hello world documentgetelementbyidoutputinnerhtml getmessage script use dataplugins datapresets attribute specify babel pluginspresets use script typetextbabel datapresetses2015stage2 loading external script via src attribute supported script typetextbabel srcfoojsscript note babelrc doesnt work babelstandalone file system access available presets andor plugins use must specified option passed babeltransform customisation custom plugins presets added using registerplugin registerpreset method respectively simple plugin convert every identifier lol function lolizer return visitor identifierpath pathnodename lol babelregisterpluginlolizer lolizer registered use name plugin var output babeltransform function helloworld alerthello plugins lolizer return function lol lollol custom plugins also work inline script script typetextbabel datapluginslolizer manually building want manually upgrade babel version used babelstandalone build release follow step upgrade babel version packagejson done npmcheckupgrades eg npmcheckupdates u packagefile packagejson babel delete nodemodules npm often produce inefficient directory layout upgrade inplace run npm install npm run build run npm run test ensure work open examplesexamplehtm ensure work\n",
      "  (0, 15171)\t0.04967536765106367\n",
      "  (0, 15170)\t0.04967536765106367\n",
      "  (0, 15168)\t0.04374768986882187\n",
      "  (0, 15137)\t0.04967536765106367\n",
      "  (0, 15129)\t0.04967536765106367\n",
      "  (0, 15110)\t0.04967536765106367\n",
      "  (0, 15109)\t0.023480825668350854\n",
      "  (0, 15042)\t0.04967536765106367\n",
      "  (0, 15041)\t0.04967536765106367\n",
      "  (0, 14984)\t0.04967536765106367\n",
      "  (0, 14974)\t0.03954193555082816\n",
      "  (0, 14972)\t0.04967536765106367\n",
      "  (0, 14970)\t0.03954193555082816\n",
      "  (0, 14932)\t0.04967536765106367\n",
      "  (0, 14929)\t0.04967536765106367\n",
      "  (0, 14925)\t0.029408503450592653\n",
      "  (0, 14898)\t0.03954193555082816\n",
      "  (0, 14883)\t0.04967536765106367\n",
      "  (0, 14862)\t0.023480825668350854\n",
      "  (0, 14796)\t0.04967536765106367\n",
      "  (0, 14795)\t0.04967536765106367\n",
      "  (0, 14612)\t0.04967536765106367\n",
      "  (0, 14599)\t0.04967536765106367\n",
      "  (0, 14591)\t0.04967536765106367\n",
      "  (0, 14566)\t0.02475288433843031\n",
      "  :\t:\n",
      "  (0, 1106)\t0.04967536765106367\n",
      "  (0, 1103)\t0.033614257768586356\n",
      "  (0, 1052)\t0.04967536765106367\n",
      "  (0, 1051)\t0.04967536765106367\n",
      "  (0, 1047)\t0.03954193555082816\n",
      "  (0, 980)\t0.04967536765106367\n",
      "  (0, 979)\t0.04374768986882187\n",
      "  (0, 897)\t0.04967536765106367\n",
      "  (0, 893)\t0.04967536765106367\n",
      "  (0, 892)\t0.03954193555082816\n",
      "  (0, 816)\t0.04967536765106367\n",
      "  (0, 811)\t0.029408503450592653\n",
      "  (0, 798)\t0.04967536765106367\n",
      "  (0, 797)\t0.0362796990601289\n",
      "  (0, 758)\t0.04967536765106367\n",
      "  (0, 755)\t0.04967536765106367\n",
      "  (0, 754)\t0.03954193555082816\n",
      "  (0, 690)\t0.04967536765106367\n",
      "  (0, 689)\t0.04967536765106367\n",
      "  (0, 630)\t0.04967536765106367\n",
      "  (0, 629)\t0.04967536765106367\n",
      "  (0, 555)\t0.04967536765106367\n",
      "  (0, 553)\t0.04374768986882187\n",
      "  (0, 445)\t0.04967536765106367\n",
      "  (0, 444)\t0.0362796990601289\n",
      "meta meta tool managing multiproject system library answer conundrum choosing mono repo many repos saying meta repo meta powered plugins wrap common command letting execute repos solution meta built loop inherits loop ability easily target particular set directory executing common command eg meta git status includeonly dir1dir2 see loop available option getting started installing npm g meta install meta command system initializing create new meta project create new directory meta project mkdir mymetarepo initialize new git repository new dir cd mymetarepo git init initialize new repository meta repo meta init meta created meta file hold reference child repository add create new project use meta project create folder repo url b import existing project use meta project import folder repo url project added meta update gitignore file meta file reference new child repo meta git clone clone existing meta repo need execute meta git clone meta repo url meta clone meta repo child repository working meta meta plugins wrap common command shouldnt much new syntax memorize crazy new utility nobody know instance want check git status repository type meta git status view branch exist repos meta git branch creating new feature crosscut number service site api create new branch repos meta git checkout b branchname revert modified file remote status meta git checkout track progress branch meta git status remove unwanted untracked file repos meta git clean fd really working meta plugins meta functionality contributed plugins node module begin meta either installed globally meta repos nodemodules directory recommend install devdependencies meta repos packagejson plugins add additional sub command meta leverage loop metaloop easily execute common command meta repo child repos easy install metanpm plugin gain ability meta npm install repos prefer speediness yarn try metayarn npm install savedev metayarn meta clone manyproject architecture one line give every engineer team project setup regardless cloned npm yarn install project execute arbitrary command many repos manage project super simple plugin architecture using commanderjs easily wrap command working platform node meta repo keep code per project repos benefiting deployment reuse use tool always use strange side effect git submodules subtree give different team different slice architecture multiple metarepos available plugins metainit metaproject metagit metaexec metagh metaloop metanpm metayarn metatemplate thirdparty plugins metabump metarelease metasearch available template metaplugin want help develop meta locally best way get started following npm g meta meta git clone gitgithubcommateodelnortemetagit cd meta npm install meta npm install meta npm link npm link clone meta project meta enter directory use meta perform npm install npm link directory listed project meta json configuration file link meta used global command write command test using binmeta git gh subcommand run single command meta git clone gitgithubcommateodelnortemetagit cd meta npm meta npm install meta npm link npm link yarn lover npm g meta meta git clone gitgithubcommateodelnortemetagit cd meta yarn meta yarn install meta yarn link yarn link meta git clone gitgithubcommateodelnortemetagit cd meta yarn meta yarn install meta yarn link yarn link see discussion detail resource monorepo multirepo choose one patrickleet developing plugin meta patrickleet\n",
      "  (0, 15281)\t0.04524744089873737\n",
      "  (0, 15280)\t0.04524744089873737\n",
      "  (0, 15279)\t0.04524744089873737\n",
      "  (0, 15278)\t0.04524744089873737\n",
      "  (0, 15277)\t0.04524744089873737\n",
      "  (0, 15275)\t0.039848140142621044\n",
      "  (0, 15202)\t0.04524744089873737\n",
      "  (0, 15199)\t0.039848140142621044\n",
      "  (0, 15195)\t0.04524744089873737\n",
      "  (0, 15194)\t0.04524744089873737\n",
      "  (0, 15193)\t0.039848140142621044\n",
      "  (0, 15167)\t0.04524744089873737\n",
      "  (0, 15165)\t0.04524744089873737\n",
      "  (0, 15160)\t0.030617974534637736\n",
      "  (0, 14940)\t0.04524744089873737\n",
      "  (0, 14925)\t0.02678710968277076\n",
      "  (0, 14879)\t0.04524744089873737\n",
      "  (0, 14867)\t0.04524744089873737\n",
      "  (0, 14862)\t0.021387808926654435\n",
      "  (0, 14765)\t0.04524744089873737\n",
      "  (0, 14763)\t0.03601727529075406\n",
      "  (0, 14451)\t0.04524744089873737\n",
      "  (0, 14450)\t0.04524744089873737\n",
      "  (0, 14380)\t0.04524744089873737\n",
      "  (0, 14376)\t0.04524744089873737\n",
      "  :\t:\n",
      "  (0, 1425)\t0.04524744089873737\n",
      "  (0, 1170)\t0.04524744089873737\n",
      "  (0, 1159)\t0.04524744089873737\n",
      "  (0, 1158)\t0.039848140142621044\n",
      "  (0, 1132)\t0.023815660053097844\n",
      "  (0, 922)\t0.04524744089873737\n",
      "  (0, 921)\t0.04524744089873737\n",
      "  (0, 919)\t0.04524744089873737\n",
      "  (0, 915)\t0.03304582566108115\n",
      "  (0, 910)\t0.04524744089873737\n",
      "  (0, 909)\t0.03601727529075406\n",
      "  (0, 799)\t0.04524744089873737\n",
      "  (0, 797)\t0.03304582566108115\n",
      "  (0, 786)\t0.04524744089873737\n",
      "  (0, 785)\t0.04524744089873737\n",
      "  (0, 572)\t0.04524744089873737\n",
      "  (0, 565)\t0.03304582566108115\n",
      "  (0, 554)\t0.04524744089873737\n",
      "  (0, 553)\t0.039848140142621044\n",
      "  (0, 531)\t0.04524744089873737\n",
      "  (0, 523)\t0.04524744089873737\n",
      "  (0, 522)\t0.025218673778521414\n",
      "  (0, 399)\t0.04524744089873737\n",
      "  (0, 398)\t0.04524744089873737\n",
      "  (0, 397)\t0.04524744089873737\n",
      "npmhub npmhub browser extension let explore npm dependency github gitlab repos viewing repository file list containing packagejson extension display link description dependency bottom page github enterprise gitlab enterprise community edition also supported rightclicking npmhubs icon toolbar selecting enable npmhub domain installation chrome extension firefox addon chrome version also work opera using edge design npmhub look like see also packagehub extension displaying dependency different package manager github ghubio jump straight github repo npm package eg ghubioexpress\n",
      "  (0, 15138)\t0.10112010400360724\n",
      "  (0, 15109)\t0.04779800625438083\n",
      "  (0, 14779)\t0.10112010400360724\n",
      "  (0, 14778)\t0.10112010400360724\n",
      "  (0, 14616)\t0.08905361265822656\n",
      "  (0, 14566)\t0.05038743258577047\n",
      "  (0, 14390)\t0.10112010400360724\n",
      "  (0, 14370)\t0.04321053915345348\n",
      "  (0, 13621)\t0.10112010400360724\n",
      "  (0, 13620)\t0.10112010400360724\n",
      "  (0, 13056)\t0.10112010400360724\n",
      "  (0, 13039)\t0.05986449759976151\n",
      "  (0, 12802)\t0.10112010400360724\n",
      "  (0, 12801)\t0.10112010400360724\n",
      "  (0, 11999)\t0.10112010400360724\n",
      "  (0, 11998)\t0.10112010400360724\n",
      "  (0, 11603)\t0.10112010400360724\n",
      "  (0, 11602)\t0.10112010400360724\n",
      "  (0, 11310)\t0.10112010400360724\n",
      "  (0, 11296)\t0.04321053915345348\n",
      "  (0, 11285)\t0.10112010400360724\n",
      "  (0, 11275)\t0.08905361265822656\n",
      "  (0, 11215)\t0.10112010400360724\n",
      "  (0, 11197)\t0.04115733686787437\n",
      "  (0, 9730)\t0.10112010400360724\n",
      "  :\t:\n",
      "  (0, 4020)\t0.10112010400360724\n",
      "  (0, 4019)\t0.10112010400360724\n",
      "  (0, 4013)\t0.10112010400360724\n",
      "  (0, 4010)\t0.07385163141517792\n",
      "  (0, 3892)\t0.10112010400360724\n",
      "  (0, 3878)\t0.05038743258577047\n",
      "  (0, 3737)\t0.10112010400360724\n",
      "  (0, 3732)\t0.08049230080168437\n",
      "  (0, 3706)\t0.10112010400360724\n",
      "  (0, 3701)\t0.08049230080168437\n",
      "  (0, 3666)\t0.10112010400360724\n",
      "  (0, 3662)\t0.10112010400360724\n",
      "  (0, 3661)\t0.10112010400360724\n",
      "  (0, 3657)\t0.05986449759976151\n",
      "  (0, 2917)\t0.10112010400360724\n",
      "  (0, 2914)\t0.08049230080168437\n",
      "  (0, 2616)\t0.08905361265822656\n",
      "  (0, 2614)\t0.0684258094563037\n",
      "  (0, 2249)\t0.10112010400360724\n",
      "  (0, 2244)\t0.08905361265822656\n",
      "  (0, 2238)\t0.07385163141517792\n",
      "  (0, 1685)\t0.08049230080168437\n",
      "  (0, 1670)\t0.05635931811092303\n",
      "  (0, 578)\t0.10112010400360724\n",
      "  (0, 577)\t0.08905361265822656\n",
      "ui docker repo deprecated development continues portainer githubcomportainerportainer ui docker web interface docker remote api goal provide pure client side implementation effortless connect manage docker goal minimal dependency really want keep project pure htmljs app consistency web ui consistent command found docker cli quickstart run docker run p 90009000 privileged v varrundockersockvarrundockersock uifduifordocker open browser httpdockerd host ip9000 bind mounting unix socket ui docker container much secure exposing docker daemon tcp privileged flag required host using selinux still secure ui docker instance behind type auth direction using nginx auth specify socket connect docker daemon default ui docker connects docker daemon withvarrundockersock work need bind mount unix socket container v varrundockersockvarrundockersock use h flag change socket connect tcp socket docker run p 90009000 privileged uifduifordocker h tcp1270012375 change addressport ui docker served ui docker listens port 9000 default run ui docker inside container bind container internal port external address port expose ui docker 102030180 docker run p 1020301809000 privileged v varrundockersockvarrundockersock uifduifordocker access docker engine protected via tl ensure access ca tl certificate tl key used access docker engine file need named capem certpem keypem respectively store somewhere disk mount volume containing file inside ui container docker run p 90009000 uifduifordocker v pathtocertscerts h tcpmydockerhostdomain2376 tlsverify want specify different name ca certificate public key respectively use tlscacert tlscert tlskey docker run p 90009000 uifduifordocker v pathtocertscerts h tcpmydockerhostdomain2376 tlsverify tlscacert certsmycapem tlscert certsmycertpem tlskey certsmykeypem note replace pathtocerts path certificate file disk check wiki info using ui docker stack angularjs bootstrap gritter spinjs golang visjs todo full repository support search push file container unit test license mit ui docker code licensed mit license ui docker copyright c 20132016 michael crosby crosbymichaelcom kevan ahlquist kevanahlquistcom permission hereby granted free charge person obtaining copy software associated documentation file software deal software without restriction including without limitation right use copy modify merge publish distribute sublicense andor sell copy software permit person software furnished subject following condition copyright notice permission notice shall included copy substantial portion software software provided without warranty kind express implied including limited warranty merchantability fitness particular purpose noninfringement event shall author copyright holder liable claim damage liability whether action contract tort otherwise arising connection software use dealing software\n",
      "  (0, 15135)\t0.04721780311009722\n",
      "  (0, 15109)\t0.022319170560722912\n",
      "  (0, 15100)\t0.04721780311009722\n",
      "  (0, 15099)\t0.04721780311009722\n",
      "  (0, 15063)\t0.04721780311009722\n",
      "  (0, 15062)\t0.04721780311009722\n",
      "  (0, 14953)\t0.04721780311009722\n",
      "  (0, 14948)\t0.04721780311009722\n",
      "  (0, 14943)\t0.027953591314043656\n",
      "  (0, 14914)\t0.04721780311009722\n",
      "  (0, 14913)\t0.04721780311009722\n",
      "  (0, 14912)\t0.04721780311009722\n",
      "  (0, 14895)\t0.04721780311009722\n",
      "  (0, 14888)\t0.04721780311009722\n",
      "  (0, 14862)\t0.022319170560722912\n",
      "  (0, 14827)\t0.04721780311009722\n",
      "  (0, 14826)\t0.04158338235677647\n",
      "  (0, 14798)\t0.04721780311009722\n",
      "  (0, 14797)\t0.04721780311009722\n",
      "  (0, 14544)\t0.04721780311009722\n",
      "  (0, 14543)\t0.04721780311009722\n",
      "  (0, 14542)\t0.04721780311009722\n",
      "  (0, 14424)\t0.04158338235677647\n",
      "  (0, 14416)\t0.04721780311009722\n",
      "  (0, 14399)\t0.04721780311009722\n",
      "  :\t:\n",
      "  (0, 771)\t0.04721780311009722\n",
      "  (0, 759)\t0.04721780311009722\n",
      "  (0, 754)\t0.03758569721207044\n",
      "  (0, 661)\t0.04721780311009722\n",
      "  (0, 660)\t0.04721780311009722\n",
      "  (0, 597)\t0.04721780311009722\n",
      "  (0, 596)\t0.04721780311009722\n",
      "  (0, 592)\t0.04721780311009722\n",
      "  (0, 583)\t0.03758569721207044\n",
      "  (0, 490)\t0.04721780311009722\n",
      "  (0, 488)\t0.03448485171056535\n",
      "  (0, 448)\t0.04721780311009722\n",
      "  (0, 446)\t0.04721780311009722\n",
      "  (0, 444)\t0.03448485171056535\n",
      "  (0, 380)\t0.04721780311009722\n",
      "  (0, 379)\t0.04721780311009722\n",
      "  (0, 378)\t0.04721780311009722\n",
      "  (0, 377)\t0.04721780311009722\n",
      "  (0, 376)\t0.04721780311009722\n",
      "  (0, 136)\t0.04721780311009722\n",
      "  (0, 135)\t0.04721780311009722\n",
      "  (0, 45)\t0.04721780311009722\n",
      "  (0, 44)\t0.04721780311009722\n",
      "  (0, 43)\t0.04721780311009722\n",
      "  (0, 42)\t0.04721780311009722\n",
      "youtubedl download video youtubecom video platform change installation description option configuration output template format selection video selection faq developer instruction embedding youtubedl bug copyright change view change made ytdlorgyoutubedl view archived tag youtubedlreleases view archived unmerged pull request youtubedltreearchiverecoveredgithubprs installation install right away unix user linux macos etc type sudo curl l httpsgithubcoml1vingyoutubedlreleaseslatestdownloadyoutubedl usrlocalbinyoutubedl sudo chmod arx usrlocalbinyoutubedl curl alternatively use recent wget sudo wget httpsgithubcoml1vingyoutubedlreleaseslatestdownloadyoutubedl usrlocalbinyoutubedl sudo chmod arx usrlocalbinyoutubedl window user download exe file place location path except systemrootsystem32 eg put cwindowssystem32 also use pip sudo h pip install upgrade youtubedl command update youtubedl already installed see pypi page information macos user install youtubedl homebrew brew install youtubedl macports sudo port install youtubedl alternatively refer developer instruction check work git repository option including pgp signature see youtubedl download page description youtubedl commandline program download video youtubecom site requires python interpreter version 26 27 32 platform specific work unix box window macos released public domain mean modify redistribute use however like youtubedl option url url option h help print help text exit version print program version exit u update update program latest version make sure sufficient permission run sudo needed ignoreerrors continue download error example skip unavailable video playlist abortonerror abort downloading video playlist command line error occurs dumpuseragent display current browser identification listextractors list supported extractor extractordescriptions output description supported extractor forcegenericextractor force extraction use generic extractor defaultsearch prefix use prefix unqualified url example gvsearch2 downloads two video google video youtubedl large apple use value auto let youtubedl guess autowarning emit warning guessing error throw error default value fixuperror repair broken url emits error possible instead searching ignoreconfig read configuration file given global configuration file etcyoutubedlconf read user configuration configyoutube dlconfig appdatayoutubedlconfigtxt window configlocation path location configuration file either path config containing directory flatplaylist extract video playlist list markwatched mark video watched youtube nomarkwatched mark video watched youtube nocolor emit color code output network option proxy url use specified httphttpssocks proxy enable sock proxy specify proper scheme example socks51270011080 pas empty string proxy direct connection sockettimeout second time wait giving second sourceaddress ip clientside ip address bind 4 forceipv4 make connection via ipv4 6 forceipv6 make connection via ipv6 geo restriction geoverificationproxy url use proxy verify ip address georestricted site default proxy specified proxy none option present used actual downloading geobypass bypass geographic restriction via faking xforwardedfor http header nogeobypass bypass geographic restriction via faking xforwardedfor http header geobypasscountry code force bypass geographic restriction explicitly provided twoletter iso 31662 country code geobypassipblock ipblock force bypass geographic restriction explicitly provided ip block cidr notation video selection playliststart number playlist video start default 1 playlistend number playlist video end default last playlistitems itemspec playlist video item download specify index video playlist separated comma like playlistitems 1258 want download video indexed 1 2 5 8 playlist specify range playlistitems 1371013 download video index 1 2 3 7 10 11 12 13 matchtitle regex download matching title regex caseless substring rejecttitle regex skip download matching title regex caseless substring maxdownloads number abort downloading number file minfilesize size download video smaller size eg 50k 446m maxfilesize size download video larger size eg 50k 446m date date download video uploaded date datebefore date download video uploaded date ie inclusive dateafter date download video uploaded date ie inclusive minviews count download video le count view maxviews count download video count view matchfilter filter generic video filter specify key see output template list available key match key present key check key present key number like commentcount 12 also work compare number key literal like uploader mike smith also work match string literal require multiple match value known excluded unless put question mark operator example match video liked 100 time disliked le 50 time dislike functionality available given service also description use matchfilter likecount 100 dislikecount 50 description noplaylist download video url refers video playlist yesplaylist download playlist url refers video playlist agelimit year download video suitable given age downloadarchive file download video listed archive file record id downloaded video includeads download advertisement well experimental download option r limitrate rate maximum download rate byte per second eg 50k 42m r retries retries number retries default 10 infinite fragmentretries retries number retries fragment default 10 infinite dash hlsnative ism skipunavailablefragments skip unavailable fragment dash hlsnative ism abortonunavailablefragment abort downloading fragment available keepfragments keep downloaded fragment disk downloading finished fragment erased default buffersize size size download buffer eg 1024 16k default 1024 noresizebuffer automatically adjust buffer size default buffer size automatically resized initial value size httpchunksize size size chunk chunkbased http downloading eg 10485760 10m default disabled may useful bypassing bandwidth throttling imposed webserver experimental playlistreverse download playlist video reverse order playlistrandom download playlist video random order xattrsetfilesize set file xattribute ytdlfilesize expected file size hlsprefernative use native hl downloader instead ffmpeg hlspreferffmpeg use ffmpeg instead native hl downloader hlsusempegts use mpegts container hl video allowing play video downloading player may able play externaldownloader command use specified external downloader currently support aria2cavconvaxelcurlffmpeghttpiewget externaldownloaderargs args give argument external downloader filesystem option batchfile file file containing url download stdin one url per line line starting considered comment ignored id use video id file name output template output filename template see output template info autonumberstart number specify start value autonumbers default 1 restrictfilenames restrict filename ascii character avoid space filename w nooverwrites overwrite file c continue force resume partially downloaded file default youtubedl resume downloads possible nocontinue resume partially downloaded file restart beginning nopart use part file write directly output file nomtime use lastmodified header set file modification time writedescription write video description description file writeinfojson write video metadata infojson file writeannotations write video annotation annotationsxml file loadinfojson file json file containing video information created writeinfojson option cooky file file read cooky dump cookie jar cachedir dir location filesystem youtubedl store downloaded information permanently default xdgcachehomeyoutubedl cacheyoutubedl moment youtube player file video obfuscated signature cached may change nocachedir disable filesystem caching rmcachedir delete filesystem cache file thumbnail image writethumbnail write thumbnail image disk writeallthumbnails write thumbnail image format disk listthumbnails simulate list available thumbnail format verbosity simulation option q quiet activate quiet mode nowarnings ignore warning simulate download video write anything disk skipdownload download video g geturl simulate quiet print url e gettitle simulate quiet print title getid simulate quiet print id getthumbnail simulate quiet print thumbnail url getdescription simulate quiet print video description getduration simulate quiet print video length getfilename simulate quiet print output filename getformat simulate quiet print output format j dumpjson simulate quiet print json information see output template description available key j dumpsinglejson simulate quiet print json information commandline argument url refers playlist dump whole playlist information single line printjson quiet print video information json video still downloaded newline output progress bar new line noprogress print progress bar consoletitle display progress console titlebar v verbose print various debugging information dumppages print downloaded page encoded using base64 debug problem verbose writepages write downloaded intermediary page file current directory debug problem printtraffic display sent read http traffic c callhome contact youtubedl server debugging nocallhome contact youtubedl server debugging workarounds encoding encoding force specified encoding experimental nocheckcertificate suppress http certificate validation preferinsecure use unencrypted connection retrieve information video currently supported youtube useragent ua specify custom user agent referer url specify custom referer use video access restricted one domain addheader fieldvalue specify custom http header value separated colon use option multiple time bidiworkaround work around terminal lack bidirectional text support requires bidiv fribidi executable path sleepinterval second number second sleep download used alone lower bound range randomized sleep download minimum possible number second sleep used along maxsleepinterval maxsleepinterval second upper bound range randomized sleep download maximum possible number second sleep must used along minsleepinterval video format option f format format video format code see format selection info allformats download available video format preferfreeformats prefer free video format unless specific one requested f listformats list available format requested video youtubeskipdashmanifest download dash manifest related data youtube video mergeoutputformat format merge required eg bestvideobestaudio output given container format one mkv mp4 ogg webm flv ignored merge required subtitle option writesub write subtitle file writeautosub write automatically generated subtitle file youtube allsubs download available subtitle video listsubs list available subtitle video subformat format subtitle format accepts format preference example srt asssrtbest sublang langs language subtitle download optional separated comma use list sub available language tag authentication option u username username login account id p password password account password option left youtubedl ask interactively 2 twofactor twofactor twofactor authentication code n netrc use netrc authentication data videopassword password video password vimeo smotri youku adobe pas option apmso mso adobe pas multiplesystem operator tv provider identifier use aplistmso list available msos apusername username multiplesystem operator account login appassword password multiplesystem operator account password option left youtubedl ask interactively aplistmso list supported multiplesystem operator postprocessing option x extractaudio convert video file audioonly file requires ffmpeg avconv ffprobe avprobe audioformat format specify audio format best aac flac mp3 m4a opus vorbis wav best default effect without x audioquality quality specify ffmpegavconv audio quality insert value 0 better 9 worse vbr specific bitrate like 128k default 5 recodevideo format encode video another format necessary currently supported mp4flvoggwebmmkvavi postprocessorargs args give argument postprocessor k keepvideo keep video file disk post processing video erased default nopostoverwrites overwrite postprocessed file postprocessed file overwritten default embedsubs embed subtitle video mp4 webm mkv video embedthumbnail embed thumbnail audio cover art addmetadata write metadata video file metadatafromtitle format parse additional metadata like song title artist video title format syntax output regular expression named capture group may also used parsed parameter replace existing value example metadatafrom title artist title match title like coldplay paradise example regex metadatafromtitle partist ptitle xattrs write metadata video file xattrs using dublin core xdg standard fixup policy automatically correct known fault file one never nothing warn emit warning detectorwarn default fix file warn otherwise preferavconv prefer avconv ffmpeg running postprocessors preferffmpeg prefer ffmpeg avconv running postprocessors default ffmpeglocation path location ffmpegavconv binary either path binary containing directory exec cmd execute command file downloading postprocessing similar find exec syntax example exec adb push sdcardmusic rm convertsubs format convert subtitle format currently supported srtassvttlrc configuration configure youtubedl placing supported command line option configuration file linux macos system wide configuration file located etcyoutubedlconf user wide configuration file configyoutubedlconfig window user wide configuration file location appdatayoutubedlconfigtxt cusersuser nameyoutubedlconf note default configuration file may exist may need create example following configuration file youtubedl always extract audio copy mtime use proxy save video movie directory home directory line starting comment always extract audio x copy mtime nomtime use proxy proxy 1270013128 save video movie directory home directory moviestitlesexts note option configuration file option aka switch used regular command line call thus must whitespace eg proxy proxy use ignoreconfig want disable configuration file particular youtubedl run also use configlocation want use custom configuration file particular youtubedl run authentication netrc file may also want configure automatic credential storage extractor support authentication providing login password username password order pas credential command line argument every youtubedl execution prevent tracking plain text password shell command history achieve using netrc file per extractor basis need create netrc file home restrict permission readwrite touch homenetrc chmod arwxurw homenetrc add credential extractor following format extractor name extractor lowercase machine extractor login login password password example machine youtube login myaccountgmailcom password myyoutubepassword machine twitch login mytwitchaccountname password mytwitchpassword activate authentication netrc file pas netrc youtubedl place configuration file window may also need setup home environment variable manually example set homeuserprofile output template option allows user indicate template output file name tldr navigate example basic usage set template argument downloading single file like youtubedl funnyvideoflv httpssomevideo however may contain special sequence replaced downloading video special sequence may formatted according python string formatting operation example name name05d clarify percent symbol followed name parenthesis followed formatting operation allowed name along sequence type id string video identifier title string video title url string video url ext string video filename extension alttitle string secondary title video displayid string alternative identifier video uploader string full name video uploader license string license name video licensed creator string creator video releasedate string date yyyymmdd video wa released timestamp numeric unix timestamp moment video became available uploaddate string video upload date yyyymmdd uploaderid string nickname id video uploader channel string full name channel video uploaded channelid string id channel location string physical location video wa filmed duration numeric length video second viewcount numeric many user watched video platform likecount numeric number positive rating video dislikecount numeric number negative rating video repostcount numeric number reposts video averagerating numeric average rating give user scale used depends webpage commentcount numeric number comment video agelimit numeric age restriction video year islive boolean whether video live stream fixedlength video starttime numeric time second reproduction start specified url endtime numeric time second reproduction end specified url format string humanreadable description format formatid string format code specified format formatnote string additional info format width numeric width video height numeric height video resolution string textual description width height tbr numeric average bitrate audio video kbit abr numeric average audio bitrate kbit acodec string name audio codec use asr numeric audio sampling rate hertz vbr numeric average video bitrate kbit fps numeric frame rate vcodec string name video codec use container string name container format filesize numeric number byte known advance filesizeapprox numeric estimate number byte protocol string protocol used actual download extractor string name extractor extractorkey string key name extractor epoch numeric unix epoch creating file autonumber numeric number increased download starting autonumberstart playlist string name id playlist contains video playlistindex numeric index video playlist padded leading zero according total length playlist playlistid string playlist identifier playlisttitle string playlist title playlistuploader string full name playlist uploader playlistuploaderid string nickname id playlist uploader available video belongs logical chapter section chapter string name title chapter video belongs chapternumber numeric number chapter video belongs chapterid string id chapter video belongs available video episode series programme series string title series programme video episode belongs season string title season video episode belongs seasonnumber numeric number season video episode belongs seasonid string id season video episode belongs episode string title video episode episodenumber numeric number video episode within season episodeid string id video episode available medium track part music album track string title track tracknumber numeric number track within album disc trackid string id track artist string artist track genre string genre track album string title album track belongs albumtype string type album albumartist string list artist appeared album discnumber numeric number disc physical medium track belongs releaseyear numeric year yyyy album wa released aforementioned sequence referenced output template replaced actual value corresponding sequence name note sequence guaranteed present since depend metadata obtained particular extractor sequence replaced na example titlesidsexts mp4 video title youtubedl test video id bawjenozkcj result youtubedl test videobawjenozkcjmp4 file created current directory numeric sequence use numeric related formatting example viewcount05d result string view count padded zero 5 character like 00042 output template also contain arbitrary hierarchical path eg playlistsplaylistindexs titlesexts result downloading video directory corresponding path template missing directory automatically created use percent literal output template use output stdout use current default template titlesidsexts case dont want special character space transferring downloaded filename window system filename 8bitunsafe channel case add restrictfilenames flag get shorter title output template window batch file using output template inside window batch file must escape plain percent character doubling titlesidsexts become titlesidsexts however touch plain character eg environment variable expansion stay intact chomepathdesktoptitlesexts output template example note window may need use double quote instead single youtubedl getfilename titlesexts bawjenozkc youtubedl test video amp4 kind weird character youtubedl getfilename titlesexts bawjenozkc restrictfilenames youtubedltestvideomp4 simple file name download youtube playlist video separate directory indexed video order playlist youtubedl playlistsplaylistindexs titlesexts httpswwwyoutubecomplaylistlistplwiyx1dc3p2jr9n8gqaqnbcvlslap7re download playlist youtube channeluser keeping playlist separate directory youtubedl uploadersplaylistsplaylistindexs titlesexts httpswwwyoutubecomuserthelinuxfoundationplaylists download udemy course keeping chapter separate directory myvideos directory home youtubedl u user p password myvideosplaylistschapternumbers chapterstitlesexts httpswwwudemycomjavatutorial download entire series season keeping series season separate directory cmyvideos youtubedl cmyvideosseriessseasonnumbers seasonsepisodenumbers episodesexts httpsvideomorerukinovdetalayah5sezon367617 stream video downloaded stdout youtubedl bawjenozkc format selection default youtubedl try download best available quality ie want best quality dont need pas special option youtubedl guess default sometimes may want download different format example slow intermittent connection key mechanism achieving socalled format selection based explicitly specify desired format select format based criterion criterion setup precedence much general syntax format selection format format shorter f format format selector expression ie expression describes format format would like download tldr navigate example simplest case requesting specific format example f 22 download format format code equal 22 get list available format code particular video using listformats f note format code extractor specific also use file extension currently 3gp aac flv m4a mp3 mp4 ogg wav webm supported download best quality format particular file extension served single file eg f webm download best quality format webm extension served single file also use special name select particular edge case format best select best quality format represented single file video audio worst select worst quality format represented single file video audio bestvideo select best quality videoonly format eg dash video may available worstvideo select worst quality videoonly format may available bestaudio select best quality audio onlyformat may available worstaudio select worst quality audio onlyformat may available example download worst quality videoonly format use f worstvideo want download multiple video dont format available specify order preference using slash note slash leftassociative ie format left hand side preferred example f 221718 download format 22 available otherwise download format 17 available otherwise download format 18 available otherwise complain suitable format available download want download several format video use comma separator eg f 221718 download three format course available sophisticated example combined precedence feature f 136137mp4bestvideo140m4abestaudio also filter video format putting condition bracket f bestheight720 f filesize10m following numeric meta field used comparison equal equal filesize number byte known advance width width video known height height video known tbr average bitrate audio video kbit abr average audio bitrate kbit vbr average video bitrate kbit asr audio sampling rate hertz fps frame rate also filtering work comparison equal start end contains following string meta field ext file extension acodec name audio codec use vcodec name video codec use container name container format protocol protocol used actual download lowercase http http rtsp rtmp rtmpe mm f4m ism httpdashsegments m3u8 m3u8native formatid short description format string comparison may prefixed negation order produce opposite comparison eg doe contain note none aforementioned meta field guaranteed present since solely depends metadata obtained particular extractor ie metadata offered video hoster format value known excluded unless put question mark operator combine format filter f height 720tbr500 selects 720p video video height known bitrate least 500 kbit merge video audio two format single file using f videoformataudioformat requires ffmpeg avconv installed example f bestvideobestaudio download best videoonly format best audioonly format mux together ffmpegavconv format selector also grouped using parenthesis example want download best mp4 webm format height lower 480 use f mp4webmheight480 since end april 2015 version 20150426 youtubedl us f bestvideobestaudiobest default format selection see 5447 5456 ffmpeg avconv installed result downloading bestvideo bestaudio separately muxing together single file giving best overall quality available otherwise fall back best result downloading best available quality served single file best also needed video dont come youtube dont provide audio video two different file want download dash format example interested getting video resolution higher 1080p add f bestvideoheight1080bestaudiobest configuration file note use youtubedl stream stdout likely pipe medium player ie explicitly specify output template youtubedl still us f best format selection order start content delivery immediately player wait bestvideo bestaudio downloaded muxed want preserve old format selection behavior prior youtubedl 20150426 ie want download best available quality medium served single file explicitly specify choice f best may want add configuration file order type every time run youtubedl format selection example note window may need use double quote instead single download best mp4 format available best mp4 available youtubedl f bestvideoextmp4bestaudioextm4abestextmp4best download best format available better 480p youtubedl f bestvideoheight480bestaudiobestheight480 download best video format bigger 50 mb youtubedl f bestfilesize50m download best format available via direct link httphttps protocol youtubedl f bestvideobestaudiobestprotocolhttp download best video format best audio format without merging youtubedl f bestvideobestaudio titlesfformatidsexts note last example output template recommended bestvideo bestaudio may file name video selection video filtered upload date using option date datebefore dateafter accept date two format absolute date date format yyyymmdd relative date date format nowtoday09dayweekmonthyears example download video uploaded last 6 month youtubedl dateafter now6months download video uploaded january 1 1970 youtubedl date 19700101 download video uploaded 200x decade youtubedl dateafter 20000101 datebefore 20091231 faq update youtubedl youve followed manual installation instruction simply run youtubedl u linux sudo youtubedl u used pip simple sudo pip install u youtubedl sufficient update installed youtubedl using package manager like aptget yum use standard system update mechanism update note distribution package often outdated rule thumb youtubedl release least month often weekly even daily simply go httpsytdlorg find current version unfortunately nothing youtubedl developer distribution serf really outdated version complain distribution bugtracker support forum last resort also uninstall version installed package manager follow manual installation instruction remove distribution package line like sudo aptget remove youtubedl afterwards simply follow manual installation instruction sudo wget httpsgithubcoml1vingyoutubedlreleaseslatestdownloadyoutubedl usrlocalbinyoutubedl sudo chmod arx usrlocalbinyoutubedl hash r youll able update sudo youtubedl u youtubedl extremely slow start window add file exclusion youtubedlexe window defender setting im getting error unable extract opengraph title youtube playlist youtube changed playlist format march 2014 later youll need least youtubedl 20140725 download youtube video installed youtubedl package manager pip setuppy tarball please use update note ubuntu package seem get updated anymore since affiliated ubuntu little feel free report bug ubuntu packaging people update package somewhat recent version see way update im getting error trying use output template error using output template conflict using title video id auto number make sure using option title id autonumber set command line configuration file remove latter always pas citw default youtubedl intends best option incidentally convincing case different please file issue explain therefore unnecessary sometimes harmful copy long option string webpage particular option citw regularly useful please put b option back people asking question aware youtubedl default downloading highest available quality reported youtube 1080p 720p case longer need b option specific video maybe youtube doe report available specific high quality format youre interested case simply request f option youtubedl try download get http error 402 trying download video whats apparently youtube requires pas captcha test download much considering provide way let solve captcha moment best course action pointing web browser youtube url solving captcha restart youtubedl need program youtubedl work fine site however want convert videoaudio youll need avconv ffmpeg site notably youtube video retrieved higher quality format without sound youtubedl detect whether avconvffmpeg present automatically pick best option video video format streamed via rtmp protocol downloaded rtmpdump installed downloading mm rtsp video requires either mplayer mpv installed downloaded video play video fully downloaded use video player mpv vlc mplayer extracted video url g doe play another machine web browser depends lot service many case request video downloadplay must come ip address cooky andor http header use cooky option write required cooky file advise downloader read cooky file site also require common user agent used use dumpuseragent see one use youtubedl also get necessary cooky http header json output obtained dumpjson may beneficial use ipv6 case restriction applied ipv4 service sometimes subset video restrict video url ip address cookie useragent exception rather rule please bear mind url protocol supported browser box including rtmp using g downloader must support well want play video machine running youtubedl relay video content machine run youtubedl use let youtubedl stream video stdout simply allow player download file written youtubedl turn error fmturlmap conn information found video info youtube ha switched new video info format july 2011 supported old version youtubedl see update youtubedl error unable download video youtube requires additional signature since september 2012 supported old version youtubedl see update youtubedl video url contains ampersand im getting strange output 1 2839 v recognized internal external command thats actually output shell since ampersand one special shell character interpreted shell preventing passing whole url youtubedl disable shell interpreting ampersand special character either put whole url quote escape backslash approach work depends shell example url httpswwwyoutubecomwatcht4vbawjenozkc end following command youtubedl httpswwwyoutubecomwatcht4vbawjenozkc youtubedl httpswwwyoutubecomwatcht4vbawjenozkc window use double quote youtubedl httpswwwyoutubecomwatcht4vbawjenozkc extractorerror could find j function uof february 2015 new youtube player contained character sequence string wa misinterpreted old version youtubedl see update youtubedl http error 429 many request 402 payment required two error code indicate service blocking ip address overuse usually soft block meaning gain access solving captcha open browser solve captcha service suggests pas cooky youtubedl note machine ha multiple external ip also pas exactly ip youve used solving captcha sourceaddress also may need pas useragent http header browser useragent case captcha suggested solve service contact service ask unblock ip address acquired whitelisted ip address already use proxy sourceaddress option select another ip address syntaxerror nonascii character error file youtubedl line 2 syntaxerror nonascii character x93 mean youre using outdated version python please update python 26 27 binary file ha code gone since june 2012 342 youtubedl packed executable zipfile simply unzip might need renaming youtubedlzip first system clone git repository laid modify code run executing mainpy file recompile executable run make youtubedl exe throw error due missing msvcr100dll run exe need install first microsoft visual c 2010 redistributable package x86 window set ffmpeg youtubedl put exe file put youtubedl ffmpeg directory youre running command work thats rather cumbersome make different directory work either ffmpeg youtubedl simply create directory say cbin cusersuser namebin put executables directly set path environment variable include directory restarting shell able access youtubedl ffmpeg youtubedl able find ffmpeg simply typing youtubedl ffmpeg matter directory youre put downloads specific folder use specify output template example homeuservideostitlesidsexts want downloads put option configuration file download video starting either prepend httpswwwyoutubecomwatchv separate id option youtubedl wnyeurxzfu youtubedl httpswwwyoutubecomwatchvwnyeurxzfu pas cooky youtubedl use cooky option example cooky pathtocookiesfiletxt order extract cooky browser use conforming browser extension exporting cooky example cookiestxt chrome cookiestxt firefox note cooky file must mozillanetscape format first line cooky file must either http cookie file netscape http cookie file make sure correct newline format cooky file convert newlines necessary correspond namely crlf rn window lf n unix unixlike system linux macos etc http error 400 bad request using cooky good sign invalid newline format passing cooky youtubedl good way workaround login particular extractor doe implement explicitly another use case working around captcha website require solve particular case order get access eg youtube cloudflare stream directly medium player first need tell youtubedl stream medium stdout also tell medium player read stdin must capable streaming pipe former latter example streaming vlc achieved youtubedl httpswwwyoutubecomwatchvbawjenozkcj vlc download new video playlist use downloadarchive feature feature initially download complete playlist downloadarchive pathtodownloadarchivefiletxt record identifier video special file subsequent run downloadarchive download new video skip video downloaded note successful downloads recorded file example first youtubedl downloadarchive archivetxt httpswwwyoutubecomplaylistlistplwiyx1dc3p2jr9n8gqaqnbcvlslap7re download complete plwiyx1dc3p2jr9n8gqaqnbcvlslap7re playlist create file archivetxt subsequent run download new video youtubedl downloadarchive archivetxt httpswwwyoutubecomplaylistlistplwiyx1dc3p2jr9n8gqaqnbcvlslap7re add hlsprefernative config youtubedl detects hl video download either builtin downloader ffmpeg since many hl stream slightly invalid ffmpegyoutubedl handle invalid case better option switch downloader needed youtubedl know one particular downloader work better given website downloader picked otherwise youtubedl pick best downloader general compatibility moment happens ffmpeg choice may change future version youtubedl improvement builtin downloader andor ffmpeg particular generic extractor used website list supported site youtubedl cannot mandate one specific downloader put either hlsprefernative hlspreferffmpeg configuration different subset video fail download correctly instead much better file issue pull request detail native ffmpeg hl downloader better choice use case add support anime video site site show current movie free matter policy well legality youtubedl doe include support service specialize infringing copyright rule thumb cannot easily find video service quite obviously allowed distribute ie ha uploaded creator creator distributor published free license service probably unfit inclusion youtubedl note service dont host infringing content link evidence service included youtubedl go dmca note whole front page service filled video allowed distribute fair use note equally unconvincing service show copyrightprotected video full without authorization support request service purchase right distribute content perfectly fine though doubt simply include source mention legitimate purchase content speed work issue also known help important issue solved youtubedl core developer team quite small best solve many issue possible sometimes take quite speed issue first please report issue issue tracker allows u coordinate effort user developer serf unified point unfortunately youtubedl project ha grown large use personal email effective communication channel please read bug reporting instruction lot bug lack necessary information offer proxy vpn shell access youtubedl developer able test issue multiple computer multiple country exclude local censorship misconfiguration issue nobody interested solving issue welcome take matter hand submit pull request coercepay somebody else feel free bump issue time time writing small comment issue still present youtubedl version france fixed belgium please month please declare issue important urgent detect whether given url supported youtubedl one look list supported site note sometimes happen site change url scheme say httpsexamplecomvideo1234567 httpsexamplecomv1234567 youtubedl report url service list unsupported case simply report bug possible detect whether url supported thats youtubedl contains generic extractor match url may tempted disable exclude remove generic extractor generic extractor allows user extract video lot website embed video another service may also used extract video service hosting therefore neither recommend support disabling excluding removing generic extractor want find whether given url supported simply call youtubedl get video back chance url either referring video unsupported find examining output run youtubedl console catching unsupportederror exception run python program need go much red tape filing bug issue template despite extensive bug reporting instruction 80 issue report got useless instance people used ancient version hundred release old simple syntactic error youtubedl general shell usage problem wa already reported multiple time people actually read error message even said please install ffmpeg people mention url trying download many simple easytoavoid problem many totally unrelated youtubedl youtubedl opensource project manned volunteer wed rather spend time fixing bug certain none simple problem apply reasonably confident able reproduce issue without asking reporter repeatedly output youtubedl v yoururlhere really thats required file issue issue template also guide basic step checking version youtubedl current developer instruction user need build youtubedl download build get distribution run youtubedl developer dont need build anything either simply execute python youtubedl run test simply invoke favorite test runner execute test file directly following work python unittest discover python testtestdownloadpy nosetests see item 6 new extractor tutorial run extractor specific test case want create build youtubedl youll need python make gnu make supported pandoc zip nosetests adding support new site want add support new site first make sure site dedicated copyright infringement youtubedl doe support site thus pull request adding support rejected ensured site distributing content legally follow quick list assuming service called yourextractor fork repository check source code git clone gitgithubcomyourgithubusernameyoutubedlgit start new git branch cd youtubedl git checkout b yourextractor start simple template save youtubedlextractoryourextractorpy coding utf8 future import unicodeliterals common import infoextractor class yourextractorieinfoextractor validurl rhttpswwwyourextractorcomwatchpid09 test url httpsyourextractorcomwatch42 md5 todo md5 sum first 10241 byte video file use test infodict id 42 ext mp4 title video title go thumbnail rrehttpsjpg todo property either value md5 checksum start string md5 regular expression start string python type example int float def realextractself url videoid selfmatchidurl webpage selfdownloadwebpageurl videoid todo code go example title selfhtmlsearchregexrh1h1 webpage title return id videoid title title description selfogsearchdescriptionwebpage uploader selfsearchregexrdividuploader webpage uploader fatalfalse todo property see youtubedlextractorcommonpy add import youtubedlextractorextractorspy run python testtestdownloadpy testdownloadtestyourextractor fail first continually rerun youre done decide add one test rename test test make list dictionary test named testdownloadtestyourextractor testdownloadtestyourextractor1 testdownloadtestyourextractor2 etc note test onlymatching key test dict counted look youtubedlextractorcommonpy possible helper method detailed description extractor may return add test code many want make sure code follows youtubedl coding convention check code flake8 flake8 youtubedlextractoryourextractorpy make sure code work python version claimed supported youtubedl namely 26 27 32 test pas add new file commit push result like git add youtubedlextractorextractorspy git add youtubedlextractoryourextractorpy git commit yourextractor add new extractor git push origin yourextractor finally create pull request well review merge case thank much contribution youtubedl coding convention section introduces guide line writing idiomatic robust futureproof extractor code extractor fragile nature since depend layout source data provided 3rd party medium hosters control layout tends change extractor implementer task write code extract medium link metadata correctly also minimize dependency source layout even make code foresee potential future change ready important allow extractor break minor layout change thus keeping old youtubedl version working even though breakage issue easily fixed emitting new version youtubedl fix incorporated previous version become broken repository distros package may prompt fetching update u needle say non rolling release distros may never receive update mandatory optional metafields extraction work youtubedl relies metadata extractor extract provides youtubedl expressed information dictionary simply info dict following meta field info dict considered mandatory successful extraction process youtubedl id medium identifier title medium title url medium download url format fact last option technically mandatory ie cant figure download location medium extraction doe make sense convention youtubedl also treat id title mandatory thus aforementioned metafields critical data extraction doe make sense without fail extracted extractor considered completely broken field apart aforementioned one considered optional mean extraction tolerant situation source field potentially unavailable even always available moment futureproof order break extraction general purpose mandatory field example say source dictionary meta youve fetched json http request ha key summary meta selfdownloadjsonurl videoid assume point metas layout summary fancy summary text assume want extract summary put resulting info dict description since description optional meta field ready key may missing meta dict extract like description metagetsummary correct like description metasummary incorrect latter break extraction process keyerror summary disappears meta later time former approach extraction go ahead description set none perfectly fine remember none equivalent absence data similarly pas fatalfalse extracting optional data webpage searchregex htmlsearchregex similar method instance description selfsearchregex rspanidtitle webpage description fatalfalse fatal set false searchregex fails extract description emit warning continue extraction also pas defaultsome fallback value example description selfsearchregex rspanidtitle webpage description defaultnone failure code silently continue extraction description set none useful metafields may may present provide fallback extracting metadata try multiple source example title present several place try extracting least make futureproof case source become unavailable example say meta previous example ha title extract since title mandatory meta field end something like title metatitle title disappears meta future due change hosters side extraction would fail since title mandatory thats expected assume another source extract title example ogtitle html meta webpage case provide fallback scenario title metagettitle selfogsearchtitlewebpage code try extract meta first fails try extracting ogtitle webpage regular expression dont capture group dont use capturing group must indication used somewhere code group used must non capturing example dont capture id attribute name since cant use anything anyway correct rididpidd incorrect rididpidd make regular expression relaxed flexible using regular expression try write fuzzy relaxed flexible skipping insignificant part likely change allowing single double quote quoted value example say need extract title following html code span styleposition absolute left 910px width 90px float right zindex 9999 classtitlesome fancy titlespan code task look similar title selfsearchregex rspanclasstitle webpage title even better title selfsearchregex rspanclasstitle1ptitle webpage title grouptitle note tolerate potential change style attribute value switch using double quote single class attribute code definitely look like title selfsearchregex rspan styleposition absolute left 910px width 90px float right zindex 9999 classtitlespan webpage title grouptitle long line policy soft limit keep line code 80 character long mean respected possible doe make readability code maintenance worse example never split long string literal like url often copied entity multiple line fit limit correct httpswwwyoutubecomwatchvfqztn594jqwlistplmyetvrpaqy00v9w81cwmzp6n6vzqfukd4 incorrect httpswwwyoutubecomwatchvfqztn594jqwlist plmyetvrpaqy00v9w81cwmzp6n6vzqfukd4 inline value extracting variable acceptable reducing code duplication improving readability complex expression however avoid extracting variable used moving opposite part extractor file make reading linear flow difficult example correct title selfhtmlsearchregexrtitletitle webpage title incorrect titlere rtitletitle line code title selfhtmlsearchregextitlere webpage title collapse fallback multiple fallback value quickly become unwieldy collapse multiple fallback value single expression via list pattern example good description selfhtmlsearchmeta ogdescription description twitterdescription webpage description defaultnone unwieldy description selfogsearchdescriptionwebpage defaultnone selfhtmlsearchmetadescription webpage defaultnone selfhtmlsearchmetatwitterdescription webpage defaultnone method supporting list pattern searchregex htmlsearchregex ogsearchproperty htmlsearchmeta trailing parenthesis always move trailing parenthesis last argument example correct lambda x xresultsetresult0videourlsetvideourl list incorrect lambda x xresultsetresult0videourlsetvideourl list use convenience conversion parsing function wrap extracted numeric data safe function youtubedlutilspy intornone floatornone use string number conversion well use urlornone safe url processing use tryget safe metadata extraction parsed json use unifiedstrdate uniform uploaddate yyyymmdd meta field extraction unifiedtimestamp uniform timestamp extraction parsefilesize filesize extraction parsecount count meta field extraction parseresolution parseduration duration extraction parseagelimit agelimit extraction explore youtubedlutilspy useful convenience function example safely extract optional description parsed json description trygetresponse lambda x xresultvideo0summary compatstr safely extract optional metadata video trygetresponse lambda x xresultvideo0 dict description videogetsummary duration floatornonevideogetdurationms scale1000 viewcount intornonevideogetviews embedding youtubedl youtubedl make best effort good commandline program thus callable programming language encounter problem parsing output feel free create report python program embed youtubedl powerful fashion like future import unicodeliterals import youtubedl ydlopts youtubedlyoutubedlydlopts ydl ydldownloadhttpswwwyoutubecomwatchvbawjenozkc likely youll want use various option list option available look youtubedlyoutubedlpy start want intercept youtubedls output set logger object complete example program output error short message download finished downloadsconverts video mp3 file future import unicodeliterals import youtubedl class myloggerobject def debugself msg pas def warningself msg pas def errorself msg printmsg def myhookd dstatus finished printdone downloading converting ydlopts format bestaudiobest postprocessors key ffmpegextractaudio preferredcodec mp3 preferredquality 192 logger mylogger progresshooks myhook youtubedlyoutubedlydlopts ydl ydldownloadhttpswwwyoutubecomwatchvbawjenozkc bug bug suggestion reported httpsgithubcomytdlorgyoutubedlissues unless prompted another pertinent reason eg github fails accept bug report please send bug report via personal email discussion join u irc channel youtubedl freenode webchat please include full output youtubedl run v ie add v flag command line copy whole output post issue body wrapped better formatting look similar youtubedl v command line debug system config debug user config debug commandline args uv uhttpswwwyoutubecomwatchvbawjenozkcj debug encoding locale cp1251 f mbcs cp866 pref cp1251 debug youtubedl version 20151206 debug git head 135392e debug python version 266 windows2003server523790sp2 debug exe version ffmpeg n75573g1d0487f ffprobe n75573g1d0487f rtmpdump 24 debug proxy map post screenshots verbose log plain text acceptable output including first line contains important debugging information issue without full output often reproducible therefore get solved short order ever please reread issue avoid couple common mistake use checklist description issue sufficient often get issue report cannot really decipher case eventually get required information asking back multiple time pose unnecessary drain resource many contributor including also native speaker may misread part please elaborate feature requesting bug want fixed make sure obvious problem could fixed proposed solution would look like report shorter two line almost certainly missing make hard u respond often polite close issue outright missing info make misinterpretation likely committer often get frustrated issue since possible way move forward ask clarification bug report mean report contain complete output youtubedl called v flag error message get bug even say would believe many bug report contain information server ha multiple ip suspect censorship adding callhome may good idea get diagnostics error error unable extract cannot reproduce multiple country add dumppages warning yield rather large output redirect file logtxt adding logtxt 21 commandline upload dump file get add writepages somewhere site support request must contain example url example url url might want download like httpswwwyoutubecomwatchvbawjenozkc obvious video present except special circumstance main page video service eg httpswwwyoutubecom example url using latest version reporting issue type youtubedl u report youre uptodate 20 report receive already fixed people using outdated version go feature request well issue already documented make sure someone ha already opened issue youre trying open search top window browse github issue repository issue feel free write something along line affect well version 20150101 information issue issue may old new post often spur rapid activity existing option enough requesting new feature please quick peek list supported option many feature request feature actually exist already please absolutely show work issue report detail existing similar option solve problem enough context bug report people want solve problem often think u favor breaking larger problem eg wanting skip already downloaded file specific request eg requesting u look whether file exists downloading info page however often happens break problem two step one simple one impossible extremely complicated one presented complicated request original problem could solved far easier eg recording downloaded video id separate file avoid must include greater context nonobvious particular every feature request doe consist adding support new site contain use case scenario explains situation missing feature would useful doe issue involve one problem one problem user seem think limit issue open limit issue open may seem appealing able dump issue one ticket mean someone solves one issue cannot mark issue closed typically reporting bunch issue lead ticket lingering since nobody want attack behemoth someone mercifully split issue multiple one particular every site support request issue pertain service one site generally common domain always using backend technology request support vimeo user video white house podcasts google plus page issue also make sure dont post bug report alongside feature request rule thumb feature request doe include output youtubedl immediately related feature hand post report network error alongside request new video service anyone going need feature post feature incapacitated friend personally talk require post feature seem like good idea really useful requested someone requires question youtubedl may sound strange bug report receive completely unrelated youtubedl relate different even reporter application please make sure actually using youtubedl using ui youtubedl report bug maintainer actual application providing ui hand ui youtubedl fails way believe related youtubedl mean go ahead report bug copyright youtubedl released public domain copyright holder readme file wa originally written daniel bolton likewise released public domain\n",
      "  (0, 15548)\t0.012068203317419418\n",
      "  (0, 15547)\t0.012068203317419418\n",
      "  (0, 15546)\t0.012068203317419418\n",
      "  (0, 15545)\t0.012068203317419418\n",
      "  (0, 15544)\t0.012068203317419418\n",
      "  (0, 15543)\t0.012068203317419418\n",
      "  (0, 15531)\t0.012068203317419418\n",
      "  (0, 15530)\t0.012068203317419418\n",
      "  (0, 15529)\t0.012068203317419418\n",
      "  (0, 15525)\t0.012068203317419418\n",
      "  (0, 15524)\t0.012068203317419418\n",
      "  (0, 15523)\t0.012068203317419418\n",
      "  (0, 15522)\t0.012068203317419418\n",
      "  (0, 15521)\t0.012068203317419418\n",
      "  (0, 15520)\t0.012068203317419418\n",
      "  (0, 15519)\t0.012068203317419418\n",
      "  (0, 15518)\t0.012068203317419418\n",
      "  (0, 15517)\t0.012068203317419418\n",
      "  (0, 15516)\t0.012068203317419418\n",
      "  (0, 15515)\t0.012068203317419418\n",
      "  (0, 15514)\t0.012068203317419418\n",
      "  (0, 15513)\t0.012068203317419418\n",
      "  (0, 15512)\t0.012068203317419418\n",
      "  (0, 15508)\t0.012068203317419418\n",
      "  (0, 15507)\t0.012068203317419418\n",
      "  :\t:\n",
      "  (0, 72)\t0.012068203317419418\n",
      "  (0, 71)\t0.012068203317419418\n",
      "  (0, 70)\t0.012068203317419418\n",
      "  (0, 63)\t0.012068203317419418\n",
      "  (0, 62)\t0.010628124983651673\n",
      "  (0, 61)\t0.012068203317419418\n",
      "  (0, 60)\t0.012068203317419418\n",
      "  (0, 59)\t0.012068203317419418\n",
      "  (0, 58)\t0.012068203317419418\n",
      "  (0, 57)\t0.012068203317419418\n",
      "  (0, 52)\t0.012068203317419418\n",
      "  (0, 51)\t0.012068203317419418\n",
      "  (0, 50)\t0.012068203317419418\n",
      "  (0, 49)\t0.012068203317419418\n",
      "  (0, 48)\t0.012068203317419418\n",
      "  (0, 47)\t0.012068203317419418\n",
      "  (0, 46)\t0.012068203317419418\n",
      "  (0, 39)\t0.012068203317419418\n",
      "  (0, 38)\t0.012068203317419418\n",
      "  (0, 37)\t0.012068203317419418\n",
      "  (0, 31)\t0.012068203317419418\n",
      "  (0, 30)\t0.012068203317419418\n",
      "  (0, 29)\t0.008813840848202576\n",
      "  (0, 5)\t0.012068203317419418\n",
      "  (0, 4)\t0.012068203317419418\n",
      "try newer example repo newer example demonstrating vue microfrontends found httpsgithubcomvuemicrofrontends httpsvuemicrofrontendsapp example better reflects microfrontends architecture encouraged use coexisting vue microfrontends demo httpcoexistingvuemicrofrontendssurgesh starterkit example repository people want multiple vue microfrontends coexist within single page vue application wa created vue cli us singlespa pull mean even add react angular framework additional microfrontends important note github repository ha four project one repo youll want one git repo per vue application roothtmlfile project also repo let different team developer charge different microfrontends local development one app time tutorial video singlespa preferred run npm run serve one singlespa application time using deployed version application make awesome developer experience boot one microfrontend time even clone npm install boot one try clone repo run following command cd app1 npm npm run serve go httpcoexistingvuemicrofrontendssurgesh browser browser console run localstoragesetitemoverridesui true refresh page click yellowish rectangle bottom right click app1 change module url httplocalhost8081jsappjs apply override reload page change app1 load localhost instead surgesh modify code locally reload page coexistingvuemicrofrontendssurgesh see httpsgithubcomjoeldenningimportmapoverrides info local development preferred run one app time need run locally following instruction first terminal tab cd roothtmlfile npm install npm run serve second terminal tab cd app1 npm install npm run serve third terminal tab cd app2 npm install npm run serve fourth terminal tab cd navbar npm install npm run serve go httplocalhost5000 browser note change port project modifying import map inside roothtmlfileindexhtml get serious deploying code youll want make longer necessary boot apps order anything get point check importmapoverrides let go deployed environment override import map one microfrontend time importmapoverrides library already loaded indexhtml roothtmlfile start using immediately make deployed environment overridable like override httpcoexistingvuemicrofrontendssurgesh documentation go httpssinglespajsorgdocsecosystemvuehtml learn work\n",
      "  (0, 15311)\t0.05164947896699808\n",
      "  (0, 15307)\t0.03968572751648721\n",
      "  (0, 15296)\t0.058647824933495275\n",
      "  (0, 15295)\t0.058647824933495275\n",
      "  (0, 15109)\t0.02772197606597635\n",
      "  (0, 14885)\t0.058647824933495275\n",
      "  (0, 14882)\t0.05164947896699808\n",
      "  (0, 14877)\t0.058647824933495275\n",
      "  (0, 14862)\t0.02772197606597635\n",
      "  (0, 14844)\t0.058647824933495275\n",
      "  (0, 14843)\t0.04283260577081553\n",
      "  (0, 14839)\t0.058647824933495275\n",
      "  (0, 14838)\t0.058647824933495275\n",
      "  (0, 14837)\t0.058647824933495275\n",
      "  (0, 14836)\t0.058647824933495275\n",
      "  (0, 14714)\t0.058647824933495275\n",
      "  (0, 14621)\t0.04283260577081553\n",
      "  (0, 14573)\t0.058647824933495275\n",
      "  (0, 14566)\t0.02922379633859103\n",
      "  (0, 14391)\t0.058647824933495275\n",
      "  (0, 14386)\t0.058647824933495275\n",
      "  (0, 14370)\t0.0250613284126298\n",
      "  (0, 14165)\t0.058647824933495275\n",
      "  (0, 14149)\t0.02387050835380747\n",
      "  (0, 14099)\t0.058647824933495275\n",
      "  :\t:\n",
      "  (0, 918)\t0.058647824933495275\n",
      "  (0, 915)\t0.04283260577081553\n",
      "  (0, 895)\t0.058647824933495275\n",
      "  (0, 892)\t0.04668407348298441\n",
      "  (0, 878)\t0.058647824933495275\n",
      "  (0, 876)\t0.04668407348298441\n",
      "  (0, 869)\t0.058647824933495275\n",
      "  (0, 867)\t0.058647824933495275\n",
      "  (0, 865)\t0.058647824933495275\n",
      "  (0, 861)\t0.05164947896699808\n",
      "  (0, 853)\t0.04283260577081553\n",
      "  (0, 830)\t0.058647824933495275\n",
      "  (0, 829)\t0.058647824933495275\n",
      "  (0, 828)\t0.058647824933495275\n",
      "  (0, 827)\t0.058647824933495275\n",
      "  (0, 826)\t0.058647824933495275\n",
      "  (0, 825)\t0.058647824933495275\n",
      "  (0, 823)\t0.058647824933495275\n",
      "  (0, 811)\t0.03472032203247354\n",
      "  (0, 770)\t0.058647824933495275\n",
      "  (0, 769)\t0.058647824933495275\n",
      "  (0, 569)\t0.058647824933495275\n",
      "  (0, 565)\t0.04283260577081553\n",
      "  (0, 545)\t0.058647824933495275\n",
      "  (0, 522)\t0.03268738154999002\n",
      "babelpresetenv ha stabilized ha moved main babel monorepo repo ha archived move make much easier release develop sync rest babel repo made readonly issueslabels moved well please report bug open pull request main monorepo babelpresetenv babel preset compiles es2015 es5 automatically determining babel plugins polyfills need based targeted browser runtime environment npm install babelpresetenv savedev without configuration option babelpresetenv behaves exactly babelpresetlatest babelpresetes2015 babelpresetes2016 babelpresetes2017 together however dont recommend using presetenv way doesnt take advantage greater capability targeting specific browser presets env also configure include polyfills transforms needed browser support compiling whats needed make bundle smaller life easier example includes polyfills code transforms needed coverage user 025 ignoring internet explorer 11 opera mini use browserslist parse information use valid query format supported browserslist presets env target refers global coverage user browserslist browser 025 ie 11 opmini also target individual version browser instead using query target chrome 52 similarly youre targeting nodejs instead browser configure babelpresetenv include polyfills transforms necessary particular version presets env target node 610 convenience use node current include necessary polyfills transforms nodejs version use run babel presets env target node current check many option especially usebuiltins polyfill le work install usage option example caveat cool project work determine environment support ecmascript feature use external data compattable determine browser support create pr necessary periodically run builddatajs generates pluginsjson ref 7 maintain mapping javascript feature babel plugins currently located pluginfeaturesjs straightforward case might case plugins split certain plugins arent standalone enough impossible support plugins babel considered latest default behavior without option babelpresetlatest wont include stagex plugins env support plugins consider latest version javascript matching babelpresetlatest ref 14 determine lowest common denominator plugins included preset targeting ie 8 chrome 55 include plugins required ie 8 since would need support still support target option node current compile currently running node version example building node 6 arrow function wont converted build node 012 support browser option like autoprefixer use browserslist declare supported environment performing query like 1 last 2 version ref 19 install npm npm install savedev babelpresetenv yarn yarn add babelpresetenv dev usage default behavior without option run transforms behaves babelpresetlatest presets env option information setting option preset refer pluginpreset option documentation target string number string default take object environment version support target environment take number string recommend using string specifying minor version like node 610 example environment chrome opera edge firefox safari ie io android node electron data generated running builddata script pull data compattable targetsnode number string current true want compile current node version specify node true node current would node processversionsnode targetsbrowsers arraystring string query select browser ex last 2 version 5 using browserslist note browser result overridden explicit item target targetsuglify true using uglifyjs minify code may run syntax error targeting later browser since uglifyjs doe support es2015 syntax prevent error set uglify option true enables transformation plugins result code fully compiled es5 however usebuiltins option still work include polyfills target need uglify ha support es2015 syntax via uglifyes using syntax unsupported uglifyes recommend using babelminify note option deprecated 2x replaced forcealltransforms option spec boolean default false enable spec compliant potentially slower transformation plugins preset support loose boolean default false enable loose transformation plugins preset allow module amd umd systemjs commonjs false default commonjs enable transformation es6 module syntax another module type setting false transform module debug boolean default false output targetsplugins used version specified plugin data version consolelog include arraystring default note whitelist deprecated removed next major favor array plugins always include valid option include babel plugins babelplugintransformes2015spread without prefix transformes2015spread supported builtins map set objectassign option useful bug native implementation combination nonsupported feature supported one doesnt work example node 4 support native class spread super used spread argument transformes2015classes transform need included possible transpile spread super otherwise note include exclude option work plugins included preset example including transformdoexpressions excluding transformfunctionbind throw error use plugin included preset add config directly exclude arraystring default array plugins always excluderemove possible option include option option useful blacklisting transform like transformregenerator dont use generator dont want include regeneratorruntime using usebuiltins using another plugin like fastasync instead babel asynctogen usebuiltins boolean default false way apply babelpresetenv polyfills via babelpolyfill note doe currently polyfill experimentalstagex builtins like regular babelpolyfill doe work npm 3 used babel 6 anyway npm install babelpolyfill save option enables new plugin replaces statement import babelpolyfill requirebabelpolyfill individual requires babelpolyfill based environment note use requirebabelpolyfill whole app multiple import requires babelpolyfill throw error since cause global collision issue hard trace recommend creating single entry file contains require statement import babelpolyfill different based environment import corejsmoduleses7stringpadstart import corejsmoduleses7stringpadend import corejsmoduleswebtimers import corejsmoduleswebimmediate import corejsmoduleswebdomiterable also work corejs directly import corejs npm install corejs save example export various target export class target chrome 52 babelrc presets env target chrome 52 class exportsa target chrome 52 webpack 2rollup loose mode babelrc presets env target chrome 52 module false loose true export class target specific browser via browserslist babelrc presets env target chrome 52 browser last 2 version safari 7 export var function classcallcheckthis target latest node via node true node current babelrc presets env target node current class exportsa show debug output babelrc presets env target safari 10 module false usebuiltins true debug true stdout using target safari 10 module transform false using plugins transformexponentiationoperator transformasynctogenerator using polyfills es7objectvalues es7objectentries es7objectgetownpropertydescriptors webtimers webimmediate webdomiterable include exclude specific pluginsbuiltins always include arrow function explicitly exclude generator presets env target browser last 2 version safari 7 include transformes2015arrowfunctions es6map exclude transformregenerator es6set caveat get syntaxerror unexpected token error using objectrestspread transform make sure plugin ha updated least v6190 cool project babelpresetmodernbrowsers\n",
      "  (0, 15318)\t0.03160279742241576\n",
      "  (0, 15312)\t0.025156044896957788\n",
      "  (0, 15282)\t0.03160279742241576\n",
      "  (0, 15276)\t0.03160279742241576\n",
      "  (0, 15275)\t0.027831688943593433\n",
      "  (0, 15140)\t0.03160279742241576\n",
      "  (0, 15136)\t0.03160279742241576\n",
      "  (0, 15130)\t0.03160279742241576\n",
      "  (0, 15128)\t0.03160279742241576\n",
      "  (0, 15122)\t0.027831688943593433\n",
      "  (0, 15119)\t0.03160279742241576\n",
      "  (0, 15116)\t0.03160279742241576\n",
      "  (0, 15109)\t0.014938183892677497\n",
      "  (0, 15106)\t0.03160279742241576\n",
      "  (0, 15105)\t0.03160279742241576\n",
      "  (0, 15103)\t0.027831688943593433\n",
      "  (0, 15047)\t0.03160279742241576\n",
      "  (0, 15046)\t0.03160279742241576\n",
      "  (0, 15040)\t0.03160279742241576\n",
      "  (0, 15038)\t0.027831688943593433\n",
      "  (0, 15007)\t0.03160279742241576\n",
      "  (0, 15006)\t0.03160279742241576\n",
      "  (0, 14971)\t0.03160279742241576\n",
      "  (0, 14970)\t0.025156044896957788\n",
      "  (0, 14962)\t0.03160279742241576\n",
      "  :\t:\n",
      "  (0, 293)\t0.03160279742241576\n",
      "  (0, 292)\t0.03160279742241576\n",
      "  (0, 291)\t0.03160279742241576\n",
      "  (0, 290)\t0.03160279742241576\n",
      "  (0, 289)\t0.03160279742241576\n",
      "  (0, 288)\t0.03160279742241576\n",
      "  (0, 287)\t0.03160279742241576\n",
      "  (0, 210)\t0.03160279742241576\n",
      "  (0, 209)\t0.03160279742241576\n",
      "  (0, 208)\t0.03160279742241576\n",
      "  (0, 207)\t0.03160279742241576\n",
      "  (0, 110)\t0.03160279742241576\n",
      "  (0, 108)\t0.027831688943593433\n",
      "  (0, 92)\t0.03160279742241576\n",
      "  (0, 91)\t0.03160279742241576\n",
      "  (0, 65)\t0.03160279742241576\n",
      "  (0, 64)\t0.03160279742241576\n",
      "  (0, 62)\t0.027831688943593433\n",
      "  (0, 33)\t0.03160279742241576\n",
      "  (0, 29)\t0.023080654138226814\n",
      "  (0, 17)\t0.03160279742241576\n",
      "  (0, 16)\t0.03160279742241576\n",
      "  (0, 15)\t0.03160279742241576\n",
      "  (0, 9)\t0.03160279742241576\n",
      "  (0, 8)\t0.03160279742241576\n",
      "repo2docker repo2docker fetch git repository build container image based configuration file found repository see repo2docker documentation information using repo2docker support question please search post httpsdiscoursejupyterorgcbinder see contributing guide information contributing repo2docker using repo2docker prerequisite docker build run repository community edition recommended python 36 supported linux macos see documentation note window support installation quick guide installing repo2docker see documentation full guide install pypi pip install jupyterrepo2docker install source git clone httpsgithubcomjupyterhubrepo2dockergit cd repo2docker pip install e usage core feature repo2docker fetch git repository github locally build container image based specification found repository optionally launch container use explore repository note docker need running machine work example jupyterrepo2docker httpsgithubcomnorvigpytudes building might take output terminal something like copypaste url browser connect first time login token http000036511tokenf94f8fabb92e22f5bfab116c382b4707fc2cade56ad1ace0 copy paste url browser see jupyter notebook content repository built information use repo2docker see usage guide repository specification repo2docker look configuration file source repository determine docker image built list configuration file repo2docker use see complete list configuration file philosophy repo2docker inspired heroku build pack\n",
      "  (0, 15122)\t0.06605329563210575\n",
      "  (0, 15109)\t0.03545297875632226\n",
      "  (0, 15085)\t0.07500331457336482\n",
      "  (0, 15068)\t0.050753137194214\n",
      "  (0, 14413)\t0.07500331457336482\n",
      "  (0, 14370)\t0.032050339474488224\n",
      "  (0, 14239)\t0.07500331457336482\n",
      "  (0, 14186)\t0.07500331457336482\n",
      "  (0, 14167)\t0.07500331457336482\n",
      "  (0, 14149)\t0.030527427898936962\n",
      "  (0, 14142)\t0.07500331457336482\n",
      "  (0, 14138)\t0.07500331457336482\n",
      "  (0, 14136)\t0.04180311825295495\n",
      "  (0, 14083)\t0.07500331457336482\n",
      "  (0, 14081)\t0.04440299769758131\n",
      "  (0, 13602)\t0.07500331457336482\n",
      "  (0, 13600)\t0.06605329563210575\n",
      "  (0, 13473)\t0.07500331457336482\n",
      "  (0, 13458)\t0.04180311825295495\n",
      "  (0, 13309)\t0.06605329563210575\n",
      "  (0, 13305)\t0.047350497912379975\n",
      "  (0, 13049)\t0.07500331457336482\n",
      "  (0, 13039)\t0.04440299769758131\n",
      "  (0, 13028)\t0.07500331457336482\n",
      "  (0, 13021)\t0.07500331457336482\n",
      "  :\t:\n",
      "  (0, 2670)\t0.07500331457336482\n",
      "  (0, 2668)\t0.06605329563210575\n",
      "  (0, 2616)\t0.06605329563210575\n",
      "  (0, 2614)\t0.050753137194214\n",
      "  (0, 2385)\t0.07500331457336482\n",
      "  (0, 2378)\t0.050753137194214\n",
      "  (0, 2033)\t0.07500331457336482\n",
      "  (0, 2021)\t0.04440299769758131\n",
      "  (0, 1859)\t0.07500331457336482\n",
      "  (0, 1858)\t0.07500331457336482\n",
      "  (0, 1856)\t0.059703156135473064\n",
      "  (0, 1846)\t0.07500331457336482\n",
      "  (0, 1843)\t0.050753137194214\n",
      "  (0, 1829)\t0.06605329563210575\n",
      "  (0, 1824)\t0.07500331457336482\n",
      "  (0, 1814)\t0.07500331457336482\n",
      "  (0, 1803)\t0.03545297875632226\n",
      "  (0, 1691)\t0.07500331457336482\n",
      "  (0, 1680)\t0.07500331457336482\n",
      "  (0, 1670)\t0.04180311825295495\n",
      "  (0, 1345)\t0.07500331457336482\n",
      "  (0, 1339)\t0.07500331457336482\n",
      "  (0, 1337)\t0.04440299769758131\n",
      "  (0, 224)\t0.07500331457336482\n",
      "  (0, 223)\t0.07500331457336482\n",
      "browserpass important repository archived maintained anymore browserpass wa rewritten scratch split two repository browser extension browserpassextension native host app browserpassnative follow new repository installation instruction highly recommend read readme repository get acquainted new change faq 1 new version backwards compatible therefore need update browser extension native host time installed browser extension web store autoupdate must install browserpass native host v3 read browserpassnative installation section see provides updated package browserpass v3 follow manual installation step described section 2 upgrade wait autoupdate come use chromiumbased browser go browserpassextension release download latest browserpasswebstorecrx open chromeextensions enable developer mode dragndrop downloaded crx file finally proceed browserpassnative installation section install new version native host use firefox go browserpassextension release download latest firefoxzip file unpack folder firefox go aboutdebuggingaddons click load temporary addon install extension finally proceed browserpassnative installation section install new version native host unpack content firefoxzip usrsharemozillaextensionsec8030f7c20a464f9b0e13a3a9e97384browserpassmaximbazcom folder according experiment firefox treat persistent extension ignore whatever currently web store need load extension every firefox restart 3 keep old version dont time upgrade native host app hasnt updated browserpass package yet go latest v2 release download chromezip firefoxzip depending browser use unpack archive new directory load extension browser chromium go chromeextensions enable developer mode click load unpacked select folder unpacked content chromezip firefox go aboutdebuggingaddons click load temporary addon select folder unpacked content firefoxzip unpack content firefoxzip usrsharemozillaextensionsec8030f7c20a464f9b0e13a3a9e97384browserpassmaximbazcom folder according experiment firefox treat persistent extension ignore whatever currently web store need load extension every firefox restart 4 happened otp otp wa implemented browserpass v3 might implemented separate extension detail see support otp browserpass v3 browserpass chrome firefox extension zx2c4s pas unix based password manager retrieves decrypted password current domain allows autofill login form well copy clipboard multiple logins current site extension show list usernames choose us native binary written golang interfacing password store secure communication binary browser extension handled native messaging table content requirement installation update usage option security faq contributing license requirement recent version chrome chromium firefox 50 pas unix password filename must match username file must line starting login user username followed username example pas websitecomjohndoe thepassword pas websitecom thepassword login johndoe installation order install browserpass correctly install two component host application browser extension installing host application following browserpass package installed via package manager arch linux debian gnulinux macos make sure read instruction nixos make sure read instruction ubuntu listed proceed manual installation step download latest github release start downloading latest release package operating system verifying authenticity release release file signed pgp key verify signature given file use gpg verify filesig report gpg signature made gpg using rsa key 8053eb88879a68cb4873d32b011fdc52da839335 gpg good signature maxim baz gpg aka primary key fingerprint eb4f 9e5a 60d3 2232 bb52 150c 12c8 7a28 feac 6b20 subkey fingerprint 8053 eb88 879a 68cb 4873 d32b 011f dc52 da83 9335 installing host application extract package would like binary run installsh installps1 window install native messaging host want systemwide installation run script sudo window systemwide installation done running installps1 administrator specifying yes install user prompt desire noninteractive installation unix system pas name browser script eg installsh chrome installing binary registering browser installation script required allow browser extension talk local binary application installing host application window wsl already use pas wsl prefer single copy password store use browserpass wsl well install window host application see previous section well linux host application wsl create localappdatabrowserpassbrowserpasswslbat following content echo bash c browserpassbrowserpasslinux64 installed linux host application location different browserpass replace path script change path localappdatabrowserpassbrowserpassfirefoxjson chromejson point browserpasswslbat gpg key ha password host application running wsl wont able unlock since cant interactively prompt password mean cant decrypt password unless youve already got key loaded gpgagent workaround use key pas websitecom wsl terminal load key gpgagent browserpass work gpgagent time possible configure larger timeouts check manual gpgagent installing chrome extension either install chrome extension chrome web store drag chromebrowserpasscrx file release package chrome extension chromeextensions page installing firefox extension install firefox extension mozilla addons site please note need firefox 50 higher update important majority improvement require changing code browser extension host application trying maintain backwards compatibility expected make sure keep component date updating host application installed host application via package manager likely update way repeat installation instruction updating browser extension installed extension webstore receive update automatically repeat installation instruction extension usage click lock icon use ctrlshiftl open browserpass entry match current domain chrome allows changing shortcut via chromeextensions keyboard shortcut firefox unfortunately doe allow changing default shortcut firefox support keyboard shortcut since version 53 filter search mode browserpass ha two mode working password entry filter search opened browserpass automatically switch filter mode least one matching entry exists filter mode designed quickly refine search result example choose one several account given domain done client side filter always fuzzy always work real time browserpass filter mode see domain name input field exit filter mode press backspace search mode designed search password entry disk much expensive operation especially visible window thats real time instead search enter pressed search fuzzy default changed glob algorithm option want search everything interactively search use filter mode refine search real time fill submit login form click select entry want submit login form filled selected credential injected directly dom browserpass doe use clipboard focus input field hitting enter submit first entry list useful combination filter mode login button found focused hit enter submit form enable automatically submit form filling option login button pressed instead password entry ha otp configuration browserpass use point display code navigating entry navigate list available credential tab shifttab arrow key copy clipboard click username password button copy clipboard keyboard shortcut also available use ctrlc copy password selected entry shiftc copy username open url click globe button use g shortcut navigate url current tab hold shift open new tab instead also specify one following metadata field pas file control exactly url navigated url link website web site keep mind browserpass fill http basic auth credential open url using browserpass manual search prevent phishing attack browserpass prefills list password entry match current domain want search credential across entire password store exit filter mode backspace domain name input field disappear type search request hit enter start search instead using backspace also type search query filter mode soon matching result left browserpass automatically switch search mode await enter initiate search password store location deciding look password store browserpass us passwordstoredir environment variable defined check passwordstore folder however using custom store location setting option browser extension configure different location browserpass look even multiple location restriction define subfolders password store gopass mount folder ha pas entry one password store configured enabled order help distinguish password entry different location eg password work personal github account green badge next password entry appear indicating origin name password store option open setting configure browserpass right click lock icon option find browserpass list extension browser option list currently available option automatically submit form filling make browserpass automatically submit login form use fuzzy search whether manual search mode fuzzy filter mode always fuzzy custom store location allows configuring multiple password store location toggle fly security browserpass aim protect password computer malicious fraudulent website protect phishing password matching origin hostname suggested selected without explicit search term minimize attack surface website allowed trigger extension action without user invocation data selected password made available website given full control nonnative component extension attacker extract password stored configured repository obtain file elsewhere filesystem reach code execution faq doe work macos native host ha exited first install required dependency brew install gnupg pinentrymac important gpg binary usrlocalbingpg gpg another location create symlink sudo ln pathtoyourgpg usrlocalbingpg dont admin right create symlink workaround patch browser launcher edit gnupggpgconf comment remove line pinentrymode loopback add line useagent add following line gnupggpgagentconf pinentryprogram usrlocalbinpinentrymac restart gpgagent gpgconf kill gpgagent finally restart browser still experience issue try starting browser terminal help issue likely due absence usrlocalbingpg follow step make sure exists configuring browserpass nixos nix nixos wish stateless setup make sure etcnixosconfigurationnix rebuild system pkgs programsbrowserpassenable true environmentsystempackages pkgs browser work chromium firefox googlechrome vivaldi note firefoxbin version work statelessly require firefox version use stateful setup following section nix stateful install browserpass native messaging host nixenv ia nixpkgsbrowserpass install browser extension like normal link necessary file firefox mkdir p mozillanativemessaginghosts ln nixprofilelibmozillanativemessaginghostscomdannyvankootenbrowserpassjson mozillanativemessaginghosts chrome mkdir p configgooglechromenativemessaginghosts ln nixprofileetcchromehostjson configgooglechromenativemessaginghostscomdannyvankootenbrowserpassjson chromium mkdir p configchromiumnativemessaginghosts ln nixprofileetcchromehostjson configchromiumnativemessaginghostscomdannyvankootenbrowserpassjson vivaldi mkdir p configvivaldinativemessaginghosts ln nixprofileetcchromehostjson configvivaldinativemessaginghostscomdannyvankootenbrowserpassjson version firefox supported way installing browserpass macos homebrew browserpass isnt included main homebrew repository must installed adding third party tap requires one additional step brew tap dustinwilsontap brew install browserpass instead running installsh homebrew supply additional command called browserpasssetup handle work way installsh example install native host file firefox browserpasssetup firefox must install browser extension manually using conventional method browser information supplied running brew install browserpass configure otp easiest way add otp password entry use passotp dont configure anything extra browserpass automatically detect otp configured show code filling form contributing check contributing detail build browser extension host app source load browserpass unpacked extension browser license mit licensed\n",
      "  (0, 15554)\t0.02534987742770941\n",
      "  (0, 15553)\t0.02534987742770941\n",
      "  (0, 15510)\t0.02534987742770941\n",
      "  (0, 15503)\t0.01851392285103217\n",
      "  (0, 15299)\t0.02534987742770941\n",
      "  (0, 15297)\t0.020178677418332416\n",
      "  (0, 15246)\t0.02534987742770941\n",
      "  (0, 15245)\t0.02534987742770941\n",
      "  (0, 15244)\t0.02534987742770941\n",
      "  (0, 15243)\t0.02534987742770941\n",
      "  (0, 15242)\t0.02534987742770941\n",
      "  (0, 15240)\t0.02534987742770941\n",
      "  (0, 15239)\t0.022324919338494977\n",
      "  (0, 15236)\t0.02534987742770941\n",
      "  (0, 15234)\t0.020178677418332416\n",
      "  (0, 15166)\t0.02534987742770941\n",
      "  (0, 15160)\t0.01715371932911798\n",
      "  (0, 15155)\t0.02534987742770941\n",
      "  (0, 15154)\t0.02534987742770941\n",
      "  (0, 15152)\t0.022324919338494977\n",
      "  (0, 15150)\t0.02534987742770941\n",
      "  (0, 15146)\t0.02534987742770941\n",
      "  (0, 15144)\t0.02534987742770941\n",
      "  (0, 15139)\t0.02534987742770941\n",
      "  (0, 15133)\t0.02534987742770941\n",
      "  :\t:\n",
      "  (0, 367)\t0.02534987742770941\n",
      "  (0, 366)\t0.02534987742770941\n",
      "  (0, 359)\t0.02534987742770941\n",
      "  (0, 358)\t0.02534987742770941\n",
      "  (0, 346)\t0.02534987742770941\n",
      "  (0, 345)\t0.02534987742770941\n",
      "  (0, 344)\t0.02534987742770941\n",
      "  (0, 343)\t0.02534987742770941\n",
      "  (0, 321)\t0.02534987742770941\n",
      "  (0, 320)\t0.02534987742770941\n",
      "  (0, 295)\t0.02534987742770941\n",
      "  (0, 294)\t0.02534987742770941\n",
      "  (0, 271)\t0.02534987742770941\n",
      "  (0, 269)\t0.02534987742770941\n",
      "  (0, 267)\t0.020178677418332416\n",
      "  (0, 264)\t0.02534987742770941\n",
      "  (0, 263)\t0.02534987742770941\n",
      "  (0, 183)\t0.02534987742770941\n",
      "  (0, 182)\t0.02534987742770941\n",
      "  (0, 99)\t0.02534987742770941\n",
      "  (0, 98)\t0.02534987742770941\n",
      "  (0, 80)\t0.02534987742770941\n",
      "  (0, 79)\t0.02534987742770941\n",
      "  (0, 7)\t0.02534987742770941\n",
      "  (0, 6)\t0.02534987742770941\n",
      "edvr ha merged basicsr github repo mirror basicsr recommend use basicsr open issue pull request etc basicsr note version compatible previous version want use previous one please refer oldversion branch basicsr english github gitee google drive pretrained model reproduced experiment training curve wandb command training testing howtos basicsr open source image video superresolution toolbox based pytorch extend restoration task future esrgan edvr dni sftgan new feature sep 8 2020 add blind face restoration inference code dfdnet note slightly different official testing code blind face restoration via deep multiscale component dictionary xiaoming li chaofeng chen shangchen zhou xianhui lin wangmeng zuo lei zhang european conference computer vision eccv 2020 aug 27 2020 add stylegan2 training testing code stylegan2 analyzing improving image quality stylegan tero karras samuli laine miika aittala janne hellsten jaakko lehtinen timo aila computer vision pattern recognition cvpr 2020 aug 19 2020 brandnew basicsr v100 online howtos provides simple pipeline traintestinference model quick start pipelinescommands cannot cover case detail following section train stylegan2 test stylegan2 test dfdnet dependency installation python 37 recommend use anaconda miniconda pytorch 13 nvidia gpu cuda please run following command basicsr root path install basicsr make sure gcc version gcc 5 pip install r requirementstxt python setuppy develop note basicsr tested ubuntu may suitable window may try window wsl cuda support available insider build fast ring todo list please see project board dataset preparation please refer datasetpreparationmd detail description currently supported datasets torchutilsdatadataset class datasetsmd train test training testing command please see traintestmd basic usage optionsconfigs please refer configmd logging please refer loggingmd model zoo baseline description currently supported model modelsmd pretrained model log example available modelzoomd also provide training curve wandb codebase design convention please see designconventionmd design convention basicsr codebase figure show overall framework description component datasetsmd modelsmd configmd loggingmd license acknowledgement project released apache 20 license detail license acknowledgement license contact question please email xintaowangoutlookcom\n",
      "  (0, 15552)\t0.049606457803758844\n",
      "  (0, 15551)\t0.049606457803758844\n",
      "  (0, 15550)\t0.049606457803758844\n",
      "  (0, 15549)\t0.049606457803758844\n",
      "  (0, 15538)\t0.049606457803758844\n",
      "  (0, 15537)\t0.049606457803758844\n",
      "  (0, 15533)\t0.049606457803758844\n",
      "  (0, 15532)\t0.04368700291729339\n",
      "  (0, 15268)\t0.049606457803758844\n",
      "  (0, 15267)\t0.049606457803758844\n",
      "  (0, 15266)\t0.049606457803758844\n",
      "  (0, 15265)\t0.049606457803758844\n",
      "  (0, 15264)\t0.049606457803758844\n",
      "  (0, 15241)\t0.049606457803758844\n",
      "  (0, 15239)\t0.04368700291729339\n",
      "  (0, 15091)\t0.04368700291729339\n",
      "  (0, 15088)\t0.049606457803758844\n",
      "  (0, 15068)\t0.03356762795023516\n",
      "  (0, 14898)\t0.03948708283670061\n",
      "  (0, 14862)\t0.023448252983176925\n",
      "  (0, 14861)\t0.049606457803758844\n",
      "  (0, 14860)\t0.049606457803758844\n",
      "  (0, 14859)\t0.049606457803758844\n",
      "  (0, 14858)\t0.049606457803758844\n",
      "  (0, 14857)\t0.049606457803758844\n",
      "  :\t:\n",
      "  (0, 743)\t0.049606457803758844\n",
      "  (0, 672)\t0.049606457803758844\n",
      "  (0, 671)\t0.049606457803758844\n",
      "  (0, 665)\t0.049606457803758844\n",
      "  (0, 664)\t0.049606457803758844\n",
      "  (0, 547)\t0.049606457803758844\n",
      "  (0, 527)\t0.049606457803758844\n",
      "  (0, 522)\t0.027648173063769706\n",
      "  (0, 480)\t0.049606457803758844\n",
      "  (0, 479)\t0.049606457803758844\n",
      "  (0, 478)\t0.049606457803758844\n",
      "  (0, 228)\t0.049606457803758844\n",
      "  (0, 227)\t0.049606457803758844\n",
      "  (0, 200)\t0.049606457803758844\n",
      "  (0, 199)\t0.04368700291729339\n",
      "  (0, 166)\t0.049606457803758844\n",
      "  (0, 165)\t0.049606457803758844\n",
      "  (0, 164)\t0.049606457803758844\n",
      "  (0, 163)\t0.03948708283670061\n",
      "  (0, 118)\t0.049606457803758844\n",
      "  (0, 117)\t0.04368700291729339\n",
      "  (0, 109)\t0.049606457803758844\n",
      "  (0, 108)\t0.04368700291729339\n",
      "  (0, 83)\t0.049606457803758844\n",
      "  (0, 81)\t0.03948708283670061\n",
      "rncasts companion repo react native course udemy\n",
      "  (0, 13860)\t0.2808419580282594\n",
      "  (0, 11615)\t0.31889518186515564\n",
      "  (0, 11614)\t0.31889518186515564\n",
      "  (0, 11216)\t0.31889518186515564\n",
      "  (0, 11197)\t0.1297949260920269\n",
      "  (0, 10878)\t0.31889518186515564\n",
      "  (0, 10876)\t0.2538427660436572\n",
      "  (0, 8951)\t0.31889518186515564\n",
      "  (0, 8948)\t0.23290056575042165\n",
      "  (0, 3215)\t0.31889518186515564\n",
      "  (0, 3208)\t0.2157895422067609\n",
      "  (0, 2629)\t0.2538427660436572\n",
      "  (0, 2628)\t0.2538427660436572\n"
     ]
    }
   ],
   "source": [
    "### TEST ###\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_t = TfidfVectorizer(stop_words='english', #min_df=20, \n",
    "                             ngram_range=(1,2), \n",
    "                             binary=True)\n",
    "\n",
    "tfidf_sparse_matrix_t = tfidf_t.fit_transform(test.text_filtered)\n",
    "#tfidf_sparse_matrix\n",
    "\n",
    "pd.DataFrame(tfidf_sparse_matrix_t.todense(), columns=tfidf_t.get_feature_names())\n",
    "\n",
    "# Get vocabularies.\n",
    "tfidf_t.vocabulary_\n",
    "\n",
    "# Transform to document-term matrix\n",
    "vector_spaces_t = tfidf_t.transform(test.text_filtered)\n",
    "vector_spaces_t.toarray()\n",
    "\n",
    "# Show sentences and vector space representation.\n",
    "# \n",
    "# (A, B) C\n",
    "# A : Document Index\n",
    "# B : Specific word-vector index\n",
    "# C : TF-IDF score\n",
    "for i, v in zip(test.text_filtered, vector_spaces_t):\n",
    "    print(i)\n",
    "    print(v)\n",
    "    \n",
    "X_tfidf_t = tfidf_sparse_matrix_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<63x40 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1046 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#df = pd.read_csv('./data/spam_clean.csv')\n",
    "#df.head()\n",
    "\n",
    "\n",
    "# create our y dataset\n",
    "y = train['language']\n",
    "\n",
    "X_bow\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lm = LogisticRegression().fit(X_bow, y)\n",
    "\n",
    "train['predicted'] = lm.predict(X_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31,  3],\n",
       "       [ 5, 24]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_matrix(train.language, train.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>javascript</th>\n",
       "      <th>python</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>javascript</th>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted   javascript  python\n",
       "language                      \n",
       "javascript          31       3\n",
       "python               5      24"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train.language, train.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  javascript       0.86      0.91      0.89        34\n",
      "      python       0.89      0.83      0.86        29\n",
      "\n",
      "    accuracy                           0.87        63\n",
      "   macro avg       0.88      0.87      0.87        63\n",
      "weighted avg       0.87      0.87      0.87        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train.language, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_tfidf = LogisticRegression().fit(X_tfidf, y)\n",
    "train['pred_tfidf'] = lm_tfidf.predict(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred_tfidf</th>\n",
       "      <th>javascript</th>\n",
       "      <th>python</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>javascript</th>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred_tfidf  javascript  python\n",
       "language                      \n",
       "javascript          28       6\n",
       "python               7      22"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train.language, train.pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  javascript       0.80      0.82      0.81        34\n",
      "      python       0.79      0.76      0.77        29\n",
      "\n",
      "    accuracy                           0.79        63\n",
      "   macro avg       0.79      0.79      0.79        63\n",
      "weighted avg       0.79      0.79      0.79        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train.language, train.pred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21x9546 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11180 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create our y dataset\n",
    "y = validate['language']\n",
    "\n",
    "X_bow_v\n",
    "X_tfidf_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression().fit(X_bow_v, y_v)\n",
    "\n",
    "validate['predicted'] = lm.predict(X_bow_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0],\n",
       "       [ 0,  9]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_matrix(validate.language, validate.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_tfidf_v = LogisticRegression().fit(X_tfidf_v, y)\n",
    "validate['pred_tfidf'] = lm_tfidf_v.predict(X_tfidf_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>javascript</th>\n",
       "      <th>python</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>javascript</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted    javascript   python \n",
       "language                         \n",
       "javascript            12        0\n",
       "python                 0        9"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(validate.language, validate.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " javascript        1.00      1.00      1.00        12\n",
      "     python        1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validate.language, validate.pred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0],\n",
       "       [ 0,  9]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create our y dataset\n",
    "y = test['language']\n",
    "\n",
    "X_bow_t\n",
    "X_tfidf_t\n",
    "\n",
    "lm = LogisticRegression().fit(X_bow_t, y)\n",
    "\n",
    "test['predicted'] = lm.predict(X_bow_t)\n",
    "\n",
    "confusion_matrix(test.language, test.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>javascript</th>\n",
       "      <th>python</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>javascript</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted    javascript   python \n",
       "language                         \n",
       "javascript            12        0\n",
       "python                 0        9"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_tfidf_t = LogisticRegression().fit(X_tfidf_t, y)\n",
    "test['pred_tfidf'] = lm_tfidf_t.predict(X_tfidf_t)\n",
    "\n",
    "pd.crosstab(test.language, test.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " javascript        1.00      1.00      1.00        12\n",
      "     python        1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test.language, test.pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
